{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30674,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport sys\nimport pickle\nfrom skimage import io\nimport matplotlib.pyplot as plt\nimport numpy \nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.optim.lr_scheduler import _LRScheduler\nfrom torch.autograd import Variable\nimport torchvision\nimport torchvision.transforms as transforms\nimport argparse\nimport glob\nimport cv2\nimport torch.optim as optim\nimport matplotlib\nmatplotlib.use('Agg')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-03-28T23:46:32.648235Z","iopub.execute_input":"2024-03-28T23:46:32.649266Z","iopub.status.idle":"2024-03-28T23:46:32.656460Z","shell.execute_reply.started":"2024-03-28T23:46:32.649227Z","shell.execute_reply":"2024-03-28T23:46:32.655389Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"## Loading Data (CIFAR10)","metadata":{}},{"cell_type":"code","source":"class CIFAR10Train(Dataset):\n    \"\"\"CIFAR10 test dataset, derived from\n    torch.utils.data.DataSet\n    \"\"\"\n\n    def __init__(self, path, transform=None):\n        #if transform is given, we transoform data using\n        with open(os.path.join(path, 'train'), 'rb') as CIFAR10:\n            self.data = pickle.load(CIFAR10, encoding='bytes')\n        self.transform = transform\n        \n    def __len__(self):\n        return len(self.data['fine_labels'.encode()])\n\n    def __getitem__(self, index):\n        label = self.data['fine_labels'.encode()][index]\n        r = self.data['data'.encode()][index, :1024].reshape(32, 32)\n        g = self.data['data'.encode()][index, 1024:2048].reshape(32, 32)\n        b = self.data['data'.encode()][index, 2048:].reshape(32, 32)\n        image = numpy.dstack((r, g, b))\n\n        if self.transform:\n            image = self.transform(image)\n        return label, image\n\nclass CIFAR10Test(Dataset):\n    \"\"\"CIFAR10 test dataset, derived from\n    torch.utils.data.DataSet\n    \"\"\"\n\n    def __init__(self, path, transform=None):\n        with open(os.path.join(path, 'test'), 'rb') as CIFAR10:\n            self.data = pickle.load(CIFAR10, encoding='bytes')\n        self.transform = transform \n\n    def __len__(self):\n        return len(self.data['data'.encode()])\n    \n    def __getitem__(self, index):\n        label = self.data['fine_labels'.encode()][index]\n        r = self.data['data'.encode()][index, :1024].reshape(32, 32)\n        g = self.data['data'.encode()][index, 1024:2048].reshape(32, 32)\n        b = self.data['data'.encode()][index, 2048:].reshape(32, 32)\n        image = numpy.dstack((r, g, b))\n\n        if self.transform:\n            image = self.transform(image)\n        return label, image","metadata":{"execution":{"iopub.status.busy":"2024-03-28T23:46:32.716500Z","iopub.execute_input":"2024-03-28T23:46:32.716809Z","iopub.status.idle":"2024-03-28T23:46:32.730966Z","shell.execute_reply.started":"2024-03-28T23:46:32.716783Z","shell.execute_reply":"2024-03-28T23:46:32.729873Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"## Models (ResNet,MobileNet)","metadata":{}},{"cell_type":"code","source":"class BasicBlock(nn.Module):\n    expansion = 1\n\n    def __init__(self, in_planes, planes, stride=1):\n        super(BasicBlock, self).__init__()\n        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(planes)\n        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(planes)\n        self.shortcut = nn.Sequential()\n        if stride != 1 or in_planes != self.expansion*planes:\n            self.shortcut = nn.Sequential(\n                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False),\n                nn.BatchNorm2d(self.expansion*planes)\n            )\n\n    def forward(self, x):\n        residual = x\n        out = F.relu(self.bn1(self.conv1(x)))\n        out = self.bn2(self.conv2(out))\n        out += self.shortcut(residual)\n        out = F.relu(out)\n        return out\n\n\nclass Bottleneck(nn.Module):\n    expansion = 4\n\n    def __init__(self, in_planes, planes, stride=1):\n        super(Bottleneck, self).__init__()\n        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(planes)\n        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(planes)\n        self.conv3 = nn.Conv2d(planes, self.expansion*planes, kernel_size=1, bias=False)\n        self.bn3 = nn.BatchNorm2d(self.expansion*planes)\n        self.shortcut = nn.Sequential()\n        if stride != 1 or in_planes != self.expansion*planes:\n            self.shortcut = nn.Sequential(\n                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False),\n                nn.BatchNorm2d(self.expansion*planes)\n            )\n        \n    def forward(self, x):\n        residual = x\n        out = F.relu(self.bn1(self.conv1(x)))\n        out = F.relu(self.bn2(self.conv2(out)))\n        out = self.bn3(self.conv3(out))\n        out += self.shortcut(residual)\n        out = F.relu(out)\n        return out\n\n\nclass ResNet(nn.Module):\n    def __init__(self, block, num_blocks, num_classes=10):\n        super(ResNet, self).__init__()\n        self.in_planes = 64\n\n        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(64)\n        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n        self.linear = nn.Linear(512*block.expansion, num_classes)\n\n    def _make_layer(self, block, planes, num_blocks, stride):\n        strides = [stride] + [1]*(num_blocks-1)\n        layers = []\n        for stride in strides:\n            layers.append(block(self.in_planes, planes, stride))\n            self.in_planes = planes * block.expansion\n        return nn.Sequential(*layers)\n\n    def forward(self, x):\n        out = F.relu(self.bn1(self.conv1(x)))\n        out = self.layer1(out)\n        out = self.layer2(out)\n        out = self.layer3(out)\n        out = self.layer4(out)\n        out = F.avg_pool2d(out, 4)\n        out = out.view(out.size(0), -1)\n        out = self.linear(out)\n        return out\n\n\ndef ResNet18():\n    return ResNet(BasicBlock, [2,2,2,2])\n\nclass MobileNet(nn.Module):\n    def __init__(self, classes = 10):\n        super(MobileNet, self).__init__()\n\n        def conv_bn(inp, oup, stride):\n            return nn.Sequential(\n                nn.Conv2d(inp, oup, 3, stride, 1, bias=False),\n                nn.BatchNorm2d(oup),\n                nn.ReLU(inplace=True)\n            )\n\n        def conv_dw(inp, oup, stride):\n            return nn.Sequential(\n                nn.Conv2d(inp, inp, 3, stride, 1, groups=inp, bias=False),\n                nn.BatchNorm2d(inp),\n                nn.ReLU(inplace=True),\n                nn.Conv2d(inp, oup, 1, 1, 0, bias=False),\n                nn.BatchNorm2d(oup),\n                nn.ReLU(inplace=True),\n            )\n\n        self.model = nn.Sequential(\n            conv_bn(  3,  32, 1), \n            conv_dw( 32,  64, 1),\n            conv_dw( 64, 128, 1),\n            conv_dw(128, 128, 1),\n            conv_dw(128, 256, 2),\n            conv_dw(256, 256, 1),\n            conv_dw(256, 512, 2),\n            conv_dw(512, 512, 1),\n            conv_dw(512, 512, 1),\n            conv_dw(512, 512, 1),\n            conv_dw(512, 512, 1),\n            conv_dw(512, 512, 1),\n            conv_dw(512, 1024, 2),\n            conv_dw(1024, 1024, 1),\n            nn.AvgPool2d(4),\n        )\n        self.fc = nn.Linear(1024, classes)\n\n    def forward(self, x):\n        x = self.model(x)\n        x = x.view(-1, 1024)\n        x = self.fc(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2024-03-28T23:46:32.733848Z","iopub.execute_input":"2024-03-28T23:46:32.734125Z","iopub.status.idle":"2024-03-28T23:46:32.766085Z","shell.execute_reply.started":"2024-03-28T23:46:32.734101Z","shell.execute_reply":"2024-03-28T23:46:32.765248Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"## Utils","metadata":{}},{"cell_type":"code","source":"def get_network():\n    #net=ResNet18().cuda()\n    net=MobileNet().cuda()\n    \"\"\" return given network\n    \"\"\"\n    return net\n\n\ndef get_training_dataloader(mean, std, batch_size=16, num_workers=2, shuffle=True):\n    \"\"\" return training dataloader\n    Args:\n        mean: mean of CIFAR10 training dataset\n        std: std of CIFAR10 training dataset\n        path: path to CIFAR10 training python dataset\n        batch_size: dataloader batchsize\n        num_workers: dataloader num_works\n        shuffle: whether to shuffle \n    Returns: train_data_loader:torch dataloader object\n    \"\"\"\n\n    transform_train = transforms.Compose([\n        #transforms.ToPILImage(),\n        transforms.RandomCrop(32, padding=4),\n        transforms.RandomHorizontalFlip(),\n        transforms.RandomRotation(15),\n        transforms.ToTensor(),\n        transforms.Normalize(mean, std)\n    ])\n    #CIFAR10_training = CIFAR10Train(path, transform=transform_train)\n    CIFAR10_training = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n    CIFAR10_training_loader = DataLoader(\n        CIFAR10_training, shuffle=shuffle, num_workers=num_workers, batch_size=batch_size)\n\n    return CIFAR10_training_loader\n\ndef get_test_dataloader(mean, std, batch_size=16, num_workers=2, shuffle=True):\n    \"\"\" return training dataloader\n    Args:\n        mean: mean of CIFAR10 test dataset\n        std: std of CIFAR10 test dataset\n        path: path to CIFAR10 test python dataset\n        batch_size: dataloader batchsize\n        num_workers: dataloader num_works\n        shuffle: whether to shuffle \n    Returns: CIFAR10_test_loader:torch dataloader object\n    \"\"\"\n\n    transform_test = transforms.Compose([\n        transforms.ToTensor(),\n        transforms.Normalize(mean, std)\n    ])\n    #CIFAR10_test = CIFAR10Test(path, transform=transform_test)\n    CIFAR10_test = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n    CIFAR10_test_loader = DataLoader(\n        CIFAR10_test, shuffle=shuffle, num_workers=num_workers, batch_size=batch_size)\n\n    return CIFAR10_test_loader\n\ndef compute_mean_std(CIFAR10_dataset):\n    \"\"\"compute the mean and std of CIFAR10 dataset\n    Args:\n        CIFAR10_training_dataset or CIFAR10_test_dataset\n        witch derived from class torch.utils.data\n    \n    Returns:\n        a tuple contains mean, std value of entire dataset\n    \"\"\"\n\n    data_r = numpy.dstack([CIFAR10_dataset[i][1][:, :, 0] for i in range(len(CIFAR10_dataset))])\n    data_g = numpy.dstack([CIFAR10_dataset[i][1][:, :, 1] for i in range(len(CIFAR10_dataset))])\n    data_b = numpy.dstack([CIFAR10_dataset[i][1][:, :, 2] for i in range(len(CIFAR10_dataset))])\n    mean = numpy.mean(data_r), numpy.mean(data_g), numpy.mean(data_b)\n    std = numpy.std(data_r), numpy.std(data_g), numpy.std(data_b)\n\n    return mean, std\n\nclass WarmUpLR(_LRScheduler):\n    \"\"\"warmup_training learning rate scheduler\n    Args:\n        optimizer: optimzier(e.g. SGD)\n        total_iters: totoal_iters of warmup phase\n    \"\"\"\n    def __init__(self, optimizer, total_iters, last_epoch=-1):\n        \n        self.total_iters = total_iters\n        super().__init__(optimizer, last_epoch)\n\n    def get_lr(self):\n        \"\"\"we will use the first m batches, and set the learning\n        rate to base_lr * m / total_iters\n        \"\"\"\n        return [base_lr * self.last_epoch / (self.total_iters + 1e-8) for base_lr in self.base_lrs]","metadata":{"execution":{"iopub.status.busy":"2024-03-28T23:46:32.797337Z","iopub.execute_input":"2024-03-28T23:46:32.797621Z","iopub.status.idle":"2024-03-28T23:46:32.811958Z","shell.execute_reply.started":"2024-03-28T23:46:32.797598Z","shell.execute_reply":"2024-03-28T23:46:32.810999Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"from datetime import datetime\nCIFAR10_TRAIN_MEAN = (0.49139968, 0.48215827 ,0.44653124)\nCIFAR10_TRAIN_STD = (0.24703233, 0.24348505, 0.26158768)\n\n#CIFAR100_TEST_MEAN = (0.5088964127604166, 0.48739301317401956, 0.44194221124387256)\n#CIFAR100_TEST_STD = (0.2682515741720801, 0.2573637364478126, 0.2770957707973042)\n\n#directory to save weights file\nCHECKPOINT_PATH = 'checkpoint'\n\n#total training epoches\nEPOCH = 25\nMILESTONES = [6, 12, 16]\n\n#initial learning rate\n#INIT_LR = 0.1\n\n#time of we run the script\nTIME_NOW = datetime.now().isoformat()\n\n#tensorboard log dir\nLOG_DIR = 'runs'\n\n#save weights file per SAVE_EPOCH epoch\nSAVE_EPOCH = 10","metadata":{"execution":{"iopub.status.busy":"2024-03-28T23:46:32.813604Z","iopub.execute_input":"2024-03-28T23:46:32.814024Z","iopub.status.idle":"2024-03-28T23:46:32.829617Z","shell.execute_reply.started":"2024-03-28T23:46:32.813995Z","shell.execute_reply":"2024-03-28T23:46:32.828872Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"## Training the model","metadata":{}},{"cell_type":"code","source":"def train(epoch):\n\n    net.train()\n    for batch_index, (images, labels) in enumerate(CIFAR10_training_loader):\n        if epoch <= 1:\n            warmup_scheduler.step()\n\n        images = Variable(images)\n        labels = Variable(labels)\n\n        labels = labels.cuda()\n        images = images.cuda()\n\n        optimizer.zero_grad()\n        outputs = net(images)\n        loss = loss_function(outputs, labels)\n        loss.backward()\n        optimizer.step()\n\n        print('Training Epoch: {epoch} [{trained_samples}/{total_samples}]\\tLoss: {:0.4f}\\tLR: {:0.6f}'.format(\n            loss.item(),\n            optimizer.param_groups[0]['lr'],\n            epoch=epoch,\n            trained_samples=batch_index * 128 + len(images),\n            total_samples=len(CIFAR10_training_loader.dataset)\n        ))\n\n\n    for name, param in net.named_parameters():\n        layer, attr = os.path.splitext(name)\n        attr = attr[1:]\n\ndef eval_training(epoch):\n    net.eval()\n\n    test_loss = 0.0 # cost function error\n    correct = 0.0\n\n    for (images, labels) in CIFAR10_test_loader:\n        images = Variable(images)\n        labels = Variable(labels)\n\n        images = images.cuda()\n        labels = labels.cuda()\n\n        outputs = net(images)\n        loss = loss_function(outputs, labels)\n        test_loss += loss.item()\n        _, preds = outputs.max(1)\n        correct += preds.eq(labels).sum()\n\n    print('Test set: Average loss: {:.4f}, Accuracy: {:.4f}'.format(\n        test_loss / len(CIFAR10_test_loader.dataset),\n        correct.float() / len(CIFAR10_test_loader.dataset)\n    ))\n    print()\n\n\n    return correct.float() / len(CIFAR10_test_loader.dataset)\n\nif __name__ == '__main__':\n    \n#     parser = argparse.ArgumentParser()\n#     parser.add_argument('-net', type=str, required=True, help='net type')\n#     parser.add_argument('-gpu', type=bool, default=True, help='use gpu or not')\n#     parser.add_argument('-w', type=int, default=2, help='number of workers for dataloader')\n#     parser.add_argument('-b', type=int, default=128, help='batch size for dataloader')\n#     parser.add_argument('-s', type=bool, default=True, help='whether shuffle the dataset')\n#     parser.add_argument('-warm', type=int, default=1, help='warm up training phase')\n#     parser.add_argument('-lr', type=float, default=0.1, help='initial learning rate')\n#     args = parser.parse_args()\n\n    net= get_network()\n    \n        \n    #data preprocessing:\n    CIFAR10_training_loader = get_training_dataloader(\n        CIFAR10_TRAIN_MEAN,\n        CIFAR10_TRAIN_STD,\n        num_workers=2,\n        batch_size=128,\n        shuffle=True\n    )\n    \n    CIFAR10_test_loader = get_test_dataloader(\n        CIFAR10_TRAIN_MEAN,\n        CIFAR10_TRAIN_STD,\n        num_workers=2,\n        batch_size=128,\n        shuffle=True\n    )\n    \n    loss_function = nn.CrossEntropyLoss()\n    optimizer = optim.SGD(net.parameters(), lr=0.1, momentum=0.9, weight_decay=5e-4)\n    train_scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=MILESTONES, gamma=0.15) #learning rate decay\n    iter_per_epoch = len(CIFAR10_training_loader)\n    warmup_scheduler = WarmUpLR(optimizer, iter_per_epoch * 1)\n    checkpoint_path = os.path.join(CHECKPOINT_PATH, \"resnet18\")\n\n    #create checkpoint folder to save model\n    if not os.path.exists(checkpoint_path):\n        os.makedirs(checkpoint_path)\n    checkpoint_path = os.path.join(checkpoint_path, '{net}-{epoch}-{type}.pth')\n\n    best_acc = 0.0\n    for epoch in range(1, EPOCH):\n        if epoch > 1:\n            train_scheduler.step(epoch)\n\n        train(epoch)\n        acc = eval_training(epoch)\n\n        #start to save best performance model after learning rate decay to 0.01 \n        if epoch > MILESTONES[1] and best_acc < acc:\n            torch.save(net.state_dict(), checkpoint_path.format(net=\"resnet18\", epoch=epoch, type='best'))\n            best_acc = acc\n            continue\n\n        if not epoch % SAVE_EPOCH:\n            torch.save(net.state_dict(), checkpoint_path.format(net=\"resnet18\", epoch=epoch, type='regular'))\n    print()\n    print(\"best_acc: \", best_acc)\n    ","metadata":{"execution":{"iopub.status.busy":"2024-03-28T23:46:32.866700Z","iopub.execute_input":"2024-03-28T23:46:32.866965Z","iopub.status.idle":"2024-03-29T00:04:28.746243Z","shell.execute_reply.started":"2024-03-28T23:46:32.866943Z","shell.execute_reply":"2024-03-29T00:04:28.745008Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"Files already downloaded and verified\nFiles already downloaded and verified\nTraining Epoch: 1 [128/50000]\tLoss: 2.3368\tLR: 0.000256\nTraining Epoch: 1 [256/50000]\tLoss: 2.3338\tLR: 0.000512\nTraining Epoch: 1 [384/50000]\tLoss: 2.3558\tLR: 0.000767\nTraining Epoch: 1 [512/50000]\tLoss: 2.3124\tLR: 0.001023\nTraining Epoch: 1 [640/50000]\tLoss: 2.3510\tLR: 0.001279\nTraining Epoch: 1 [768/50000]\tLoss: 2.3451\tLR: 0.001535\nTraining Epoch: 1 [896/50000]\tLoss: 2.3393\tLR: 0.001790\nTraining Epoch: 1 [1024/50000]\tLoss: 2.3196\tLR: 0.002046\nTraining Epoch: 1 [1152/50000]\tLoss: 2.3040\tLR: 0.002302\nTraining Epoch: 1 [1280/50000]\tLoss: 2.3220\tLR: 0.002558\nTraining Epoch: 1 [1408/50000]\tLoss: 2.2916\tLR: 0.002813\nTraining Epoch: 1 [1536/50000]\tLoss: 2.3081\tLR: 0.003069\nTraining Epoch: 1 [1664/50000]\tLoss: 2.3249\tLR: 0.003325\nTraining Epoch: 1 [1792/50000]\tLoss: 2.3121\tLR: 0.003581\nTraining Epoch: 1 [1920/50000]\tLoss: 2.3320\tLR: 0.003836\nTraining Epoch: 1 [2048/50000]\tLoss: 2.2692\tLR: 0.004092\nTraining Epoch: 1 [2176/50000]\tLoss: 2.3053\tLR: 0.004348\nTraining Epoch: 1 [2304/50000]\tLoss: 2.3342\tLR: 0.004604\nTraining Epoch: 1 [2432/50000]\tLoss: 2.3359\tLR: 0.004859\nTraining Epoch: 1 [2560/50000]\tLoss: 2.2711\tLR: 0.005115\nTraining Epoch: 1 [2688/50000]\tLoss: 2.3020\tLR: 0.005371\nTraining Epoch: 1 [2816/50000]\tLoss: 2.2620\tLR: 0.005627\nTraining Epoch: 1 [2944/50000]\tLoss: 2.2638\tLR: 0.005882\nTraining Epoch: 1 [3072/50000]\tLoss: 2.2824\tLR: 0.006138\nTraining Epoch: 1 [3200/50000]\tLoss: 2.2723\tLR: 0.006394\nTraining Epoch: 1 [3328/50000]\tLoss: 2.2357\tLR: 0.006650\nTraining Epoch: 1 [3456/50000]\tLoss: 2.2348\tLR: 0.006905\nTraining Epoch: 1 [3584/50000]\tLoss: 2.3816\tLR: 0.007161\nTraining Epoch: 1 [3712/50000]\tLoss: 2.2623\tLR: 0.007417\nTraining Epoch: 1 [3840/50000]\tLoss: 2.2781\tLR: 0.007673\nTraining Epoch: 1 [3968/50000]\tLoss: 2.2967\tLR: 0.007928\nTraining Epoch: 1 [4096/50000]\tLoss: 2.2320\tLR: 0.008184\nTraining Epoch: 1 [4224/50000]\tLoss: 2.2296\tLR: 0.008440\nTraining Epoch: 1 [4352/50000]\tLoss: 2.2319\tLR: 0.008696\nTraining Epoch: 1 [4480/50000]\tLoss: 2.3090\tLR: 0.008951\nTraining Epoch: 1 [4608/50000]\tLoss: 2.3592\tLR: 0.009207\nTraining Epoch: 1 [4736/50000]\tLoss: 2.2242\tLR: 0.009463\nTraining Epoch: 1 [4864/50000]\tLoss: 2.2536\tLR: 0.009719\nTraining Epoch: 1 [4992/50000]\tLoss: 2.2856\tLR: 0.009974\nTraining Epoch: 1 [5120/50000]\tLoss: 2.3128\tLR: 0.010230\nTraining Epoch: 1 [5248/50000]\tLoss: 2.2083\tLR: 0.010486\nTraining Epoch: 1 [5376/50000]\tLoss: 2.1901\tLR: 0.010742\nTraining Epoch: 1 [5504/50000]\tLoss: 2.2180\tLR: 0.010997\nTraining Epoch: 1 [5632/50000]\tLoss: 2.2542\tLR: 0.011253\nTraining Epoch: 1 [5760/50000]\tLoss: 2.1902\tLR: 0.011509\nTraining Epoch: 1 [5888/50000]\tLoss: 2.1561\tLR: 0.011765\nTraining Epoch: 1 [6016/50000]\tLoss: 2.2364\tLR: 0.012020\nTraining Epoch: 1 [6144/50000]\tLoss: 2.1296\tLR: 0.012276\nTraining Epoch: 1 [6272/50000]\tLoss: 2.1412\tLR: 0.012532\nTraining Epoch: 1 [6400/50000]\tLoss: 2.2183\tLR: 0.012788\nTraining Epoch: 1 [6528/50000]\tLoss: 2.2332\tLR: 0.013043\nTraining Epoch: 1 [6656/50000]\tLoss: 2.1632\tLR: 0.013299\nTraining Epoch: 1 [6784/50000]\tLoss: 2.0980\tLR: 0.013555\nTraining Epoch: 1 [6912/50000]\tLoss: 2.1540\tLR: 0.013811\nTraining Epoch: 1 [7040/50000]\tLoss: 2.1895\tLR: 0.014066\nTraining Epoch: 1 [7168/50000]\tLoss: 2.0608\tLR: 0.014322\nTraining Epoch: 1 [7296/50000]\tLoss: 2.0984\tLR: 0.014578\nTraining Epoch: 1 [7424/50000]\tLoss: 2.1601\tLR: 0.014834\nTraining Epoch: 1 [7552/50000]\tLoss: 2.1087\tLR: 0.015090\nTraining Epoch: 1 [7680/50000]\tLoss: 2.1988\tLR: 0.015345\nTraining Epoch: 1 [7808/50000]\tLoss: 2.1176\tLR: 0.015601\nTraining Epoch: 1 [7936/50000]\tLoss: 2.1370\tLR: 0.015857\nTraining Epoch: 1 [8064/50000]\tLoss: 2.0152\tLR: 0.016113\nTraining Epoch: 1 [8192/50000]\tLoss: 2.0641\tLR: 0.016368\nTraining Epoch: 1 [8320/50000]\tLoss: 2.0668\tLR: 0.016624\nTraining Epoch: 1 [8448/50000]\tLoss: 2.0517\tLR: 0.016880\nTraining Epoch: 1 [8576/50000]\tLoss: 2.1291\tLR: 0.017136\nTraining Epoch: 1 [8704/50000]\tLoss: 2.1757\tLR: 0.017391\nTraining Epoch: 1 [8832/50000]\tLoss: 2.1023\tLR: 0.017647\nTraining Epoch: 1 [8960/50000]\tLoss: 2.2108\tLR: 0.017903\nTraining Epoch: 1 [9088/50000]\tLoss: 2.0924\tLR: 0.018159\nTraining Epoch: 1 [9216/50000]\tLoss: 2.1674\tLR: 0.018414\nTraining Epoch: 1 [9344/50000]\tLoss: 2.1430\tLR: 0.018670\nTraining Epoch: 1 [9472/50000]\tLoss: 1.9865\tLR: 0.018926\nTraining Epoch: 1 [9600/50000]\tLoss: 1.9677\tLR: 0.019182\nTraining Epoch: 1 [9728/50000]\tLoss: 1.9923\tLR: 0.019437\nTraining Epoch: 1 [9856/50000]\tLoss: 2.0896\tLR: 0.019693\nTraining Epoch: 1 [9984/50000]\tLoss: 2.0360\tLR: 0.019949\nTraining Epoch: 1 [10112/50000]\tLoss: 1.9649\tLR: 0.020205\nTraining Epoch: 1 [10240/50000]\tLoss: 2.0343\tLR: 0.020460\nTraining Epoch: 1 [10368/50000]\tLoss: 1.9955\tLR: 0.020716\nTraining Epoch: 1 [10496/50000]\tLoss: 2.0003\tLR: 0.020972\nTraining Epoch: 1 [10624/50000]\tLoss: 2.0051\tLR: 0.021228\nTraining Epoch: 1 [10752/50000]\tLoss: 1.9298\tLR: 0.021483\nTraining Epoch: 1 [10880/50000]\tLoss: 2.0529\tLR: 0.021739\nTraining Epoch: 1 [11008/50000]\tLoss: 2.0055\tLR: 0.021995\nTraining Epoch: 1 [11136/50000]\tLoss: 2.0002\tLR: 0.022251\nTraining Epoch: 1 [11264/50000]\tLoss: 2.0258\tLR: 0.022506\nTraining Epoch: 1 [11392/50000]\tLoss: 1.9614\tLR: 0.022762\nTraining Epoch: 1 [11520/50000]\tLoss: 1.9952\tLR: 0.023018\nTraining Epoch: 1 [11648/50000]\tLoss: 2.0268\tLR: 0.023274\nTraining Epoch: 1 [11776/50000]\tLoss: 1.9487\tLR: 0.023529\nTraining Epoch: 1 [11904/50000]\tLoss: 2.0682\tLR: 0.023785\nTraining Epoch: 1 [12032/50000]\tLoss: 2.0156\tLR: 0.024041\nTraining Epoch: 1 [12160/50000]\tLoss: 1.9353\tLR: 0.024297\nTraining Epoch: 1 [12288/50000]\tLoss: 2.0066\tLR: 0.024552\nTraining Epoch: 1 [12416/50000]\tLoss: 2.0342\tLR: 0.024808\nTraining Epoch: 1 [12544/50000]\tLoss: 2.1050\tLR: 0.025064\nTraining Epoch: 1 [12672/50000]\tLoss: 2.0152\tLR: 0.025320\nTraining Epoch: 1 [12800/50000]\tLoss: 1.8953\tLR: 0.025575\nTraining Epoch: 1 [12928/50000]\tLoss: 1.9471\tLR: 0.025831\nTraining Epoch: 1 [13056/50000]\tLoss: 2.0696\tLR: 0.026087\nTraining Epoch: 1 [13184/50000]\tLoss: 1.9963\tLR: 0.026343\nTraining Epoch: 1 [13312/50000]\tLoss: 1.9163\tLR: 0.026598\nTraining Epoch: 1 [13440/50000]\tLoss: 2.1108\tLR: 0.026854\nTraining Epoch: 1 [13568/50000]\tLoss: 1.9803\tLR: 0.027110\nTraining Epoch: 1 [13696/50000]\tLoss: 2.0483\tLR: 0.027366\nTraining Epoch: 1 [13824/50000]\tLoss: 1.9309\tLR: 0.027621\nTraining Epoch: 1 [13952/50000]\tLoss: 1.9030\tLR: 0.027877\nTraining Epoch: 1 [14080/50000]\tLoss: 2.0599\tLR: 0.028133\nTraining Epoch: 1 [14208/50000]\tLoss: 1.9352\tLR: 0.028389\nTraining Epoch: 1 [14336/50000]\tLoss: 1.8348\tLR: 0.028645\nTraining Epoch: 1 [14464/50000]\tLoss: 1.8228\tLR: 0.028900\nTraining Epoch: 1 [14592/50000]\tLoss: 1.7492\tLR: 0.029156\nTraining Epoch: 1 [14720/50000]\tLoss: 1.9990\tLR: 0.029412\nTraining Epoch: 1 [14848/50000]\tLoss: 1.8985\tLR: 0.029668\nTraining Epoch: 1 [14976/50000]\tLoss: 1.8567\tLR: 0.029923\nTraining Epoch: 1 [15104/50000]\tLoss: 2.2094\tLR: 0.030179\nTraining Epoch: 1 [15232/50000]\tLoss: 1.8807\tLR: 0.030435\nTraining Epoch: 1 [15360/50000]\tLoss: 1.7904\tLR: 0.030691\nTraining Epoch: 1 [15488/50000]\tLoss: 1.7792\tLR: 0.030946\nTraining Epoch: 1 [15616/50000]\tLoss: 1.9601\tLR: 0.031202\nTraining Epoch: 1 [15744/50000]\tLoss: 1.8347\tLR: 0.031458\nTraining Epoch: 1 [15872/50000]\tLoss: 2.1608\tLR: 0.031714\nTraining Epoch: 1 [16000/50000]\tLoss: 1.9062\tLR: 0.031969\nTraining Epoch: 1 [16128/50000]\tLoss: 1.8198\tLR: 0.032225\nTraining Epoch: 1 [16256/50000]\tLoss: 1.8302\tLR: 0.032481\nTraining Epoch: 1 [16384/50000]\tLoss: 1.6514\tLR: 0.032737\nTraining Epoch: 1 [16512/50000]\tLoss: 1.8677\tLR: 0.032992\nTraining Epoch: 1 [16640/50000]\tLoss: 1.9784\tLR: 0.033248\nTraining Epoch: 1 [16768/50000]\tLoss: 1.9504\tLR: 0.033504\nTraining Epoch: 1 [16896/50000]\tLoss: 1.9513\tLR: 0.033760\nTraining Epoch: 1 [17024/50000]\tLoss: 1.7670\tLR: 0.034015\nTraining Epoch: 1 [17152/50000]\tLoss: 1.8005\tLR: 0.034271\nTraining Epoch: 1 [17280/50000]\tLoss: 1.8410\tLR: 0.034527\nTraining Epoch: 1 [17408/50000]\tLoss: 1.9309\tLR: 0.034783\nTraining Epoch: 1 [17536/50000]\tLoss: 1.9758\tLR: 0.035038\nTraining Epoch: 1 [17664/50000]\tLoss: 1.8259\tLR: 0.035294\nTraining Epoch: 1 [17792/50000]\tLoss: 1.7855\tLR: 0.035550\nTraining Epoch: 1 [17920/50000]\tLoss: 1.8960\tLR: 0.035806\nTraining Epoch: 1 [18048/50000]\tLoss: 1.9520\tLR: 0.036061\nTraining Epoch: 1 [18176/50000]\tLoss: 2.0219\tLR: 0.036317\nTraining Epoch: 1 [18304/50000]\tLoss: 2.0112\tLR: 0.036573\nTraining Epoch: 1 [18432/50000]\tLoss: 1.8690\tLR: 0.036829\nTraining Epoch: 1 [18560/50000]\tLoss: 2.0428\tLR: 0.037084\nTraining Epoch: 1 [18688/50000]\tLoss: 1.9462\tLR: 0.037340\nTraining Epoch: 1 [18816/50000]\tLoss: 1.8709\tLR: 0.037596\nTraining Epoch: 1 [18944/50000]\tLoss: 1.8824\tLR: 0.037852\nTraining Epoch: 1 [19072/50000]\tLoss: 2.0133\tLR: 0.038107\nTraining Epoch: 1 [19200/50000]\tLoss: 1.9631\tLR: 0.038363\nTraining Epoch: 1 [19328/50000]\tLoss: 1.8326\tLR: 0.038619\nTraining Epoch: 1 [19456/50000]\tLoss: 1.8609\tLR: 0.038875\nTraining Epoch: 1 [19584/50000]\tLoss: 1.9224\tLR: 0.039130\nTraining Epoch: 1 [19712/50000]\tLoss: 1.8940\tLR: 0.039386\nTraining Epoch: 1 [19840/50000]\tLoss: 1.7994\tLR: 0.039642\nTraining Epoch: 1 [19968/50000]\tLoss: 1.9481\tLR: 0.039898\nTraining Epoch: 1 [20096/50000]\tLoss: 1.9371\tLR: 0.040153\nTraining Epoch: 1 [20224/50000]\tLoss: 2.0215\tLR: 0.040409\nTraining Epoch: 1 [20352/50000]\tLoss: 2.0078\tLR: 0.040665\nTraining Epoch: 1 [20480/50000]\tLoss: 2.0211\tLR: 0.040921\nTraining Epoch: 1 [20608/50000]\tLoss: 1.8855\tLR: 0.041176\nTraining Epoch: 1 [20736/50000]\tLoss: 1.9245\tLR: 0.041432\nTraining Epoch: 1 [20864/50000]\tLoss: 1.9254\tLR: 0.041688\nTraining Epoch: 1 [20992/50000]\tLoss: 1.7663\tLR: 0.041944\nTraining Epoch: 1 [21120/50000]\tLoss: 1.8155\tLR: 0.042199\nTraining Epoch: 1 [21248/50000]\tLoss: 1.9173\tLR: 0.042455\nTraining Epoch: 1 [21376/50000]\tLoss: 1.7295\tLR: 0.042711\nTraining Epoch: 1 [21504/50000]\tLoss: 1.7884\tLR: 0.042967\nTraining Epoch: 1 [21632/50000]\tLoss: 1.6155\tLR: 0.043223\nTraining Epoch: 1 [21760/50000]\tLoss: 1.8517\tLR: 0.043478\nTraining Epoch: 1 [21888/50000]\tLoss: 1.8040\tLR: 0.043734\nTraining Epoch: 1 [22016/50000]\tLoss: 1.8493\tLR: 0.043990\nTraining Epoch: 1 [22144/50000]\tLoss: 1.9245\tLR: 0.044246\nTraining Epoch: 1 [22272/50000]\tLoss: 2.0117\tLR: 0.044501\nTraining Epoch: 1 [22400/50000]\tLoss: 1.9572\tLR: 0.044757\nTraining Epoch: 1 [22528/50000]\tLoss: 1.9541\tLR: 0.045013\nTraining Epoch: 1 [22656/50000]\tLoss: 1.9146\tLR: 0.045269\nTraining Epoch: 1 [22784/50000]\tLoss: 1.9523\tLR: 0.045524\nTraining Epoch: 1 [22912/50000]\tLoss: 1.7837\tLR: 0.045780\nTraining Epoch: 1 [23040/50000]\tLoss: 1.7423\tLR: 0.046036\nTraining Epoch: 1 [23168/50000]\tLoss: 1.8901\tLR: 0.046292\nTraining Epoch: 1 [23296/50000]\tLoss: 1.7575\tLR: 0.046547\nTraining Epoch: 1 [23424/50000]\tLoss: 1.7454\tLR: 0.046803\nTraining Epoch: 1 [23552/50000]\tLoss: 1.8543\tLR: 0.047059\nTraining Epoch: 1 [23680/50000]\tLoss: 1.8691\tLR: 0.047315\nTraining Epoch: 1 [23808/50000]\tLoss: 1.8876\tLR: 0.047570\nTraining Epoch: 1 [23936/50000]\tLoss: 2.0004\tLR: 0.047826\nTraining Epoch: 1 [24064/50000]\tLoss: 1.7175\tLR: 0.048082\nTraining Epoch: 1 [24192/50000]\tLoss: 1.6682\tLR: 0.048338\nTraining Epoch: 1 [24320/50000]\tLoss: 1.8763\tLR: 0.048593\nTraining Epoch: 1 [24448/50000]\tLoss: 1.8120\tLR: 0.048849\nTraining Epoch: 1 [24576/50000]\tLoss: 1.8017\tLR: 0.049105\nTraining Epoch: 1 [24704/50000]\tLoss: 1.8004\tLR: 0.049361\nTraining Epoch: 1 [24832/50000]\tLoss: 1.9333\tLR: 0.049616\nTraining Epoch: 1 [24960/50000]\tLoss: 1.8094\tLR: 0.049872\nTraining Epoch: 1 [25088/50000]\tLoss: 1.7873\tLR: 0.050128\nTraining Epoch: 1 [25216/50000]\tLoss: 1.8534\tLR: 0.050384\nTraining Epoch: 1 [25344/50000]\tLoss: 1.7515\tLR: 0.050639\nTraining Epoch: 1 [25472/50000]\tLoss: 2.0632\tLR: 0.050895\nTraining Epoch: 1 [25600/50000]\tLoss: 1.6288\tLR: 0.051151\nTraining Epoch: 1 [25728/50000]\tLoss: 1.7729\tLR: 0.051407\nTraining Epoch: 1 [25856/50000]\tLoss: 1.9622\tLR: 0.051662\nTraining Epoch: 1 [25984/50000]\tLoss: 1.9057\tLR: 0.051918\nTraining Epoch: 1 [26112/50000]\tLoss: 1.8196\tLR: 0.052174\nTraining Epoch: 1 [26240/50000]\tLoss: 1.8160\tLR: 0.052430\nTraining Epoch: 1 [26368/50000]\tLoss: 2.2050\tLR: 0.052685\nTraining Epoch: 1 [26496/50000]\tLoss: 1.8968\tLR: 0.052941\nTraining Epoch: 1 [26624/50000]\tLoss: 1.6099\tLR: 0.053197\nTraining Epoch: 1 [26752/50000]\tLoss: 1.8317\tLR: 0.053453\nTraining Epoch: 1 [26880/50000]\tLoss: 1.7378\tLR: 0.053708\nTraining Epoch: 1 [27008/50000]\tLoss: 1.8927\tLR: 0.053964\nTraining Epoch: 1 [27136/50000]\tLoss: 1.8591\tLR: 0.054220\nTraining Epoch: 1 [27264/50000]\tLoss: 1.7252\tLR: 0.054476\nTraining Epoch: 1 [27392/50000]\tLoss: 1.7528\tLR: 0.054731\nTraining Epoch: 1 [27520/50000]\tLoss: 1.6538\tLR: 0.054987\nTraining Epoch: 1 [27648/50000]\tLoss: 1.7880\tLR: 0.055243\nTraining Epoch: 1 [27776/50000]\tLoss: 1.6768\tLR: 0.055499\nTraining Epoch: 1 [27904/50000]\tLoss: 1.5384\tLR: 0.055754\nTraining Epoch: 1 [28032/50000]\tLoss: 1.6786\tLR: 0.056010\nTraining Epoch: 1 [28160/50000]\tLoss: 1.9673\tLR: 0.056266\nTraining Epoch: 1 [28288/50000]\tLoss: 1.8274\tLR: 0.056522\nTraining Epoch: 1 [28416/50000]\tLoss: 1.8468\tLR: 0.056777\nTraining Epoch: 1 [28544/50000]\tLoss: 1.8325\tLR: 0.057033\nTraining Epoch: 1 [28672/50000]\tLoss: 1.6735\tLR: 0.057289\nTraining Epoch: 1 [28800/50000]\tLoss: 1.7506\tLR: 0.057545\nTraining Epoch: 1 [28928/50000]\tLoss: 1.7780\tLR: 0.057801\nTraining Epoch: 1 [29056/50000]\tLoss: 1.7892\tLR: 0.058056\nTraining Epoch: 1 [29184/50000]\tLoss: 1.6408\tLR: 0.058312\nTraining Epoch: 1 [29312/50000]\tLoss: 1.8072\tLR: 0.058568\nTraining Epoch: 1 [29440/50000]\tLoss: 1.8743\tLR: 0.058824\nTraining Epoch: 1 [29568/50000]\tLoss: 1.8040\tLR: 0.059079\nTraining Epoch: 1 [29696/50000]\tLoss: 1.7880\tLR: 0.059335\nTraining Epoch: 1 [29824/50000]\tLoss: 1.8050\tLR: 0.059591\nTraining Epoch: 1 [29952/50000]\tLoss: 1.7307\tLR: 0.059847\nTraining Epoch: 1 [30080/50000]\tLoss: 1.7645\tLR: 0.060102\nTraining Epoch: 1 [30208/50000]\tLoss: 1.8992\tLR: 0.060358\nTraining Epoch: 1 [30336/50000]\tLoss: 1.7292\tLR: 0.060614\nTraining Epoch: 1 [30464/50000]\tLoss: 1.6836\tLR: 0.060870\nTraining Epoch: 1 [30592/50000]\tLoss: 1.6854\tLR: 0.061125\nTraining Epoch: 1 [30720/50000]\tLoss: 1.7691\tLR: 0.061381\nTraining Epoch: 1 [30848/50000]\tLoss: 1.7219\tLR: 0.061637\nTraining Epoch: 1 [30976/50000]\tLoss: 1.9085\tLR: 0.061893\nTraining Epoch: 1 [31104/50000]\tLoss: 1.7605\tLR: 0.062148\nTraining Epoch: 1 [31232/50000]\tLoss: 1.8691\tLR: 0.062404\nTraining Epoch: 1 [31360/50000]\tLoss: 1.5656\tLR: 0.062660\nTraining Epoch: 1 [31488/50000]\tLoss: 1.4891\tLR: 0.062916\nTraining Epoch: 1 [31616/50000]\tLoss: 1.7834\tLR: 0.063171\nTraining Epoch: 1 [31744/50000]\tLoss: 1.8510\tLR: 0.063427\nTraining Epoch: 1 [31872/50000]\tLoss: 1.7545\tLR: 0.063683\nTraining Epoch: 1 [32000/50000]\tLoss: 1.8375\tLR: 0.063939\nTraining Epoch: 1 [32128/50000]\tLoss: 1.6439\tLR: 0.064194\nTraining Epoch: 1 [32256/50000]\tLoss: 1.7430\tLR: 0.064450\nTraining Epoch: 1 [32384/50000]\tLoss: 1.8201\tLR: 0.064706\nTraining Epoch: 1 [32512/50000]\tLoss: 1.9050\tLR: 0.064962\nTraining Epoch: 1 [32640/50000]\tLoss: 1.7552\tLR: 0.065217\nTraining Epoch: 1 [32768/50000]\tLoss: 1.7140\tLR: 0.065473\nTraining Epoch: 1 [32896/50000]\tLoss: 1.8502\tLR: 0.065729\nTraining Epoch: 1 [33024/50000]\tLoss: 2.0668\tLR: 0.065985\nTraining Epoch: 1 [33152/50000]\tLoss: 1.7916\tLR: 0.066240\nTraining Epoch: 1 [33280/50000]\tLoss: 1.7873\tLR: 0.066496\nTraining Epoch: 1 [33408/50000]\tLoss: 1.8350\tLR: 0.066752\nTraining Epoch: 1 [33536/50000]\tLoss: 1.8949\tLR: 0.067008\nTraining Epoch: 1 [33664/50000]\tLoss: 1.7676\tLR: 0.067263\nTraining Epoch: 1 [33792/50000]\tLoss: 1.7857\tLR: 0.067519\nTraining Epoch: 1 [33920/50000]\tLoss: 1.8171\tLR: 0.067775\nTraining Epoch: 1 [34048/50000]\tLoss: 1.6466\tLR: 0.068031\nTraining Epoch: 1 [34176/50000]\tLoss: 1.7134\tLR: 0.068286\nTraining Epoch: 1 [34304/50000]\tLoss: 1.7898\tLR: 0.068542\nTraining Epoch: 1 [34432/50000]\tLoss: 1.8546\tLR: 0.068798\nTraining Epoch: 1 [34560/50000]\tLoss: 1.5979\tLR: 0.069054\nTraining Epoch: 1 [34688/50000]\tLoss: 1.8040\tLR: 0.069309\nTraining Epoch: 1 [34816/50000]\tLoss: 1.7495\tLR: 0.069565\nTraining Epoch: 1 [34944/50000]\tLoss: 1.7132\tLR: 0.069821\nTraining Epoch: 1 [35072/50000]\tLoss: 1.6232\tLR: 0.070077\nTraining Epoch: 1 [35200/50000]\tLoss: 1.8348\tLR: 0.070332\nTraining Epoch: 1 [35328/50000]\tLoss: 1.8662\tLR: 0.070588\nTraining Epoch: 1 [35456/50000]\tLoss: 1.6865\tLR: 0.070844\nTraining Epoch: 1 [35584/50000]\tLoss: 1.5239\tLR: 0.071100\nTraining Epoch: 1 [35712/50000]\tLoss: 1.7189\tLR: 0.071355\nTraining Epoch: 1 [35840/50000]\tLoss: 1.7083\tLR: 0.071611\nTraining Epoch: 1 [35968/50000]\tLoss: 1.6085\tLR: 0.071867\nTraining Epoch: 1 [36096/50000]\tLoss: 1.7020\tLR: 0.072123\nTraining Epoch: 1 [36224/50000]\tLoss: 1.6527\tLR: 0.072379\nTraining Epoch: 1 [36352/50000]\tLoss: 1.7205\tLR: 0.072634\nTraining Epoch: 1 [36480/50000]\tLoss: 1.7639\tLR: 0.072890\nTraining Epoch: 1 [36608/50000]\tLoss: 1.7206\tLR: 0.073146\nTraining Epoch: 1 [36736/50000]\tLoss: 1.7441\tLR: 0.073402\nTraining Epoch: 1 [36864/50000]\tLoss: 1.5519\tLR: 0.073657\nTraining Epoch: 1 [36992/50000]\tLoss: 1.7225\tLR: 0.073913\nTraining Epoch: 1 [37120/50000]\tLoss: 1.5551\tLR: 0.074169\nTraining Epoch: 1 [37248/50000]\tLoss: 1.7278\tLR: 0.074425\nTraining Epoch: 1 [37376/50000]\tLoss: 1.6097\tLR: 0.074680\nTraining Epoch: 1 [37504/50000]\tLoss: 1.6804\tLR: 0.074936\nTraining Epoch: 1 [37632/50000]\tLoss: 1.5145\tLR: 0.075192\nTraining Epoch: 1 [37760/50000]\tLoss: 1.6142\tLR: 0.075448\nTraining Epoch: 1 [37888/50000]\tLoss: 1.6588\tLR: 0.075703\nTraining Epoch: 1 [38016/50000]\tLoss: 1.5364\tLR: 0.075959\nTraining Epoch: 1 [38144/50000]\tLoss: 1.5440\tLR: 0.076215\nTraining Epoch: 1 [38272/50000]\tLoss: 1.6644\tLR: 0.076471\nTraining Epoch: 1 [38400/50000]\tLoss: 1.5817\tLR: 0.076726\nTraining Epoch: 1 [38528/50000]\tLoss: 1.6683\tLR: 0.076982\nTraining Epoch: 1 [38656/50000]\tLoss: 1.6206\tLR: 0.077238\nTraining Epoch: 1 [38784/50000]\tLoss: 1.6438\tLR: 0.077494\nTraining Epoch: 1 [38912/50000]\tLoss: 1.5569\tLR: 0.077749\nTraining Epoch: 1 [39040/50000]\tLoss: 1.6540\tLR: 0.078005\nTraining Epoch: 1 [39168/50000]\tLoss: 1.6943\tLR: 0.078261\nTraining Epoch: 1 [39296/50000]\tLoss: 1.5776\tLR: 0.078517\nTraining Epoch: 1 [39424/50000]\tLoss: 1.6521\tLR: 0.078772\nTraining Epoch: 1 [39552/50000]\tLoss: 1.7793\tLR: 0.079028\nTraining Epoch: 1 [39680/50000]\tLoss: 1.9434\tLR: 0.079284\nTraining Epoch: 1 [39808/50000]\tLoss: 1.6005\tLR: 0.079540\nTraining Epoch: 1 [39936/50000]\tLoss: 1.6779\tLR: 0.079795\nTraining Epoch: 1 [40064/50000]\tLoss: 1.6036\tLR: 0.080051\nTraining Epoch: 1 [40192/50000]\tLoss: 1.6401\tLR: 0.080307\nTraining Epoch: 1 [40320/50000]\tLoss: 1.4841\tLR: 0.080563\nTraining Epoch: 1 [40448/50000]\tLoss: 1.6376\tLR: 0.080818\nTraining Epoch: 1 [40576/50000]\tLoss: 1.5894\tLR: 0.081074\nTraining Epoch: 1 [40704/50000]\tLoss: 1.6211\tLR: 0.081330\nTraining Epoch: 1 [40832/50000]\tLoss: 1.5398\tLR: 0.081586\nTraining Epoch: 1 [40960/50000]\tLoss: 1.5103\tLR: 0.081841\nTraining Epoch: 1 [41088/50000]\tLoss: 1.5834\tLR: 0.082097\nTraining Epoch: 1 [41216/50000]\tLoss: 1.5778\tLR: 0.082353\nTraining Epoch: 1 [41344/50000]\tLoss: 1.6103\tLR: 0.082609\nTraining Epoch: 1 [41472/50000]\tLoss: 1.6050\tLR: 0.082864\nTraining Epoch: 1 [41600/50000]\tLoss: 1.6615\tLR: 0.083120\nTraining Epoch: 1 [41728/50000]\tLoss: 1.5466\tLR: 0.083376\nTraining Epoch: 1 [41856/50000]\tLoss: 1.3937\tLR: 0.083632\nTraining Epoch: 1 [41984/50000]\tLoss: 1.5071\tLR: 0.083887\nTraining Epoch: 1 [42112/50000]\tLoss: 1.4660\tLR: 0.084143\nTraining Epoch: 1 [42240/50000]\tLoss: 1.5920\tLR: 0.084399\nTraining Epoch: 1 [42368/50000]\tLoss: 1.6362\tLR: 0.084655\nTraining Epoch: 1 [42496/50000]\tLoss: 1.4352\tLR: 0.084910\nTraining Epoch: 1 [42624/50000]\tLoss: 1.4901\tLR: 0.085166\nTraining Epoch: 1 [42752/50000]\tLoss: 1.6178\tLR: 0.085422\nTraining Epoch: 1 [42880/50000]\tLoss: 1.6486\tLR: 0.085678\nTraining Epoch: 1 [43008/50000]\tLoss: 1.5627\tLR: 0.085934\nTraining Epoch: 1 [43136/50000]\tLoss: 1.6160\tLR: 0.086189\nTraining Epoch: 1 [43264/50000]\tLoss: 1.6483\tLR: 0.086445\nTraining Epoch: 1 [43392/50000]\tLoss: 1.5688\tLR: 0.086701\nTraining Epoch: 1 [43520/50000]\tLoss: 1.5358\tLR: 0.086957\nTraining Epoch: 1 [43648/50000]\tLoss: 1.7012\tLR: 0.087212\nTraining Epoch: 1 [43776/50000]\tLoss: 1.5301\tLR: 0.087468\nTraining Epoch: 1 [43904/50000]\tLoss: 1.5821\tLR: 0.087724\nTraining Epoch: 1 [44032/50000]\tLoss: 1.6392\tLR: 0.087980\nTraining Epoch: 1 [44160/50000]\tLoss: 1.6249\tLR: 0.088235\nTraining Epoch: 1 [44288/50000]\tLoss: 1.5214\tLR: 0.088491\nTraining Epoch: 1 [44416/50000]\tLoss: 1.5122\tLR: 0.088747\nTraining Epoch: 1 [44544/50000]\tLoss: 1.4892\tLR: 0.089003\nTraining Epoch: 1 [44672/50000]\tLoss: 1.5325\tLR: 0.089258\nTraining Epoch: 1 [44800/50000]\tLoss: 1.4010\tLR: 0.089514\nTraining Epoch: 1 [44928/50000]\tLoss: 1.5287\tLR: 0.089770\nTraining Epoch: 1 [45056/50000]\tLoss: 1.5090\tLR: 0.090026\nTraining Epoch: 1 [45184/50000]\tLoss: 1.4705\tLR: 0.090281\nTraining Epoch: 1 [45312/50000]\tLoss: 1.6950\tLR: 0.090537\nTraining Epoch: 1 [45440/50000]\tLoss: 1.5125\tLR: 0.090793\nTraining Epoch: 1 [45568/50000]\tLoss: 1.5421\tLR: 0.091049\nTraining Epoch: 1 [45696/50000]\tLoss: 1.5025\tLR: 0.091304\nTraining Epoch: 1 [45824/50000]\tLoss: 1.4778\tLR: 0.091560\nTraining Epoch: 1 [45952/50000]\tLoss: 1.5590\tLR: 0.091816\nTraining Epoch: 1 [46080/50000]\tLoss: 1.4891\tLR: 0.092072\nTraining Epoch: 1 [46208/50000]\tLoss: 1.4464\tLR: 0.092327\nTraining Epoch: 1 [46336/50000]\tLoss: 1.4504\tLR: 0.092583\nTraining Epoch: 1 [46464/50000]\tLoss: 1.5411\tLR: 0.092839\nTraining Epoch: 1 [46592/50000]\tLoss: 1.5189\tLR: 0.093095\nTraining Epoch: 1 [46720/50000]\tLoss: 1.6105\tLR: 0.093350\nTraining Epoch: 1 [46848/50000]\tLoss: 1.4178\tLR: 0.093606\nTraining Epoch: 1 [46976/50000]\tLoss: 1.5110\tLR: 0.093862\nTraining Epoch: 1 [47104/50000]\tLoss: 1.4475\tLR: 0.094118\nTraining Epoch: 1 [47232/50000]\tLoss: 1.5350\tLR: 0.094373\nTraining Epoch: 1 [47360/50000]\tLoss: 1.5000\tLR: 0.094629\nTraining Epoch: 1 [47488/50000]\tLoss: 1.6192\tLR: 0.094885\nTraining Epoch: 1 [47616/50000]\tLoss: 1.4830\tLR: 0.095141\nTraining Epoch: 1 [47744/50000]\tLoss: 1.4731\tLR: 0.095396\nTraining Epoch: 1 [47872/50000]\tLoss: 1.5587\tLR: 0.095652\nTraining Epoch: 1 [48000/50000]\tLoss: 1.4568\tLR: 0.095908\nTraining Epoch: 1 [48128/50000]\tLoss: 1.5142\tLR: 0.096164\nTraining Epoch: 1 [48256/50000]\tLoss: 1.5236\tLR: 0.096419\nTraining Epoch: 1 [48384/50000]\tLoss: 1.4537\tLR: 0.096675\nTraining Epoch: 1 [48512/50000]\tLoss: 1.5220\tLR: 0.096931\nTraining Epoch: 1 [48640/50000]\tLoss: 1.3784\tLR: 0.097187\nTraining Epoch: 1 [48768/50000]\tLoss: 1.4660\tLR: 0.097442\nTraining Epoch: 1 [48896/50000]\tLoss: 1.3552\tLR: 0.097698\nTraining Epoch: 1 [49024/50000]\tLoss: 1.5591\tLR: 0.097954\nTraining Epoch: 1 [49152/50000]\tLoss: 1.4879\tLR: 0.098210\nTraining Epoch: 1 [49280/50000]\tLoss: 1.5029\tLR: 0.098465\nTraining Epoch: 1 [49408/50000]\tLoss: 1.4314\tLR: 0.098721\nTraining Epoch: 1 [49536/50000]\tLoss: 1.5464\tLR: 0.098977\nTraining Epoch: 1 [49664/50000]\tLoss: 1.5118\tLR: 0.099233\nTraining Epoch: 1 [49792/50000]\tLoss: 1.4091\tLR: 0.099488\nTraining Epoch: 1 [49920/50000]\tLoss: 1.5070\tLR: 0.099744\nTraining Epoch: 1 [50000/50000]\tLoss: 1.5927\tLR: 0.100000\nTest set: Average loss: 0.0115, Accuracy: 0.4825\n\nTraining Epoch: 2 [128/50000]\tLoss: 1.3508\tLR: 0.100000\nTraining Epoch: 2 [256/50000]\tLoss: 1.4134\tLR: 0.100000\nTraining Epoch: 2 [384/50000]\tLoss: 1.4706\tLR: 0.100000\nTraining Epoch: 2 [512/50000]\tLoss: 1.4971\tLR: 0.100000\nTraining Epoch: 2 [640/50000]\tLoss: 1.6206\tLR: 0.100000\nTraining Epoch: 2 [768/50000]\tLoss: 1.5923\tLR: 0.100000\nTraining Epoch: 2 [896/50000]\tLoss: 1.4239\tLR: 0.100000\nTraining Epoch: 2 [1024/50000]\tLoss: 1.3537\tLR: 0.100000\nTraining Epoch: 2 [1152/50000]\tLoss: 1.4830\tLR: 0.100000\nTraining Epoch: 2 [1280/50000]\tLoss: 1.5242\tLR: 0.100000\nTraining Epoch: 2 [1408/50000]\tLoss: 1.5259\tLR: 0.100000\nTraining Epoch: 2 [1536/50000]\tLoss: 1.5291\tLR: 0.100000\nTraining Epoch: 2 [1664/50000]\tLoss: 1.6832\tLR: 0.100000\nTraining Epoch: 2 [1792/50000]\tLoss: 1.5155\tLR: 0.100000\nTraining Epoch: 2 [1920/50000]\tLoss: 1.5426\tLR: 0.100000\nTraining Epoch: 2 [2048/50000]\tLoss: 1.4996\tLR: 0.100000\nTraining Epoch: 2 [2176/50000]\tLoss: 1.4888\tLR: 0.100000\nTraining Epoch: 2 [2304/50000]\tLoss: 1.4536\tLR: 0.100000\nTraining Epoch: 2 [2432/50000]\tLoss: 1.6102\tLR: 0.100000\nTraining Epoch: 2 [2560/50000]\tLoss: 1.4191\tLR: 0.100000\nTraining Epoch: 2 [2688/50000]\tLoss: 1.4305\tLR: 0.100000\nTraining Epoch: 2 [2816/50000]\tLoss: 1.5184\tLR: 0.100000\nTraining Epoch: 2 [2944/50000]\tLoss: 1.3751\tLR: 0.100000\nTraining Epoch: 2 [3072/50000]\tLoss: 1.3823\tLR: 0.100000\nTraining Epoch: 2 [3200/50000]\tLoss: 1.5874\tLR: 0.100000\nTraining Epoch: 2 [3328/50000]\tLoss: 1.6862\tLR: 0.100000\nTraining Epoch: 2 [3456/50000]\tLoss: 1.4752\tLR: 0.100000\nTraining Epoch: 2 [3584/50000]\tLoss: 1.4690\tLR: 0.100000\nTraining Epoch: 2 [3712/50000]\tLoss: 1.4884\tLR: 0.100000\nTraining Epoch: 2 [3840/50000]\tLoss: 1.3368\tLR: 0.100000\nTraining Epoch: 2 [3968/50000]\tLoss: 1.4488\tLR: 0.100000\nTraining Epoch: 2 [4096/50000]\tLoss: 1.4536\tLR: 0.100000\nTraining Epoch: 2 [4224/50000]\tLoss: 1.4771\tLR: 0.100000\nTraining Epoch: 2 [4352/50000]\tLoss: 1.6307\tLR: 0.100000\nTraining Epoch: 2 [4480/50000]\tLoss: 1.4009\tLR: 0.100000\nTraining Epoch: 2 [4608/50000]\tLoss: 1.3828\tLR: 0.100000\nTraining Epoch: 2 [4736/50000]\tLoss: 1.3431\tLR: 0.100000\nTraining Epoch: 2 [4864/50000]\tLoss: 1.4900\tLR: 0.100000\nTraining Epoch: 2 [4992/50000]\tLoss: 1.4295\tLR: 0.100000\nTraining Epoch: 2 [5120/50000]\tLoss: 1.6339\tLR: 0.100000\nTraining Epoch: 2 [5248/50000]\tLoss: 1.4452\tLR: 0.100000\nTraining Epoch: 2 [5376/50000]\tLoss: 1.3400\tLR: 0.100000\nTraining Epoch: 2 [5504/50000]\tLoss: 1.4849\tLR: 0.100000\nTraining Epoch: 2 [5632/50000]\tLoss: 1.5400\tLR: 0.100000\nTraining Epoch: 2 [5760/50000]\tLoss: 1.7287\tLR: 0.100000\nTraining Epoch: 2 [5888/50000]\tLoss: 1.4987\tLR: 0.100000\nTraining Epoch: 2 [6016/50000]\tLoss: 1.4112\tLR: 0.100000\nTraining Epoch: 2 [6144/50000]\tLoss: 1.3680\tLR: 0.100000\nTraining Epoch: 2 [6272/50000]\tLoss: 1.4714\tLR: 0.100000\nTraining Epoch: 2 [6400/50000]\tLoss: 1.3515\tLR: 0.100000\nTraining Epoch: 2 [6528/50000]\tLoss: 1.4129\tLR: 0.100000\nTraining Epoch: 2 [6656/50000]\tLoss: 1.4120\tLR: 0.100000\nTraining Epoch: 2 [6784/50000]\tLoss: 1.3744\tLR: 0.100000\nTraining Epoch: 2 [6912/50000]\tLoss: 1.3921\tLR: 0.100000\nTraining Epoch: 2 [7040/50000]\tLoss: 1.3191\tLR: 0.100000\nTraining Epoch: 2 [7168/50000]\tLoss: 1.3424\tLR: 0.100000\nTraining Epoch: 2 [7296/50000]\tLoss: 1.3364\tLR: 0.100000\nTraining Epoch: 2 [7424/50000]\tLoss: 1.2778\tLR: 0.100000\nTraining Epoch: 2 [7552/50000]\tLoss: 1.3406\tLR: 0.100000\nTraining Epoch: 2 [7680/50000]\tLoss: 1.4024\tLR: 0.100000\nTraining Epoch: 2 [7808/50000]\tLoss: 1.4200\tLR: 0.100000\nTraining Epoch: 2 [7936/50000]\tLoss: 1.2830\tLR: 0.100000\nTraining Epoch: 2 [8064/50000]\tLoss: 1.2963\tLR: 0.100000\nTraining Epoch: 2 [8192/50000]\tLoss: 1.6917\tLR: 0.100000\nTraining Epoch: 2 [8320/50000]\tLoss: 1.4863\tLR: 0.100000\nTraining Epoch: 2 [8448/50000]\tLoss: 1.4131\tLR: 0.100000\nTraining Epoch: 2 [8576/50000]\tLoss: 1.2354\tLR: 0.100000\nTraining Epoch: 2 [8704/50000]\tLoss: 1.3873\tLR: 0.100000\nTraining Epoch: 2 [8832/50000]\tLoss: 1.4212\tLR: 0.100000\nTraining Epoch: 2 [8960/50000]\tLoss: 1.5067\tLR: 0.100000\nTraining Epoch: 2 [9088/50000]\tLoss: 1.4430\tLR: 0.100000\nTraining Epoch: 2 [9216/50000]\tLoss: 1.4243\tLR: 0.100000\nTraining Epoch: 2 [9344/50000]\tLoss: 1.3530\tLR: 0.100000\nTraining Epoch: 2 [9472/50000]\tLoss: 1.5245\tLR: 0.100000\nTraining Epoch: 2 [9600/50000]\tLoss: 1.3189\tLR: 0.100000\nTraining Epoch: 2 [9728/50000]\tLoss: 1.4825\tLR: 0.100000\nTraining Epoch: 2 [9856/50000]\tLoss: 1.3668\tLR: 0.100000\nTraining Epoch: 2 [9984/50000]\tLoss: 1.4188\tLR: 0.100000\nTraining Epoch: 2 [10112/50000]\tLoss: 1.2965\tLR: 0.100000\nTraining Epoch: 2 [10240/50000]\tLoss: 1.4079\tLR: 0.100000\nTraining Epoch: 2 [10368/50000]\tLoss: 1.2096\tLR: 0.100000\nTraining Epoch: 2 [10496/50000]\tLoss: 1.3941\tLR: 0.100000\nTraining Epoch: 2 [10624/50000]\tLoss: 1.3160\tLR: 0.100000\nTraining Epoch: 2 [10752/50000]\tLoss: 1.4328\tLR: 0.100000\nTraining Epoch: 2 [10880/50000]\tLoss: 1.3740\tLR: 0.100000\nTraining Epoch: 2 [11008/50000]\tLoss: 1.4287\tLR: 0.100000\nTraining Epoch: 2 [11136/50000]\tLoss: 1.3595\tLR: 0.100000\nTraining Epoch: 2 [11264/50000]\tLoss: 1.3537\tLR: 0.100000\nTraining Epoch: 2 [11392/50000]\tLoss: 1.2577\tLR: 0.100000\nTraining Epoch: 2 [11520/50000]\tLoss: 1.2974\tLR: 0.100000\nTraining Epoch: 2 [11648/50000]\tLoss: 1.3046\tLR: 0.100000\nTraining Epoch: 2 [11776/50000]\tLoss: 1.4543\tLR: 0.100000\nTraining Epoch: 2 [11904/50000]\tLoss: 1.1873\tLR: 0.100000\nTraining Epoch: 2 [12032/50000]\tLoss: 1.4186\tLR: 0.100000\nTraining Epoch: 2 [12160/50000]\tLoss: 1.3741\tLR: 0.100000\nTraining Epoch: 2 [12288/50000]\tLoss: 1.3483\tLR: 0.100000\nTraining Epoch: 2 [12416/50000]\tLoss: 1.5574\tLR: 0.100000\nTraining Epoch: 2 [12544/50000]\tLoss: 1.4448\tLR: 0.100000\nTraining Epoch: 2 [12672/50000]\tLoss: 1.2392\tLR: 0.100000\nTraining Epoch: 2 [12800/50000]\tLoss: 1.3580\tLR: 0.100000\nTraining Epoch: 2 [12928/50000]\tLoss: 1.3645\tLR: 0.100000\nTraining Epoch: 2 [13056/50000]\tLoss: 1.2774\tLR: 0.100000\nTraining Epoch: 2 [13184/50000]\tLoss: 1.3106\tLR: 0.100000\nTraining Epoch: 2 [13312/50000]\tLoss: 1.3208\tLR: 0.100000\nTraining Epoch: 2 [13440/50000]\tLoss: 1.5355\tLR: 0.100000\nTraining Epoch: 2 [13568/50000]\tLoss: 1.3257\tLR: 0.100000\nTraining Epoch: 2 [13696/50000]\tLoss: 1.4695\tLR: 0.100000\nTraining Epoch: 2 [13824/50000]\tLoss: 1.4448\tLR: 0.100000\nTraining Epoch: 2 [13952/50000]\tLoss: 1.3114\tLR: 0.100000\nTraining Epoch: 2 [14080/50000]\tLoss: 1.4131\tLR: 0.100000\nTraining Epoch: 2 [14208/50000]\tLoss: 1.2930\tLR: 0.100000\nTraining Epoch: 2 [14336/50000]\tLoss: 1.4844\tLR: 0.100000\nTraining Epoch: 2 [14464/50000]\tLoss: 1.3900\tLR: 0.100000\nTraining Epoch: 2 [14592/50000]\tLoss: 1.2850\tLR: 0.100000\nTraining Epoch: 2 [14720/50000]\tLoss: 1.3097\tLR: 0.100000\nTraining Epoch: 2 [14848/50000]\tLoss: 1.4353\tLR: 0.100000\nTraining Epoch: 2 [14976/50000]\tLoss: 1.3049\tLR: 0.100000\nTraining Epoch: 2 [15104/50000]\tLoss: 1.2398\tLR: 0.100000\nTraining Epoch: 2 [15232/50000]\tLoss: 1.4128\tLR: 0.100000\nTraining Epoch: 2 [15360/50000]\tLoss: 1.4321\tLR: 0.100000\nTraining Epoch: 2 [15488/50000]\tLoss: 1.2794\tLR: 0.100000\nTraining Epoch: 2 [15616/50000]\tLoss: 1.4484\tLR: 0.100000\nTraining Epoch: 2 [15744/50000]\tLoss: 1.2969\tLR: 0.100000\nTraining Epoch: 2 [15872/50000]\tLoss: 1.2498\tLR: 0.100000\nTraining Epoch: 2 [16000/50000]\tLoss: 1.4455\tLR: 0.100000\nTraining Epoch: 2 [16128/50000]\tLoss: 1.2151\tLR: 0.100000\nTraining Epoch: 2 [16256/50000]\tLoss: 1.2861\tLR: 0.100000\nTraining Epoch: 2 [16384/50000]\tLoss: 1.0492\tLR: 0.100000\nTraining Epoch: 2 [16512/50000]\tLoss: 1.1752\tLR: 0.100000\nTraining Epoch: 2 [16640/50000]\tLoss: 1.2457\tLR: 0.100000\nTraining Epoch: 2 [16768/50000]\tLoss: 1.3895\tLR: 0.100000\nTraining Epoch: 2 [16896/50000]\tLoss: 1.3040\tLR: 0.100000\nTraining Epoch: 2 [17024/50000]\tLoss: 1.4002\tLR: 0.100000\nTraining Epoch: 2 [17152/50000]\tLoss: 1.4428\tLR: 0.100000\nTraining Epoch: 2 [17280/50000]\tLoss: 1.4212\tLR: 0.100000\nTraining Epoch: 2 [17408/50000]\tLoss: 1.5480\tLR: 0.100000\nTraining Epoch: 2 [17536/50000]\tLoss: 1.3424\tLR: 0.100000\nTraining Epoch: 2 [17664/50000]\tLoss: 1.0870\tLR: 0.100000\nTraining Epoch: 2 [17792/50000]\tLoss: 1.2505\tLR: 0.100000\nTraining Epoch: 2 [17920/50000]\tLoss: 1.1573\tLR: 0.100000\nTraining Epoch: 2 [18048/50000]\tLoss: 1.3542\tLR: 0.100000\nTraining Epoch: 2 [18176/50000]\tLoss: 1.2582\tLR: 0.100000\nTraining Epoch: 2 [18304/50000]\tLoss: 1.5255\tLR: 0.100000\nTraining Epoch: 2 [18432/50000]\tLoss: 1.5538\tLR: 0.100000\nTraining Epoch: 2 [18560/50000]\tLoss: 1.2354\tLR: 0.100000\nTraining Epoch: 2 [18688/50000]\tLoss: 1.2723\tLR: 0.100000\nTraining Epoch: 2 [18816/50000]\tLoss: 1.1214\tLR: 0.100000\nTraining Epoch: 2 [18944/50000]\tLoss: 1.4554\tLR: 0.100000\nTraining Epoch: 2 [19072/50000]\tLoss: 1.4347\tLR: 0.100000\nTraining Epoch: 2 [19200/50000]\tLoss: 1.2245\tLR: 0.100000\nTraining Epoch: 2 [19328/50000]\tLoss: 1.2228\tLR: 0.100000\nTraining Epoch: 2 [19456/50000]\tLoss: 1.2318\tLR: 0.100000\nTraining Epoch: 2 [19584/50000]\tLoss: 1.2674\tLR: 0.100000\nTraining Epoch: 2 [19712/50000]\tLoss: 1.1842\tLR: 0.100000\nTraining Epoch: 2 [19840/50000]\tLoss: 1.2623\tLR: 0.100000\nTraining Epoch: 2 [19968/50000]\tLoss: 1.3362\tLR: 0.100000\nTraining Epoch: 2 [20096/50000]\tLoss: 1.2507\tLR: 0.100000\nTraining Epoch: 2 [20224/50000]\tLoss: 1.4591\tLR: 0.100000\nTraining Epoch: 2 [20352/50000]\tLoss: 1.3762\tLR: 0.100000\nTraining Epoch: 2 [20480/50000]\tLoss: 1.0423\tLR: 0.100000\nTraining Epoch: 2 [20608/50000]\tLoss: 1.2551\tLR: 0.100000\nTraining Epoch: 2 [20736/50000]\tLoss: 1.2476\tLR: 0.100000\nTraining Epoch: 2 [20864/50000]\tLoss: 1.4113\tLR: 0.100000\nTraining Epoch: 2 [20992/50000]\tLoss: 1.3981\tLR: 0.100000\nTraining Epoch: 2 [21120/50000]\tLoss: 1.2949\tLR: 0.100000\nTraining Epoch: 2 [21248/50000]\tLoss: 1.1670\tLR: 0.100000\nTraining Epoch: 2 [21376/50000]\tLoss: 1.2456\tLR: 0.100000\nTraining Epoch: 2 [21504/50000]\tLoss: 1.1276\tLR: 0.100000\nTraining Epoch: 2 [21632/50000]\tLoss: 1.3203\tLR: 0.100000\nTraining Epoch: 2 [21760/50000]\tLoss: 1.1985\tLR: 0.100000\nTraining Epoch: 2 [21888/50000]\tLoss: 1.2147\tLR: 0.100000\nTraining Epoch: 2 [22016/50000]\tLoss: 1.3434\tLR: 0.100000\nTraining Epoch: 2 [22144/50000]\tLoss: 1.3005\tLR: 0.100000\nTraining Epoch: 2 [22272/50000]\tLoss: 1.0795\tLR: 0.100000\nTraining Epoch: 2 [22400/50000]\tLoss: 1.0988\tLR: 0.100000\nTraining Epoch: 2 [22528/50000]\tLoss: 1.4034\tLR: 0.100000\nTraining Epoch: 2 [22656/50000]\tLoss: 1.3125\tLR: 0.100000\nTraining Epoch: 2 [22784/50000]\tLoss: 1.1463\tLR: 0.100000\nTraining Epoch: 2 [22912/50000]\tLoss: 1.3699\tLR: 0.100000\nTraining Epoch: 2 [23040/50000]\tLoss: 1.2045\tLR: 0.100000\nTraining Epoch: 2 [23168/50000]\tLoss: 1.2929\tLR: 0.100000\nTraining Epoch: 2 [23296/50000]\tLoss: 1.1865\tLR: 0.100000\nTraining Epoch: 2 [23424/50000]\tLoss: 1.2106\tLR: 0.100000\nTraining Epoch: 2 [23552/50000]\tLoss: 1.0176\tLR: 0.100000\nTraining Epoch: 2 [23680/50000]\tLoss: 1.4311\tLR: 0.100000\nTraining Epoch: 2 [23808/50000]\tLoss: 1.5494\tLR: 0.100000\nTraining Epoch: 2 [23936/50000]\tLoss: 1.1196\tLR: 0.100000\nTraining Epoch: 2 [24064/50000]\tLoss: 1.3151\tLR: 0.100000\nTraining Epoch: 2 [24192/50000]\tLoss: 1.2150\tLR: 0.100000\nTraining Epoch: 2 [24320/50000]\tLoss: 1.4173\tLR: 0.100000\nTraining Epoch: 2 [24448/50000]\tLoss: 1.2533\tLR: 0.100000\nTraining Epoch: 2 [24576/50000]\tLoss: 1.2978\tLR: 0.100000\nTraining Epoch: 2 [24704/50000]\tLoss: 1.1084\tLR: 0.100000\nTraining Epoch: 2 [24832/50000]\tLoss: 1.1410\tLR: 0.100000\nTraining Epoch: 2 [24960/50000]\tLoss: 1.3887\tLR: 0.100000\nTraining Epoch: 2 [25088/50000]\tLoss: 1.0153\tLR: 0.100000\nTraining Epoch: 2 [25216/50000]\tLoss: 1.0302\tLR: 0.100000\nTraining Epoch: 2 [25344/50000]\tLoss: 1.2734\tLR: 0.100000\nTraining Epoch: 2 [25472/50000]\tLoss: 1.4015\tLR: 0.100000\nTraining Epoch: 2 [25600/50000]\tLoss: 1.1663\tLR: 0.100000\nTraining Epoch: 2 [25728/50000]\tLoss: 1.1481\tLR: 0.100000\nTraining Epoch: 2 [25856/50000]\tLoss: 1.2556\tLR: 0.100000\nTraining Epoch: 2 [25984/50000]\tLoss: 1.1966\tLR: 0.100000\nTraining Epoch: 2 [26112/50000]\tLoss: 1.4267\tLR: 0.100000\nTraining Epoch: 2 [26240/50000]\tLoss: 1.2985\tLR: 0.100000\nTraining Epoch: 2 [26368/50000]\tLoss: 1.0223\tLR: 0.100000\nTraining Epoch: 2 [26496/50000]\tLoss: 1.1645\tLR: 0.100000\nTraining Epoch: 2 [26624/50000]\tLoss: 1.2381\tLR: 0.100000\nTraining Epoch: 2 [26752/50000]\tLoss: 1.1621\tLR: 0.100000\nTraining Epoch: 2 [26880/50000]\tLoss: 1.2981\tLR: 0.100000\nTraining Epoch: 2 [27008/50000]\tLoss: 1.2378\tLR: 0.100000\nTraining Epoch: 2 [27136/50000]\tLoss: 1.2503\tLR: 0.100000\nTraining Epoch: 2 [27264/50000]\tLoss: 1.1331\tLR: 0.100000\nTraining Epoch: 2 [27392/50000]\tLoss: 1.1859\tLR: 0.100000\nTraining Epoch: 2 [27520/50000]\tLoss: 1.1090\tLR: 0.100000\nTraining Epoch: 2 [27648/50000]\tLoss: 1.3507\tLR: 0.100000\nTraining Epoch: 2 [27776/50000]\tLoss: 1.1803\tLR: 0.100000\nTraining Epoch: 2 [27904/50000]\tLoss: 1.3236\tLR: 0.100000\nTraining Epoch: 2 [28032/50000]\tLoss: 1.1928\tLR: 0.100000\nTraining Epoch: 2 [28160/50000]\tLoss: 1.3495\tLR: 0.100000\nTraining Epoch: 2 [28288/50000]\tLoss: 1.2009\tLR: 0.100000\nTraining Epoch: 2 [28416/50000]\tLoss: 1.2185\tLR: 0.100000\nTraining Epoch: 2 [28544/50000]\tLoss: 1.1658\tLR: 0.100000\nTraining Epoch: 2 [28672/50000]\tLoss: 1.1683\tLR: 0.100000\nTraining Epoch: 2 [28800/50000]\tLoss: 1.2793\tLR: 0.100000\nTraining Epoch: 2 [28928/50000]\tLoss: 1.2536\tLR: 0.100000\nTraining Epoch: 2 [29056/50000]\tLoss: 1.2300\tLR: 0.100000\nTraining Epoch: 2 [29184/50000]\tLoss: 1.2745\tLR: 0.100000\nTraining Epoch: 2 [29312/50000]\tLoss: 1.2320\tLR: 0.100000\nTraining Epoch: 2 [29440/50000]\tLoss: 1.3558\tLR: 0.100000\nTraining Epoch: 2 [29568/50000]\tLoss: 1.2772\tLR: 0.100000\nTraining Epoch: 2 [29696/50000]\tLoss: 1.1422\tLR: 0.100000\nTraining Epoch: 2 [29824/50000]\tLoss: 1.3151\tLR: 0.100000\nTraining Epoch: 2 [29952/50000]\tLoss: 1.1870\tLR: 0.100000\nTraining Epoch: 2 [30080/50000]\tLoss: 1.1731\tLR: 0.100000\nTraining Epoch: 2 [30208/50000]\tLoss: 1.2199\tLR: 0.100000\nTraining Epoch: 2 [30336/50000]\tLoss: 1.0002\tLR: 0.100000\nTraining Epoch: 2 [30464/50000]\tLoss: 1.0801\tLR: 0.100000\nTraining Epoch: 2 [30592/50000]\tLoss: 1.1455\tLR: 0.100000\nTraining Epoch: 2 [30720/50000]\tLoss: 1.0809\tLR: 0.100000\nTraining Epoch: 2 [30848/50000]\tLoss: 1.0946\tLR: 0.100000\nTraining Epoch: 2 [30976/50000]\tLoss: 1.0659\tLR: 0.100000\nTraining Epoch: 2 [31104/50000]\tLoss: 1.4263\tLR: 0.100000\nTraining Epoch: 2 [31232/50000]\tLoss: 1.2344\tLR: 0.100000\nTraining Epoch: 2 [31360/50000]\tLoss: 1.0533\tLR: 0.100000\nTraining Epoch: 2 [31488/50000]\tLoss: 1.1781\tLR: 0.100000\nTraining Epoch: 2 [31616/50000]\tLoss: 1.1108\tLR: 0.100000\nTraining Epoch: 2 [31744/50000]\tLoss: 1.1858\tLR: 0.100000\nTraining Epoch: 2 [31872/50000]\tLoss: 1.2049\tLR: 0.100000\nTraining Epoch: 2 [32000/50000]\tLoss: 1.1495\tLR: 0.100000\nTraining Epoch: 2 [32128/50000]\tLoss: 1.3722\tLR: 0.100000\nTraining Epoch: 2 [32256/50000]\tLoss: 1.0415\tLR: 0.100000\nTraining Epoch: 2 [32384/50000]\tLoss: 1.3562\tLR: 0.100000\nTraining Epoch: 2 [32512/50000]\tLoss: 1.0301\tLR: 0.100000\nTraining Epoch: 2 [32640/50000]\tLoss: 1.1389\tLR: 0.100000\nTraining Epoch: 2 [32768/50000]\tLoss: 1.2991\tLR: 0.100000\nTraining Epoch: 2 [32896/50000]\tLoss: 1.1078\tLR: 0.100000\nTraining Epoch: 2 [33024/50000]\tLoss: 1.1577\tLR: 0.100000\nTraining Epoch: 2 [33152/50000]\tLoss: 1.0567\tLR: 0.100000\nTraining Epoch: 2 [33280/50000]\tLoss: 1.1166\tLR: 0.100000\nTraining Epoch: 2 [33408/50000]\tLoss: 1.2985\tLR: 0.100000\nTraining Epoch: 2 [33536/50000]\tLoss: 1.1854\tLR: 0.100000\nTraining Epoch: 2 [33664/50000]\tLoss: 0.9688\tLR: 0.100000\nTraining Epoch: 2 [33792/50000]\tLoss: 1.1798\tLR: 0.100000\nTraining Epoch: 2 [33920/50000]\tLoss: 1.0794\tLR: 0.100000\nTraining Epoch: 2 [34048/50000]\tLoss: 1.2068\tLR: 0.100000\nTraining Epoch: 2 [34176/50000]\tLoss: 1.0184\tLR: 0.100000\nTraining Epoch: 2 [34304/50000]\tLoss: 1.3997\tLR: 0.100000\nTraining Epoch: 2 [34432/50000]\tLoss: 1.0779\tLR: 0.100000\nTraining Epoch: 2 [34560/50000]\tLoss: 1.2658\tLR: 0.100000\nTraining Epoch: 2 [34688/50000]\tLoss: 1.0641\tLR: 0.100000\nTraining Epoch: 2 [34816/50000]\tLoss: 1.1980\tLR: 0.100000\nTraining Epoch: 2 [34944/50000]\tLoss: 1.1953\tLR: 0.100000\nTraining Epoch: 2 [35072/50000]\tLoss: 1.1356\tLR: 0.100000\nTraining Epoch: 2 [35200/50000]\tLoss: 1.0130\tLR: 0.100000\nTraining Epoch: 2 [35328/50000]\tLoss: 1.1760\tLR: 0.100000\nTraining Epoch: 2 [35456/50000]\tLoss: 1.2002\tLR: 0.100000\nTraining Epoch: 2 [35584/50000]\tLoss: 1.1139\tLR: 0.100000\nTraining Epoch: 2 [35712/50000]\tLoss: 1.2790\tLR: 0.100000\nTraining Epoch: 2 [35840/50000]\tLoss: 1.1792\tLR: 0.100000\nTraining Epoch: 2 [35968/50000]\tLoss: 1.2559\tLR: 0.100000\nTraining Epoch: 2 [36096/50000]\tLoss: 1.0661\tLR: 0.100000\nTraining Epoch: 2 [36224/50000]\tLoss: 1.1896\tLR: 0.100000\nTraining Epoch: 2 [36352/50000]\tLoss: 1.1920\tLR: 0.100000\nTraining Epoch: 2 [36480/50000]\tLoss: 1.1601\tLR: 0.100000\nTraining Epoch: 2 [36608/50000]\tLoss: 1.0800\tLR: 0.100000\nTraining Epoch: 2 [36736/50000]\tLoss: 1.1326\tLR: 0.100000\nTraining Epoch: 2 [36864/50000]\tLoss: 1.2185\tLR: 0.100000\nTraining Epoch: 2 [36992/50000]\tLoss: 1.2414\tLR: 0.100000\nTraining Epoch: 2 [37120/50000]\tLoss: 1.1919\tLR: 0.100000\nTraining Epoch: 2 [37248/50000]\tLoss: 1.0771\tLR: 0.100000\nTraining Epoch: 2 [37376/50000]\tLoss: 1.2242\tLR: 0.100000\nTraining Epoch: 2 [37504/50000]\tLoss: 1.1627\tLR: 0.100000\nTraining Epoch: 2 [37632/50000]\tLoss: 1.0474\tLR: 0.100000\nTraining Epoch: 2 [37760/50000]\tLoss: 1.2981\tLR: 0.100000\nTraining Epoch: 2 [37888/50000]\tLoss: 1.0952\tLR: 0.100000\nTraining Epoch: 2 [38016/50000]\tLoss: 1.0542\tLR: 0.100000\nTraining Epoch: 2 [38144/50000]\tLoss: 1.1989\tLR: 0.100000\nTraining Epoch: 2 [38272/50000]\tLoss: 1.1898\tLR: 0.100000\nTraining Epoch: 2 [38400/50000]\tLoss: 1.1887\tLR: 0.100000\nTraining Epoch: 2 [38528/50000]\tLoss: 1.1510\tLR: 0.100000\nTraining Epoch: 2 [38656/50000]\tLoss: 1.0998\tLR: 0.100000\nTraining Epoch: 2 [38784/50000]\tLoss: 0.9989\tLR: 0.100000\nTraining Epoch: 2 [38912/50000]\tLoss: 1.0696\tLR: 0.100000\nTraining Epoch: 2 [39040/50000]\tLoss: 1.1575\tLR: 0.100000\nTraining Epoch: 2 [39168/50000]\tLoss: 1.0458\tLR: 0.100000\nTraining Epoch: 2 [39296/50000]\tLoss: 1.2227\tLR: 0.100000\nTraining Epoch: 2 [39424/50000]\tLoss: 1.1043\tLR: 0.100000\nTraining Epoch: 2 [39552/50000]\tLoss: 1.2031\tLR: 0.100000\nTraining Epoch: 2 [39680/50000]\tLoss: 1.2226\tLR: 0.100000\nTraining Epoch: 2 [39808/50000]\tLoss: 1.0611\tLR: 0.100000\nTraining Epoch: 2 [39936/50000]\tLoss: 1.2226\tLR: 0.100000\nTraining Epoch: 2 [40064/50000]\tLoss: 1.1392\tLR: 0.100000\nTraining Epoch: 2 [40192/50000]\tLoss: 1.1748\tLR: 0.100000\nTraining Epoch: 2 [40320/50000]\tLoss: 1.0822\tLR: 0.100000\nTraining Epoch: 2 [40448/50000]\tLoss: 1.0948\tLR: 0.100000\nTraining Epoch: 2 [40576/50000]\tLoss: 1.0632\tLR: 0.100000\nTraining Epoch: 2 [40704/50000]\tLoss: 1.1290\tLR: 0.100000\nTraining Epoch: 2 [40832/50000]\tLoss: 1.1676\tLR: 0.100000\nTraining Epoch: 2 [40960/50000]\tLoss: 1.1799\tLR: 0.100000\nTraining Epoch: 2 [41088/50000]\tLoss: 1.0885\tLR: 0.100000\nTraining Epoch: 2 [41216/50000]\tLoss: 1.1942\tLR: 0.100000\nTraining Epoch: 2 [41344/50000]\tLoss: 1.0415\tLR: 0.100000\nTraining Epoch: 2 [41472/50000]\tLoss: 1.4104\tLR: 0.100000\nTraining Epoch: 2 [41600/50000]\tLoss: 1.2265\tLR: 0.100000\nTraining Epoch: 2 [41728/50000]\tLoss: 1.3012\tLR: 0.100000\nTraining Epoch: 2 [41856/50000]\tLoss: 1.1428\tLR: 0.100000\nTraining Epoch: 2 [41984/50000]\tLoss: 1.0528\tLR: 0.100000\nTraining Epoch: 2 [42112/50000]\tLoss: 1.0822\tLR: 0.100000\nTraining Epoch: 2 [42240/50000]\tLoss: 1.1145\tLR: 0.100000\nTraining Epoch: 2 [42368/50000]\tLoss: 1.1459\tLR: 0.100000\nTraining Epoch: 2 [42496/50000]\tLoss: 1.3198\tLR: 0.100000\nTraining Epoch: 2 [42624/50000]\tLoss: 1.2765\tLR: 0.100000\nTraining Epoch: 2 [42752/50000]\tLoss: 1.1831\tLR: 0.100000\nTraining Epoch: 2 [42880/50000]\tLoss: 1.0562\tLR: 0.100000\nTraining Epoch: 2 [43008/50000]\tLoss: 0.9808\tLR: 0.100000\nTraining Epoch: 2 [43136/50000]\tLoss: 1.0950\tLR: 0.100000\nTraining Epoch: 2 [43264/50000]\tLoss: 1.1981\tLR: 0.100000\nTraining Epoch: 2 [43392/50000]\tLoss: 1.1752\tLR: 0.100000\nTraining Epoch: 2 [43520/50000]\tLoss: 0.8712\tLR: 0.100000\nTraining Epoch: 2 [43648/50000]\tLoss: 1.0715\tLR: 0.100000\nTraining Epoch: 2 [43776/50000]\tLoss: 1.1483\tLR: 0.100000\nTraining Epoch: 2 [43904/50000]\tLoss: 1.1413\tLR: 0.100000\nTraining Epoch: 2 [44032/50000]\tLoss: 1.1678\tLR: 0.100000\nTraining Epoch: 2 [44160/50000]\tLoss: 1.1010\tLR: 0.100000\nTraining Epoch: 2 [44288/50000]\tLoss: 1.0277\tLR: 0.100000\nTraining Epoch: 2 [44416/50000]\tLoss: 1.0923\tLR: 0.100000\nTraining Epoch: 2 [44544/50000]\tLoss: 1.0823\tLR: 0.100000\nTraining Epoch: 2 [44672/50000]\tLoss: 1.0751\tLR: 0.100000\nTraining Epoch: 2 [44800/50000]\tLoss: 1.3039\tLR: 0.100000\nTraining Epoch: 2 [44928/50000]\tLoss: 1.2513\tLR: 0.100000\nTraining Epoch: 2 [45056/50000]\tLoss: 1.2003\tLR: 0.100000\nTraining Epoch: 2 [45184/50000]\tLoss: 1.1477\tLR: 0.100000\nTraining Epoch: 2 [45312/50000]\tLoss: 1.1266\tLR: 0.100000\nTraining Epoch: 2 [45440/50000]\tLoss: 1.3798\tLR: 0.100000\nTraining Epoch: 2 [45568/50000]\tLoss: 0.9203\tLR: 0.100000\nTraining Epoch: 2 [45696/50000]\tLoss: 1.0950\tLR: 0.100000\nTraining Epoch: 2 [45824/50000]\tLoss: 1.0805\tLR: 0.100000\nTraining Epoch: 2 [45952/50000]\tLoss: 1.0929\tLR: 0.100000\nTraining Epoch: 2 [46080/50000]\tLoss: 1.2038\tLR: 0.100000\nTraining Epoch: 2 [46208/50000]\tLoss: 1.1083\tLR: 0.100000\nTraining Epoch: 2 [46336/50000]\tLoss: 0.9858\tLR: 0.100000\nTraining Epoch: 2 [46464/50000]\tLoss: 1.1077\tLR: 0.100000\nTraining Epoch: 2 [46592/50000]\tLoss: 1.0533\tLR: 0.100000\nTraining Epoch: 2 [46720/50000]\tLoss: 1.0096\tLR: 0.100000\nTraining Epoch: 2 [46848/50000]\tLoss: 1.1458\tLR: 0.100000\nTraining Epoch: 2 [46976/50000]\tLoss: 1.0821\tLR: 0.100000\nTraining Epoch: 2 [47104/50000]\tLoss: 1.1863\tLR: 0.100000\nTraining Epoch: 2 [47232/50000]\tLoss: 1.1411\tLR: 0.100000\nTraining Epoch: 2 [47360/50000]\tLoss: 0.8657\tLR: 0.100000\nTraining Epoch: 2 [47488/50000]\tLoss: 0.9257\tLR: 0.100000\nTraining Epoch: 2 [47616/50000]\tLoss: 0.9612\tLR: 0.100000\nTraining Epoch: 2 [47744/50000]\tLoss: 1.1184\tLR: 0.100000\nTraining Epoch: 2 [47872/50000]\tLoss: 1.1092\tLR: 0.100000\nTraining Epoch: 2 [48000/50000]\tLoss: 1.1335\tLR: 0.100000\nTraining Epoch: 2 [48128/50000]\tLoss: 1.1821\tLR: 0.100000\nTraining Epoch: 2 [48256/50000]\tLoss: 1.0304\tLR: 0.100000\nTraining Epoch: 2 [48384/50000]\tLoss: 1.1416\tLR: 0.100000\nTraining Epoch: 2 [48512/50000]\tLoss: 1.1895\tLR: 0.100000\nTraining Epoch: 2 [48640/50000]\tLoss: 1.2955\tLR: 0.100000\nTraining Epoch: 2 [48768/50000]\tLoss: 1.1400\tLR: 0.100000\nTraining Epoch: 2 [48896/50000]\tLoss: 0.9000\tLR: 0.100000\nTraining Epoch: 2 [49024/50000]\tLoss: 0.9681\tLR: 0.100000\nTraining Epoch: 2 [49152/50000]\tLoss: 1.1053\tLR: 0.100000\nTraining Epoch: 2 [49280/50000]\tLoss: 1.0597\tLR: 0.100000\nTraining Epoch: 2 [49408/50000]\tLoss: 0.9590\tLR: 0.100000\nTraining Epoch: 2 [49536/50000]\tLoss: 0.9788\tLR: 0.100000\nTraining Epoch: 2 [49664/50000]\tLoss: 1.0369\tLR: 0.100000\nTraining Epoch: 2 [49792/50000]\tLoss: 1.0992\tLR: 0.100000\nTraining Epoch: 2 [49920/50000]\tLoss: 0.9932\tLR: 0.100000\nTraining Epoch: 2 [50000/50000]\tLoss: 0.9129\tLR: 0.100000\nTest set: Average loss: 0.0091, Accuracy: 0.6047\n\nTraining Epoch: 3 [128/50000]\tLoss: 1.0579\tLR: 0.100000\nTraining Epoch: 3 [256/50000]\tLoss: 1.0692\tLR: 0.100000\nTraining Epoch: 3 [384/50000]\tLoss: 1.0414\tLR: 0.100000\nTraining Epoch: 3 [512/50000]\tLoss: 1.0228\tLR: 0.100000\nTraining Epoch: 3 [640/50000]\tLoss: 0.9293\tLR: 0.100000\nTraining Epoch: 3 [768/50000]\tLoss: 1.0665\tLR: 0.100000\nTraining Epoch: 3 [896/50000]\tLoss: 0.9963\tLR: 0.100000\nTraining Epoch: 3 [1024/50000]\tLoss: 0.9688\tLR: 0.100000\nTraining Epoch: 3 [1152/50000]\tLoss: 1.1437\tLR: 0.100000\nTraining Epoch: 3 [1280/50000]\tLoss: 1.0497\tLR: 0.100000\nTraining Epoch: 3 [1408/50000]\tLoss: 1.1407\tLR: 0.100000\nTraining Epoch: 3 [1536/50000]\tLoss: 1.0979\tLR: 0.100000\nTraining Epoch: 3 [1664/50000]\tLoss: 1.1308\tLR: 0.100000\nTraining Epoch: 3 [1792/50000]\tLoss: 0.9855\tLR: 0.100000\nTraining Epoch: 3 [1920/50000]\tLoss: 1.3928\tLR: 0.100000\nTraining Epoch: 3 [2048/50000]\tLoss: 0.9638\tLR: 0.100000\nTraining Epoch: 3 [2176/50000]\tLoss: 1.0168\tLR: 0.100000\nTraining Epoch: 3 [2304/50000]\tLoss: 1.2208\tLR: 0.100000\nTraining Epoch: 3 [2432/50000]\tLoss: 1.2388\tLR: 0.100000\nTraining Epoch: 3 [2560/50000]\tLoss: 1.2539\tLR: 0.100000\nTraining Epoch: 3 [2688/50000]\tLoss: 1.1661\tLR: 0.100000\nTraining Epoch: 3 [2816/50000]\tLoss: 0.9344\tLR: 0.100000\nTraining Epoch: 3 [2944/50000]\tLoss: 1.0714\tLR: 0.100000\nTraining Epoch: 3 [3072/50000]\tLoss: 1.1094\tLR: 0.100000\nTraining Epoch: 3 [3200/50000]\tLoss: 1.1010\tLR: 0.100000\nTraining Epoch: 3 [3328/50000]\tLoss: 1.0949\tLR: 0.100000\nTraining Epoch: 3 [3456/50000]\tLoss: 1.1576\tLR: 0.100000\nTraining Epoch: 3 [3584/50000]\tLoss: 0.9257\tLR: 0.100000\nTraining Epoch: 3 [3712/50000]\tLoss: 0.9290\tLR: 0.100000\nTraining Epoch: 3 [3840/50000]\tLoss: 0.9712\tLR: 0.100000\nTraining Epoch: 3 [3968/50000]\tLoss: 0.8551\tLR: 0.100000\nTraining Epoch: 3 [4096/50000]\tLoss: 1.0513\tLR: 0.100000\nTraining Epoch: 3 [4224/50000]\tLoss: 0.9923\tLR: 0.100000\nTraining Epoch: 3 [4352/50000]\tLoss: 1.1346\tLR: 0.100000\nTraining Epoch: 3 [4480/50000]\tLoss: 1.0715\tLR: 0.100000\nTraining Epoch: 3 [4608/50000]\tLoss: 1.1930\tLR: 0.100000\nTraining Epoch: 3 [4736/50000]\tLoss: 0.9708\tLR: 0.100000\nTraining Epoch: 3 [4864/50000]\tLoss: 1.0101\tLR: 0.100000\nTraining Epoch: 3 [4992/50000]\tLoss: 0.7993\tLR: 0.100000\nTraining Epoch: 3 [5120/50000]\tLoss: 0.9789\tLR: 0.100000\nTraining Epoch: 3 [5248/50000]\tLoss: 1.2635\tLR: 0.100000\nTraining Epoch: 3 [5376/50000]\tLoss: 0.9375\tLR: 0.100000\nTraining Epoch: 3 [5504/50000]\tLoss: 1.0257\tLR: 0.100000\nTraining Epoch: 3 [5632/50000]\tLoss: 0.9328\tLR: 0.100000\nTraining Epoch: 3 [5760/50000]\tLoss: 1.1639\tLR: 0.100000\nTraining Epoch: 3 [5888/50000]\tLoss: 0.9369\tLR: 0.100000\nTraining Epoch: 3 [6016/50000]\tLoss: 0.9557\tLR: 0.100000\nTraining Epoch: 3 [6144/50000]\tLoss: 0.8595\tLR: 0.100000\nTraining Epoch: 3 [6272/50000]\tLoss: 1.0688\tLR: 0.100000\nTraining Epoch: 3 [6400/50000]\tLoss: 0.9330\tLR: 0.100000\nTraining Epoch: 3 [6528/50000]\tLoss: 1.0523\tLR: 0.100000\nTraining Epoch: 3 [6656/50000]\tLoss: 1.1277\tLR: 0.100000\nTraining Epoch: 3 [6784/50000]\tLoss: 1.0352\tLR: 0.100000\nTraining Epoch: 3 [6912/50000]\tLoss: 0.9196\tLR: 0.100000\nTraining Epoch: 3 [7040/50000]\tLoss: 1.0495\tLR: 0.100000\nTraining Epoch: 3 [7168/50000]\tLoss: 0.9936\tLR: 0.100000\nTraining Epoch: 3 [7296/50000]\tLoss: 0.9591\tLR: 0.100000\nTraining Epoch: 3 [7424/50000]\tLoss: 0.9234\tLR: 0.100000\nTraining Epoch: 3 [7552/50000]\tLoss: 0.9506\tLR: 0.100000\nTraining Epoch: 3 [7680/50000]\tLoss: 0.8594\tLR: 0.100000\nTraining Epoch: 3 [7808/50000]\tLoss: 0.9759\tLR: 0.100000\nTraining Epoch: 3 [7936/50000]\tLoss: 1.1117\tLR: 0.100000\nTraining Epoch: 3 [8064/50000]\tLoss: 1.1196\tLR: 0.100000\nTraining Epoch: 3 [8192/50000]\tLoss: 1.1612\tLR: 0.100000\nTraining Epoch: 3 [8320/50000]\tLoss: 1.1017\tLR: 0.100000\nTraining Epoch: 3 [8448/50000]\tLoss: 0.9799\tLR: 0.100000\nTraining Epoch: 3 [8576/50000]\tLoss: 0.9684\tLR: 0.100000\nTraining Epoch: 3 [8704/50000]\tLoss: 1.0134\tLR: 0.100000\nTraining Epoch: 3 [8832/50000]\tLoss: 0.9690\tLR: 0.100000\nTraining Epoch: 3 [8960/50000]\tLoss: 0.9620\tLR: 0.100000\nTraining Epoch: 3 [9088/50000]\tLoss: 1.0000\tLR: 0.100000\nTraining Epoch: 3 [9216/50000]\tLoss: 1.1082\tLR: 0.100000\nTraining Epoch: 3 [9344/50000]\tLoss: 0.9646\tLR: 0.100000\nTraining Epoch: 3 [9472/50000]\tLoss: 0.8585\tLR: 0.100000\nTraining Epoch: 3 [9600/50000]\tLoss: 1.0526\tLR: 0.100000\nTraining Epoch: 3 [9728/50000]\tLoss: 1.0050\tLR: 0.100000\nTraining Epoch: 3 [9856/50000]\tLoss: 1.2244\tLR: 0.100000\nTraining Epoch: 3 [9984/50000]\tLoss: 1.0405\tLR: 0.100000\nTraining Epoch: 3 [10112/50000]\tLoss: 0.8498\tLR: 0.100000\nTraining Epoch: 3 [10240/50000]\tLoss: 0.9344\tLR: 0.100000\nTraining Epoch: 3 [10368/50000]\tLoss: 1.0483\tLR: 0.100000\nTraining Epoch: 3 [10496/50000]\tLoss: 1.0120\tLR: 0.100000\nTraining Epoch: 3 [10624/50000]\tLoss: 0.7882\tLR: 0.100000\nTraining Epoch: 3 [10752/50000]\tLoss: 0.9553\tLR: 0.100000\nTraining Epoch: 3 [10880/50000]\tLoss: 1.1079\tLR: 0.100000\nTraining Epoch: 3 [11008/50000]\tLoss: 0.9829\tLR: 0.100000\nTraining Epoch: 3 [11136/50000]\tLoss: 1.1682\tLR: 0.100000\nTraining Epoch: 3 [11264/50000]\tLoss: 0.9304\tLR: 0.100000\nTraining Epoch: 3 [11392/50000]\tLoss: 1.0612\tLR: 0.100000\nTraining Epoch: 3 [11520/50000]\tLoss: 0.9477\tLR: 0.100000\nTraining Epoch: 3 [11648/50000]\tLoss: 0.9427\tLR: 0.100000\nTraining Epoch: 3 [11776/50000]\tLoss: 0.9646\tLR: 0.100000\nTraining Epoch: 3 [11904/50000]\tLoss: 0.9319\tLR: 0.100000\nTraining Epoch: 3 [12032/50000]\tLoss: 0.9786\tLR: 0.100000\nTraining Epoch: 3 [12160/50000]\tLoss: 0.9460\tLR: 0.100000\nTraining Epoch: 3 [12288/50000]\tLoss: 0.8996\tLR: 0.100000\nTraining Epoch: 3 [12416/50000]\tLoss: 0.9373\tLR: 0.100000\nTraining Epoch: 3 [12544/50000]\tLoss: 1.1530\tLR: 0.100000\nTraining Epoch: 3 [12672/50000]\tLoss: 0.9089\tLR: 0.100000\nTraining Epoch: 3 [12800/50000]\tLoss: 1.0363\tLR: 0.100000\nTraining Epoch: 3 [12928/50000]\tLoss: 1.0499\tLR: 0.100000\nTraining Epoch: 3 [13056/50000]\tLoss: 0.9543\tLR: 0.100000\nTraining Epoch: 3 [13184/50000]\tLoss: 0.9659\tLR: 0.100000\nTraining Epoch: 3 [13312/50000]\tLoss: 0.9706\tLR: 0.100000\nTraining Epoch: 3 [13440/50000]\tLoss: 1.1248\tLR: 0.100000\nTraining Epoch: 3 [13568/50000]\tLoss: 0.9558\tLR: 0.100000\nTraining Epoch: 3 [13696/50000]\tLoss: 1.0411\tLR: 0.100000\nTraining Epoch: 3 [13824/50000]\tLoss: 0.9059\tLR: 0.100000\nTraining Epoch: 3 [13952/50000]\tLoss: 1.0401\tLR: 0.100000\nTraining Epoch: 3 [14080/50000]\tLoss: 1.0121\tLR: 0.100000\nTraining Epoch: 3 [14208/50000]\tLoss: 0.9037\tLR: 0.100000\nTraining Epoch: 3 [14336/50000]\tLoss: 1.0266\tLR: 0.100000\nTraining Epoch: 3 [14464/50000]\tLoss: 0.8982\tLR: 0.100000\nTraining Epoch: 3 [14592/50000]\tLoss: 0.8639\tLR: 0.100000\nTraining Epoch: 3 [14720/50000]\tLoss: 1.1446\tLR: 0.100000\nTraining Epoch: 3 [14848/50000]\tLoss: 1.1220\tLR: 0.100000\nTraining Epoch: 3 [14976/50000]\tLoss: 0.9925\tLR: 0.100000\nTraining Epoch: 3 [15104/50000]\tLoss: 1.1867\tLR: 0.100000\nTraining Epoch: 3 [15232/50000]\tLoss: 0.9300\tLR: 0.100000\nTraining Epoch: 3 [15360/50000]\tLoss: 1.0926\tLR: 0.100000\nTraining Epoch: 3 [15488/50000]\tLoss: 0.9768\tLR: 0.100000\nTraining Epoch: 3 [15616/50000]\tLoss: 0.9177\tLR: 0.100000\nTraining Epoch: 3 [15744/50000]\tLoss: 0.8929\tLR: 0.100000\nTraining Epoch: 3 [15872/50000]\tLoss: 0.9849\tLR: 0.100000\nTraining Epoch: 3 [16000/50000]\tLoss: 0.8931\tLR: 0.100000\nTraining Epoch: 3 [16128/50000]\tLoss: 1.0489\tLR: 0.100000\nTraining Epoch: 3 [16256/50000]\tLoss: 0.9631\tLR: 0.100000\nTraining Epoch: 3 [16384/50000]\tLoss: 0.7754\tLR: 0.100000\nTraining Epoch: 3 [16512/50000]\tLoss: 0.9826\tLR: 0.100000\nTraining Epoch: 3 [16640/50000]\tLoss: 0.9608\tLR: 0.100000\nTraining Epoch: 3 [16768/50000]\tLoss: 1.1997\tLR: 0.100000\nTraining Epoch: 3 [16896/50000]\tLoss: 1.0887\tLR: 0.100000\nTraining Epoch: 3 [17024/50000]\tLoss: 0.9260\tLR: 0.100000\nTraining Epoch: 3 [17152/50000]\tLoss: 0.9241\tLR: 0.100000\nTraining Epoch: 3 [17280/50000]\tLoss: 0.8449\tLR: 0.100000\nTraining Epoch: 3 [17408/50000]\tLoss: 0.9188\tLR: 0.100000\nTraining Epoch: 3 [17536/50000]\tLoss: 1.0796\tLR: 0.100000\nTraining Epoch: 3 [17664/50000]\tLoss: 0.9492\tLR: 0.100000\nTraining Epoch: 3 [17792/50000]\tLoss: 0.8579\tLR: 0.100000\nTraining Epoch: 3 [17920/50000]\tLoss: 1.0626\tLR: 0.100000\nTraining Epoch: 3 [18048/50000]\tLoss: 0.9729\tLR: 0.100000\nTraining Epoch: 3 [18176/50000]\tLoss: 1.0748\tLR: 0.100000\nTraining Epoch: 3 [18304/50000]\tLoss: 0.9117\tLR: 0.100000\nTraining Epoch: 3 [18432/50000]\tLoss: 1.0326\tLR: 0.100000\nTraining Epoch: 3 [18560/50000]\tLoss: 0.9835\tLR: 0.100000\nTraining Epoch: 3 [18688/50000]\tLoss: 0.8977\tLR: 0.100000\nTraining Epoch: 3 [18816/50000]\tLoss: 0.9768\tLR: 0.100000\nTraining Epoch: 3 [18944/50000]\tLoss: 0.9346\tLR: 0.100000\nTraining Epoch: 3 [19072/50000]\tLoss: 0.8863\tLR: 0.100000\nTraining Epoch: 3 [19200/50000]\tLoss: 0.8640\tLR: 0.100000\nTraining Epoch: 3 [19328/50000]\tLoss: 1.0934\tLR: 0.100000\nTraining Epoch: 3 [19456/50000]\tLoss: 0.8635\tLR: 0.100000\nTraining Epoch: 3 [19584/50000]\tLoss: 1.2217\tLR: 0.100000\nTraining Epoch: 3 [19712/50000]\tLoss: 1.0163\tLR: 0.100000\nTraining Epoch: 3 [19840/50000]\tLoss: 0.9642\tLR: 0.100000\nTraining Epoch: 3 [19968/50000]\tLoss: 1.0124\tLR: 0.100000\nTraining Epoch: 3 [20096/50000]\tLoss: 0.8704\tLR: 0.100000\nTraining Epoch: 3 [20224/50000]\tLoss: 1.0037\tLR: 0.100000\nTraining Epoch: 3 [20352/50000]\tLoss: 1.0791\tLR: 0.100000\nTraining Epoch: 3 [20480/50000]\tLoss: 1.0482\tLR: 0.100000\nTraining Epoch: 3 [20608/50000]\tLoss: 1.0158\tLR: 0.100000\nTraining Epoch: 3 [20736/50000]\tLoss: 0.8486\tLR: 0.100000\nTraining Epoch: 3 [20864/50000]\tLoss: 1.0069\tLR: 0.100000\nTraining Epoch: 3 [20992/50000]\tLoss: 0.8953\tLR: 0.100000\nTraining Epoch: 3 [21120/50000]\tLoss: 0.9737\tLR: 0.100000\nTraining Epoch: 3 [21248/50000]\tLoss: 0.8098\tLR: 0.100000\nTraining Epoch: 3 [21376/50000]\tLoss: 0.9579\tLR: 0.100000\nTraining Epoch: 3 [21504/50000]\tLoss: 0.9265\tLR: 0.100000\nTraining Epoch: 3 [21632/50000]\tLoss: 0.7722\tLR: 0.100000\nTraining Epoch: 3 [21760/50000]\tLoss: 0.8161\tLR: 0.100000\nTraining Epoch: 3 [21888/50000]\tLoss: 1.1622\tLR: 0.100000\nTraining Epoch: 3 [22016/50000]\tLoss: 1.0406\tLR: 0.100000\nTraining Epoch: 3 [22144/50000]\tLoss: 1.0261\tLR: 0.100000\nTraining Epoch: 3 [22272/50000]\tLoss: 1.0270\tLR: 0.100000\nTraining Epoch: 3 [22400/50000]\tLoss: 1.1769\tLR: 0.100000\nTraining Epoch: 3 [22528/50000]\tLoss: 1.0681\tLR: 0.100000\nTraining Epoch: 3 [22656/50000]\tLoss: 1.1126\tLR: 0.100000\nTraining Epoch: 3 [22784/50000]\tLoss: 0.9719\tLR: 0.100000\nTraining Epoch: 3 [22912/50000]\tLoss: 0.8817\tLR: 0.100000\nTraining Epoch: 3 [23040/50000]\tLoss: 0.9998\tLR: 0.100000\nTraining Epoch: 3 [23168/50000]\tLoss: 0.8169\tLR: 0.100000\nTraining Epoch: 3 [23296/50000]\tLoss: 1.0417\tLR: 0.100000\nTraining Epoch: 3 [23424/50000]\tLoss: 0.9032\tLR: 0.100000\nTraining Epoch: 3 [23552/50000]\tLoss: 0.9555\tLR: 0.100000\nTraining Epoch: 3 [23680/50000]\tLoss: 0.8941\tLR: 0.100000\nTraining Epoch: 3 [23808/50000]\tLoss: 0.9926\tLR: 0.100000\nTraining Epoch: 3 [23936/50000]\tLoss: 0.9660\tLR: 0.100000\nTraining Epoch: 3 [24064/50000]\tLoss: 1.0333\tLR: 0.100000\nTraining Epoch: 3 [24192/50000]\tLoss: 0.8913\tLR: 0.100000\nTraining Epoch: 3 [24320/50000]\tLoss: 0.9081\tLR: 0.100000\nTraining Epoch: 3 [24448/50000]\tLoss: 0.8694\tLR: 0.100000\nTraining Epoch: 3 [24576/50000]\tLoss: 0.7810\tLR: 0.100000\nTraining Epoch: 3 [24704/50000]\tLoss: 1.0015\tLR: 0.100000\nTraining Epoch: 3 [24832/50000]\tLoss: 0.7763\tLR: 0.100000\nTraining Epoch: 3 [24960/50000]\tLoss: 0.7696\tLR: 0.100000\nTraining Epoch: 3 [25088/50000]\tLoss: 0.9996\tLR: 0.100000\nTraining Epoch: 3 [25216/50000]\tLoss: 1.1040\tLR: 0.100000\nTraining Epoch: 3 [25344/50000]\tLoss: 0.8168\tLR: 0.100000\nTraining Epoch: 3 [25472/50000]\tLoss: 0.8435\tLR: 0.100000\nTraining Epoch: 3 [25600/50000]\tLoss: 0.8695\tLR: 0.100000\nTraining Epoch: 3 [25728/50000]\tLoss: 0.7900\tLR: 0.100000\nTraining Epoch: 3 [25856/50000]\tLoss: 0.9442\tLR: 0.100000\nTraining Epoch: 3 [25984/50000]\tLoss: 0.9573\tLR: 0.100000\nTraining Epoch: 3 [26112/50000]\tLoss: 0.8582\tLR: 0.100000\nTraining Epoch: 3 [26240/50000]\tLoss: 0.8797\tLR: 0.100000\nTraining Epoch: 3 [26368/50000]\tLoss: 0.9460\tLR: 0.100000\nTraining Epoch: 3 [26496/50000]\tLoss: 0.9933\tLR: 0.100000\nTraining Epoch: 3 [26624/50000]\tLoss: 0.9761\tLR: 0.100000\nTraining Epoch: 3 [26752/50000]\tLoss: 1.0977\tLR: 0.100000\nTraining Epoch: 3 [26880/50000]\tLoss: 1.1521\tLR: 0.100000\nTraining Epoch: 3 [27008/50000]\tLoss: 1.0654\tLR: 0.100000\nTraining Epoch: 3 [27136/50000]\tLoss: 1.0871\tLR: 0.100000\nTraining Epoch: 3 [27264/50000]\tLoss: 0.9018\tLR: 0.100000\nTraining Epoch: 3 [27392/50000]\tLoss: 0.9112\tLR: 0.100000\nTraining Epoch: 3 [27520/50000]\tLoss: 0.8133\tLR: 0.100000\nTraining Epoch: 3 [27648/50000]\tLoss: 0.8738\tLR: 0.100000\nTraining Epoch: 3 [27776/50000]\tLoss: 1.0129\tLR: 0.100000\nTraining Epoch: 3 [27904/50000]\tLoss: 1.0153\tLR: 0.100000\nTraining Epoch: 3 [28032/50000]\tLoss: 1.0176\tLR: 0.100000\nTraining Epoch: 3 [28160/50000]\tLoss: 1.1728\tLR: 0.100000\nTraining Epoch: 3 [28288/50000]\tLoss: 0.9801\tLR: 0.100000\nTraining Epoch: 3 [28416/50000]\tLoss: 0.8945\tLR: 0.100000\nTraining Epoch: 3 [28544/50000]\tLoss: 0.8507\tLR: 0.100000\nTraining Epoch: 3 [28672/50000]\tLoss: 0.9098\tLR: 0.100000\nTraining Epoch: 3 [28800/50000]\tLoss: 0.9449\tLR: 0.100000\nTraining Epoch: 3 [28928/50000]\tLoss: 0.9429\tLR: 0.100000\nTraining Epoch: 3 [29056/50000]\tLoss: 0.9729\tLR: 0.100000\nTraining Epoch: 3 [29184/50000]\tLoss: 0.9736\tLR: 0.100000\nTraining Epoch: 3 [29312/50000]\tLoss: 0.8341\tLR: 0.100000\nTraining Epoch: 3 [29440/50000]\tLoss: 0.9511\tLR: 0.100000\nTraining Epoch: 3 [29568/50000]\tLoss: 0.9415\tLR: 0.100000\nTraining Epoch: 3 [29696/50000]\tLoss: 0.9861\tLR: 0.100000\nTraining Epoch: 3 [29824/50000]\tLoss: 0.7555\tLR: 0.100000\nTraining Epoch: 3 [29952/50000]\tLoss: 0.8391\tLR: 0.100000\nTraining Epoch: 3 [30080/50000]\tLoss: 0.8377\tLR: 0.100000\nTraining Epoch: 3 [30208/50000]\tLoss: 0.8680\tLR: 0.100000\nTraining Epoch: 3 [30336/50000]\tLoss: 0.9090\tLR: 0.100000\nTraining Epoch: 3 [30464/50000]\tLoss: 0.8305\tLR: 0.100000\nTraining Epoch: 3 [30592/50000]\tLoss: 1.1528\tLR: 0.100000\nTraining Epoch: 3 [30720/50000]\tLoss: 1.1302\tLR: 0.100000\nTraining Epoch: 3 [30848/50000]\tLoss: 0.8103\tLR: 0.100000\nTraining Epoch: 3 [30976/50000]\tLoss: 0.7252\tLR: 0.100000\nTraining Epoch: 3 [31104/50000]\tLoss: 0.9468\tLR: 0.100000\nTraining Epoch: 3 [31232/50000]\tLoss: 1.0430\tLR: 0.100000\nTraining Epoch: 3 [31360/50000]\tLoss: 1.0489\tLR: 0.100000\nTraining Epoch: 3 [31488/50000]\tLoss: 0.8860\tLR: 0.100000\nTraining Epoch: 3 [31616/50000]\tLoss: 0.8670\tLR: 0.100000\nTraining Epoch: 3 [31744/50000]\tLoss: 0.8891\tLR: 0.100000\nTraining Epoch: 3 [31872/50000]\tLoss: 0.9569\tLR: 0.100000\nTraining Epoch: 3 [32000/50000]\tLoss: 0.9824\tLR: 0.100000\nTraining Epoch: 3 [32128/50000]\tLoss: 0.8907\tLR: 0.100000\nTraining Epoch: 3 [32256/50000]\tLoss: 0.7792\tLR: 0.100000\nTraining Epoch: 3 [32384/50000]\tLoss: 1.1041\tLR: 0.100000\nTraining Epoch: 3 [32512/50000]\tLoss: 1.0807\tLR: 0.100000\nTraining Epoch: 3 [32640/50000]\tLoss: 0.8134\tLR: 0.100000\nTraining Epoch: 3 [32768/50000]\tLoss: 0.9509\tLR: 0.100000\nTraining Epoch: 3 [32896/50000]\tLoss: 0.9214\tLR: 0.100000\nTraining Epoch: 3 [33024/50000]\tLoss: 0.8824\tLR: 0.100000\nTraining Epoch: 3 [33152/50000]\tLoss: 0.9077\tLR: 0.100000\nTraining Epoch: 3 [33280/50000]\tLoss: 0.8789\tLR: 0.100000\nTraining Epoch: 3 [33408/50000]\tLoss: 0.8932\tLR: 0.100000\nTraining Epoch: 3 [33536/50000]\tLoss: 0.8341\tLR: 0.100000\nTraining Epoch: 3 [33664/50000]\tLoss: 1.1724\tLR: 0.100000\nTraining Epoch: 3 [33792/50000]\tLoss: 1.0157\tLR: 0.100000\nTraining Epoch: 3 [33920/50000]\tLoss: 0.9121\tLR: 0.100000\nTraining Epoch: 3 [34048/50000]\tLoss: 1.0106\tLR: 0.100000\nTraining Epoch: 3 [34176/50000]\tLoss: 0.9868\tLR: 0.100000\nTraining Epoch: 3 [34304/50000]\tLoss: 1.0466\tLR: 0.100000\nTraining Epoch: 3 [34432/50000]\tLoss: 0.9394\tLR: 0.100000\nTraining Epoch: 3 [34560/50000]\tLoss: 0.9727\tLR: 0.100000\nTraining Epoch: 3 [34688/50000]\tLoss: 0.8598\tLR: 0.100000\nTraining Epoch: 3 [34816/50000]\tLoss: 0.9029\tLR: 0.100000\nTraining Epoch: 3 [34944/50000]\tLoss: 0.9969\tLR: 0.100000\nTraining Epoch: 3 [35072/50000]\tLoss: 0.7726\tLR: 0.100000\nTraining Epoch: 3 [35200/50000]\tLoss: 0.8156\tLR: 0.100000\nTraining Epoch: 3 [35328/50000]\tLoss: 0.9227\tLR: 0.100000\nTraining Epoch: 3 [35456/50000]\tLoss: 0.8978\tLR: 0.100000\nTraining Epoch: 3 [35584/50000]\tLoss: 0.8966\tLR: 0.100000\nTraining Epoch: 3 [35712/50000]\tLoss: 1.0558\tLR: 0.100000\nTraining Epoch: 3 [35840/50000]\tLoss: 0.9664\tLR: 0.100000\nTraining Epoch: 3 [35968/50000]\tLoss: 0.8071\tLR: 0.100000\nTraining Epoch: 3 [36096/50000]\tLoss: 1.0885\tLR: 0.100000\nTraining Epoch: 3 [36224/50000]\tLoss: 1.0483\tLR: 0.100000\nTraining Epoch: 3 [36352/50000]\tLoss: 0.7878\tLR: 0.100000\nTraining Epoch: 3 [36480/50000]\tLoss: 1.0762\tLR: 0.100000\nTraining Epoch: 3 [36608/50000]\tLoss: 0.8583\tLR: 0.100000\nTraining Epoch: 3 [36736/50000]\tLoss: 1.0067\tLR: 0.100000\nTraining Epoch: 3 [36864/50000]\tLoss: 0.7255\tLR: 0.100000\nTraining Epoch: 3 [36992/50000]\tLoss: 0.9942\tLR: 0.100000\nTraining Epoch: 3 [37120/50000]\tLoss: 0.9070\tLR: 0.100000\nTraining Epoch: 3 [37248/50000]\tLoss: 0.8523\tLR: 0.100000\nTraining Epoch: 3 [37376/50000]\tLoss: 0.9233\tLR: 0.100000\nTraining Epoch: 3 [37504/50000]\tLoss: 0.8254\tLR: 0.100000\nTraining Epoch: 3 [37632/50000]\tLoss: 0.8519\tLR: 0.100000\nTraining Epoch: 3 [37760/50000]\tLoss: 0.7622\tLR: 0.100000\nTraining Epoch: 3 [37888/50000]\tLoss: 0.8798\tLR: 0.100000\nTraining Epoch: 3 [38016/50000]\tLoss: 1.1827\tLR: 0.100000\nTraining Epoch: 3 [38144/50000]\tLoss: 0.8390\tLR: 0.100000\nTraining Epoch: 3 [38272/50000]\tLoss: 0.9054\tLR: 0.100000\nTraining Epoch: 3 [38400/50000]\tLoss: 0.8165\tLR: 0.100000\nTraining Epoch: 3 [38528/50000]\tLoss: 0.8962\tLR: 0.100000\nTraining Epoch: 3 [38656/50000]\tLoss: 1.0762\tLR: 0.100000\nTraining Epoch: 3 [38784/50000]\tLoss: 0.9508\tLR: 0.100000\nTraining Epoch: 3 [38912/50000]\tLoss: 0.9562\tLR: 0.100000\nTraining Epoch: 3 [39040/50000]\tLoss: 0.8641\tLR: 0.100000\nTraining Epoch: 3 [39168/50000]\tLoss: 1.0666\tLR: 0.100000\nTraining Epoch: 3 [39296/50000]\tLoss: 1.1123\tLR: 0.100000\nTraining Epoch: 3 [39424/50000]\tLoss: 1.0394\tLR: 0.100000\nTraining Epoch: 3 [39552/50000]\tLoss: 0.9905\tLR: 0.100000\nTraining Epoch: 3 [39680/50000]\tLoss: 0.8654\tLR: 0.100000\nTraining Epoch: 3 [39808/50000]\tLoss: 0.6694\tLR: 0.100000\nTraining Epoch: 3 [39936/50000]\tLoss: 0.8646\tLR: 0.100000\nTraining Epoch: 3 [40064/50000]\tLoss: 0.7394\tLR: 0.100000\nTraining Epoch: 3 [40192/50000]\tLoss: 1.0229\tLR: 0.100000\nTraining Epoch: 3 [40320/50000]\tLoss: 1.0435\tLR: 0.100000\nTraining Epoch: 3 [40448/50000]\tLoss: 0.9323\tLR: 0.100000\nTraining Epoch: 3 [40576/50000]\tLoss: 0.7917\tLR: 0.100000\nTraining Epoch: 3 [40704/50000]\tLoss: 1.1363\tLR: 0.100000\nTraining Epoch: 3 [40832/50000]\tLoss: 0.8532\tLR: 0.100000\nTraining Epoch: 3 [40960/50000]\tLoss: 0.9123\tLR: 0.100000\nTraining Epoch: 3 [41088/50000]\tLoss: 0.8722\tLR: 0.100000\nTraining Epoch: 3 [41216/50000]\tLoss: 0.8402\tLR: 0.100000\nTraining Epoch: 3 [41344/50000]\tLoss: 0.8403\tLR: 0.100000\nTraining Epoch: 3 [41472/50000]\tLoss: 0.7607\tLR: 0.100000\nTraining Epoch: 3 [41600/50000]\tLoss: 0.8037\tLR: 0.100000\nTraining Epoch: 3 [41728/50000]\tLoss: 0.8660\tLR: 0.100000\nTraining Epoch: 3 [41856/50000]\tLoss: 0.9560\tLR: 0.100000\nTraining Epoch: 3 [41984/50000]\tLoss: 0.9237\tLR: 0.100000\nTraining Epoch: 3 [42112/50000]\tLoss: 0.8088\tLR: 0.100000\nTraining Epoch: 3 [42240/50000]\tLoss: 1.0033\tLR: 0.100000\nTraining Epoch: 3 [42368/50000]\tLoss: 0.8923\tLR: 0.100000\nTraining Epoch: 3 [42496/50000]\tLoss: 0.7043\tLR: 0.100000\nTraining Epoch: 3 [42624/50000]\tLoss: 0.9905\tLR: 0.100000\nTraining Epoch: 3 [42752/50000]\tLoss: 0.8766\tLR: 0.100000\nTraining Epoch: 3 [42880/50000]\tLoss: 0.7486\tLR: 0.100000\nTraining Epoch: 3 [43008/50000]\tLoss: 1.1288\tLR: 0.100000\nTraining Epoch: 3 [43136/50000]\tLoss: 0.7446\tLR: 0.100000\nTraining Epoch: 3 [43264/50000]\tLoss: 1.0586\tLR: 0.100000\nTraining Epoch: 3 [43392/50000]\tLoss: 0.9171\tLR: 0.100000\nTraining Epoch: 3 [43520/50000]\tLoss: 1.1723\tLR: 0.100000\nTraining Epoch: 3 [43648/50000]\tLoss: 0.7708\tLR: 0.100000\nTraining Epoch: 3 [43776/50000]\tLoss: 0.9177\tLR: 0.100000\nTraining Epoch: 3 [43904/50000]\tLoss: 0.7833\tLR: 0.100000\nTraining Epoch: 3 [44032/50000]\tLoss: 0.8297\tLR: 0.100000\nTraining Epoch: 3 [44160/50000]\tLoss: 0.8319\tLR: 0.100000\nTraining Epoch: 3 [44288/50000]\tLoss: 0.6476\tLR: 0.100000\nTraining Epoch: 3 [44416/50000]\tLoss: 0.9428\tLR: 0.100000\nTraining Epoch: 3 [44544/50000]\tLoss: 0.9206\tLR: 0.100000\nTraining Epoch: 3 [44672/50000]\tLoss: 0.8230\tLR: 0.100000\nTraining Epoch: 3 [44800/50000]\tLoss: 0.8867\tLR: 0.100000\nTraining Epoch: 3 [44928/50000]\tLoss: 0.9283\tLR: 0.100000\nTraining Epoch: 3 [45056/50000]\tLoss: 0.8581\tLR: 0.100000\nTraining Epoch: 3 [45184/50000]\tLoss: 0.8022\tLR: 0.100000\nTraining Epoch: 3 [45312/50000]\tLoss: 0.8742\tLR: 0.100000\nTraining Epoch: 3 [45440/50000]\tLoss: 0.9901\tLR: 0.100000\nTraining Epoch: 3 [45568/50000]\tLoss: 0.8251\tLR: 0.100000\nTraining Epoch: 3 [45696/50000]\tLoss: 0.8629\tLR: 0.100000\nTraining Epoch: 3 [45824/50000]\tLoss: 1.0371\tLR: 0.100000\nTraining Epoch: 3 [45952/50000]\tLoss: 0.8189\tLR: 0.100000\nTraining Epoch: 3 [46080/50000]\tLoss: 0.9374\tLR: 0.100000\nTraining Epoch: 3 [46208/50000]\tLoss: 0.9365\tLR: 0.100000\nTraining Epoch: 3 [46336/50000]\tLoss: 0.8129\tLR: 0.100000\nTraining Epoch: 3 [46464/50000]\tLoss: 0.8150\tLR: 0.100000\nTraining Epoch: 3 [46592/50000]\tLoss: 0.7906\tLR: 0.100000\nTraining Epoch: 3 [46720/50000]\tLoss: 0.7750\tLR: 0.100000\nTraining Epoch: 3 [46848/50000]\tLoss: 0.9207\tLR: 0.100000\nTraining Epoch: 3 [46976/50000]\tLoss: 0.8834\tLR: 0.100000\nTraining Epoch: 3 [47104/50000]\tLoss: 1.0957\tLR: 0.100000\nTraining Epoch: 3 [47232/50000]\tLoss: 0.8354\tLR: 0.100000\nTraining Epoch: 3 [47360/50000]\tLoss: 0.8212\tLR: 0.100000\nTraining Epoch: 3 [47488/50000]\tLoss: 0.7973\tLR: 0.100000\nTraining Epoch: 3 [47616/50000]\tLoss: 0.8637\tLR: 0.100000\nTraining Epoch: 3 [47744/50000]\tLoss: 0.9788\tLR: 0.100000\nTraining Epoch: 3 [47872/50000]\tLoss: 0.7417\tLR: 0.100000\nTraining Epoch: 3 [48000/50000]\tLoss: 0.9680\tLR: 0.100000\nTraining Epoch: 3 [48128/50000]\tLoss: 0.8313\tLR: 0.100000\nTraining Epoch: 3 [48256/50000]\tLoss: 0.8192\tLR: 0.100000\nTraining Epoch: 3 [48384/50000]\tLoss: 0.8015\tLR: 0.100000\nTraining Epoch: 3 [48512/50000]\tLoss: 0.7757\tLR: 0.100000\nTraining Epoch: 3 [48640/50000]\tLoss: 0.8007\tLR: 0.100000\nTraining Epoch: 3 [48768/50000]\tLoss: 0.8533\tLR: 0.100000\nTraining Epoch: 3 [48896/50000]\tLoss: 0.9237\tLR: 0.100000\nTraining Epoch: 3 [49024/50000]\tLoss: 0.8323\tLR: 0.100000\nTraining Epoch: 3 [49152/50000]\tLoss: 0.9776\tLR: 0.100000\nTraining Epoch: 3 [49280/50000]\tLoss: 0.8652\tLR: 0.100000\nTraining Epoch: 3 [49408/50000]\tLoss: 0.7837\tLR: 0.100000\nTraining Epoch: 3 [49536/50000]\tLoss: 0.9014\tLR: 0.100000\nTraining Epoch: 3 [49664/50000]\tLoss: 0.9447\tLR: 0.100000\nTraining Epoch: 3 [49792/50000]\tLoss: 0.8199\tLR: 0.100000\nTraining Epoch: 3 [49920/50000]\tLoss: 0.8065\tLR: 0.100000\nTraining Epoch: 3 [50000/50000]\tLoss: 0.6157\tLR: 0.100000\nTest set: Average loss: 0.0063, Accuracy: 0.7263\n\nTraining Epoch: 4 [128/50000]\tLoss: 0.7982\tLR: 0.100000\nTraining Epoch: 4 [256/50000]\tLoss: 0.7460\tLR: 0.100000\nTraining Epoch: 4 [384/50000]\tLoss: 0.9755\tLR: 0.100000\nTraining Epoch: 4 [512/50000]\tLoss: 0.9285\tLR: 0.100000\nTraining Epoch: 4 [640/50000]\tLoss: 0.9215\tLR: 0.100000\nTraining Epoch: 4 [768/50000]\tLoss: 0.7753\tLR: 0.100000\nTraining Epoch: 4 [896/50000]\tLoss: 0.8745\tLR: 0.100000\nTraining Epoch: 4 [1024/50000]\tLoss: 0.7960\tLR: 0.100000\nTraining Epoch: 4 [1152/50000]\tLoss: 0.7136\tLR: 0.100000\nTraining Epoch: 4 [1280/50000]\tLoss: 0.6818\tLR: 0.100000\nTraining Epoch: 4 [1408/50000]\tLoss: 0.7192\tLR: 0.100000\nTraining Epoch: 4 [1536/50000]\tLoss: 0.8533\tLR: 0.100000\nTraining Epoch: 4 [1664/50000]\tLoss: 1.0387\tLR: 0.100000\nTraining Epoch: 4 [1792/50000]\tLoss: 0.8150\tLR: 0.100000\nTraining Epoch: 4 [1920/50000]\tLoss: 0.8418\tLR: 0.100000\nTraining Epoch: 4 [2048/50000]\tLoss: 0.8952\tLR: 0.100000\nTraining Epoch: 4 [2176/50000]\tLoss: 0.8454\tLR: 0.100000\nTraining Epoch: 4 [2304/50000]\tLoss: 0.8377\tLR: 0.100000\nTraining Epoch: 4 [2432/50000]\tLoss: 0.9576\tLR: 0.100000\nTraining Epoch: 4 [2560/50000]\tLoss: 0.5981\tLR: 0.100000\nTraining Epoch: 4 [2688/50000]\tLoss: 0.8829\tLR: 0.100000\nTraining Epoch: 4 [2816/50000]\tLoss: 0.8528\tLR: 0.100000\nTraining Epoch: 4 [2944/50000]\tLoss: 0.9580\tLR: 0.100000\nTraining Epoch: 4 [3072/50000]\tLoss: 0.8742\tLR: 0.100000\nTraining Epoch: 4 [3200/50000]\tLoss: 0.9504\tLR: 0.100000\nTraining Epoch: 4 [3328/50000]\tLoss: 1.0462\tLR: 0.100000\nTraining Epoch: 4 [3456/50000]\tLoss: 0.8481\tLR: 0.100000\nTraining Epoch: 4 [3584/50000]\tLoss: 0.8900\tLR: 0.100000\nTraining Epoch: 4 [3712/50000]\tLoss: 0.8249\tLR: 0.100000\nTraining Epoch: 4 [3840/50000]\tLoss: 0.9246\tLR: 0.100000\nTraining Epoch: 4 [3968/50000]\tLoss: 0.9423\tLR: 0.100000\nTraining Epoch: 4 [4096/50000]\tLoss: 0.5305\tLR: 0.100000\nTraining Epoch: 4 [4224/50000]\tLoss: 0.8008\tLR: 0.100000\nTraining Epoch: 4 [4352/50000]\tLoss: 0.7281\tLR: 0.100000\nTraining Epoch: 4 [4480/50000]\tLoss: 0.8200\tLR: 0.100000\nTraining Epoch: 4 [4608/50000]\tLoss: 0.7266\tLR: 0.100000\nTraining Epoch: 4 [4736/50000]\tLoss: 0.9374\tLR: 0.100000\nTraining Epoch: 4 [4864/50000]\tLoss: 0.8006\tLR: 0.100000\nTraining Epoch: 4 [4992/50000]\tLoss: 0.9613\tLR: 0.100000\nTraining Epoch: 4 [5120/50000]\tLoss: 0.7564\tLR: 0.100000\nTraining Epoch: 4 [5248/50000]\tLoss: 0.8151\tLR: 0.100000\nTraining Epoch: 4 [5376/50000]\tLoss: 0.8416\tLR: 0.100000\nTraining Epoch: 4 [5504/50000]\tLoss: 0.7752\tLR: 0.100000\nTraining Epoch: 4 [5632/50000]\tLoss: 0.7358\tLR: 0.100000\nTraining Epoch: 4 [5760/50000]\tLoss: 0.9866\tLR: 0.100000\nTraining Epoch: 4 [5888/50000]\tLoss: 0.8062\tLR: 0.100000\nTraining Epoch: 4 [6016/50000]\tLoss: 0.7280\tLR: 0.100000\nTraining Epoch: 4 [6144/50000]\tLoss: 0.6294\tLR: 0.100000\nTraining Epoch: 4 [6272/50000]\tLoss: 0.8157\tLR: 0.100000\nTraining Epoch: 4 [6400/50000]\tLoss: 0.9331\tLR: 0.100000\nTraining Epoch: 4 [6528/50000]\tLoss: 0.7879\tLR: 0.100000\nTraining Epoch: 4 [6656/50000]\tLoss: 0.7727\tLR: 0.100000\nTraining Epoch: 4 [6784/50000]\tLoss: 0.7511\tLR: 0.100000\nTraining Epoch: 4 [6912/50000]\tLoss: 0.7433\tLR: 0.100000\nTraining Epoch: 4 [7040/50000]\tLoss: 1.0846\tLR: 0.100000\nTraining Epoch: 4 [7168/50000]\tLoss: 1.0599\tLR: 0.100000\nTraining Epoch: 4 [7296/50000]\tLoss: 0.9041\tLR: 0.100000\nTraining Epoch: 4 [7424/50000]\tLoss: 0.7782\tLR: 0.100000\nTraining Epoch: 4 [7552/50000]\tLoss: 0.7929\tLR: 0.100000\nTraining Epoch: 4 [7680/50000]\tLoss: 0.9190\tLR: 0.100000\nTraining Epoch: 4 [7808/50000]\tLoss: 0.7857\tLR: 0.100000\nTraining Epoch: 4 [7936/50000]\tLoss: 0.8379\tLR: 0.100000\nTraining Epoch: 4 [8064/50000]\tLoss: 0.8161\tLR: 0.100000\nTraining Epoch: 4 [8192/50000]\tLoss: 0.7920\tLR: 0.100000\nTraining Epoch: 4 [8320/50000]\tLoss: 0.6583\tLR: 0.100000\nTraining Epoch: 4 [8448/50000]\tLoss: 0.7236\tLR: 0.100000\nTraining Epoch: 4 [8576/50000]\tLoss: 0.8938\tLR: 0.100000\nTraining Epoch: 4 [8704/50000]\tLoss: 0.8396\tLR: 0.100000\nTraining Epoch: 4 [8832/50000]\tLoss: 0.7384\tLR: 0.100000\nTraining Epoch: 4 [8960/50000]\tLoss: 0.8687\tLR: 0.100000\nTraining Epoch: 4 [9088/50000]\tLoss: 0.9352\tLR: 0.100000\nTraining Epoch: 4 [9216/50000]\tLoss: 0.7742\tLR: 0.100000\nTraining Epoch: 4 [9344/50000]\tLoss: 1.0439\tLR: 0.100000\nTraining Epoch: 4 [9472/50000]\tLoss: 0.8318\tLR: 0.100000\nTraining Epoch: 4 [9600/50000]\tLoss: 0.7980\tLR: 0.100000\nTraining Epoch: 4 [9728/50000]\tLoss: 0.7754\tLR: 0.100000\nTraining Epoch: 4 [9856/50000]\tLoss: 0.9000\tLR: 0.100000\nTraining Epoch: 4 [9984/50000]\tLoss: 0.8198\tLR: 0.100000\nTraining Epoch: 4 [10112/50000]\tLoss: 0.7838\tLR: 0.100000\nTraining Epoch: 4 [10240/50000]\tLoss: 0.7866\tLR: 0.100000\nTraining Epoch: 4 [10368/50000]\tLoss: 0.7466\tLR: 0.100000\nTraining Epoch: 4 [10496/50000]\tLoss: 0.7523\tLR: 0.100000\nTraining Epoch: 4 [10624/50000]\tLoss: 0.8977\tLR: 0.100000\nTraining Epoch: 4 [10752/50000]\tLoss: 0.8214\tLR: 0.100000\nTraining Epoch: 4 [10880/50000]\tLoss: 0.7945\tLR: 0.100000\nTraining Epoch: 4 [11008/50000]\tLoss: 0.6626\tLR: 0.100000\nTraining Epoch: 4 [11136/50000]\tLoss: 0.9101\tLR: 0.100000\nTraining Epoch: 4 [11264/50000]\tLoss: 0.8771\tLR: 0.100000\nTraining Epoch: 4 [11392/50000]\tLoss: 0.7146\tLR: 0.100000\nTraining Epoch: 4 [11520/50000]\tLoss: 0.7722\tLR: 0.100000\nTraining Epoch: 4 [11648/50000]\tLoss: 0.9005\tLR: 0.100000\nTraining Epoch: 4 [11776/50000]\tLoss: 0.8309\tLR: 0.100000\nTraining Epoch: 4 [11904/50000]\tLoss: 0.9695\tLR: 0.100000\nTraining Epoch: 4 [12032/50000]\tLoss: 0.8237\tLR: 0.100000\nTraining Epoch: 4 [12160/50000]\tLoss: 0.8361\tLR: 0.100000\nTraining Epoch: 4 [12288/50000]\tLoss: 0.8935\tLR: 0.100000\nTraining Epoch: 4 [12416/50000]\tLoss: 0.7620\tLR: 0.100000\nTraining Epoch: 4 [12544/50000]\tLoss: 0.7723\tLR: 0.100000\nTraining Epoch: 4 [12672/50000]\tLoss: 0.7587\tLR: 0.100000\nTraining Epoch: 4 [12800/50000]\tLoss: 0.8877\tLR: 0.100000\nTraining Epoch: 4 [12928/50000]\tLoss: 0.8321\tLR: 0.100000\nTraining Epoch: 4 [13056/50000]\tLoss: 0.7323\tLR: 0.100000\nTraining Epoch: 4 [13184/50000]\tLoss: 0.8872\tLR: 0.100000\nTraining Epoch: 4 [13312/50000]\tLoss: 0.7546\tLR: 0.100000\nTraining Epoch: 4 [13440/50000]\tLoss: 0.7829\tLR: 0.100000\nTraining Epoch: 4 [13568/50000]\tLoss: 0.7559\tLR: 0.100000\nTraining Epoch: 4 [13696/50000]\tLoss: 0.7799\tLR: 0.100000\nTraining Epoch: 4 [13824/50000]\tLoss: 0.7320\tLR: 0.100000\nTraining Epoch: 4 [13952/50000]\tLoss: 1.0081\tLR: 0.100000\nTraining Epoch: 4 [14080/50000]\tLoss: 0.8027\tLR: 0.100000\nTraining Epoch: 4 [14208/50000]\tLoss: 0.8037\tLR: 0.100000\nTraining Epoch: 4 [14336/50000]\tLoss: 0.7560\tLR: 0.100000\nTraining Epoch: 4 [14464/50000]\tLoss: 0.7960\tLR: 0.100000\nTraining Epoch: 4 [14592/50000]\tLoss: 0.8616\tLR: 0.100000\nTraining Epoch: 4 [14720/50000]\tLoss: 0.8283\tLR: 0.100000\nTraining Epoch: 4 [14848/50000]\tLoss: 0.6622\tLR: 0.100000\nTraining Epoch: 4 [14976/50000]\tLoss: 0.9534\tLR: 0.100000\nTraining Epoch: 4 [15104/50000]\tLoss: 0.9850\tLR: 0.100000\nTraining Epoch: 4 [15232/50000]\tLoss: 1.0206\tLR: 0.100000\nTraining Epoch: 4 [15360/50000]\tLoss: 0.8299\tLR: 0.100000\nTraining Epoch: 4 [15488/50000]\tLoss: 0.7997\tLR: 0.100000\nTraining Epoch: 4 [15616/50000]\tLoss: 0.7414\tLR: 0.100000\nTraining Epoch: 4 [15744/50000]\tLoss: 0.7302\tLR: 0.100000\nTraining Epoch: 4 [15872/50000]\tLoss: 0.7357\tLR: 0.100000\nTraining Epoch: 4 [16000/50000]\tLoss: 0.8391\tLR: 0.100000\nTraining Epoch: 4 [16128/50000]\tLoss: 0.6703\tLR: 0.100000\nTraining Epoch: 4 [16256/50000]\tLoss: 0.8222\tLR: 0.100000\nTraining Epoch: 4 [16384/50000]\tLoss: 0.8528\tLR: 0.100000\nTraining Epoch: 4 [16512/50000]\tLoss: 0.8069\tLR: 0.100000\nTraining Epoch: 4 [16640/50000]\tLoss: 0.7992\tLR: 0.100000\nTraining Epoch: 4 [16768/50000]\tLoss: 0.8920\tLR: 0.100000\nTraining Epoch: 4 [16896/50000]\tLoss: 0.7338\tLR: 0.100000\nTraining Epoch: 4 [17024/50000]\tLoss: 0.6977\tLR: 0.100000\nTraining Epoch: 4 [17152/50000]\tLoss: 0.8509\tLR: 0.100000\nTraining Epoch: 4 [17280/50000]\tLoss: 0.7474\tLR: 0.100000\nTraining Epoch: 4 [17408/50000]\tLoss: 0.9083\tLR: 0.100000\nTraining Epoch: 4 [17536/50000]\tLoss: 0.8591\tLR: 0.100000\nTraining Epoch: 4 [17664/50000]\tLoss: 0.7830\tLR: 0.100000\nTraining Epoch: 4 [17792/50000]\tLoss: 0.8573\tLR: 0.100000\nTraining Epoch: 4 [17920/50000]\tLoss: 0.6649\tLR: 0.100000\nTraining Epoch: 4 [18048/50000]\tLoss: 0.8911\tLR: 0.100000\nTraining Epoch: 4 [18176/50000]\tLoss: 0.9093\tLR: 0.100000\nTraining Epoch: 4 [18304/50000]\tLoss: 0.8303\tLR: 0.100000\nTraining Epoch: 4 [18432/50000]\tLoss: 0.9177\tLR: 0.100000\nTraining Epoch: 4 [18560/50000]\tLoss: 0.9806\tLR: 0.100000\nTraining Epoch: 4 [18688/50000]\tLoss: 0.9769\tLR: 0.100000\nTraining Epoch: 4 [18816/50000]\tLoss: 0.7412\tLR: 0.100000\nTraining Epoch: 4 [18944/50000]\tLoss: 0.7980\tLR: 0.100000\nTraining Epoch: 4 [19072/50000]\tLoss: 0.7678\tLR: 0.100000\nTraining Epoch: 4 [19200/50000]\tLoss: 0.8695\tLR: 0.100000\nTraining Epoch: 4 [19328/50000]\tLoss: 0.9778\tLR: 0.100000\nTraining Epoch: 4 [19456/50000]\tLoss: 0.8903\tLR: 0.100000\nTraining Epoch: 4 [19584/50000]\tLoss: 0.9520\tLR: 0.100000\nTraining Epoch: 4 [19712/50000]\tLoss: 0.8055\tLR: 0.100000\nTraining Epoch: 4 [19840/50000]\tLoss: 0.7051\tLR: 0.100000\nTraining Epoch: 4 [19968/50000]\tLoss: 0.7624\tLR: 0.100000\nTraining Epoch: 4 [20096/50000]\tLoss: 0.7817\tLR: 0.100000\nTraining Epoch: 4 [20224/50000]\tLoss: 0.8013\tLR: 0.100000\nTraining Epoch: 4 [20352/50000]\tLoss: 0.8573\tLR: 0.100000\nTraining Epoch: 4 [20480/50000]\tLoss: 0.8815\tLR: 0.100000\nTraining Epoch: 4 [20608/50000]\tLoss: 0.8822\tLR: 0.100000\nTraining Epoch: 4 [20736/50000]\tLoss: 0.7605\tLR: 0.100000\nTraining Epoch: 4 [20864/50000]\tLoss: 0.8824\tLR: 0.100000\nTraining Epoch: 4 [20992/50000]\tLoss: 0.6873\tLR: 0.100000\nTraining Epoch: 4 [21120/50000]\tLoss: 0.8781\tLR: 0.100000\nTraining Epoch: 4 [21248/50000]\tLoss: 0.7354\tLR: 0.100000\nTraining Epoch: 4 [21376/50000]\tLoss: 0.6876\tLR: 0.100000\nTraining Epoch: 4 [21504/50000]\tLoss: 0.5922\tLR: 0.100000\nTraining Epoch: 4 [21632/50000]\tLoss: 0.7316\tLR: 0.100000\nTraining Epoch: 4 [21760/50000]\tLoss: 0.7942\tLR: 0.100000\nTraining Epoch: 4 [21888/50000]\tLoss: 0.6857\tLR: 0.100000\nTraining Epoch: 4 [22016/50000]\tLoss: 0.5453\tLR: 0.100000\nTraining Epoch: 4 [22144/50000]\tLoss: 0.9745\tLR: 0.100000\nTraining Epoch: 4 [22272/50000]\tLoss: 0.7509\tLR: 0.100000\nTraining Epoch: 4 [22400/50000]\tLoss: 0.8553\tLR: 0.100000\nTraining Epoch: 4 [22528/50000]\tLoss: 0.8376\tLR: 0.100000\nTraining Epoch: 4 [22656/50000]\tLoss: 0.8309\tLR: 0.100000\nTraining Epoch: 4 [22784/50000]\tLoss: 0.8079\tLR: 0.100000\nTraining Epoch: 4 [22912/50000]\tLoss: 0.7903\tLR: 0.100000\nTraining Epoch: 4 [23040/50000]\tLoss: 0.8166\tLR: 0.100000\nTraining Epoch: 4 [23168/50000]\tLoss: 0.7075\tLR: 0.100000\nTraining Epoch: 4 [23296/50000]\tLoss: 0.8363\tLR: 0.100000\nTraining Epoch: 4 [23424/50000]\tLoss: 0.8548\tLR: 0.100000\nTraining Epoch: 4 [23552/50000]\tLoss: 0.8055\tLR: 0.100000\nTraining Epoch: 4 [23680/50000]\tLoss: 0.7019\tLR: 0.100000\nTraining Epoch: 4 [23808/50000]\tLoss: 0.8043\tLR: 0.100000\nTraining Epoch: 4 [23936/50000]\tLoss: 0.7837\tLR: 0.100000\nTraining Epoch: 4 [24064/50000]\tLoss: 0.8391\tLR: 0.100000\nTraining Epoch: 4 [24192/50000]\tLoss: 0.8929\tLR: 0.100000\nTraining Epoch: 4 [24320/50000]\tLoss: 0.6183\tLR: 0.100000\nTraining Epoch: 4 [24448/50000]\tLoss: 0.8249\tLR: 0.100000\nTraining Epoch: 4 [24576/50000]\tLoss: 0.7105\tLR: 0.100000\nTraining Epoch: 4 [24704/50000]\tLoss: 0.6919\tLR: 0.100000\nTraining Epoch: 4 [24832/50000]\tLoss: 0.7874\tLR: 0.100000\nTraining Epoch: 4 [24960/50000]\tLoss: 0.6838\tLR: 0.100000\nTraining Epoch: 4 [25088/50000]\tLoss: 0.7339\tLR: 0.100000\nTraining Epoch: 4 [25216/50000]\tLoss: 0.8308\tLR: 0.100000\nTraining Epoch: 4 [25344/50000]\tLoss: 0.7203\tLR: 0.100000\nTraining Epoch: 4 [25472/50000]\tLoss: 0.8799\tLR: 0.100000\nTraining Epoch: 4 [25600/50000]\tLoss: 0.7635\tLR: 0.100000\nTraining Epoch: 4 [25728/50000]\tLoss: 0.6662\tLR: 0.100000\nTraining Epoch: 4 [25856/50000]\tLoss: 0.7280\tLR: 0.100000\nTraining Epoch: 4 [25984/50000]\tLoss: 0.8016\tLR: 0.100000\nTraining Epoch: 4 [26112/50000]\tLoss: 0.8164\tLR: 0.100000\nTraining Epoch: 4 [26240/50000]\tLoss: 1.0305\tLR: 0.100000\nTraining Epoch: 4 [26368/50000]\tLoss: 0.8083\tLR: 0.100000\nTraining Epoch: 4 [26496/50000]\tLoss: 0.6865\tLR: 0.100000\nTraining Epoch: 4 [26624/50000]\tLoss: 0.8593\tLR: 0.100000\nTraining Epoch: 4 [26752/50000]\tLoss: 0.7351\tLR: 0.100000\nTraining Epoch: 4 [26880/50000]\tLoss: 0.8614\tLR: 0.100000\nTraining Epoch: 4 [27008/50000]\tLoss: 0.8021\tLR: 0.100000\nTraining Epoch: 4 [27136/50000]\tLoss: 0.6909\tLR: 0.100000\nTraining Epoch: 4 [27264/50000]\tLoss: 0.9014\tLR: 0.100000\nTraining Epoch: 4 [27392/50000]\tLoss: 0.6833\tLR: 0.100000\nTraining Epoch: 4 [27520/50000]\tLoss: 0.9067\tLR: 0.100000\nTraining Epoch: 4 [27648/50000]\tLoss: 0.8657\tLR: 0.100000\nTraining Epoch: 4 [27776/50000]\tLoss: 0.7809\tLR: 0.100000\nTraining Epoch: 4 [27904/50000]\tLoss: 0.6660\tLR: 0.100000\nTraining Epoch: 4 [28032/50000]\tLoss: 0.7729\tLR: 0.100000\nTraining Epoch: 4 [28160/50000]\tLoss: 0.7845\tLR: 0.100000\nTraining Epoch: 4 [28288/50000]\tLoss: 0.8330\tLR: 0.100000\nTraining Epoch: 4 [28416/50000]\tLoss: 0.8161\tLR: 0.100000\nTraining Epoch: 4 [28544/50000]\tLoss: 0.8449\tLR: 0.100000\nTraining Epoch: 4 [28672/50000]\tLoss: 0.9321\tLR: 0.100000\nTraining Epoch: 4 [28800/50000]\tLoss: 0.6496\tLR: 0.100000\nTraining Epoch: 4 [28928/50000]\tLoss: 0.7523\tLR: 0.100000\nTraining Epoch: 4 [29056/50000]\tLoss: 0.5835\tLR: 0.100000\nTraining Epoch: 4 [29184/50000]\tLoss: 0.6599\tLR: 0.100000\nTraining Epoch: 4 [29312/50000]\tLoss: 0.6045\tLR: 0.100000\nTraining Epoch: 4 [29440/50000]\tLoss: 0.7989\tLR: 0.100000\nTraining Epoch: 4 [29568/50000]\tLoss: 0.7766\tLR: 0.100000\nTraining Epoch: 4 [29696/50000]\tLoss: 0.6347\tLR: 0.100000\nTraining Epoch: 4 [29824/50000]\tLoss: 0.8662\tLR: 0.100000\nTraining Epoch: 4 [29952/50000]\tLoss: 0.8566\tLR: 0.100000\nTraining Epoch: 4 [30080/50000]\tLoss: 0.6338\tLR: 0.100000\nTraining Epoch: 4 [30208/50000]\tLoss: 0.7336\tLR: 0.100000\nTraining Epoch: 4 [30336/50000]\tLoss: 0.7457\tLR: 0.100000\nTraining Epoch: 4 [30464/50000]\tLoss: 0.7375\tLR: 0.100000\nTraining Epoch: 4 [30592/50000]\tLoss: 0.7095\tLR: 0.100000\nTraining Epoch: 4 [30720/50000]\tLoss: 0.7934\tLR: 0.100000\nTraining Epoch: 4 [30848/50000]\tLoss: 0.9275\tLR: 0.100000\nTraining Epoch: 4 [30976/50000]\tLoss: 0.7957\tLR: 0.100000\nTraining Epoch: 4 [31104/50000]\tLoss: 0.9702\tLR: 0.100000\nTraining Epoch: 4 [31232/50000]\tLoss: 0.8012\tLR: 0.100000\nTraining Epoch: 4 [31360/50000]\tLoss: 0.7765\tLR: 0.100000\nTraining Epoch: 4 [31488/50000]\tLoss: 0.6884\tLR: 0.100000\nTraining Epoch: 4 [31616/50000]\tLoss: 0.7104\tLR: 0.100000\nTraining Epoch: 4 [31744/50000]\tLoss: 0.9254\tLR: 0.100000\nTraining Epoch: 4 [31872/50000]\tLoss: 0.7760\tLR: 0.100000\nTraining Epoch: 4 [32000/50000]\tLoss: 0.7638\tLR: 0.100000\nTraining Epoch: 4 [32128/50000]\tLoss: 0.8867\tLR: 0.100000\nTraining Epoch: 4 [32256/50000]\tLoss: 0.6762\tLR: 0.100000\nTraining Epoch: 4 [32384/50000]\tLoss: 0.9750\tLR: 0.100000\nTraining Epoch: 4 [32512/50000]\tLoss: 0.8147\tLR: 0.100000\nTraining Epoch: 4 [32640/50000]\tLoss: 0.7647\tLR: 0.100000\nTraining Epoch: 4 [32768/50000]\tLoss: 0.7229\tLR: 0.100000\nTraining Epoch: 4 [32896/50000]\tLoss: 0.6860\tLR: 0.100000\nTraining Epoch: 4 [33024/50000]\tLoss: 0.7052\tLR: 0.100000\nTraining Epoch: 4 [33152/50000]\tLoss: 0.6953\tLR: 0.100000\nTraining Epoch: 4 [33280/50000]\tLoss: 0.8534\tLR: 0.100000\nTraining Epoch: 4 [33408/50000]\tLoss: 0.9068\tLR: 0.100000\nTraining Epoch: 4 [33536/50000]\tLoss: 0.7529\tLR: 0.100000\nTraining Epoch: 4 [33664/50000]\tLoss: 0.6497\tLR: 0.100000\nTraining Epoch: 4 [33792/50000]\tLoss: 0.8323\tLR: 0.100000\nTraining Epoch: 4 [33920/50000]\tLoss: 0.6350\tLR: 0.100000\nTraining Epoch: 4 [34048/50000]\tLoss: 0.9265\tLR: 0.100000\nTraining Epoch: 4 [34176/50000]\tLoss: 0.8355\tLR: 0.100000\nTraining Epoch: 4 [34304/50000]\tLoss: 0.6897\tLR: 0.100000\nTraining Epoch: 4 [34432/50000]\tLoss: 0.8046\tLR: 0.100000\nTraining Epoch: 4 [34560/50000]\tLoss: 0.6987\tLR: 0.100000\nTraining Epoch: 4 [34688/50000]\tLoss: 0.7723\tLR: 0.100000\nTraining Epoch: 4 [34816/50000]\tLoss: 0.7744\tLR: 0.100000\nTraining Epoch: 4 [34944/50000]\tLoss: 0.8229\tLR: 0.100000\nTraining Epoch: 4 [35072/50000]\tLoss: 0.8135\tLR: 0.100000\nTraining Epoch: 4 [35200/50000]\tLoss: 0.7786\tLR: 0.100000\nTraining Epoch: 4 [35328/50000]\tLoss: 0.8499\tLR: 0.100000\nTraining Epoch: 4 [35456/50000]\tLoss: 0.6749\tLR: 0.100000\nTraining Epoch: 4 [35584/50000]\tLoss: 0.7291\tLR: 0.100000\nTraining Epoch: 4 [35712/50000]\tLoss: 0.9222\tLR: 0.100000\nTraining Epoch: 4 [35840/50000]\tLoss: 1.0479\tLR: 0.100000\nTraining Epoch: 4 [35968/50000]\tLoss: 0.8749\tLR: 0.100000\nTraining Epoch: 4 [36096/50000]\tLoss: 0.9424\tLR: 0.100000\nTraining Epoch: 4 [36224/50000]\tLoss: 0.9289\tLR: 0.100000\nTraining Epoch: 4 [36352/50000]\tLoss: 0.8381\tLR: 0.100000\nTraining Epoch: 4 [36480/50000]\tLoss: 0.6530\tLR: 0.100000\nTraining Epoch: 4 [36608/50000]\tLoss: 0.8773\tLR: 0.100000\nTraining Epoch: 4 [36736/50000]\tLoss: 0.7646\tLR: 0.100000\nTraining Epoch: 4 [36864/50000]\tLoss: 0.8360\tLR: 0.100000\nTraining Epoch: 4 [36992/50000]\tLoss: 0.6346\tLR: 0.100000\nTraining Epoch: 4 [37120/50000]\tLoss: 0.9399\tLR: 0.100000\nTraining Epoch: 4 [37248/50000]\tLoss: 0.8523\tLR: 0.100000\nTraining Epoch: 4 [37376/50000]\tLoss: 0.8788\tLR: 0.100000\nTraining Epoch: 4 [37504/50000]\tLoss: 0.7559\tLR: 0.100000\nTraining Epoch: 4 [37632/50000]\tLoss: 0.7462\tLR: 0.100000\nTraining Epoch: 4 [37760/50000]\tLoss: 0.7240\tLR: 0.100000\nTraining Epoch: 4 [37888/50000]\tLoss: 0.9004\tLR: 0.100000\nTraining Epoch: 4 [38016/50000]\tLoss: 0.8256\tLR: 0.100000\nTraining Epoch: 4 [38144/50000]\tLoss: 1.1310\tLR: 0.100000\nTraining Epoch: 4 [38272/50000]\tLoss: 0.7169\tLR: 0.100000\nTraining Epoch: 4 [38400/50000]\tLoss: 0.6367\tLR: 0.100000\nTraining Epoch: 4 [38528/50000]\tLoss: 0.6788\tLR: 0.100000\nTraining Epoch: 4 [38656/50000]\tLoss: 0.8752\tLR: 0.100000\nTraining Epoch: 4 [38784/50000]\tLoss: 0.9298\tLR: 0.100000\nTraining Epoch: 4 [38912/50000]\tLoss: 0.8520\tLR: 0.100000\nTraining Epoch: 4 [39040/50000]\tLoss: 0.8618\tLR: 0.100000\nTraining Epoch: 4 [39168/50000]\tLoss: 0.7814\tLR: 0.100000\nTraining Epoch: 4 [39296/50000]\tLoss: 0.5087\tLR: 0.100000\nTraining Epoch: 4 [39424/50000]\tLoss: 0.7537\tLR: 0.100000\nTraining Epoch: 4 [39552/50000]\tLoss: 0.6825\tLR: 0.100000\nTraining Epoch: 4 [39680/50000]\tLoss: 0.6763\tLR: 0.100000\nTraining Epoch: 4 [39808/50000]\tLoss: 0.7368\tLR: 0.100000\nTraining Epoch: 4 [39936/50000]\tLoss: 0.7207\tLR: 0.100000\nTraining Epoch: 4 [40064/50000]\tLoss: 0.6638\tLR: 0.100000\nTraining Epoch: 4 [40192/50000]\tLoss: 0.7739\tLR: 0.100000\nTraining Epoch: 4 [40320/50000]\tLoss: 0.6562\tLR: 0.100000\nTraining Epoch: 4 [40448/50000]\tLoss: 0.6470\tLR: 0.100000\nTraining Epoch: 4 [40576/50000]\tLoss: 0.7158\tLR: 0.100000\nTraining Epoch: 4 [40704/50000]\tLoss: 0.7511\tLR: 0.100000\nTraining Epoch: 4 [40832/50000]\tLoss: 0.7949\tLR: 0.100000\nTraining Epoch: 4 [40960/50000]\tLoss: 0.6739\tLR: 0.100000\nTraining Epoch: 4 [41088/50000]\tLoss: 0.7461\tLR: 0.100000\nTraining Epoch: 4 [41216/50000]\tLoss: 0.7092\tLR: 0.100000\nTraining Epoch: 4 [41344/50000]\tLoss: 0.7881\tLR: 0.100000\nTraining Epoch: 4 [41472/50000]\tLoss: 0.7754\tLR: 0.100000\nTraining Epoch: 4 [41600/50000]\tLoss: 0.8507\tLR: 0.100000\nTraining Epoch: 4 [41728/50000]\tLoss: 0.7901\tLR: 0.100000\nTraining Epoch: 4 [41856/50000]\tLoss: 0.6903\tLR: 0.100000\nTraining Epoch: 4 [41984/50000]\tLoss: 0.7592\tLR: 0.100000\nTraining Epoch: 4 [42112/50000]\tLoss: 0.8516\tLR: 0.100000\nTraining Epoch: 4 [42240/50000]\tLoss: 0.7151\tLR: 0.100000\nTraining Epoch: 4 [42368/50000]\tLoss: 0.9133\tLR: 0.100000\nTraining Epoch: 4 [42496/50000]\tLoss: 0.9443\tLR: 0.100000\nTraining Epoch: 4 [42624/50000]\tLoss: 0.7380\tLR: 0.100000\nTraining Epoch: 4 [42752/50000]\tLoss: 0.8068\tLR: 0.100000\nTraining Epoch: 4 [42880/50000]\tLoss: 0.8306\tLR: 0.100000\nTraining Epoch: 4 [43008/50000]\tLoss: 0.8233\tLR: 0.100000\nTraining Epoch: 4 [43136/50000]\tLoss: 0.9469\tLR: 0.100000\nTraining Epoch: 4 [43264/50000]\tLoss: 0.7489\tLR: 0.100000\nTraining Epoch: 4 [43392/50000]\tLoss: 0.8488\tLR: 0.100000\nTraining Epoch: 4 [43520/50000]\tLoss: 0.8465\tLR: 0.100000\nTraining Epoch: 4 [43648/50000]\tLoss: 0.7631\tLR: 0.100000\nTraining Epoch: 4 [43776/50000]\tLoss: 0.7633\tLR: 0.100000\nTraining Epoch: 4 [43904/50000]\tLoss: 0.6649\tLR: 0.100000\nTraining Epoch: 4 [44032/50000]\tLoss: 0.8364\tLR: 0.100000\nTraining Epoch: 4 [44160/50000]\tLoss: 0.7039\tLR: 0.100000\nTraining Epoch: 4 [44288/50000]\tLoss: 0.7455\tLR: 0.100000\nTraining Epoch: 4 [44416/50000]\tLoss: 0.6992\tLR: 0.100000\nTraining Epoch: 4 [44544/50000]\tLoss: 0.9505\tLR: 0.100000\nTraining Epoch: 4 [44672/50000]\tLoss: 0.6265\tLR: 0.100000\nTraining Epoch: 4 [44800/50000]\tLoss: 0.7303\tLR: 0.100000\nTraining Epoch: 4 [44928/50000]\tLoss: 0.7325\tLR: 0.100000\nTraining Epoch: 4 [45056/50000]\tLoss: 0.9095\tLR: 0.100000\nTraining Epoch: 4 [45184/50000]\tLoss: 0.8084\tLR: 0.100000\nTraining Epoch: 4 [45312/50000]\tLoss: 0.6884\tLR: 0.100000\nTraining Epoch: 4 [45440/50000]\tLoss: 0.7886\tLR: 0.100000\nTraining Epoch: 4 [45568/50000]\tLoss: 0.7744\tLR: 0.100000\nTraining Epoch: 4 [45696/50000]\tLoss: 0.8172\tLR: 0.100000\nTraining Epoch: 4 [45824/50000]\tLoss: 0.7262\tLR: 0.100000\nTraining Epoch: 4 [45952/50000]\tLoss: 1.1145\tLR: 0.100000\nTraining Epoch: 4 [46080/50000]\tLoss: 0.6439\tLR: 0.100000\nTraining Epoch: 4 [46208/50000]\tLoss: 0.6990\tLR: 0.100000\nTraining Epoch: 4 [46336/50000]\tLoss: 0.7228\tLR: 0.100000\nTraining Epoch: 4 [46464/50000]\tLoss: 0.5364\tLR: 0.100000\nTraining Epoch: 4 [46592/50000]\tLoss: 0.7304\tLR: 0.100000\nTraining Epoch: 4 [46720/50000]\tLoss: 0.7716\tLR: 0.100000\nTraining Epoch: 4 [46848/50000]\tLoss: 0.7517\tLR: 0.100000\nTraining Epoch: 4 [46976/50000]\tLoss: 0.7038\tLR: 0.100000\nTraining Epoch: 4 [47104/50000]\tLoss: 0.8011\tLR: 0.100000\nTraining Epoch: 4 [47232/50000]\tLoss: 0.7195\tLR: 0.100000\nTraining Epoch: 4 [47360/50000]\tLoss: 0.6782\tLR: 0.100000\nTraining Epoch: 4 [47488/50000]\tLoss: 0.6975\tLR: 0.100000\nTraining Epoch: 4 [47616/50000]\tLoss: 0.7619\tLR: 0.100000\nTraining Epoch: 4 [47744/50000]\tLoss: 0.8402\tLR: 0.100000\nTraining Epoch: 4 [47872/50000]\tLoss: 0.8866\tLR: 0.100000\nTraining Epoch: 4 [48000/50000]\tLoss: 0.8067\tLR: 0.100000\nTraining Epoch: 4 [48128/50000]\tLoss: 0.8940\tLR: 0.100000\nTraining Epoch: 4 [48256/50000]\tLoss: 0.8445\tLR: 0.100000\nTraining Epoch: 4 [48384/50000]\tLoss: 0.7006\tLR: 0.100000\nTraining Epoch: 4 [48512/50000]\tLoss: 0.5883\tLR: 0.100000\nTraining Epoch: 4 [48640/50000]\tLoss: 0.8964\tLR: 0.100000\nTraining Epoch: 4 [48768/50000]\tLoss: 0.8355\tLR: 0.100000\nTraining Epoch: 4 [48896/50000]\tLoss: 0.8187\tLR: 0.100000\nTraining Epoch: 4 [49024/50000]\tLoss: 0.6442\tLR: 0.100000\nTraining Epoch: 4 [49152/50000]\tLoss: 0.7403\tLR: 0.100000\nTraining Epoch: 4 [49280/50000]\tLoss: 0.9196\tLR: 0.100000\nTraining Epoch: 4 [49408/50000]\tLoss: 0.8044\tLR: 0.100000\nTraining Epoch: 4 [49536/50000]\tLoss: 0.7872\tLR: 0.100000\nTraining Epoch: 4 [49664/50000]\tLoss: 0.8903\tLR: 0.100000\nTraining Epoch: 4 [49792/50000]\tLoss: 0.7847\tLR: 0.100000\nTraining Epoch: 4 [49920/50000]\tLoss: 0.7428\tLR: 0.100000\nTraining Epoch: 4 [50000/50000]\tLoss: 0.6003\tLR: 0.100000\nTest set: Average loss: 0.0058, Accuracy: 0.7522\n\nTraining Epoch: 5 [128/50000]\tLoss: 0.6969\tLR: 0.100000\nTraining Epoch: 5 [256/50000]\tLoss: 0.8515\tLR: 0.100000\nTraining Epoch: 5 [384/50000]\tLoss: 0.7294\tLR: 0.100000\nTraining Epoch: 5 [512/50000]\tLoss: 0.7803\tLR: 0.100000\nTraining Epoch: 5 [640/50000]\tLoss: 0.7662\tLR: 0.100000\nTraining Epoch: 5 [768/50000]\tLoss: 0.7475\tLR: 0.100000\nTraining Epoch: 5 [896/50000]\tLoss: 0.7089\tLR: 0.100000\nTraining Epoch: 5 [1024/50000]\tLoss: 0.6966\tLR: 0.100000\nTraining Epoch: 5 [1152/50000]\tLoss: 0.7643\tLR: 0.100000\nTraining Epoch: 5 [1280/50000]\tLoss: 0.5287\tLR: 0.100000\nTraining Epoch: 5 [1408/50000]\tLoss: 0.6919\tLR: 0.100000\nTraining Epoch: 5 [1536/50000]\tLoss: 0.7507\tLR: 0.100000\nTraining Epoch: 5 [1664/50000]\tLoss: 0.8329\tLR: 0.100000\nTraining Epoch: 5 [1792/50000]\tLoss: 0.7207\tLR: 0.100000\nTraining Epoch: 5 [1920/50000]\tLoss: 0.7169\tLR: 0.100000\nTraining Epoch: 5 [2048/50000]\tLoss: 0.7327\tLR: 0.100000\nTraining Epoch: 5 [2176/50000]\tLoss: 0.6726\tLR: 0.100000\nTraining Epoch: 5 [2304/50000]\tLoss: 0.6669\tLR: 0.100000\nTraining Epoch: 5 [2432/50000]\tLoss: 0.7880\tLR: 0.100000\nTraining Epoch: 5 [2560/50000]\tLoss: 0.6442\tLR: 0.100000\nTraining Epoch: 5 [2688/50000]\tLoss: 0.8403\tLR: 0.100000\nTraining Epoch: 5 [2816/50000]\tLoss: 0.9621\tLR: 0.100000\nTraining Epoch: 5 [2944/50000]\tLoss: 0.6572\tLR: 0.100000\nTraining Epoch: 5 [3072/50000]\tLoss: 0.7492\tLR: 0.100000\nTraining Epoch: 5 [3200/50000]\tLoss: 0.6110\tLR: 0.100000\nTraining Epoch: 5 [3328/50000]\tLoss: 0.7806\tLR: 0.100000\nTraining Epoch: 5 [3456/50000]\tLoss: 0.5429\tLR: 0.100000\nTraining Epoch: 5 [3584/50000]\tLoss: 0.8904\tLR: 0.100000\nTraining Epoch: 5 [3712/50000]\tLoss: 0.7062\tLR: 0.100000\nTraining Epoch: 5 [3840/50000]\tLoss: 0.8416\tLR: 0.100000\nTraining Epoch: 5 [3968/50000]\tLoss: 0.6861\tLR: 0.100000\nTraining Epoch: 5 [4096/50000]\tLoss: 0.7965\tLR: 0.100000\nTraining Epoch: 5 [4224/50000]\tLoss: 0.5357\tLR: 0.100000\nTraining Epoch: 5 [4352/50000]\tLoss: 0.7718\tLR: 0.100000\nTraining Epoch: 5 [4480/50000]\tLoss: 0.8738\tLR: 0.100000\nTraining Epoch: 5 [4608/50000]\tLoss: 0.8416\tLR: 0.100000\nTraining Epoch: 5 [4736/50000]\tLoss: 0.7376\tLR: 0.100000\nTraining Epoch: 5 [4864/50000]\tLoss: 0.6999\tLR: 0.100000\nTraining Epoch: 5 [4992/50000]\tLoss: 0.8128\tLR: 0.100000\nTraining Epoch: 5 [5120/50000]\tLoss: 0.6741\tLR: 0.100000\nTraining Epoch: 5 [5248/50000]\tLoss: 0.7743\tLR: 0.100000\nTraining Epoch: 5 [5376/50000]\tLoss: 0.6805\tLR: 0.100000\nTraining Epoch: 5 [5504/50000]\tLoss: 0.7378\tLR: 0.100000\nTraining Epoch: 5 [5632/50000]\tLoss: 0.7792\tLR: 0.100000\nTraining Epoch: 5 [5760/50000]\tLoss: 0.6742\tLR: 0.100000\nTraining Epoch: 5 [5888/50000]\tLoss: 0.6217\tLR: 0.100000\nTraining Epoch: 5 [6016/50000]\tLoss: 0.7392\tLR: 0.100000\nTraining Epoch: 5 [6144/50000]\tLoss: 0.8247\tLR: 0.100000\nTraining Epoch: 5 [6272/50000]\tLoss: 0.6414\tLR: 0.100000\nTraining Epoch: 5 [6400/50000]\tLoss: 0.8068\tLR: 0.100000\nTraining Epoch: 5 [6528/50000]\tLoss: 0.6884\tLR: 0.100000\nTraining Epoch: 5 [6656/50000]\tLoss: 0.8276\tLR: 0.100000\nTraining Epoch: 5 [6784/50000]\tLoss: 0.8813\tLR: 0.100000\nTraining Epoch: 5 [6912/50000]\tLoss: 0.8115\tLR: 0.100000\nTraining Epoch: 5 [7040/50000]\tLoss: 0.6035\tLR: 0.100000\nTraining Epoch: 5 [7168/50000]\tLoss: 0.5686\tLR: 0.100000\nTraining Epoch: 5 [7296/50000]\tLoss: 0.6919\tLR: 0.100000\nTraining Epoch: 5 [7424/50000]\tLoss: 0.7604\tLR: 0.100000\nTraining Epoch: 5 [7552/50000]\tLoss: 0.7306\tLR: 0.100000\nTraining Epoch: 5 [7680/50000]\tLoss: 0.6001\tLR: 0.100000\nTraining Epoch: 5 [7808/50000]\tLoss: 0.5519\tLR: 0.100000\nTraining Epoch: 5 [7936/50000]\tLoss: 0.6405\tLR: 0.100000\nTraining Epoch: 5 [8064/50000]\tLoss: 0.8874\tLR: 0.100000\nTraining Epoch: 5 [8192/50000]\tLoss: 0.8367\tLR: 0.100000\nTraining Epoch: 5 [8320/50000]\tLoss: 0.7341\tLR: 0.100000\nTraining Epoch: 5 [8448/50000]\tLoss: 0.8309\tLR: 0.100000\nTraining Epoch: 5 [8576/50000]\tLoss: 0.7850\tLR: 0.100000\nTraining Epoch: 5 [8704/50000]\tLoss: 0.7700\tLR: 0.100000\nTraining Epoch: 5 [8832/50000]\tLoss: 0.7163\tLR: 0.100000\nTraining Epoch: 5 [8960/50000]\tLoss: 0.6878\tLR: 0.100000\nTraining Epoch: 5 [9088/50000]\tLoss: 0.7108\tLR: 0.100000\nTraining Epoch: 5 [9216/50000]\tLoss: 0.8273\tLR: 0.100000\nTraining Epoch: 5 [9344/50000]\tLoss: 0.6433\tLR: 0.100000\nTraining Epoch: 5 [9472/50000]\tLoss: 0.7249\tLR: 0.100000\nTraining Epoch: 5 [9600/50000]\tLoss: 0.7643\tLR: 0.100000\nTraining Epoch: 5 [9728/50000]\tLoss: 0.8111\tLR: 0.100000\nTraining Epoch: 5 [9856/50000]\tLoss: 0.6553\tLR: 0.100000\nTraining Epoch: 5 [9984/50000]\tLoss: 0.6424\tLR: 0.100000\nTraining Epoch: 5 [10112/50000]\tLoss: 0.7893\tLR: 0.100000\nTraining Epoch: 5 [10240/50000]\tLoss: 0.9268\tLR: 0.100000\nTraining Epoch: 5 [10368/50000]\tLoss: 0.6787\tLR: 0.100000\nTraining Epoch: 5 [10496/50000]\tLoss: 0.7631\tLR: 0.100000\nTraining Epoch: 5 [10624/50000]\tLoss: 0.8417\tLR: 0.100000\nTraining Epoch: 5 [10752/50000]\tLoss: 0.7289\tLR: 0.100000\nTraining Epoch: 5 [10880/50000]\tLoss: 0.5938\tLR: 0.100000\nTraining Epoch: 5 [11008/50000]\tLoss: 0.7793\tLR: 0.100000\nTraining Epoch: 5 [11136/50000]\tLoss: 0.6901\tLR: 0.100000\nTraining Epoch: 5 [11264/50000]\tLoss: 0.5516\tLR: 0.100000\nTraining Epoch: 5 [11392/50000]\tLoss: 0.7586\tLR: 0.100000\nTraining Epoch: 5 [11520/50000]\tLoss: 0.7223\tLR: 0.100000\nTraining Epoch: 5 [11648/50000]\tLoss: 0.6273\tLR: 0.100000\nTraining Epoch: 5 [11776/50000]\tLoss: 0.6381\tLR: 0.100000\nTraining Epoch: 5 [11904/50000]\tLoss: 0.6521\tLR: 0.100000\nTraining Epoch: 5 [12032/50000]\tLoss: 0.9730\tLR: 0.100000\nTraining Epoch: 5 [12160/50000]\tLoss: 0.7976\tLR: 0.100000\nTraining Epoch: 5 [12288/50000]\tLoss: 0.7920\tLR: 0.100000\nTraining Epoch: 5 [12416/50000]\tLoss: 0.9799\tLR: 0.100000\nTraining Epoch: 5 [12544/50000]\tLoss: 0.6959\tLR: 0.100000\nTraining Epoch: 5 [12672/50000]\tLoss: 0.7550\tLR: 0.100000\nTraining Epoch: 5 [12800/50000]\tLoss: 0.7284\tLR: 0.100000\nTraining Epoch: 5 [12928/50000]\tLoss: 0.8523\tLR: 0.100000\nTraining Epoch: 5 [13056/50000]\tLoss: 0.7646\tLR: 0.100000\nTraining Epoch: 5 [13184/50000]\tLoss: 0.7480\tLR: 0.100000\nTraining Epoch: 5 [13312/50000]\tLoss: 0.7974\tLR: 0.100000\nTraining Epoch: 5 [13440/50000]\tLoss: 0.8955\tLR: 0.100000\nTraining Epoch: 5 [13568/50000]\tLoss: 0.6929\tLR: 0.100000\nTraining Epoch: 5 [13696/50000]\tLoss: 0.8147\tLR: 0.100000\nTraining Epoch: 5 [13824/50000]\tLoss: 0.7799\tLR: 0.100000\nTraining Epoch: 5 [13952/50000]\tLoss: 0.6564\tLR: 0.100000\nTraining Epoch: 5 [14080/50000]\tLoss: 0.6882\tLR: 0.100000\nTraining Epoch: 5 [14208/50000]\tLoss: 0.5824\tLR: 0.100000\nTraining Epoch: 5 [14336/50000]\tLoss: 0.6670\tLR: 0.100000\nTraining Epoch: 5 [14464/50000]\tLoss: 0.5292\tLR: 0.100000\nTraining Epoch: 5 [14592/50000]\tLoss: 0.7384\tLR: 0.100000\nTraining Epoch: 5 [14720/50000]\tLoss: 0.6222\tLR: 0.100000\nTraining Epoch: 5 [14848/50000]\tLoss: 0.7569\tLR: 0.100000\nTraining Epoch: 5 [14976/50000]\tLoss: 0.6397\tLR: 0.100000\nTraining Epoch: 5 [15104/50000]\tLoss: 0.7333\tLR: 0.100000\nTraining Epoch: 5 [15232/50000]\tLoss: 0.6649\tLR: 0.100000\nTraining Epoch: 5 [15360/50000]\tLoss: 0.7114\tLR: 0.100000\nTraining Epoch: 5 [15488/50000]\tLoss: 0.7574\tLR: 0.100000\nTraining Epoch: 5 [15616/50000]\tLoss: 0.6155\tLR: 0.100000\nTraining Epoch: 5 [15744/50000]\tLoss: 0.7200\tLR: 0.100000\nTraining Epoch: 5 [15872/50000]\tLoss: 0.6724\tLR: 0.100000\nTraining Epoch: 5 [16000/50000]\tLoss: 0.6997\tLR: 0.100000\nTraining Epoch: 5 [16128/50000]\tLoss: 0.5902\tLR: 0.100000\nTraining Epoch: 5 [16256/50000]\tLoss: 0.6263\tLR: 0.100000\nTraining Epoch: 5 [16384/50000]\tLoss: 0.8940\tLR: 0.100000\nTraining Epoch: 5 [16512/50000]\tLoss: 0.7686\tLR: 0.100000\nTraining Epoch: 5 [16640/50000]\tLoss: 0.7413\tLR: 0.100000\nTraining Epoch: 5 [16768/50000]\tLoss: 0.7143\tLR: 0.100000\nTraining Epoch: 5 [16896/50000]\tLoss: 0.7462\tLR: 0.100000\nTraining Epoch: 5 [17024/50000]\tLoss: 0.7254\tLR: 0.100000\nTraining Epoch: 5 [17152/50000]\tLoss: 0.6643\tLR: 0.100000\nTraining Epoch: 5 [17280/50000]\tLoss: 0.7931\tLR: 0.100000\nTraining Epoch: 5 [17408/50000]\tLoss: 0.7825\tLR: 0.100000\nTraining Epoch: 5 [17536/50000]\tLoss: 0.8896\tLR: 0.100000\nTraining Epoch: 5 [17664/50000]\tLoss: 0.6638\tLR: 0.100000\nTraining Epoch: 5 [17792/50000]\tLoss: 0.4786\tLR: 0.100000\nTraining Epoch: 5 [17920/50000]\tLoss: 0.9482\tLR: 0.100000\nTraining Epoch: 5 [18048/50000]\tLoss: 0.6490\tLR: 0.100000\nTraining Epoch: 5 [18176/50000]\tLoss: 0.8106\tLR: 0.100000\nTraining Epoch: 5 [18304/50000]\tLoss: 0.8126\tLR: 0.100000\nTraining Epoch: 5 [18432/50000]\tLoss: 0.8223\tLR: 0.100000\nTraining Epoch: 5 [18560/50000]\tLoss: 0.6614\tLR: 0.100000\nTraining Epoch: 5 [18688/50000]\tLoss: 0.8239\tLR: 0.100000\nTraining Epoch: 5 [18816/50000]\tLoss: 0.8325\tLR: 0.100000\nTraining Epoch: 5 [18944/50000]\tLoss: 0.7480\tLR: 0.100000\nTraining Epoch: 5 [19072/50000]\tLoss: 0.7487\tLR: 0.100000\nTraining Epoch: 5 [19200/50000]\tLoss: 0.6822\tLR: 0.100000\nTraining Epoch: 5 [19328/50000]\tLoss: 0.5168\tLR: 0.100000\nTraining Epoch: 5 [19456/50000]\tLoss: 0.6243\tLR: 0.100000\nTraining Epoch: 5 [19584/50000]\tLoss: 0.8253\tLR: 0.100000\nTraining Epoch: 5 [19712/50000]\tLoss: 0.7195\tLR: 0.100000\nTraining Epoch: 5 [19840/50000]\tLoss: 0.7368\tLR: 0.100000\nTraining Epoch: 5 [19968/50000]\tLoss: 0.7921\tLR: 0.100000\nTraining Epoch: 5 [20096/50000]\tLoss: 0.8172\tLR: 0.100000\nTraining Epoch: 5 [20224/50000]\tLoss: 0.7970\tLR: 0.100000\nTraining Epoch: 5 [20352/50000]\tLoss: 0.8698\tLR: 0.100000\nTraining Epoch: 5 [20480/50000]\tLoss: 0.8006\tLR: 0.100000\nTraining Epoch: 5 [20608/50000]\tLoss: 0.7737\tLR: 0.100000\nTraining Epoch: 5 [20736/50000]\tLoss: 0.7058\tLR: 0.100000\nTraining Epoch: 5 [20864/50000]\tLoss: 0.8936\tLR: 0.100000\nTraining Epoch: 5 [20992/50000]\tLoss: 0.8171\tLR: 0.100000\nTraining Epoch: 5 [21120/50000]\tLoss: 0.8143\tLR: 0.100000\nTraining Epoch: 5 [21248/50000]\tLoss: 0.8303\tLR: 0.100000\nTraining Epoch: 5 [21376/50000]\tLoss: 0.7263\tLR: 0.100000\nTraining Epoch: 5 [21504/50000]\tLoss: 0.6784\tLR: 0.100000\nTraining Epoch: 5 [21632/50000]\tLoss: 0.9274\tLR: 0.100000\nTraining Epoch: 5 [21760/50000]\tLoss: 0.7762\tLR: 0.100000\nTraining Epoch: 5 [21888/50000]\tLoss: 0.7822\tLR: 0.100000\nTraining Epoch: 5 [22016/50000]\tLoss: 0.9084\tLR: 0.100000\nTraining Epoch: 5 [22144/50000]\tLoss: 0.7177\tLR: 0.100000\nTraining Epoch: 5 [22272/50000]\tLoss: 0.7202\tLR: 0.100000\nTraining Epoch: 5 [22400/50000]\tLoss: 0.6521\tLR: 0.100000\nTraining Epoch: 5 [22528/50000]\tLoss: 0.7564\tLR: 0.100000\nTraining Epoch: 5 [22656/50000]\tLoss: 0.8603\tLR: 0.100000\nTraining Epoch: 5 [22784/50000]\tLoss: 0.5352\tLR: 0.100000\nTraining Epoch: 5 [22912/50000]\tLoss: 0.6805\tLR: 0.100000\nTraining Epoch: 5 [23040/50000]\tLoss: 0.8382\tLR: 0.100000\nTraining Epoch: 5 [23168/50000]\tLoss: 0.7200\tLR: 0.100000\nTraining Epoch: 5 [23296/50000]\tLoss: 0.7957\tLR: 0.100000\nTraining Epoch: 5 [23424/50000]\tLoss: 0.7951\tLR: 0.100000\nTraining Epoch: 5 [23552/50000]\tLoss: 0.8061\tLR: 0.100000\nTraining Epoch: 5 [23680/50000]\tLoss: 0.6754\tLR: 0.100000\nTraining Epoch: 5 [23808/50000]\tLoss: 0.8848\tLR: 0.100000\nTraining Epoch: 5 [23936/50000]\tLoss: 0.9164\tLR: 0.100000\nTraining Epoch: 5 [24064/50000]\tLoss: 0.7063\tLR: 0.100000\nTraining Epoch: 5 [24192/50000]\tLoss: 0.7164\tLR: 0.100000\nTraining Epoch: 5 [24320/50000]\tLoss: 0.3993\tLR: 0.100000\nTraining Epoch: 5 [24448/50000]\tLoss: 0.6997\tLR: 0.100000\nTraining Epoch: 5 [24576/50000]\tLoss: 0.7677\tLR: 0.100000\nTraining Epoch: 5 [24704/50000]\tLoss: 0.6963\tLR: 0.100000\nTraining Epoch: 5 [24832/50000]\tLoss: 0.6874\tLR: 0.100000\nTraining Epoch: 5 [24960/50000]\tLoss: 0.7518\tLR: 0.100000\nTraining Epoch: 5 [25088/50000]\tLoss: 0.5845\tLR: 0.100000\nTraining Epoch: 5 [25216/50000]\tLoss: 0.9169\tLR: 0.100000\nTraining Epoch: 5 [25344/50000]\tLoss: 0.6633\tLR: 0.100000\nTraining Epoch: 5 [25472/50000]\tLoss: 0.7774\tLR: 0.100000\nTraining Epoch: 5 [25600/50000]\tLoss: 0.5238\tLR: 0.100000\nTraining Epoch: 5 [25728/50000]\tLoss: 0.5786\tLR: 0.100000\nTraining Epoch: 5 [25856/50000]\tLoss: 0.7265\tLR: 0.100000\nTraining Epoch: 5 [25984/50000]\tLoss: 0.8482\tLR: 0.100000\nTraining Epoch: 5 [26112/50000]\tLoss: 0.8985\tLR: 0.100000\nTraining Epoch: 5 [26240/50000]\tLoss: 0.5769\tLR: 0.100000\nTraining Epoch: 5 [26368/50000]\tLoss: 0.6372\tLR: 0.100000\nTraining Epoch: 5 [26496/50000]\tLoss: 0.6609\tLR: 0.100000\nTraining Epoch: 5 [26624/50000]\tLoss: 0.8365\tLR: 0.100000\nTraining Epoch: 5 [26752/50000]\tLoss: 0.9263\tLR: 0.100000\nTraining Epoch: 5 [26880/50000]\tLoss: 0.7785\tLR: 0.100000\nTraining Epoch: 5 [27008/50000]\tLoss: 0.7164\tLR: 0.100000\nTraining Epoch: 5 [27136/50000]\tLoss: 0.7588\tLR: 0.100000\nTraining Epoch: 5 [27264/50000]\tLoss: 0.7639\tLR: 0.100000\nTraining Epoch: 5 [27392/50000]\tLoss: 0.9228\tLR: 0.100000\nTraining Epoch: 5 [27520/50000]\tLoss: 0.6686\tLR: 0.100000\nTraining Epoch: 5 [27648/50000]\tLoss: 0.6706\tLR: 0.100000\nTraining Epoch: 5 [27776/50000]\tLoss: 0.6916\tLR: 0.100000\nTraining Epoch: 5 [27904/50000]\tLoss: 0.8223\tLR: 0.100000\nTraining Epoch: 5 [28032/50000]\tLoss: 0.7179\tLR: 0.100000\nTraining Epoch: 5 [28160/50000]\tLoss: 0.7684\tLR: 0.100000\nTraining Epoch: 5 [28288/50000]\tLoss: 0.8563\tLR: 0.100000\nTraining Epoch: 5 [28416/50000]\tLoss: 0.6797\tLR: 0.100000\nTraining Epoch: 5 [28544/50000]\tLoss: 0.6957\tLR: 0.100000\nTraining Epoch: 5 [28672/50000]\tLoss: 0.8263\tLR: 0.100000\nTraining Epoch: 5 [28800/50000]\tLoss: 0.6645\tLR: 0.100000\nTraining Epoch: 5 [28928/50000]\tLoss: 0.5554\tLR: 0.100000\nTraining Epoch: 5 [29056/50000]\tLoss: 0.5869\tLR: 0.100000\nTraining Epoch: 5 [29184/50000]\tLoss: 0.7919\tLR: 0.100000\nTraining Epoch: 5 [29312/50000]\tLoss: 0.6785\tLR: 0.100000\nTraining Epoch: 5 [29440/50000]\tLoss: 0.7028\tLR: 0.100000\nTraining Epoch: 5 [29568/50000]\tLoss: 0.7785\tLR: 0.100000\nTraining Epoch: 5 [29696/50000]\tLoss: 0.5775\tLR: 0.100000\nTraining Epoch: 5 [29824/50000]\tLoss: 0.6532\tLR: 0.100000\nTraining Epoch: 5 [29952/50000]\tLoss: 0.6462\tLR: 0.100000\nTraining Epoch: 5 [30080/50000]\tLoss: 0.5666\tLR: 0.100000\nTraining Epoch: 5 [30208/50000]\tLoss: 0.8767\tLR: 0.100000\nTraining Epoch: 5 [30336/50000]\tLoss: 0.7496\tLR: 0.100000\nTraining Epoch: 5 [30464/50000]\tLoss: 0.7123\tLR: 0.100000\nTraining Epoch: 5 [30592/50000]\tLoss: 0.7692\tLR: 0.100000\nTraining Epoch: 5 [30720/50000]\tLoss: 0.5832\tLR: 0.100000\nTraining Epoch: 5 [30848/50000]\tLoss: 0.7373\tLR: 0.100000\nTraining Epoch: 5 [30976/50000]\tLoss: 0.6677\tLR: 0.100000\nTraining Epoch: 5 [31104/50000]\tLoss: 0.7367\tLR: 0.100000\nTraining Epoch: 5 [31232/50000]\tLoss: 0.7937\tLR: 0.100000\nTraining Epoch: 5 [31360/50000]\tLoss: 0.7285\tLR: 0.100000\nTraining Epoch: 5 [31488/50000]\tLoss: 0.9141\tLR: 0.100000\nTraining Epoch: 5 [31616/50000]\tLoss: 0.5992\tLR: 0.100000\nTraining Epoch: 5 [31744/50000]\tLoss: 0.7799\tLR: 0.100000\nTraining Epoch: 5 [31872/50000]\tLoss: 0.6657\tLR: 0.100000\nTraining Epoch: 5 [32000/50000]\tLoss: 0.6660\tLR: 0.100000\nTraining Epoch: 5 [32128/50000]\tLoss: 0.7099\tLR: 0.100000\nTraining Epoch: 5 [32256/50000]\tLoss: 0.5676\tLR: 0.100000\nTraining Epoch: 5 [32384/50000]\tLoss: 0.9060\tLR: 0.100000\nTraining Epoch: 5 [32512/50000]\tLoss: 0.6861\tLR: 0.100000\nTraining Epoch: 5 [32640/50000]\tLoss: 0.6992\tLR: 0.100000\nTraining Epoch: 5 [32768/50000]\tLoss: 0.6049\tLR: 0.100000\nTraining Epoch: 5 [32896/50000]\tLoss: 0.7747\tLR: 0.100000\nTraining Epoch: 5 [33024/50000]\tLoss: 0.8373\tLR: 0.100000\nTraining Epoch: 5 [33152/50000]\tLoss: 0.8884\tLR: 0.100000\nTraining Epoch: 5 [33280/50000]\tLoss: 0.6852\tLR: 0.100000\nTraining Epoch: 5 [33408/50000]\tLoss: 0.6625\tLR: 0.100000\nTraining Epoch: 5 [33536/50000]\tLoss: 0.7782\tLR: 0.100000\nTraining Epoch: 5 [33664/50000]\tLoss: 0.7925\tLR: 0.100000\nTraining Epoch: 5 [33792/50000]\tLoss: 0.7892\tLR: 0.100000\nTraining Epoch: 5 [33920/50000]\tLoss: 0.7334\tLR: 0.100000\nTraining Epoch: 5 [34048/50000]\tLoss: 0.6951\tLR: 0.100000\nTraining Epoch: 5 [34176/50000]\tLoss: 0.5668\tLR: 0.100000\nTraining Epoch: 5 [34304/50000]\tLoss: 0.8513\tLR: 0.100000\nTraining Epoch: 5 [34432/50000]\tLoss: 0.6632\tLR: 0.100000\nTraining Epoch: 5 [34560/50000]\tLoss: 0.5683\tLR: 0.100000\nTraining Epoch: 5 [34688/50000]\tLoss: 0.7682\tLR: 0.100000\nTraining Epoch: 5 [34816/50000]\tLoss: 0.6776\tLR: 0.100000\nTraining Epoch: 5 [34944/50000]\tLoss: 0.6397\tLR: 0.100000\nTraining Epoch: 5 [35072/50000]\tLoss: 0.7804\tLR: 0.100000\nTraining Epoch: 5 [35200/50000]\tLoss: 0.6991\tLR: 0.100000\nTraining Epoch: 5 [35328/50000]\tLoss: 0.7538\tLR: 0.100000\nTraining Epoch: 5 [35456/50000]\tLoss: 0.7138\tLR: 0.100000\nTraining Epoch: 5 [35584/50000]\tLoss: 0.7856\tLR: 0.100000\nTraining Epoch: 5 [35712/50000]\tLoss: 0.7529\tLR: 0.100000\nTraining Epoch: 5 [35840/50000]\tLoss: 0.7274\tLR: 0.100000\nTraining Epoch: 5 [35968/50000]\tLoss: 0.6664\tLR: 0.100000\nTraining Epoch: 5 [36096/50000]\tLoss: 0.7622\tLR: 0.100000\nTraining Epoch: 5 [36224/50000]\tLoss: 0.6720\tLR: 0.100000\nTraining Epoch: 5 [36352/50000]\tLoss: 0.7367\tLR: 0.100000\nTraining Epoch: 5 [36480/50000]\tLoss: 0.4583\tLR: 0.100000\nTraining Epoch: 5 [36608/50000]\tLoss: 0.6668\tLR: 0.100000\nTraining Epoch: 5 [36736/50000]\tLoss: 0.7184\tLR: 0.100000\nTraining Epoch: 5 [36864/50000]\tLoss: 0.8005\tLR: 0.100000\nTraining Epoch: 5 [36992/50000]\tLoss: 0.7512\tLR: 0.100000\nTraining Epoch: 5 [37120/50000]\tLoss: 0.5338\tLR: 0.100000\nTraining Epoch: 5 [37248/50000]\tLoss: 0.6558\tLR: 0.100000\nTraining Epoch: 5 [37376/50000]\tLoss: 0.8268\tLR: 0.100000\nTraining Epoch: 5 [37504/50000]\tLoss: 0.7890\tLR: 0.100000\nTraining Epoch: 5 [37632/50000]\tLoss: 0.8321\tLR: 0.100000\nTraining Epoch: 5 [37760/50000]\tLoss: 0.6185\tLR: 0.100000\nTraining Epoch: 5 [37888/50000]\tLoss: 0.7159\tLR: 0.100000\nTraining Epoch: 5 [38016/50000]\tLoss: 0.6348\tLR: 0.100000\nTraining Epoch: 5 [38144/50000]\tLoss: 0.6591\tLR: 0.100000\nTraining Epoch: 5 [38272/50000]\tLoss: 0.6421\tLR: 0.100000\nTraining Epoch: 5 [38400/50000]\tLoss: 0.7408\tLR: 0.100000\nTraining Epoch: 5 [38528/50000]\tLoss: 0.6335\tLR: 0.100000\nTraining Epoch: 5 [38656/50000]\tLoss: 0.6625\tLR: 0.100000\nTraining Epoch: 5 [38784/50000]\tLoss: 0.6845\tLR: 0.100000\nTraining Epoch: 5 [38912/50000]\tLoss: 0.7977\tLR: 0.100000\nTraining Epoch: 5 [39040/50000]\tLoss: 0.8504\tLR: 0.100000\nTraining Epoch: 5 [39168/50000]\tLoss: 0.5966\tLR: 0.100000\nTraining Epoch: 5 [39296/50000]\tLoss: 0.7601\tLR: 0.100000\nTraining Epoch: 5 [39424/50000]\tLoss: 0.8265\tLR: 0.100000\nTraining Epoch: 5 [39552/50000]\tLoss: 0.6261\tLR: 0.100000\nTraining Epoch: 5 [39680/50000]\tLoss: 0.7597\tLR: 0.100000\nTraining Epoch: 5 [39808/50000]\tLoss: 0.6854\tLR: 0.100000\nTraining Epoch: 5 [39936/50000]\tLoss: 0.7495\tLR: 0.100000\nTraining Epoch: 5 [40064/50000]\tLoss: 0.6568\tLR: 0.100000\nTraining Epoch: 5 [40192/50000]\tLoss: 0.7150\tLR: 0.100000\nTraining Epoch: 5 [40320/50000]\tLoss: 0.5533\tLR: 0.100000\nTraining Epoch: 5 [40448/50000]\tLoss: 0.8253\tLR: 0.100000\nTraining Epoch: 5 [40576/50000]\tLoss: 0.8299\tLR: 0.100000\nTraining Epoch: 5 [40704/50000]\tLoss: 0.6121\tLR: 0.100000\nTraining Epoch: 5 [40832/50000]\tLoss: 0.8243\tLR: 0.100000\nTraining Epoch: 5 [40960/50000]\tLoss: 0.6679\tLR: 0.100000\nTraining Epoch: 5 [41088/50000]\tLoss: 0.7470\tLR: 0.100000\nTraining Epoch: 5 [41216/50000]\tLoss: 0.5819\tLR: 0.100000\nTraining Epoch: 5 [41344/50000]\tLoss: 0.7413\tLR: 0.100000\nTraining Epoch: 5 [41472/50000]\tLoss: 0.7388\tLR: 0.100000\nTraining Epoch: 5 [41600/50000]\tLoss: 0.5831\tLR: 0.100000\nTraining Epoch: 5 [41728/50000]\tLoss: 0.9045\tLR: 0.100000\nTraining Epoch: 5 [41856/50000]\tLoss: 0.8684\tLR: 0.100000\nTraining Epoch: 5 [41984/50000]\tLoss: 0.8233\tLR: 0.100000\nTraining Epoch: 5 [42112/50000]\tLoss: 0.6932\tLR: 0.100000\nTraining Epoch: 5 [42240/50000]\tLoss: 0.8508\tLR: 0.100000\nTraining Epoch: 5 [42368/50000]\tLoss: 0.6277\tLR: 0.100000\nTraining Epoch: 5 [42496/50000]\tLoss: 0.5676\tLR: 0.100000\nTraining Epoch: 5 [42624/50000]\tLoss: 0.6667\tLR: 0.100000\nTraining Epoch: 5 [42752/50000]\tLoss: 0.6832\tLR: 0.100000\nTraining Epoch: 5 [42880/50000]\tLoss: 0.8030\tLR: 0.100000\nTraining Epoch: 5 [43008/50000]\tLoss: 0.9141\tLR: 0.100000\nTraining Epoch: 5 [43136/50000]\tLoss: 0.7487\tLR: 0.100000\nTraining Epoch: 5 [43264/50000]\tLoss: 0.8068\tLR: 0.100000\nTraining Epoch: 5 [43392/50000]\tLoss: 0.7495\tLR: 0.100000\nTraining Epoch: 5 [43520/50000]\tLoss: 0.8417\tLR: 0.100000\nTraining Epoch: 5 [43648/50000]\tLoss: 0.6415\tLR: 0.100000\nTraining Epoch: 5 [43776/50000]\tLoss: 0.8767\tLR: 0.100000\nTraining Epoch: 5 [43904/50000]\tLoss: 0.7298\tLR: 0.100000\nTraining Epoch: 5 [44032/50000]\tLoss: 0.6471\tLR: 0.100000\nTraining Epoch: 5 [44160/50000]\tLoss: 0.5424\tLR: 0.100000\nTraining Epoch: 5 [44288/50000]\tLoss: 0.7922\tLR: 0.100000\nTraining Epoch: 5 [44416/50000]\tLoss: 0.8743\tLR: 0.100000\nTraining Epoch: 5 [44544/50000]\tLoss: 0.6547\tLR: 0.100000\nTraining Epoch: 5 [44672/50000]\tLoss: 0.7177\tLR: 0.100000\nTraining Epoch: 5 [44800/50000]\tLoss: 0.7266\tLR: 0.100000\nTraining Epoch: 5 [44928/50000]\tLoss: 0.7792\tLR: 0.100000\nTraining Epoch: 5 [45056/50000]\tLoss: 0.6893\tLR: 0.100000\nTraining Epoch: 5 [45184/50000]\tLoss: 0.7285\tLR: 0.100000\nTraining Epoch: 5 [45312/50000]\tLoss: 0.7140\tLR: 0.100000\nTraining Epoch: 5 [45440/50000]\tLoss: 0.6121\tLR: 0.100000\nTraining Epoch: 5 [45568/50000]\tLoss: 0.7596\tLR: 0.100000\nTraining Epoch: 5 [45696/50000]\tLoss: 0.7440\tLR: 0.100000\nTraining Epoch: 5 [45824/50000]\tLoss: 0.7516\tLR: 0.100000\nTraining Epoch: 5 [45952/50000]\tLoss: 0.6573\tLR: 0.100000\nTraining Epoch: 5 [46080/50000]\tLoss: 0.7051\tLR: 0.100000\nTraining Epoch: 5 [46208/50000]\tLoss: 0.9141\tLR: 0.100000\nTraining Epoch: 5 [46336/50000]\tLoss: 0.6053\tLR: 0.100000\nTraining Epoch: 5 [46464/50000]\tLoss: 0.7295\tLR: 0.100000\nTraining Epoch: 5 [46592/50000]\tLoss: 0.7195\tLR: 0.100000\nTraining Epoch: 5 [46720/50000]\tLoss: 0.8602\tLR: 0.100000\nTraining Epoch: 5 [46848/50000]\tLoss: 0.5504\tLR: 0.100000\nTraining Epoch: 5 [46976/50000]\tLoss: 0.6662\tLR: 0.100000\nTraining Epoch: 5 [47104/50000]\tLoss: 0.7929\tLR: 0.100000\nTraining Epoch: 5 [47232/50000]\tLoss: 0.7428\tLR: 0.100000\nTraining Epoch: 5 [47360/50000]\tLoss: 0.8533\tLR: 0.100000\nTraining Epoch: 5 [47488/50000]\tLoss: 0.7735\tLR: 0.100000\nTraining Epoch: 5 [47616/50000]\tLoss: 0.6907\tLR: 0.100000\nTraining Epoch: 5 [47744/50000]\tLoss: 0.8686\tLR: 0.100000\nTraining Epoch: 5 [47872/50000]\tLoss: 0.7515\tLR: 0.100000\nTraining Epoch: 5 [48000/50000]\tLoss: 0.7759\tLR: 0.100000\nTraining Epoch: 5 [48128/50000]\tLoss: 0.6831\tLR: 0.100000\nTraining Epoch: 5 [48256/50000]\tLoss: 0.6889\tLR: 0.100000\nTraining Epoch: 5 [48384/50000]\tLoss: 0.6691\tLR: 0.100000\nTraining Epoch: 5 [48512/50000]\tLoss: 0.7876\tLR: 0.100000\nTraining Epoch: 5 [48640/50000]\tLoss: 0.7094\tLR: 0.100000\nTraining Epoch: 5 [48768/50000]\tLoss: 0.8855\tLR: 0.100000\nTraining Epoch: 5 [48896/50000]\tLoss: 0.6873\tLR: 0.100000\nTraining Epoch: 5 [49024/50000]\tLoss: 0.6763\tLR: 0.100000\nTraining Epoch: 5 [49152/50000]\tLoss: 0.7762\tLR: 0.100000\nTraining Epoch: 5 [49280/50000]\tLoss: 0.7273\tLR: 0.100000\nTraining Epoch: 5 [49408/50000]\tLoss: 0.8224\tLR: 0.100000\nTraining Epoch: 5 [49536/50000]\tLoss: 0.8470\tLR: 0.100000\nTraining Epoch: 5 [49664/50000]\tLoss: 0.7103\tLR: 0.100000\nTraining Epoch: 5 [49792/50000]\tLoss: 0.7476\tLR: 0.100000\nTraining Epoch: 5 [49920/50000]\tLoss: 0.7256\tLR: 0.100000\nTraining Epoch: 5 [50000/50000]\tLoss: 0.7970\tLR: 0.100000\nTest set: Average loss: 0.0055, Accuracy: 0.7621\n\nTraining Epoch: 6 [128/50000]\tLoss: 0.7084\tLR: 0.015000\nTraining Epoch: 6 [256/50000]\tLoss: 0.7603\tLR: 0.015000\nTraining Epoch: 6 [384/50000]\tLoss: 0.6096\tLR: 0.015000\nTraining Epoch: 6 [512/50000]\tLoss: 0.7391\tLR: 0.015000\nTraining Epoch: 6 [640/50000]\tLoss: 0.7840\tLR: 0.015000\nTraining Epoch: 6 [768/50000]\tLoss: 0.7072\tLR: 0.015000\nTraining Epoch: 6 [896/50000]\tLoss: 0.6822\tLR: 0.015000\nTraining Epoch: 6 [1024/50000]\tLoss: 0.7322\tLR: 0.015000\nTraining Epoch: 6 [1152/50000]\tLoss: 0.6946\tLR: 0.015000\nTraining Epoch: 6 [1280/50000]\tLoss: 0.6773\tLR: 0.015000\nTraining Epoch: 6 [1408/50000]\tLoss: 0.6500\tLR: 0.015000\nTraining Epoch: 6 [1536/50000]\tLoss: 0.7902\tLR: 0.015000\nTraining Epoch: 6 [1664/50000]\tLoss: 0.5818\tLR: 0.015000\nTraining Epoch: 6 [1792/50000]\tLoss: 0.5930\tLR: 0.015000\nTraining Epoch: 6 [1920/50000]\tLoss: 0.6005\tLR: 0.015000\nTraining Epoch: 6 [2048/50000]\tLoss: 0.7056\tLR: 0.015000\nTraining Epoch: 6 [2176/50000]\tLoss: 0.6909\tLR: 0.015000\nTraining Epoch: 6 [2304/50000]\tLoss: 0.6335\tLR: 0.015000\nTraining Epoch: 6 [2432/50000]\tLoss: 0.6245\tLR: 0.015000\nTraining Epoch: 6 [2560/50000]\tLoss: 0.7657\tLR: 0.015000\nTraining Epoch: 6 [2688/50000]\tLoss: 0.6241\tLR: 0.015000\nTraining Epoch: 6 [2816/50000]\tLoss: 0.5810\tLR: 0.015000\nTraining Epoch: 6 [2944/50000]\tLoss: 0.6764\tLR: 0.015000\nTraining Epoch: 6 [3072/50000]\tLoss: 0.5129\tLR: 0.015000\nTraining Epoch: 6 [3200/50000]\tLoss: 0.6822\tLR: 0.015000\nTraining Epoch: 6 [3328/50000]\tLoss: 0.5964\tLR: 0.015000\nTraining Epoch: 6 [3456/50000]\tLoss: 0.5714\tLR: 0.015000\nTraining Epoch: 6 [3584/50000]\tLoss: 0.5434\tLR: 0.015000\nTraining Epoch: 6 [3712/50000]\tLoss: 0.4719\tLR: 0.015000\nTraining Epoch: 6 [3840/50000]\tLoss: 0.5660\tLR: 0.015000\nTraining Epoch: 6 [3968/50000]\tLoss: 0.6268\tLR: 0.015000\nTraining Epoch: 6 [4096/50000]\tLoss: 0.5855\tLR: 0.015000\nTraining Epoch: 6 [4224/50000]\tLoss: 0.4821\tLR: 0.015000\nTraining Epoch: 6 [4352/50000]\tLoss: 0.5676\tLR: 0.015000\nTraining Epoch: 6 [4480/50000]\tLoss: 0.6382\tLR: 0.015000\nTraining Epoch: 6 [4608/50000]\tLoss: 0.5279\tLR: 0.015000\nTraining Epoch: 6 [4736/50000]\tLoss: 0.5442\tLR: 0.015000\nTraining Epoch: 6 [4864/50000]\tLoss: 0.5260\tLR: 0.015000\nTraining Epoch: 6 [4992/50000]\tLoss: 0.5153\tLR: 0.015000\nTraining Epoch: 6 [5120/50000]\tLoss: 0.4607\tLR: 0.015000\nTraining Epoch: 6 [5248/50000]\tLoss: 0.5816\tLR: 0.015000\nTraining Epoch: 6 [5376/50000]\tLoss: 0.5649\tLR: 0.015000\nTraining Epoch: 6 [5504/50000]\tLoss: 0.6762\tLR: 0.015000\nTraining Epoch: 6 [5632/50000]\tLoss: 0.5577\tLR: 0.015000\nTraining Epoch: 6 [5760/50000]\tLoss: 0.6684\tLR: 0.015000\nTraining Epoch: 6 [5888/50000]\tLoss: 0.4731\tLR: 0.015000\nTraining Epoch: 6 [6016/50000]\tLoss: 0.4515\tLR: 0.015000\nTraining Epoch: 6 [6144/50000]\tLoss: 0.6108\tLR: 0.015000\nTraining Epoch: 6 [6272/50000]\tLoss: 0.4599\tLR: 0.015000\nTraining Epoch: 6 [6400/50000]\tLoss: 0.5707\tLR: 0.015000\nTraining Epoch: 6 [6528/50000]\tLoss: 0.6524\tLR: 0.015000\nTraining Epoch: 6 [6656/50000]\tLoss: 0.4906\tLR: 0.015000\nTraining Epoch: 6 [6784/50000]\tLoss: 0.7358\tLR: 0.015000\nTraining Epoch: 6 [6912/50000]\tLoss: 0.6320\tLR: 0.015000\nTraining Epoch: 6 [7040/50000]\tLoss: 0.6573\tLR: 0.015000\nTraining Epoch: 6 [7168/50000]\tLoss: 0.7484\tLR: 0.015000\nTraining Epoch: 6 [7296/50000]\tLoss: 0.5717\tLR: 0.015000\nTraining Epoch: 6 [7424/50000]\tLoss: 0.4465\tLR: 0.015000\nTraining Epoch: 6 [7552/50000]\tLoss: 0.5889\tLR: 0.015000\nTraining Epoch: 6 [7680/50000]\tLoss: 0.5523\tLR: 0.015000\nTraining Epoch: 6 [7808/50000]\tLoss: 0.4881\tLR: 0.015000\nTraining Epoch: 6 [7936/50000]\tLoss: 0.6210\tLR: 0.015000\nTraining Epoch: 6 [8064/50000]\tLoss: 0.6047\tLR: 0.015000\nTraining Epoch: 6 [8192/50000]\tLoss: 0.4818\tLR: 0.015000\nTraining Epoch: 6 [8320/50000]\tLoss: 0.5778\tLR: 0.015000\nTraining Epoch: 6 [8448/50000]\tLoss: 0.6155\tLR: 0.015000\nTraining Epoch: 6 [8576/50000]\tLoss: 0.5029\tLR: 0.015000\nTraining Epoch: 6 [8704/50000]\tLoss: 0.6026\tLR: 0.015000\nTraining Epoch: 6 [8832/50000]\tLoss: 0.5028\tLR: 0.015000\nTraining Epoch: 6 [8960/50000]\tLoss: 0.7123\tLR: 0.015000\nTraining Epoch: 6 [9088/50000]\tLoss: 0.6906\tLR: 0.015000\nTraining Epoch: 6 [9216/50000]\tLoss: 0.4759\tLR: 0.015000\nTraining Epoch: 6 [9344/50000]\tLoss: 0.4886\tLR: 0.015000\nTraining Epoch: 6 [9472/50000]\tLoss: 0.5742\tLR: 0.015000\nTraining Epoch: 6 [9600/50000]\tLoss: 0.4981\tLR: 0.015000\nTraining Epoch: 6 [9728/50000]\tLoss: 0.5361\tLR: 0.015000\nTraining Epoch: 6 [9856/50000]\tLoss: 0.6257\tLR: 0.015000\nTraining Epoch: 6 [9984/50000]\tLoss: 0.5166\tLR: 0.015000\nTraining Epoch: 6 [10112/50000]\tLoss: 0.5282\tLR: 0.015000\nTraining Epoch: 6 [10240/50000]\tLoss: 0.5859\tLR: 0.015000\nTraining Epoch: 6 [10368/50000]\tLoss: 0.6772\tLR: 0.015000\nTraining Epoch: 6 [10496/50000]\tLoss: 0.5200\tLR: 0.015000\nTraining Epoch: 6 [10624/50000]\tLoss: 0.4590\tLR: 0.015000\nTraining Epoch: 6 [10752/50000]\tLoss: 0.4573\tLR: 0.015000\nTraining Epoch: 6 [10880/50000]\tLoss: 0.5901\tLR: 0.015000\nTraining Epoch: 6 [11008/50000]\tLoss: 0.5040\tLR: 0.015000\nTraining Epoch: 6 [11136/50000]\tLoss: 0.4480\tLR: 0.015000\nTraining Epoch: 6 [11264/50000]\tLoss: 0.6285\tLR: 0.015000\nTraining Epoch: 6 [11392/50000]\tLoss: 0.9188\tLR: 0.015000\nTraining Epoch: 6 [11520/50000]\tLoss: 0.5862\tLR: 0.015000\nTraining Epoch: 6 [11648/50000]\tLoss: 0.4734\tLR: 0.015000\nTraining Epoch: 6 [11776/50000]\tLoss: 0.4374\tLR: 0.015000\nTraining Epoch: 6 [11904/50000]\tLoss: 0.5124\tLR: 0.015000\nTraining Epoch: 6 [12032/50000]\tLoss: 0.5456\tLR: 0.015000\nTraining Epoch: 6 [12160/50000]\tLoss: 0.6121\tLR: 0.015000\nTraining Epoch: 6 [12288/50000]\tLoss: 0.6599\tLR: 0.015000\nTraining Epoch: 6 [12416/50000]\tLoss: 0.5079\tLR: 0.015000\nTraining Epoch: 6 [12544/50000]\tLoss: 0.5667\tLR: 0.015000\nTraining Epoch: 6 [12672/50000]\tLoss: 0.6496\tLR: 0.015000\nTraining Epoch: 6 [12800/50000]\tLoss: 0.4575\tLR: 0.015000\nTraining Epoch: 6 [12928/50000]\tLoss: 0.5834\tLR: 0.015000\nTraining Epoch: 6 [13056/50000]\tLoss: 0.4238\tLR: 0.015000\nTraining Epoch: 6 [13184/50000]\tLoss: 0.5777\tLR: 0.015000\nTraining Epoch: 6 [13312/50000]\tLoss: 0.5083\tLR: 0.015000\nTraining Epoch: 6 [13440/50000]\tLoss: 0.5739\tLR: 0.015000\nTraining Epoch: 6 [13568/50000]\tLoss: 0.4817\tLR: 0.015000\nTraining Epoch: 6 [13696/50000]\tLoss: 0.4472\tLR: 0.015000\nTraining Epoch: 6 [13824/50000]\tLoss: 0.5257\tLR: 0.015000\nTraining Epoch: 6 [13952/50000]\tLoss: 0.7475\tLR: 0.015000\nTraining Epoch: 6 [14080/50000]\tLoss: 0.4739\tLR: 0.015000\nTraining Epoch: 6 [14208/50000]\tLoss: 0.6587\tLR: 0.015000\nTraining Epoch: 6 [14336/50000]\tLoss: 0.4102\tLR: 0.015000\nTraining Epoch: 6 [14464/50000]\tLoss: 0.6778\tLR: 0.015000\nTraining Epoch: 6 [14592/50000]\tLoss: 0.4392\tLR: 0.015000\nTraining Epoch: 6 [14720/50000]\tLoss: 0.5551\tLR: 0.015000\nTraining Epoch: 6 [14848/50000]\tLoss: 0.4950\tLR: 0.015000\nTraining Epoch: 6 [14976/50000]\tLoss: 0.4447\tLR: 0.015000\nTraining Epoch: 6 [15104/50000]\tLoss: 0.5060\tLR: 0.015000\nTraining Epoch: 6 [15232/50000]\tLoss: 0.5270\tLR: 0.015000\nTraining Epoch: 6 [15360/50000]\tLoss: 0.5631\tLR: 0.015000\nTraining Epoch: 6 [15488/50000]\tLoss: 0.4598\tLR: 0.015000\nTraining Epoch: 6 [15616/50000]\tLoss: 0.7584\tLR: 0.015000\nTraining Epoch: 6 [15744/50000]\tLoss: 0.6574\tLR: 0.015000\nTraining Epoch: 6 [15872/50000]\tLoss: 0.5144\tLR: 0.015000\nTraining Epoch: 6 [16000/50000]\tLoss: 0.4945\tLR: 0.015000\nTraining Epoch: 6 [16128/50000]\tLoss: 0.4671\tLR: 0.015000\nTraining Epoch: 6 [16256/50000]\tLoss: 0.5118\tLR: 0.015000\nTraining Epoch: 6 [16384/50000]\tLoss: 0.3819\tLR: 0.015000\nTraining Epoch: 6 [16512/50000]\tLoss: 0.5084\tLR: 0.015000\nTraining Epoch: 6 [16640/50000]\tLoss: 0.5891\tLR: 0.015000\nTraining Epoch: 6 [16768/50000]\tLoss: 0.5388\tLR: 0.015000\nTraining Epoch: 6 [16896/50000]\tLoss: 0.3999\tLR: 0.015000\nTraining Epoch: 6 [17024/50000]\tLoss: 0.4687\tLR: 0.015000\nTraining Epoch: 6 [17152/50000]\tLoss: 0.6311\tLR: 0.015000\nTraining Epoch: 6 [17280/50000]\tLoss: 0.4378\tLR: 0.015000\nTraining Epoch: 6 [17408/50000]\tLoss: 0.5234\tLR: 0.015000\nTraining Epoch: 6 [17536/50000]\tLoss: 0.5505\tLR: 0.015000\nTraining Epoch: 6 [17664/50000]\tLoss: 0.5269\tLR: 0.015000\nTraining Epoch: 6 [17792/50000]\tLoss: 0.7176\tLR: 0.015000\nTraining Epoch: 6 [17920/50000]\tLoss: 0.3662\tLR: 0.015000\nTraining Epoch: 6 [18048/50000]\tLoss: 0.4826\tLR: 0.015000\nTraining Epoch: 6 [18176/50000]\tLoss: 0.4433\tLR: 0.015000\nTraining Epoch: 6 [18304/50000]\tLoss: 0.4960\tLR: 0.015000\nTraining Epoch: 6 [18432/50000]\tLoss: 0.8243\tLR: 0.015000\nTraining Epoch: 6 [18560/50000]\tLoss: 0.5958\tLR: 0.015000\nTraining Epoch: 6 [18688/50000]\tLoss: 0.5098\tLR: 0.015000\nTraining Epoch: 6 [18816/50000]\tLoss: 0.6298\tLR: 0.015000\nTraining Epoch: 6 [18944/50000]\tLoss: 0.6634\tLR: 0.015000\nTraining Epoch: 6 [19072/50000]\tLoss: 0.5021\tLR: 0.015000\nTraining Epoch: 6 [19200/50000]\tLoss: 0.5465\tLR: 0.015000\nTraining Epoch: 6 [19328/50000]\tLoss: 0.3994\tLR: 0.015000\nTraining Epoch: 6 [19456/50000]\tLoss: 0.5476\tLR: 0.015000\nTraining Epoch: 6 [19584/50000]\tLoss: 0.5197\tLR: 0.015000\nTraining Epoch: 6 [19712/50000]\tLoss: 0.4516\tLR: 0.015000\nTraining Epoch: 6 [19840/50000]\tLoss: 0.4704\tLR: 0.015000\nTraining Epoch: 6 [19968/50000]\tLoss: 0.6326\tLR: 0.015000\nTraining Epoch: 6 [20096/50000]\tLoss: 0.5337\tLR: 0.015000\nTraining Epoch: 6 [20224/50000]\tLoss: 0.4443\tLR: 0.015000\nTraining Epoch: 6 [20352/50000]\tLoss: 0.5334\tLR: 0.015000\nTraining Epoch: 6 [20480/50000]\tLoss: 0.4521\tLR: 0.015000\nTraining Epoch: 6 [20608/50000]\tLoss: 0.6320\tLR: 0.015000\nTraining Epoch: 6 [20736/50000]\tLoss: 0.4936\tLR: 0.015000\nTraining Epoch: 6 [20864/50000]\tLoss: 0.4629\tLR: 0.015000\nTraining Epoch: 6 [20992/50000]\tLoss: 0.4735\tLR: 0.015000\nTraining Epoch: 6 [21120/50000]\tLoss: 0.6032\tLR: 0.015000\nTraining Epoch: 6 [21248/50000]\tLoss: 0.5961\tLR: 0.015000\nTraining Epoch: 6 [21376/50000]\tLoss: 0.5402\tLR: 0.015000\nTraining Epoch: 6 [21504/50000]\tLoss: 0.4714\tLR: 0.015000\nTraining Epoch: 6 [21632/50000]\tLoss: 0.4766\tLR: 0.015000\nTraining Epoch: 6 [21760/50000]\tLoss: 0.4450\tLR: 0.015000\nTraining Epoch: 6 [21888/50000]\tLoss: 0.4562\tLR: 0.015000\nTraining Epoch: 6 [22016/50000]\tLoss: 0.4839\tLR: 0.015000\nTraining Epoch: 6 [22144/50000]\tLoss: 0.5162\tLR: 0.015000\nTraining Epoch: 6 [22272/50000]\tLoss: 0.4501\tLR: 0.015000\nTraining Epoch: 6 [22400/50000]\tLoss: 0.6351\tLR: 0.015000\nTraining Epoch: 6 [22528/50000]\tLoss: 0.4600\tLR: 0.015000\nTraining Epoch: 6 [22656/50000]\tLoss: 0.4640\tLR: 0.015000\nTraining Epoch: 6 [22784/50000]\tLoss: 0.4280\tLR: 0.015000\nTraining Epoch: 6 [22912/50000]\tLoss: 0.5525\tLR: 0.015000\nTraining Epoch: 6 [23040/50000]\tLoss: 0.4729\tLR: 0.015000\nTraining Epoch: 6 [23168/50000]\tLoss: 0.5510\tLR: 0.015000\nTraining Epoch: 6 [23296/50000]\tLoss: 0.4786\tLR: 0.015000\nTraining Epoch: 6 [23424/50000]\tLoss: 0.5206\tLR: 0.015000\nTraining Epoch: 6 [23552/50000]\tLoss: 0.6249\tLR: 0.015000\nTraining Epoch: 6 [23680/50000]\tLoss: 0.4716\tLR: 0.015000\nTraining Epoch: 6 [23808/50000]\tLoss: 0.4367\tLR: 0.015000\nTraining Epoch: 6 [23936/50000]\tLoss: 0.4756\tLR: 0.015000\nTraining Epoch: 6 [24064/50000]\tLoss: 0.4877\tLR: 0.015000\nTraining Epoch: 6 [24192/50000]\tLoss: 0.4245\tLR: 0.015000\nTraining Epoch: 6 [24320/50000]\tLoss: 0.5008\tLR: 0.015000\nTraining Epoch: 6 [24448/50000]\tLoss: 0.6468\tLR: 0.015000\nTraining Epoch: 6 [24576/50000]\tLoss: 0.6348\tLR: 0.015000\nTraining Epoch: 6 [24704/50000]\tLoss: 0.5539\tLR: 0.015000\nTraining Epoch: 6 [24832/50000]\tLoss: 0.4838\tLR: 0.015000\nTraining Epoch: 6 [24960/50000]\tLoss: 0.4369\tLR: 0.015000\nTraining Epoch: 6 [25088/50000]\tLoss: 0.6267\tLR: 0.015000\nTraining Epoch: 6 [25216/50000]\tLoss: 0.6301\tLR: 0.015000\nTraining Epoch: 6 [25344/50000]\tLoss: 0.4958\tLR: 0.015000\nTraining Epoch: 6 [25472/50000]\tLoss: 0.5171\tLR: 0.015000\nTraining Epoch: 6 [25600/50000]\tLoss: 0.4345\tLR: 0.015000\nTraining Epoch: 6 [25728/50000]\tLoss: 0.4529\tLR: 0.015000\nTraining Epoch: 6 [25856/50000]\tLoss: 0.3971\tLR: 0.015000\nTraining Epoch: 6 [25984/50000]\tLoss: 0.4947\tLR: 0.015000\nTraining Epoch: 6 [26112/50000]\tLoss: 0.5255\tLR: 0.015000\nTraining Epoch: 6 [26240/50000]\tLoss: 0.5555\tLR: 0.015000\nTraining Epoch: 6 [26368/50000]\tLoss: 0.5866\tLR: 0.015000\nTraining Epoch: 6 [26496/50000]\tLoss: 0.4600\tLR: 0.015000\nTraining Epoch: 6 [26624/50000]\tLoss: 0.3750\tLR: 0.015000\nTraining Epoch: 6 [26752/50000]\tLoss: 0.3574\tLR: 0.015000\nTraining Epoch: 6 [26880/50000]\tLoss: 0.5890\tLR: 0.015000\nTraining Epoch: 6 [27008/50000]\tLoss: 0.6157\tLR: 0.015000\nTraining Epoch: 6 [27136/50000]\tLoss: 0.3700\tLR: 0.015000\nTraining Epoch: 6 [27264/50000]\tLoss: 0.5711\tLR: 0.015000\nTraining Epoch: 6 [27392/50000]\tLoss: 0.5683\tLR: 0.015000\nTraining Epoch: 6 [27520/50000]\tLoss: 0.4058\tLR: 0.015000\nTraining Epoch: 6 [27648/50000]\tLoss: 0.4595\tLR: 0.015000\nTraining Epoch: 6 [27776/50000]\tLoss: 0.5201\tLR: 0.015000\nTraining Epoch: 6 [27904/50000]\tLoss: 0.4894\tLR: 0.015000\nTraining Epoch: 6 [28032/50000]\tLoss: 0.4177\tLR: 0.015000\nTraining Epoch: 6 [28160/50000]\tLoss: 0.5419\tLR: 0.015000\nTraining Epoch: 6 [28288/50000]\tLoss: 0.4745\tLR: 0.015000\nTraining Epoch: 6 [28416/50000]\tLoss: 0.5393\tLR: 0.015000\nTraining Epoch: 6 [28544/50000]\tLoss: 0.3447\tLR: 0.015000\nTraining Epoch: 6 [28672/50000]\tLoss: 0.6564\tLR: 0.015000\nTraining Epoch: 6 [28800/50000]\tLoss: 0.5728\tLR: 0.015000\nTraining Epoch: 6 [28928/50000]\tLoss: 0.4413\tLR: 0.015000\nTraining Epoch: 6 [29056/50000]\tLoss: 0.6038\tLR: 0.015000\nTraining Epoch: 6 [29184/50000]\tLoss: 0.4429\tLR: 0.015000\nTraining Epoch: 6 [29312/50000]\tLoss: 0.6640\tLR: 0.015000\nTraining Epoch: 6 [29440/50000]\tLoss: 0.5854\tLR: 0.015000\nTraining Epoch: 6 [29568/50000]\tLoss: 0.4362\tLR: 0.015000\nTraining Epoch: 6 [29696/50000]\tLoss: 0.6121\tLR: 0.015000\nTraining Epoch: 6 [29824/50000]\tLoss: 0.5604\tLR: 0.015000\nTraining Epoch: 6 [29952/50000]\tLoss: 0.5239\tLR: 0.015000\nTraining Epoch: 6 [30080/50000]\tLoss: 0.3768\tLR: 0.015000\nTraining Epoch: 6 [30208/50000]\tLoss: 0.6143\tLR: 0.015000\nTraining Epoch: 6 [30336/50000]\tLoss: 0.6138\tLR: 0.015000\nTraining Epoch: 6 [30464/50000]\tLoss: 0.5504\tLR: 0.015000\nTraining Epoch: 6 [30592/50000]\tLoss: 0.5901\tLR: 0.015000\nTraining Epoch: 6 [30720/50000]\tLoss: 0.4514\tLR: 0.015000\nTraining Epoch: 6 [30848/50000]\tLoss: 0.4177\tLR: 0.015000\nTraining Epoch: 6 [30976/50000]\tLoss: 0.4918\tLR: 0.015000\nTraining Epoch: 6 [31104/50000]\tLoss: 0.4556\tLR: 0.015000\nTraining Epoch: 6 [31232/50000]\tLoss: 0.4560\tLR: 0.015000\nTraining Epoch: 6 [31360/50000]\tLoss: 0.5156\tLR: 0.015000\nTraining Epoch: 6 [31488/50000]\tLoss: 0.5598\tLR: 0.015000\nTraining Epoch: 6 [31616/50000]\tLoss: 0.5810\tLR: 0.015000\nTraining Epoch: 6 [31744/50000]\tLoss: 0.5508\tLR: 0.015000\nTraining Epoch: 6 [31872/50000]\tLoss: 0.4943\tLR: 0.015000\nTraining Epoch: 6 [32000/50000]\tLoss: 0.4665\tLR: 0.015000\nTraining Epoch: 6 [32128/50000]\tLoss: 0.5393\tLR: 0.015000\nTraining Epoch: 6 [32256/50000]\tLoss: 0.4363\tLR: 0.015000\nTraining Epoch: 6 [32384/50000]\tLoss: 0.6425\tLR: 0.015000\nTraining Epoch: 6 [32512/50000]\tLoss: 0.5372\tLR: 0.015000\nTraining Epoch: 6 [32640/50000]\tLoss: 0.3863\tLR: 0.015000\nTraining Epoch: 6 [32768/50000]\tLoss: 0.4533\tLR: 0.015000\nTraining Epoch: 6 [32896/50000]\tLoss: 0.4031\tLR: 0.015000\nTraining Epoch: 6 [33024/50000]\tLoss: 0.5744\tLR: 0.015000\nTraining Epoch: 6 [33152/50000]\tLoss: 0.5847\tLR: 0.015000\nTraining Epoch: 6 [33280/50000]\tLoss: 0.5385\tLR: 0.015000\nTraining Epoch: 6 [33408/50000]\tLoss: 0.4472\tLR: 0.015000\nTraining Epoch: 6 [33536/50000]\tLoss: 0.3120\tLR: 0.015000\nTraining Epoch: 6 [33664/50000]\tLoss: 0.4751\tLR: 0.015000\nTraining Epoch: 6 [33792/50000]\tLoss: 0.5878\tLR: 0.015000\nTraining Epoch: 6 [33920/50000]\tLoss: 0.4990\tLR: 0.015000\nTraining Epoch: 6 [34048/50000]\tLoss: 0.4535\tLR: 0.015000\nTraining Epoch: 6 [34176/50000]\tLoss: 0.4973\tLR: 0.015000\nTraining Epoch: 6 [34304/50000]\tLoss: 0.4580\tLR: 0.015000\nTraining Epoch: 6 [34432/50000]\tLoss: 0.4393\tLR: 0.015000\nTraining Epoch: 6 [34560/50000]\tLoss: 0.4672\tLR: 0.015000\nTraining Epoch: 6 [34688/50000]\tLoss: 0.5661\tLR: 0.015000\nTraining Epoch: 6 [34816/50000]\tLoss: 0.5600\tLR: 0.015000\nTraining Epoch: 6 [34944/50000]\tLoss: 0.4483\tLR: 0.015000\nTraining Epoch: 6 [35072/50000]\tLoss: 0.6488\tLR: 0.015000\nTraining Epoch: 6 [35200/50000]\tLoss: 0.5318\tLR: 0.015000\nTraining Epoch: 6 [35328/50000]\tLoss: 0.5916\tLR: 0.015000\nTraining Epoch: 6 [35456/50000]\tLoss: 0.5771\tLR: 0.015000\nTraining Epoch: 6 [35584/50000]\tLoss: 0.5091\tLR: 0.015000\nTraining Epoch: 6 [35712/50000]\tLoss: 0.5387\tLR: 0.015000\nTraining Epoch: 6 [35840/50000]\tLoss: 0.4985\tLR: 0.015000\nTraining Epoch: 6 [35968/50000]\tLoss: 0.6213\tLR: 0.015000\nTraining Epoch: 6 [36096/50000]\tLoss: 0.5189\tLR: 0.015000\nTraining Epoch: 6 [36224/50000]\tLoss: 0.4796\tLR: 0.015000\nTraining Epoch: 6 [36352/50000]\tLoss: 0.5640\tLR: 0.015000\nTraining Epoch: 6 [36480/50000]\tLoss: 0.4339\tLR: 0.015000\nTraining Epoch: 6 [36608/50000]\tLoss: 0.4808\tLR: 0.015000\nTraining Epoch: 6 [36736/50000]\tLoss: 0.5533\tLR: 0.015000\nTraining Epoch: 6 [36864/50000]\tLoss: 0.6785\tLR: 0.015000\nTraining Epoch: 6 [36992/50000]\tLoss: 0.5421\tLR: 0.015000\nTraining Epoch: 6 [37120/50000]\tLoss: 0.5866\tLR: 0.015000\nTraining Epoch: 6 [37248/50000]\tLoss: 0.3665\tLR: 0.015000\nTraining Epoch: 6 [37376/50000]\tLoss: 0.5012\tLR: 0.015000\nTraining Epoch: 6 [37504/50000]\tLoss: 0.4650\tLR: 0.015000\nTraining Epoch: 6 [37632/50000]\tLoss: 0.5275\tLR: 0.015000\nTraining Epoch: 6 [37760/50000]\tLoss: 0.4596\tLR: 0.015000\nTraining Epoch: 6 [37888/50000]\tLoss: 0.4363\tLR: 0.015000\nTraining Epoch: 6 [38016/50000]\tLoss: 0.4869\tLR: 0.015000\nTraining Epoch: 6 [38144/50000]\tLoss: 0.3583\tLR: 0.015000\nTraining Epoch: 6 [38272/50000]\tLoss: 0.4676\tLR: 0.015000\nTraining Epoch: 6 [38400/50000]\tLoss: 0.6090\tLR: 0.015000\nTraining Epoch: 6 [38528/50000]\tLoss: 0.4915\tLR: 0.015000\nTraining Epoch: 6 [38656/50000]\tLoss: 0.4598\tLR: 0.015000\nTraining Epoch: 6 [38784/50000]\tLoss: 0.4464\tLR: 0.015000\nTraining Epoch: 6 [38912/50000]\tLoss: 0.4675\tLR: 0.015000\nTraining Epoch: 6 [39040/50000]\tLoss: 0.4876\tLR: 0.015000\nTraining Epoch: 6 [39168/50000]\tLoss: 0.5100\tLR: 0.015000\nTraining Epoch: 6 [39296/50000]\tLoss: 0.4302\tLR: 0.015000\nTraining Epoch: 6 [39424/50000]\tLoss: 0.4959\tLR: 0.015000\nTraining Epoch: 6 [39552/50000]\tLoss: 0.6323\tLR: 0.015000\nTraining Epoch: 6 [39680/50000]\tLoss: 0.4717\tLR: 0.015000\nTraining Epoch: 6 [39808/50000]\tLoss: 0.3105\tLR: 0.015000\nTraining Epoch: 6 [39936/50000]\tLoss: 0.6012\tLR: 0.015000\nTraining Epoch: 6 [40064/50000]\tLoss: 0.4809\tLR: 0.015000\nTraining Epoch: 6 [40192/50000]\tLoss: 0.4317\tLR: 0.015000\nTraining Epoch: 6 [40320/50000]\tLoss: 0.5506\tLR: 0.015000\nTraining Epoch: 6 [40448/50000]\tLoss: 0.5223\tLR: 0.015000\nTraining Epoch: 6 [40576/50000]\tLoss: 0.3894\tLR: 0.015000\nTraining Epoch: 6 [40704/50000]\tLoss: 0.4587\tLR: 0.015000\nTraining Epoch: 6 [40832/50000]\tLoss: 0.4202\tLR: 0.015000\nTraining Epoch: 6 [40960/50000]\tLoss: 0.4823\tLR: 0.015000\nTraining Epoch: 6 [41088/50000]\tLoss: 0.4447\tLR: 0.015000\nTraining Epoch: 6 [41216/50000]\tLoss: 0.4967\tLR: 0.015000\nTraining Epoch: 6 [41344/50000]\tLoss: 0.5106\tLR: 0.015000\nTraining Epoch: 6 [41472/50000]\tLoss: 0.5541\tLR: 0.015000\nTraining Epoch: 6 [41600/50000]\tLoss: 0.4606\tLR: 0.015000\nTraining Epoch: 6 [41728/50000]\tLoss: 0.5052\tLR: 0.015000\nTraining Epoch: 6 [41856/50000]\tLoss: 0.6309\tLR: 0.015000\nTraining Epoch: 6 [41984/50000]\tLoss: 0.4764\tLR: 0.015000\nTraining Epoch: 6 [42112/50000]\tLoss: 0.4142\tLR: 0.015000\nTraining Epoch: 6 [42240/50000]\tLoss: 0.5443\tLR: 0.015000\nTraining Epoch: 6 [42368/50000]\tLoss: 0.4526\tLR: 0.015000\nTraining Epoch: 6 [42496/50000]\tLoss: 0.5618\tLR: 0.015000\nTraining Epoch: 6 [42624/50000]\tLoss: 0.4209\tLR: 0.015000\nTraining Epoch: 6 [42752/50000]\tLoss: 0.4119\tLR: 0.015000\nTraining Epoch: 6 [42880/50000]\tLoss: 0.3468\tLR: 0.015000\nTraining Epoch: 6 [43008/50000]\tLoss: 0.6433\tLR: 0.015000\nTraining Epoch: 6 [43136/50000]\tLoss: 0.6055\tLR: 0.015000\nTraining Epoch: 6 [43264/50000]\tLoss: 0.3861\tLR: 0.015000\nTraining Epoch: 6 [43392/50000]\tLoss: 0.4451\tLR: 0.015000\nTraining Epoch: 6 [43520/50000]\tLoss: 0.3861\tLR: 0.015000\nTraining Epoch: 6 [43648/50000]\tLoss: 0.4007\tLR: 0.015000\nTraining Epoch: 6 [43776/50000]\tLoss: 0.4194\tLR: 0.015000\nTraining Epoch: 6 [43904/50000]\tLoss: 0.5598\tLR: 0.015000\nTraining Epoch: 6 [44032/50000]\tLoss: 0.5265\tLR: 0.015000\nTraining Epoch: 6 [44160/50000]\tLoss: 0.5269\tLR: 0.015000\nTraining Epoch: 6 [44288/50000]\tLoss: 0.3762\tLR: 0.015000\nTraining Epoch: 6 [44416/50000]\tLoss: 0.4467\tLR: 0.015000\nTraining Epoch: 6 [44544/50000]\tLoss: 0.4019\tLR: 0.015000\nTraining Epoch: 6 [44672/50000]\tLoss: 0.3774\tLR: 0.015000\nTraining Epoch: 6 [44800/50000]\tLoss: 0.3678\tLR: 0.015000\nTraining Epoch: 6 [44928/50000]\tLoss: 0.4132\tLR: 0.015000\nTraining Epoch: 6 [45056/50000]\tLoss: 0.4120\tLR: 0.015000\nTraining Epoch: 6 [45184/50000]\tLoss: 0.4823\tLR: 0.015000\nTraining Epoch: 6 [45312/50000]\tLoss: 0.5159\tLR: 0.015000\nTraining Epoch: 6 [45440/50000]\tLoss: 0.5819\tLR: 0.015000\nTraining Epoch: 6 [45568/50000]\tLoss: 0.5033\tLR: 0.015000\nTraining Epoch: 6 [45696/50000]\tLoss: 0.4295\tLR: 0.015000\nTraining Epoch: 6 [45824/50000]\tLoss: 0.3595\tLR: 0.015000\nTraining Epoch: 6 [45952/50000]\tLoss: 0.4244\tLR: 0.015000\nTraining Epoch: 6 [46080/50000]\tLoss: 0.4481\tLR: 0.015000\nTraining Epoch: 6 [46208/50000]\tLoss: 0.4453\tLR: 0.015000\nTraining Epoch: 6 [46336/50000]\tLoss: 0.5242\tLR: 0.015000\nTraining Epoch: 6 [46464/50000]\tLoss: 0.5931\tLR: 0.015000\nTraining Epoch: 6 [46592/50000]\tLoss: 0.5025\tLR: 0.015000\nTraining Epoch: 6 [46720/50000]\tLoss: 0.5590\tLR: 0.015000\nTraining Epoch: 6 [46848/50000]\tLoss: 0.4165\tLR: 0.015000\nTraining Epoch: 6 [46976/50000]\tLoss: 0.4472\tLR: 0.015000\nTraining Epoch: 6 [47104/50000]\tLoss: 0.6765\tLR: 0.015000\nTraining Epoch: 6 [47232/50000]\tLoss: 0.4665\tLR: 0.015000\nTraining Epoch: 6 [47360/50000]\tLoss: 0.4914\tLR: 0.015000\nTraining Epoch: 6 [47488/50000]\tLoss: 0.4585\tLR: 0.015000\nTraining Epoch: 6 [47616/50000]\tLoss: 0.4951\tLR: 0.015000\nTraining Epoch: 6 [47744/50000]\tLoss: 0.4299\tLR: 0.015000\nTraining Epoch: 6 [47872/50000]\tLoss: 0.6255\tLR: 0.015000\nTraining Epoch: 6 [48000/50000]\tLoss: 0.3965\tLR: 0.015000\nTraining Epoch: 6 [48128/50000]\tLoss: 0.4407\tLR: 0.015000\nTraining Epoch: 6 [48256/50000]\tLoss: 0.3770\tLR: 0.015000\nTraining Epoch: 6 [48384/50000]\tLoss: 0.4304\tLR: 0.015000\nTraining Epoch: 6 [48512/50000]\tLoss: 0.3707\tLR: 0.015000\nTraining Epoch: 6 [48640/50000]\tLoss: 0.4316\tLR: 0.015000\nTraining Epoch: 6 [48768/50000]\tLoss: 0.5700\tLR: 0.015000\nTraining Epoch: 6 [48896/50000]\tLoss: 0.5062\tLR: 0.015000\nTraining Epoch: 6 [49024/50000]\tLoss: 0.5725\tLR: 0.015000\nTraining Epoch: 6 [49152/50000]\tLoss: 0.4594\tLR: 0.015000\nTraining Epoch: 6 [49280/50000]\tLoss: 0.4631\tLR: 0.015000\nTraining Epoch: 6 [49408/50000]\tLoss: 0.3650\tLR: 0.015000\nTraining Epoch: 6 [49536/50000]\tLoss: 0.3816\tLR: 0.015000\nTraining Epoch: 6 [49664/50000]\tLoss: 0.3518\tLR: 0.015000\nTraining Epoch: 6 [49792/50000]\tLoss: 0.4103\tLR: 0.015000\nTraining Epoch: 6 [49920/50000]\tLoss: 0.5362\tLR: 0.015000\nTraining Epoch: 6 [50000/50000]\tLoss: 0.7382\tLR: 0.015000\nTest set: Average loss: 0.0034, Accuracy: 0.8520\n\nTraining Epoch: 7 [128/50000]\tLoss: 0.3793\tLR: 0.015000\nTraining Epoch: 7 [256/50000]\tLoss: 0.3870\tLR: 0.015000\nTraining Epoch: 7 [384/50000]\tLoss: 0.4284\tLR: 0.015000\nTraining Epoch: 7 [512/50000]\tLoss: 0.4347\tLR: 0.015000\nTraining Epoch: 7 [640/50000]\tLoss: 0.4468\tLR: 0.015000\nTraining Epoch: 7 [768/50000]\tLoss: 0.4249\tLR: 0.015000\nTraining Epoch: 7 [896/50000]\tLoss: 0.4743\tLR: 0.015000\nTraining Epoch: 7 [1024/50000]\tLoss: 0.5874\tLR: 0.015000\nTraining Epoch: 7 [1152/50000]\tLoss: 0.4297\tLR: 0.015000\nTraining Epoch: 7 [1280/50000]\tLoss: 0.4721\tLR: 0.015000\nTraining Epoch: 7 [1408/50000]\tLoss: 0.4953\tLR: 0.015000\nTraining Epoch: 7 [1536/50000]\tLoss: 0.4989\tLR: 0.015000\nTraining Epoch: 7 [1664/50000]\tLoss: 0.6124\tLR: 0.015000\nTraining Epoch: 7 [1792/50000]\tLoss: 0.5507\tLR: 0.015000\nTraining Epoch: 7 [1920/50000]\tLoss: 0.7188\tLR: 0.015000\nTraining Epoch: 7 [2048/50000]\tLoss: 0.4211\tLR: 0.015000\nTraining Epoch: 7 [2176/50000]\tLoss: 0.5667\tLR: 0.015000\nTraining Epoch: 7 [2304/50000]\tLoss: 0.4296\tLR: 0.015000\nTraining Epoch: 7 [2432/50000]\tLoss: 0.5814\tLR: 0.015000\nTraining Epoch: 7 [2560/50000]\tLoss: 0.3059\tLR: 0.015000\nTraining Epoch: 7 [2688/50000]\tLoss: 0.4508\tLR: 0.015000\nTraining Epoch: 7 [2816/50000]\tLoss: 0.5743\tLR: 0.015000\nTraining Epoch: 7 [2944/50000]\tLoss: 0.4676\tLR: 0.015000\nTraining Epoch: 7 [3072/50000]\tLoss: 0.4574\tLR: 0.015000\nTraining Epoch: 7 [3200/50000]\tLoss: 0.5314\tLR: 0.015000\nTraining Epoch: 7 [3328/50000]\tLoss: 0.4973\tLR: 0.015000\nTraining Epoch: 7 [3456/50000]\tLoss: 0.4789\tLR: 0.015000\nTraining Epoch: 7 [3584/50000]\tLoss: 0.4200\tLR: 0.015000\nTraining Epoch: 7 [3712/50000]\tLoss: 0.4548\tLR: 0.015000\nTraining Epoch: 7 [3840/50000]\tLoss: 0.4914\tLR: 0.015000\nTraining Epoch: 7 [3968/50000]\tLoss: 0.4710\tLR: 0.015000\nTraining Epoch: 7 [4096/50000]\tLoss: 0.5149\tLR: 0.015000\nTraining Epoch: 7 [4224/50000]\tLoss: 0.4810\tLR: 0.015000\nTraining Epoch: 7 [4352/50000]\tLoss: 0.3556\tLR: 0.015000\nTraining Epoch: 7 [4480/50000]\tLoss: 0.5530\tLR: 0.015000\nTraining Epoch: 7 [4608/50000]\tLoss: 0.4838\tLR: 0.015000\nTraining Epoch: 7 [4736/50000]\tLoss: 0.5288\tLR: 0.015000\nTraining Epoch: 7 [4864/50000]\tLoss: 0.5618\tLR: 0.015000\nTraining Epoch: 7 [4992/50000]\tLoss: 0.5197\tLR: 0.015000\nTraining Epoch: 7 [5120/50000]\tLoss: 0.5571\tLR: 0.015000\nTraining Epoch: 7 [5248/50000]\tLoss: 0.5207\tLR: 0.015000\nTraining Epoch: 7 [5376/50000]\tLoss: 0.4698\tLR: 0.015000\nTraining Epoch: 7 [5504/50000]\tLoss: 0.4410\tLR: 0.015000\nTraining Epoch: 7 [5632/50000]\tLoss: 0.4211\tLR: 0.015000\nTraining Epoch: 7 [5760/50000]\tLoss: 0.5077\tLR: 0.015000\nTraining Epoch: 7 [5888/50000]\tLoss: 0.5242\tLR: 0.015000\nTraining Epoch: 7 [6016/50000]\tLoss: 0.2941\tLR: 0.015000\nTraining Epoch: 7 [6144/50000]\tLoss: 0.3844\tLR: 0.015000\nTraining Epoch: 7 [6272/50000]\tLoss: 0.4349\tLR: 0.015000\nTraining Epoch: 7 [6400/50000]\tLoss: 0.4492\tLR: 0.015000\nTraining Epoch: 7 [6528/50000]\tLoss: 0.3471\tLR: 0.015000\nTraining Epoch: 7 [6656/50000]\tLoss: 0.4546\tLR: 0.015000\nTraining Epoch: 7 [6784/50000]\tLoss: 0.4598\tLR: 0.015000\nTraining Epoch: 7 [6912/50000]\tLoss: 0.6720\tLR: 0.015000\nTraining Epoch: 7 [7040/50000]\tLoss: 0.3333\tLR: 0.015000\nTraining Epoch: 7 [7168/50000]\tLoss: 0.4543\tLR: 0.015000\nTraining Epoch: 7 [7296/50000]\tLoss: 0.4401\tLR: 0.015000\nTraining Epoch: 7 [7424/50000]\tLoss: 0.4458\tLR: 0.015000\nTraining Epoch: 7 [7552/50000]\tLoss: 0.4238\tLR: 0.015000\nTraining Epoch: 7 [7680/50000]\tLoss: 0.3521\tLR: 0.015000\nTraining Epoch: 7 [7808/50000]\tLoss: 0.3867\tLR: 0.015000\nTraining Epoch: 7 [7936/50000]\tLoss: 0.5294\tLR: 0.015000\nTraining Epoch: 7 [8064/50000]\tLoss: 0.4180\tLR: 0.015000\nTraining Epoch: 7 [8192/50000]\tLoss: 0.4188\tLR: 0.015000\nTraining Epoch: 7 [8320/50000]\tLoss: 0.6388\tLR: 0.015000\nTraining Epoch: 7 [8448/50000]\tLoss: 0.5548\tLR: 0.015000\nTraining Epoch: 7 [8576/50000]\tLoss: 0.5016\tLR: 0.015000\nTraining Epoch: 7 [8704/50000]\tLoss: 0.5763\tLR: 0.015000\nTraining Epoch: 7 [8832/50000]\tLoss: 0.6443\tLR: 0.015000\nTraining Epoch: 7 [8960/50000]\tLoss: 0.3491\tLR: 0.015000\nTraining Epoch: 7 [9088/50000]\tLoss: 0.5624\tLR: 0.015000\nTraining Epoch: 7 [9216/50000]\tLoss: 0.4735\tLR: 0.015000\nTraining Epoch: 7 [9344/50000]\tLoss: 0.4513\tLR: 0.015000\nTraining Epoch: 7 [9472/50000]\tLoss: 0.5641\tLR: 0.015000\nTraining Epoch: 7 [9600/50000]\tLoss: 0.3614\tLR: 0.015000\nTraining Epoch: 7 [9728/50000]\tLoss: 0.5986\tLR: 0.015000\nTraining Epoch: 7 [9856/50000]\tLoss: 0.6033\tLR: 0.015000\nTraining Epoch: 7 [9984/50000]\tLoss: 0.4160\tLR: 0.015000\nTraining Epoch: 7 [10112/50000]\tLoss: 0.3615\tLR: 0.015000\nTraining Epoch: 7 [10240/50000]\tLoss: 0.5391\tLR: 0.015000\nTraining Epoch: 7 [10368/50000]\tLoss: 0.6111\tLR: 0.015000\nTraining Epoch: 7 [10496/50000]\tLoss: 0.4751\tLR: 0.015000\nTraining Epoch: 7 [10624/50000]\tLoss: 0.4494\tLR: 0.015000\nTraining Epoch: 7 [10752/50000]\tLoss: 0.5188\tLR: 0.015000\nTraining Epoch: 7 [10880/50000]\tLoss: 0.4767\tLR: 0.015000\nTraining Epoch: 7 [11008/50000]\tLoss: 0.4276\tLR: 0.015000\nTraining Epoch: 7 [11136/50000]\tLoss: 0.3958\tLR: 0.015000\nTraining Epoch: 7 [11264/50000]\tLoss: 0.3654\tLR: 0.015000\nTraining Epoch: 7 [11392/50000]\tLoss: 0.5209\tLR: 0.015000\nTraining Epoch: 7 [11520/50000]\tLoss: 0.3642\tLR: 0.015000\nTraining Epoch: 7 [11648/50000]\tLoss: 0.3918\tLR: 0.015000\nTraining Epoch: 7 [11776/50000]\tLoss: 0.5430\tLR: 0.015000\nTraining Epoch: 7 [11904/50000]\tLoss: 0.4500\tLR: 0.015000\nTraining Epoch: 7 [12032/50000]\tLoss: 0.4289\tLR: 0.015000\nTraining Epoch: 7 [12160/50000]\tLoss: 0.3627\tLR: 0.015000\nTraining Epoch: 7 [12288/50000]\tLoss: 0.5527\tLR: 0.015000\nTraining Epoch: 7 [12416/50000]\tLoss: 0.5256\tLR: 0.015000\nTraining Epoch: 7 [12544/50000]\tLoss: 0.4318\tLR: 0.015000\nTraining Epoch: 7 [12672/50000]\tLoss: 0.5764\tLR: 0.015000\nTraining Epoch: 7 [12800/50000]\tLoss: 0.3904\tLR: 0.015000\nTraining Epoch: 7 [12928/50000]\tLoss: 0.4628\tLR: 0.015000\nTraining Epoch: 7 [13056/50000]\tLoss: 0.3246\tLR: 0.015000\nTraining Epoch: 7 [13184/50000]\tLoss: 0.4147\tLR: 0.015000\nTraining Epoch: 7 [13312/50000]\tLoss: 0.6058\tLR: 0.015000\nTraining Epoch: 7 [13440/50000]\tLoss: 0.5426\tLR: 0.015000\nTraining Epoch: 7 [13568/50000]\tLoss: 0.4380\tLR: 0.015000\nTraining Epoch: 7 [13696/50000]\tLoss: 0.6146\tLR: 0.015000\nTraining Epoch: 7 [13824/50000]\tLoss: 0.4156\tLR: 0.015000\nTraining Epoch: 7 [13952/50000]\tLoss: 0.5739\tLR: 0.015000\nTraining Epoch: 7 [14080/50000]\tLoss: 0.4154\tLR: 0.015000\nTraining Epoch: 7 [14208/50000]\tLoss: 0.3239\tLR: 0.015000\nTraining Epoch: 7 [14336/50000]\tLoss: 0.4185\tLR: 0.015000\nTraining Epoch: 7 [14464/50000]\tLoss: 0.4885\tLR: 0.015000\nTraining Epoch: 7 [14592/50000]\tLoss: 0.4384\tLR: 0.015000\nTraining Epoch: 7 [14720/50000]\tLoss: 0.4273\tLR: 0.015000\nTraining Epoch: 7 [14848/50000]\tLoss: 0.5871\tLR: 0.015000\nTraining Epoch: 7 [14976/50000]\tLoss: 0.5458\tLR: 0.015000\nTraining Epoch: 7 [15104/50000]\tLoss: 0.4856\tLR: 0.015000\nTraining Epoch: 7 [15232/50000]\tLoss: 0.4957\tLR: 0.015000\nTraining Epoch: 7 [15360/50000]\tLoss: 0.4405\tLR: 0.015000\nTraining Epoch: 7 [15488/50000]\tLoss: 0.5436\tLR: 0.015000\nTraining Epoch: 7 [15616/50000]\tLoss: 0.4865\tLR: 0.015000\nTraining Epoch: 7 [15744/50000]\tLoss: 0.3506\tLR: 0.015000\nTraining Epoch: 7 [15872/50000]\tLoss: 0.6435\tLR: 0.015000\nTraining Epoch: 7 [16000/50000]\tLoss: 0.4150\tLR: 0.015000\nTraining Epoch: 7 [16128/50000]\tLoss: 0.4993\tLR: 0.015000\nTraining Epoch: 7 [16256/50000]\tLoss: 0.4653\tLR: 0.015000\nTraining Epoch: 7 [16384/50000]\tLoss: 0.4358\tLR: 0.015000\nTraining Epoch: 7 [16512/50000]\tLoss: 0.3969\tLR: 0.015000\nTraining Epoch: 7 [16640/50000]\tLoss: 0.3770\tLR: 0.015000\nTraining Epoch: 7 [16768/50000]\tLoss: 0.5347\tLR: 0.015000\nTraining Epoch: 7 [16896/50000]\tLoss: 0.4492\tLR: 0.015000\nTraining Epoch: 7 [17024/50000]\tLoss: 0.4564\tLR: 0.015000\nTraining Epoch: 7 [17152/50000]\tLoss: 0.5016\tLR: 0.015000\nTraining Epoch: 7 [17280/50000]\tLoss: 0.4445\tLR: 0.015000\nTraining Epoch: 7 [17408/50000]\tLoss: 0.5869\tLR: 0.015000\nTraining Epoch: 7 [17536/50000]\tLoss: 0.4161\tLR: 0.015000\nTraining Epoch: 7 [17664/50000]\tLoss: 0.5396\tLR: 0.015000\nTraining Epoch: 7 [17792/50000]\tLoss: 0.5770\tLR: 0.015000\nTraining Epoch: 7 [17920/50000]\tLoss: 0.3276\tLR: 0.015000\nTraining Epoch: 7 [18048/50000]\tLoss: 0.4308\tLR: 0.015000\nTraining Epoch: 7 [18176/50000]\tLoss: 0.3583\tLR: 0.015000\nTraining Epoch: 7 [18304/50000]\tLoss: 0.6111\tLR: 0.015000\nTraining Epoch: 7 [18432/50000]\tLoss: 0.4296\tLR: 0.015000\nTraining Epoch: 7 [18560/50000]\tLoss: 0.5460\tLR: 0.015000\nTraining Epoch: 7 [18688/50000]\tLoss: 0.4309\tLR: 0.015000\nTraining Epoch: 7 [18816/50000]\tLoss: 0.5554\tLR: 0.015000\nTraining Epoch: 7 [18944/50000]\tLoss: 0.4041\tLR: 0.015000\nTraining Epoch: 7 [19072/50000]\tLoss: 0.4896\tLR: 0.015000\nTraining Epoch: 7 [19200/50000]\tLoss: 0.3426\tLR: 0.015000\nTraining Epoch: 7 [19328/50000]\tLoss: 0.5718\tLR: 0.015000\nTraining Epoch: 7 [19456/50000]\tLoss: 0.4547\tLR: 0.015000\nTraining Epoch: 7 [19584/50000]\tLoss: 0.5467\tLR: 0.015000\nTraining Epoch: 7 [19712/50000]\tLoss: 0.4973\tLR: 0.015000\nTraining Epoch: 7 [19840/50000]\tLoss: 0.4819\tLR: 0.015000\nTraining Epoch: 7 [19968/50000]\tLoss: 0.4168\tLR: 0.015000\nTraining Epoch: 7 [20096/50000]\tLoss: 0.4450\tLR: 0.015000\nTraining Epoch: 7 [20224/50000]\tLoss: 0.3789\tLR: 0.015000\nTraining Epoch: 7 [20352/50000]\tLoss: 0.3092\tLR: 0.015000\nTraining Epoch: 7 [20480/50000]\tLoss: 0.5155\tLR: 0.015000\nTraining Epoch: 7 [20608/50000]\tLoss: 0.4784\tLR: 0.015000\nTraining Epoch: 7 [20736/50000]\tLoss: 0.5195\tLR: 0.015000\nTraining Epoch: 7 [20864/50000]\tLoss: 0.5159\tLR: 0.015000\nTraining Epoch: 7 [20992/50000]\tLoss: 0.3894\tLR: 0.015000\nTraining Epoch: 7 [21120/50000]\tLoss: 0.4108\tLR: 0.015000\nTraining Epoch: 7 [21248/50000]\tLoss: 0.5630\tLR: 0.015000\nTraining Epoch: 7 [21376/50000]\tLoss: 0.5288\tLR: 0.015000\nTraining Epoch: 7 [21504/50000]\tLoss: 0.4329\tLR: 0.015000\nTraining Epoch: 7 [21632/50000]\tLoss: 0.4408\tLR: 0.015000\nTraining Epoch: 7 [21760/50000]\tLoss: 0.4272\tLR: 0.015000\nTraining Epoch: 7 [21888/50000]\tLoss: 0.5321\tLR: 0.015000\nTraining Epoch: 7 [22016/50000]\tLoss: 0.3647\tLR: 0.015000\nTraining Epoch: 7 [22144/50000]\tLoss: 0.4714\tLR: 0.015000\nTraining Epoch: 7 [22272/50000]\tLoss: 0.4282\tLR: 0.015000\nTraining Epoch: 7 [22400/50000]\tLoss: 0.5447\tLR: 0.015000\nTraining Epoch: 7 [22528/50000]\tLoss: 0.3423\tLR: 0.015000\nTraining Epoch: 7 [22656/50000]\tLoss: 0.4453\tLR: 0.015000\nTraining Epoch: 7 [22784/50000]\tLoss: 0.4885\tLR: 0.015000\nTraining Epoch: 7 [22912/50000]\tLoss: 0.4967\tLR: 0.015000\nTraining Epoch: 7 [23040/50000]\tLoss: 0.6044\tLR: 0.015000\nTraining Epoch: 7 [23168/50000]\tLoss: 0.5159\tLR: 0.015000\nTraining Epoch: 7 [23296/50000]\tLoss: 0.4017\tLR: 0.015000\nTraining Epoch: 7 [23424/50000]\tLoss: 0.4695\tLR: 0.015000\nTraining Epoch: 7 [23552/50000]\tLoss: 0.4543\tLR: 0.015000\nTraining Epoch: 7 [23680/50000]\tLoss: 0.4798\tLR: 0.015000\nTraining Epoch: 7 [23808/50000]\tLoss: 0.4538\tLR: 0.015000\nTraining Epoch: 7 [23936/50000]\tLoss: 0.5363\tLR: 0.015000\nTraining Epoch: 7 [24064/50000]\tLoss: 0.3942\tLR: 0.015000\nTraining Epoch: 7 [24192/50000]\tLoss: 0.4331\tLR: 0.015000\nTraining Epoch: 7 [24320/50000]\tLoss: 0.5450\tLR: 0.015000\nTraining Epoch: 7 [24448/50000]\tLoss: 0.5430\tLR: 0.015000\nTraining Epoch: 7 [24576/50000]\tLoss: 0.4906\tLR: 0.015000\nTraining Epoch: 7 [24704/50000]\tLoss: 0.4684\tLR: 0.015000\nTraining Epoch: 7 [24832/50000]\tLoss: 0.4366\tLR: 0.015000\nTraining Epoch: 7 [24960/50000]\tLoss: 0.4948\tLR: 0.015000\nTraining Epoch: 7 [25088/50000]\tLoss: 0.3177\tLR: 0.015000\nTraining Epoch: 7 [25216/50000]\tLoss: 0.3840\tLR: 0.015000\nTraining Epoch: 7 [25344/50000]\tLoss: 0.3611\tLR: 0.015000\nTraining Epoch: 7 [25472/50000]\tLoss: 0.4539\tLR: 0.015000\nTraining Epoch: 7 [25600/50000]\tLoss: 0.4721\tLR: 0.015000\nTraining Epoch: 7 [25728/50000]\tLoss: 0.5222\tLR: 0.015000\nTraining Epoch: 7 [25856/50000]\tLoss: 0.3835\tLR: 0.015000\nTraining Epoch: 7 [25984/50000]\tLoss: 0.5421\tLR: 0.015000\nTraining Epoch: 7 [26112/50000]\tLoss: 0.4813\tLR: 0.015000\nTraining Epoch: 7 [26240/50000]\tLoss: 0.5256\tLR: 0.015000\nTraining Epoch: 7 [26368/50000]\tLoss: 0.4280\tLR: 0.015000\nTraining Epoch: 7 [26496/50000]\tLoss: 0.4928\tLR: 0.015000\nTraining Epoch: 7 [26624/50000]\tLoss: 0.3762\tLR: 0.015000\nTraining Epoch: 7 [26752/50000]\tLoss: 0.4657\tLR: 0.015000\nTraining Epoch: 7 [26880/50000]\tLoss: 0.3873\tLR: 0.015000\nTraining Epoch: 7 [27008/50000]\tLoss: 0.4744\tLR: 0.015000\nTraining Epoch: 7 [27136/50000]\tLoss: 0.3648\tLR: 0.015000\nTraining Epoch: 7 [27264/50000]\tLoss: 0.3844\tLR: 0.015000\nTraining Epoch: 7 [27392/50000]\tLoss: 0.5034\tLR: 0.015000\nTraining Epoch: 7 [27520/50000]\tLoss: 0.4856\tLR: 0.015000\nTraining Epoch: 7 [27648/50000]\tLoss: 0.5432\tLR: 0.015000\nTraining Epoch: 7 [27776/50000]\tLoss: 0.4478\tLR: 0.015000\nTraining Epoch: 7 [27904/50000]\tLoss: 0.4246\tLR: 0.015000\nTraining Epoch: 7 [28032/50000]\tLoss: 0.4261\tLR: 0.015000\nTraining Epoch: 7 [28160/50000]\tLoss: 0.3974\tLR: 0.015000\nTraining Epoch: 7 [28288/50000]\tLoss: 0.3868\tLR: 0.015000\nTraining Epoch: 7 [28416/50000]\tLoss: 0.4383\tLR: 0.015000\nTraining Epoch: 7 [28544/50000]\tLoss: 0.4627\tLR: 0.015000\nTraining Epoch: 7 [28672/50000]\tLoss: 0.4344\tLR: 0.015000\nTraining Epoch: 7 [28800/50000]\tLoss: 0.4540\tLR: 0.015000\nTraining Epoch: 7 [28928/50000]\tLoss: 0.6098\tLR: 0.015000\nTraining Epoch: 7 [29056/50000]\tLoss: 0.4645\tLR: 0.015000\nTraining Epoch: 7 [29184/50000]\tLoss: 0.3782\tLR: 0.015000\nTraining Epoch: 7 [29312/50000]\tLoss: 0.5935\tLR: 0.015000\nTraining Epoch: 7 [29440/50000]\tLoss: 0.4107\tLR: 0.015000\nTraining Epoch: 7 [29568/50000]\tLoss: 0.4844\tLR: 0.015000\nTraining Epoch: 7 [29696/50000]\tLoss: 0.4404\tLR: 0.015000\nTraining Epoch: 7 [29824/50000]\tLoss: 0.5550\tLR: 0.015000\nTraining Epoch: 7 [29952/50000]\tLoss: 0.5301\tLR: 0.015000\nTraining Epoch: 7 [30080/50000]\tLoss: 0.4256\tLR: 0.015000\nTraining Epoch: 7 [30208/50000]\tLoss: 0.4103\tLR: 0.015000\nTraining Epoch: 7 [30336/50000]\tLoss: 0.5133\tLR: 0.015000\nTraining Epoch: 7 [30464/50000]\tLoss: 0.4355\tLR: 0.015000\nTraining Epoch: 7 [30592/50000]\tLoss: 0.5643\tLR: 0.015000\nTraining Epoch: 7 [30720/50000]\tLoss: 0.5676\tLR: 0.015000\nTraining Epoch: 7 [30848/50000]\tLoss: 0.3472\tLR: 0.015000\nTraining Epoch: 7 [30976/50000]\tLoss: 0.4368\tLR: 0.015000\nTraining Epoch: 7 [31104/50000]\tLoss: 0.4760\tLR: 0.015000\nTraining Epoch: 7 [31232/50000]\tLoss: 0.3825\tLR: 0.015000\nTraining Epoch: 7 [31360/50000]\tLoss: 0.4579\tLR: 0.015000\nTraining Epoch: 7 [31488/50000]\tLoss: 0.4465\tLR: 0.015000\nTraining Epoch: 7 [31616/50000]\tLoss: 0.4292\tLR: 0.015000\nTraining Epoch: 7 [31744/50000]\tLoss: 0.4143\tLR: 0.015000\nTraining Epoch: 7 [31872/50000]\tLoss: 0.3414\tLR: 0.015000\nTraining Epoch: 7 [32000/50000]\tLoss: 0.5113\tLR: 0.015000\nTraining Epoch: 7 [32128/50000]\tLoss: 0.4817\tLR: 0.015000\nTraining Epoch: 7 [32256/50000]\tLoss: 0.3300\tLR: 0.015000\nTraining Epoch: 7 [32384/50000]\tLoss: 0.3986\tLR: 0.015000\nTraining Epoch: 7 [32512/50000]\tLoss: 0.5585\tLR: 0.015000\nTraining Epoch: 7 [32640/50000]\tLoss: 0.5223\tLR: 0.015000\nTraining Epoch: 7 [32768/50000]\tLoss: 0.5672\tLR: 0.015000\nTraining Epoch: 7 [32896/50000]\tLoss: 0.3008\tLR: 0.015000\nTraining Epoch: 7 [33024/50000]\tLoss: 0.6373\tLR: 0.015000\nTraining Epoch: 7 [33152/50000]\tLoss: 0.3996\tLR: 0.015000\nTraining Epoch: 7 [33280/50000]\tLoss: 0.4707\tLR: 0.015000\nTraining Epoch: 7 [33408/50000]\tLoss: 0.4581\tLR: 0.015000\nTraining Epoch: 7 [33536/50000]\tLoss: 0.4975\tLR: 0.015000\nTraining Epoch: 7 [33664/50000]\tLoss: 0.4441\tLR: 0.015000\nTraining Epoch: 7 [33792/50000]\tLoss: 0.4213\tLR: 0.015000\nTraining Epoch: 7 [33920/50000]\tLoss: 0.5241\tLR: 0.015000\nTraining Epoch: 7 [34048/50000]\tLoss: 0.6268\tLR: 0.015000\nTraining Epoch: 7 [34176/50000]\tLoss: 0.4053\tLR: 0.015000\nTraining Epoch: 7 [34304/50000]\tLoss: 0.4338\tLR: 0.015000\nTraining Epoch: 7 [34432/50000]\tLoss: 0.4520\tLR: 0.015000\nTraining Epoch: 7 [34560/50000]\tLoss: 0.4822\tLR: 0.015000\nTraining Epoch: 7 [34688/50000]\tLoss: 0.4693\tLR: 0.015000\nTraining Epoch: 7 [34816/50000]\tLoss: 0.4698\tLR: 0.015000\nTraining Epoch: 7 [34944/50000]\tLoss: 0.4160\tLR: 0.015000\nTraining Epoch: 7 [35072/50000]\tLoss: 0.4326\tLR: 0.015000\nTraining Epoch: 7 [35200/50000]\tLoss: 0.3423\tLR: 0.015000\nTraining Epoch: 7 [35328/50000]\tLoss: 0.4297\tLR: 0.015000\nTraining Epoch: 7 [35456/50000]\tLoss: 0.3407\tLR: 0.015000\nTraining Epoch: 7 [35584/50000]\tLoss: 0.4022\tLR: 0.015000\nTraining Epoch: 7 [35712/50000]\tLoss: 0.3303\tLR: 0.015000\nTraining Epoch: 7 [35840/50000]\tLoss: 0.6318\tLR: 0.015000\nTraining Epoch: 7 [35968/50000]\tLoss: 0.4261\tLR: 0.015000\nTraining Epoch: 7 [36096/50000]\tLoss: 0.3498\tLR: 0.015000\nTraining Epoch: 7 [36224/50000]\tLoss: 0.5601\tLR: 0.015000\nTraining Epoch: 7 [36352/50000]\tLoss: 0.4982\tLR: 0.015000\nTraining Epoch: 7 [36480/50000]\tLoss: 0.4826\tLR: 0.015000\nTraining Epoch: 7 [36608/50000]\tLoss: 0.4608\tLR: 0.015000\nTraining Epoch: 7 [36736/50000]\tLoss: 0.4084\tLR: 0.015000\nTraining Epoch: 7 [36864/50000]\tLoss: 0.4619\tLR: 0.015000\nTraining Epoch: 7 [36992/50000]\tLoss: 0.4958\tLR: 0.015000\nTraining Epoch: 7 [37120/50000]\tLoss: 0.4655\tLR: 0.015000\nTraining Epoch: 7 [37248/50000]\tLoss: 0.3614\tLR: 0.015000\nTraining Epoch: 7 [37376/50000]\tLoss: 0.4910\tLR: 0.015000\nTraining Epoch: 7 [37504/50000]\tLoss: 0.3118\tLR: 0.015000\nTraining Epoch: 7 [37632/50000]\tLoss: 0.5200\tLR: 0.015000\nTraining Epoch: 7 [37760/50000]\tLoss: 0.4719\tLR: 0.015000\nTraining Epoch: 7 [37888/50000]\tLoss: 0.6677\tLR: 0.015000\nTraining Epoch: 7 [38016/50000]\tLoss: 0.4228\tLR: 0.015000\nTraining Epoch: 7 [38144/50000]\tLoss: 0.3753\tLR: 0.015000\nTraining Epoch: 7 [38272/50000]\tLoss: 0.4356\tLR: 0.015000\nTraining Epoch: 7 [38400/50000]\tLoss: 0.3608\tLR: 0.015000\nTraining Epoch: 7 [38528/50000]\tLoss: 0.4319\tLR: 0.015000\nTraining Epoch: 7 [38656/50000]\tLoss: 0.4684\tLR: 0.015000\nTraining Epoch: 7 [38784/50000]\tLoss: 0.4836\tLR: 0.015000\nTraining Epoch: 7 [38912/50000]\tLoss: 0.4882\tLR: 0.015000\nTraining Epoch: 7 [39040/50000]\tLoss: 0.3637\tLR: 0.015000\nTraining Epoch: 7 [39168/50000]\tLoss: 0.4435\tLR: 0.015000\nTraining Epoch: 7 [39296/50000]\tLoss: 0.4157\tLR: 0.015000\nTraining Epoch: 7 [39424/50000]\tLoss: 0.4629\tLR: 0.015000\nTraining Epoch: 7 [39552/50000]\tLoss: 0.5305\tLR: 0.015000\nTraining Epoch: 7 [39680/50000]\tLoss: 0.3832\tLR: 0.015000\nTraining Epoch: 7 [39808/50000]\tLoss: 0.5340\tLR: 0.015000\nTraining Epoch: 7 [39936/50000]\tLoss: 0.4251\tLR: 0.015000\nTraining Epoch: 7 [40064/50000]\tLoss: 0.4432\tLR: 0.015000\nTraining Epoch: 7 [40192/50000]\tLoss: 0.5651\tLR: 0.015000\nTraining Epoch: 7 [40320/50000]\tLoss: 0.4857\tLR: 0.015000\nTraining Epoch: 7 [40448/50000]\tLoss: 0.3907\tLR: 0.015000\nTraining Epoch: 7 [40576/50000]\tLoss: 0.4436\tLR: 0.015000\nTraining Epoch: 7 [40704/50000]\tLoss: 0.3960\tLR: 0.015000\nTraining Epoch: 7 [40832/50000]\tLoss: 0.5763\tLR: 0.015000\nTraining Epoch: 7 [40960/50000]\tLoss: 0.4747\tLR: 0.015000\nTraining Epoch: 7 [41088/50000]\tLoss: 0.5882\tLR: 0.015000\nTraining Epoch: 7 [41216/50000]\tLoss: 0.4362\tLR: 0.015000\nTraining Epoch: 7 [41344/50000]\tLoss: 0.5147\tLR: 0.015000\nTraining Epoch: 7 [41472/50000]\tLoss: 0.4108\tLR: 0.015000\nTraining Epoch: 7 [41600/50000]\tLoss: 0.4259\tLR: 0.015000\nTraining Epoch: 7 [41728/50000]\tLoss: 0.5197\tLR: 0.015000\nTraining Epoch: 7 [41856/50000]\tLoss: 0.3616\tLR: 0.015000\nTraining Epoch: 7 [41984/50000]\tLoss: 0.4612\tLR: 0.015000\nTraining Epoch: 7 [42112/50000]\tLoss: 0.4178\tLR: 0.015000\nTraining Epoch: 7 [42240/50000]\tLoss: 0.3892\tLR: 0.015000\nTraining Epoch: 7 [42368/50000]\tLoss: 0.4680\tLR: 0.015000\nTraining Epoch: 7 [42496/50000]\tLoss: 0.6308\tLR: 0.015000\nTraining Epoch: 7 [42624/50000]\tLoss: 0.3860\tLR: 0.015000\nTraining Epoch: 7 [42752/50000]\tLoss: 0.4504\tLR: 0.015000\nTraining Epoch: 7 [42880/50000]\tLoss: 0.5103\tLR: 0.015000\nTraining Epoch: 7 [43008/50000]\tLoss: 0.3300\tLR: 0.015000\nTraining Epoch: 7 [43136/50000]\tLoss: 0.4821\tLR: 0.015000\nTraining Epoch: 7 [43264/50000]\tLoss: 0.3664\tLR: 0.015000\nTraining Epoch: 7 [43392/50000]\tLoss: 0.4099\tLR: 0.015000\nTraining Epoch: 7 [43520/50000]\tLoss: 0.4171\tLR: 0.015000\nTraining Epoch: 7 [43648/50000]\tLoss: 0.3537\tLR: 0.015000\nTraining Epoch: 7 [43776/50000]\tLoss: 0.4489\tLR: 0.015000\nTraining Epoch: 7 [43904/50000]\tLoss: 0.5346\tLR: 0.015000\nTraining Epoch: 7 [44032/50000]\tLoss: 0.4882\tLR: 0.015000\nTraining Epoch: 7 [44160/50000]\tLoss: 0.3986\tLR: 0.015000\nTraining Epoch: 7 [44288/50000]\tLoss: 0.4205\tLR: 0.015000\nTraining Epoch: 7 [44416/50000]\tLoss: 0.2680\tLR: 0.015000\nTraining Epoch: 7 [44544/50000]\tLoss: 0.4295\tLR: 0.015000\nTraining Epoch: 7 [44672/50000]\tLoss: 0.4480\tLR: 0.015000\nTraining Epoch: 7 [44800/50000]\tLoss: 0.3554\tLR: 0.015000\nTraining Epoch: 7 [44928/50000]\tLoss: 0.5937\tLR: 0.015000\nTraining Epoch: 7 [45056/50000]\tLoss: 0.4705\tLR: 0.015000\nTraining Epoch: 7 [45184/50000]\tLoss: 0.5817\tLR: 0.015000\nTraining Epoch: 7 [45312/50000]\tLoss: 0.5149\tLR: 0.015000\nTraining Epoch: 7 [45440/50000]\tLoss: 0.4624\tLR: 0.015000\nTraining Epoch: 7 [45568/50000]\tLoss: 0.5909\tLR: 0.015000\nTraining Epoch: 7 [45696/50000]\tLoss: 0.4796\tLR: 0.015000\nTraining Epoch: 7 [45824/50000]\tLoss: 0.4656\tLR: 0.015000\nTraining Epoch: 7 [45952/50000]\tLoss: 0.4793\tLR: 0.015000\nTraining Epoch: 7 [46080/50000]\tLoss: 0.5431\tLR: 0.015000\nTraining Epoch: 7 [46208/50000]\tLoss: 0.3549\tLR: 0.015000\nTraining Epoch: 7 [46336/50000]\tLoss: 0.4504\tLR: 0.015000\nTraining Epoch: 7 [46464/50000]\tLoss: 0.4633\tLR: 0.015000\nTraining Epoch: 7 [46592/50000]\tLoss: 0.3982\tLR: 0.015000\nTraining Epoch: 7 [46720/50000]\tLoss: 0.4181\tLR: 0.015000\nTraining Epoch: 7 [46848/50000]\tLoss: 0.3419\tLR: 0.015000\nTraining Epoch: 7 [46976/50000]\tLoss: 0.4830\tLR: 0.015000\nTraining Epoch: 7 [47104/50000]\tLoss: 0.5065\tLR: 0.015000\nTraining Epoch: 7 [47232/50000]\tLoss: 0.4370\tLR: 0.015000\nTraining Epoch: 7 [47360/50000]\tLoss: 0.4277\tLR: 0.015000\nTraining Epoch: 7 [47488/50000]\tLoss: 0.6424\tLR: 0.015000\nTraining Epoch: 7 [47616/50000]\tLoss: 0.5467\tLR: 0.015000\nTraining Epoch: 7 [47744/50000]\tLoss: 0.4386\tLR: 0.015000\nTraining Epoch: 7 [47872/50000]\tLoss: 0.4262\tLR: 0.015000\nTraining Epoch: 7 [48000/50000]\tLoss: 0.4736\tLR: 0.015000\nTraining Epoch: 7 [48128/50000]\tLoss: 0.4892\tLR: 0.015000\nTraining Epoch: 7 [48256/50000]\tLoss: 0.4424\tLR: 0.015000\nTraining Epoch: 7 [48384/50000]\tLoss: 0.4606\tLR: 0.015000\nTraining Epoch: 7 [48512/50000]\tLoss: 0.5066\tLR: 0.015000\nTraining Epoch: 7 [48640/50000]\tLoss: 0.4640\tLR: 0.015000\nTraining Epoch: 7 [48768/50000]\tLoss: 0.5378\tLR: 0.015000\nTraining Epoch: 7 [48896/50000]\tLoss: 0.5382\tLR: 0.015000\nTraining Epoch: 7 [49024/50000]\tLoss: 0.4328\tLR: 0.015000\nTraining Epoch: 7 [49152/50000]\tLoss: 0.4881\tLR: 0.015000\nTraining Epoch: 7 [49280/50000]\tLoss: 0.4244\tLR: 0.015000\nTraining Epoch: 7 [49408/50000]\tLoss: 0.5813\tLR: 0.015000\nTraining Epoch: 7 [49536/50000]\tLoss: 0.4636\tLR: 0.015000\nTraining Epoch: 7 [49664/50000]\tLoss: 0.4210\tLR: 0.015000\nTraining Epoch: 7 [49792/50000]\tLoss: 0.4292\tLR: 0.015000\nTraining Epoch: 7 [49920/50000]\tLoss: 0.5498\tLR: 0.015000\nTraining Epoch: 7 [50000/50000]\tLoss: 0.3632\tLR: 0.015000\nTest set: Average loss: 0.0031, Accuracy: 0.8674\n\nTraining Epoch: 8 [128/50000]\tLoss: 0.3585\tLR: 0.015000\nTraining Epoch: 8 [256/50000]\tLoss: 0.4258\tLR: 0.015000\nTraining Epoch: 8 [384/50000]\tLoss: 0.3592\tLR: 0.015000\nTraining Epoch: 8 [512/50000]\tLoss: 0.4704\tLR: 0.015000\nTraining Epoch: 8 [640/50000]\tLoss: 0.4440\tLR: 0.015000\nTraining Epoch: 8 [768/50000]\tLoss: 0.4162\tLR: 0.015000\nTraining Epoch: 8 [896/50000]\tLoss: 0.3882\tLR: 0.015000\nTraining Epoch: 8 [1024/50000]\tLoss: 0.4438\tLR: 0.015000\nTraining Epoch: 8 [1152/50000]\tLoss: 0.4007\tLR: 0.015000\nTraining Epoch: 8 [1280/50000]\tLoss: 0.4440\tLR: 0.015000\nTraining Epoch: 8 [1408/50000]\tLoss: 0.4995\tLR: 0.015000\nTraining Epoch: 8 [1536/50000]\tLoss: 0.3314\tLR: 0.015000\nTraining Epoch: 8 [1664/50000]\tLoss: 0.4057\tLR: 0.015000\nTraining Epoch: 8 [1792/50000]\tLoss: 0.4552\tLR: 0.015000\nTraining Epoch: 8 [1920/50000]\tLoss: 0.3781\tLR: 0.015000\nTraining Epoch: 8 [2048/50000]\tLoss: 0.3840\tLR: 0.015000\nTraining Epoch: 8 [2176/50000]\tLoss: 0.5042\tLR: 0.015000\nTraining Epoch: 8 [2304/50000]\tLoss: 0.6299\tLR: 0.015000\nTraining Epoch: 8 [2432/50000]\tLoss: 0.4714\tLR: 0.015000\nTraining Epoch: 8 [2560/50000]\tLoss: 0.3851\tLR: 0.015000\nTraining Epoch: 8 [2688/50000]\tLoss: 0.5700\tLR: 0.015000\nTraining Epoch: 8 [2816/50000]\tLoss: 0.3939\tLR: 0.015000\nTraining Epoch: 8 [2944/50000]\tLoss: 0.3460\tLR: 0.015000\nTraining Epoch: 8 [3072/50000]\tLoss: 0.4747\tLR: 0.015000\nTraining Epoch: 8 [3200/50000]\tLoss: 0.4543\tLR: 0.015000\nTraining Epoch: 8 [3328/50000]\tLoss: 0.3691\tLR: 0.015000\nTraining Epoch: 8 [3456/50000]\tLoss: 0.3360\tLR: 0.015000\nTraining Epoch: 8 [3584/50000]\tLoss: 0.3564\tLR: 0.015000\nTraining Epoch: 8 [3712/50000]\tLoss: 0.3684\tLR: 0.015000\nTraining Epoch: 8 [3840/50000]\tLoss: 0.4057\tLR: 0.015000\nTraining Epoch: 8 [3968/50000]\tLoss: 0.5202\tLR: 0.015000\nTraining Epoch: 8 [4096/50000]\tLoss: 0.3989\tLR: 0.015000\nTraining Epoch: 8 [4224/50000]\tLoss: 0.5284\tLR: 0.015000\nTraining Epoch: 8 [4352/50000]\tLoss: 0.3265\tLR: 0.015000\nTraining Epoch: 8 [4480/50000]\tLoss: 0.3624\tLR: 0.015000\nTraining Epoch: 8 [4608/50000]\tLoss: 0.4591\tLR: 0.015000\nTraining Epoch: 8 [4736/50000]\tLoss: 0.4614\tLR: 0.015000\nTraining Epoch: 8 [4864/50000]\tLoss: 0.5618\tLR: 0.015000\nTraining Epoch: 8 [4992/50000]\tLoss: 0.3649\tLR: 0.015000\nTraining Epoch: 8 [5120/50000]\tLoss: 0.3804\tLR: 0.015000\nTraining Epoch: 8 [5248/50000]\tLoss: 0.4317\tLR: 0.015000\nTraining Epoch: 8 [5376/50000]\tLoss: 0.3550\tLR: 0.015000\nTraining Epoch: 8 [5504/50000]\tLoss: 0.3693\tLR: 0.015000\nTraining Epoch: 8 [5632/50000]\tLoss: 0.3113\tLR: 0.015000\nTraining Epoch: 8 [5760/50000]\tLoss: 0.5501\tLR: 0.015000\nTraining Epoch: 8 [5888/50000]\tLoss: 0.5516\tLR: 0.015000\nTraining Epoch: 8 [6016/50000]\tLoss: 0.5083\tLR: 0.015000\nTraining Epoch: 8 [6144/50000]\tLoss: 0.3820\tLR: 0.015000\nTraining Epoch: 8 [6272/50000]\tLoss: 0.4406\tLR: 0.015000\nTraining Epoch: 8 [6400/50000]\tLoss: 0.4104\tLR: 0.015000\nTraining Epoch: 8 [6528/50000]\tLoss: 0.4378\tLR: 0.015000\nTraining Epoch: 8 [6656/50000]\tLoss: 0.4389\tLR: 0.015000\nTraining Epoch: 8 [6784/50000]\tLoss: 0.6094\tLR: 0.015000\nTraining Epoch: 8 [6912/50000]\tLoss: 0.4593\tLR: 0.015000\nTraining Epoch: 8 [7040/50000]\tLoss: 0.4228\tLR: 0.015000\nTraining Epoch: 8 [7168/50000]\tLoss: 0.3836\tLR: 0.015000\nTraining Epoch: 8 [7296/50000]\tLoss: 0.3638\tLR: 0.015000\nTraining Epoch: 8 [7424/50000]\tLoss: 0.3368\tLR: 0.015000\nTraining Epoch: 8 [7552/50000]\tLoss: 0.4130\tLR: 0.015000\nTraining Epoch: 8 [7680/50000]\tLoss: 0.3345\tLR: 0.015000\nTraining Epoch: 8 [7808/50000]\tLoss: 0.4240\tLR: 0.015000\nTraining Epoch: 8 [7936/50000]\tLoss: 0.3881\tLR: 0.015000\nTraining Epoch: 8 [8064/50000]\tLoss: 0.4753\tLR: 0.015000\nTraining Epoch: 8 [8192/50000]\tLoss: 0.4957\tLR: 0.015000\nTraining Epoch: 8 [8320/50000]\tLoss: 0.5218\tLR: 0.015000\nTraining Epoch: 8 [8448/50000]\tLoss: 0.4634\tLR: 0.015000\nTraining Epoch: 8 [8576/50000]\tLoss: 0.5173\tLR: 0.015000\nTraining Epoch: 8 [8704/50000]\tLoss: 0.4030\tLR: 0.015000\nTraining Epoch: 8 [8832/50000]\tLoss: 0.3895\tLR: 0.015000\nTraining Epoch: 8 [8960/50000]\tLoss: 0.4555\tLR: 0.015000\nTraining Epoch: 8 [9088/50000]\tLoss: 0.4567\tLR: 0.015000\nTraining Epoch: 8 [9216/50000]\tLoss: 0.4455\tLR: 0.015000\nTraining Epoch: 8 [9344/50000]\tLoss: 0.3731\tLR: 0.015000\nTraining Epoch: 8 [9472/50000]\tLoss: 0.3139\tLR: 0.015000\nTraining Epoch: 8 [9600/50000]\tLoss: 0.3945\tLR: 0.015000\nTraining Epoch: 8 [9728/50000]\tLoss: 0.3871\tLR: 0.015000\nTraining Epoch: 8 [9856/50000]\tLoss: 0.4489\tLR: 0.015000\nTraining Epoch: 8 [9984/50000]\tLoss: 0.3963\tLR: 0.015000\nTraining Epoch: 8 [10112/50000]\tLoss: 0.3658\tLR: 0.015000\nTraining Epoch: 8 [10240/50000]\tLoss: 0.3900\tLR: 0.015000\nTraining Epoch: 8 [10368/50000]\tLoss: 0.4837\tLR: 0.015000\nTraining Epoch: 8 [10496/50000]\tLoss: 0.4742\tLR: 0.015000\nTraining Epoch: 8 [10624/50000]\tLoss: 0.5837\tLR: 0.015000\nTraining Epoch: 8 [10752/50000]\tLoss: 0.3505\tLR: 0.015000\nTraining Epoch: 8 [10880/50000]\tLoss: 0.4218\tLR: 0.015000\nTraining Epoch: 8 [11008/50000]\tLoss: 0.4736\tLR: 0.015000\nTraining Epoch: 8 [11136/50000]\tLoss: 0.3468\tLR: 0.015000\nTraining Epoch: 8 [11264/50000]\tLoss: 0.4294\tLR: 0.015000\nTraining Epoch: 8 [11392/50000]\tLoss: 0.4670\tLR: 0.015000\nTraining Epoch: 8 [11520/50000]\tLoss: 0.5839\tLR: 0.015000\nTraining Epoch: 8 [11648/50000]\tLoss: 0.4567\tLR: 0.015000\nTraining Epoch: 8 [11776/50000]\tLoss: 0.4060\tLR: 0.015000\nTraining Epoch: 8 [11904/50000]\tLoss: 0.3160\tLR: 0.015000\nTraining Epoch: 8 [12032/50000]\tLoss: 0.4555\tLR: 0.015000\nTraining Epoch: 8 [12160/50000]\tLoss: 0.4585\tLR: 0.015000\nTraining Epoch: 8 [12288/50000]\tLoss: 0.4366\tLR: 0.015000\nTraining Epoch: 8 [12416/50000]\tLoss: 0.3579\tLR: 0.015000\nTraining Epoch: 8 [12544/50000]\tLoss: 0.3175\tLR: 0.015000\nTraining Epoch: 8 [12672/50000]\tLoss: 0.5019\tLR: 0.015000\nTraining Epoch: 8 [12800/50000]\tLoss: 0.4918\tLR: 0.015000\nTraining Epoch: 8 [12928/50000]\tLoss: 0.3339\tLR: 0.015000\nTraining Epoch: 8 [13056/50000]\tLoss: 0.4231\tLR: 0.015000\nTraining Epoch: 8 [13184/50000]\tLoss: 0.3411\tLR: 0.015000\nTraining Epoch: 8 [13312/50000]\tLoss: 0.5226\tLR: 0.015000\nTraining Epoch: 8 [13440/50000]\tLoss: 0.4326\tLR: 0.015000\nTraining Epoch: 8 [13568/50000]\tLoss: 0.4668\tLR: 0.015000\nTraining Epoch: 8 [13696/50000]\tLoss: 0.4831\tLR: 0.015000\nTraining Epoch: 8 [13824/50000]\tLoss: 0.3814\tLR: 0.015000\nTraining Epoch: 8 [13952/50000]\tLoss: 0.5589\tLR: 0.015000\nTraining Epoch: 8 [14080/50000]\tLoss: 0.2656\tLR: 0.015000\nTraining Epoch: 8 [14208/50000]\tLoss: 0.3979\tLR: 0.015000\nTraining Epoch: 8 [14336/50000]\tLoss: 0.4836\tLR: 0.015000\nTraining Epoch: 8 [14464/50000]\tLoss: 0.3649\tLR: 0.015000\nTraining Epoch: 8 [14592/50000]\tLoss: 0.4071\tLR: 0.015000\nTraining Epoch: 8 [14720/50000]\tLoss: 0.3920\tLR: 0.015000\nTraining Epoch: 8 [14848/50000]\tLoss: 0.4768\tLR: 0.015000\nTraining Epoch: 8 [14976/50000]\tLoss: 0.4186\tLR: 0.015000\nTraining Epoch: 8 [15104/50000]\tLoss: 0.3758\tLR: 0.015000\nTraining Epoch: 8 [15232/50000]\tLoss: 0.4355\tLR: 0.015000\nTraining Epoch: 8 [15360/50000]\tLoss: 0.3338\tLR: 0.015000\nTraining Epoch: 8 [15488/50000]\tLoss: 0.4103\tLR: 0.015000\nTraining Epoch: 8 [15616/50000]\tLoss: 0.3312\tLR: 0.015000\nTraining Epoch: 8 [15744/50000]\tLoss: 0.3310\tLR: 0.015000\nTraining Epoch: 8 [15872/50000]\tLoss: 0.3808\tLR: 0.015000\nTraining Epoch: 8 [16000/50000]\tLoss: 0.5245\tLR: 0.015000\nTraining Epoch: 8 [16128/50000]\tLoss: 0.3999\tLR: 0.015000\nTraining Epoch: 8 [16256/50000]\tLoss: 0.4329\tLR: 0.015000\nTraining Epoch: 8 [16384/50000]\tLoss: 0.3473\tLR: 0.015000\nTraining Epoch: 8 [16512/50000]\tLoss: 0.3755\tLR: 0.015000\nTraining Epoch: 8 [16640/50000]\tLoss: 0.3575\tLR: 0.015000\nTraining Epoch: 8 [16768/50000]\tLoss: 0.6523\tLR: 0.015000\nTraining Epoch: 8 [16896/50000]\tLoss: 0.4951\tLR: 0.015000\nTraining Epoch: 8 [17024/50000]\tLoss: 0.5161\tLR: 0.015000\nTraining Epoch: 8 [17152/50000]\tLoss: 0.3748\tLR: 0.015000\nTraining Epoch: 8 [17280/50000]\tLoss: 0.4015\tLR: 0.015000\nTraining Epoch: 8 [17408/50000]\tLoss: 0.4659\tLR: 0.015000\nTraining Epoch: 8 [17536/50000]\tLoss: 0.4102\tLR: 0.015000\nTraining Epoch: 8 [17664/50000]\tLoss: 0.4342\tLR: 0.015000\nTraining Epoch: 8 [17792/50000]\tLoss: 0.3455\tLR: 0.015000\nTraining Epoch: 8 [17920/50000]\tLoss: 0.3703\tLR: 0.015000\nTraining Epoch: 8 [18048/50000]\tLoss: 0.4234\tLR: 0.015000\nTraining Epoch: 8 [18176/50000]\tLoss: 0.4308\tLR: 0.015000\nTraining Epoch: 8 [18304/50000]\tLoss: 0.3742\tLR: 0.015000\nTraining Epoch: 8 [18432/50000]\tLoss: 0.3229\tLR: 0.015000\nTraining Epoch: 8 [18560/50000]\tLoss: 0.4284\tLR: 0.015000\nTraining Epoch: 8 [18688/50000]\tLoss: 0.3862\tLR: 0.015000\nTraining Epoch: 8 [18816/50000]\tLoss: 0.3326\tLR: 0.015000\nTraining Epoch: 8 [18944/50000]\tLoss: 0.4350\tLR: 0.015000\nTraining Epoch: 8 [19072/50000]\tLoss: 0.3633\tLR: 0.015000\nTraining Epoch: 8 [19200/50000]\tLoss: 0.5035\tLR: 0.015000\nTraining Epoch: 8 [19328/50000]\tLoss: 0.3336\tLR: 0.015000\nTraining Epoch: 8 [19456/50000]\tLoss: 0.4079\tLR: 0.015000\nTraining Epoch: 8 [19584/50000]\tLoss: 0.5429\tLR: 0.015000\nTraining Epoch: 8 [19712/50000]\tLoss: 0.3813\tLR: 0.015000\nTraining Epoch: 8 [19840/50000]\tLoss: 0.5231\tLR: 0.015000\nTraining Epoch: 8 [19968/50000]\tLoss: 0.3811\tLR: 0.015000\nTraining Epoch: 8 [20096/50000]\tLoss: 0.4767\tLR: 0.015000\nTraining Epoch: 8 [20224/50000]\tLoss: 0.3079\tLR: 0.015000\nTraining Epoch: 8 [20352/50000]\tLoss: 0.5083\tLR: 0.015000\nTraining Epoch: 8 [20480/50000]\tLoss: 0.5784\tLR: 0.015000\nTraining Epoch: 8 [20608/50000]\tLoss: 0.4260\tLR: 0.015000\nTraining Epoch: 8 [20736/50000]\tLoss: 0.5713\tLR: 0.015000\nTraining Epoch: 8 [20864/50000]\tLoss: 0.3395\tLR: 0.015000\nTraining Epoch: 8 [20992/50000]\tLoss: 0.5035\tLR: 0.015000\nTraining Epoch: 8 [21120/50000]\tLoss: 0.4195\tLR: 0.015000\nTraining Epoch: 8 [21248/50000]\tLoss: 0.5338\tLR: 0.015000\nTraining Epoch: 8 [21376/50000]\tLoss: 0.3880\tLR: 0.015000\nTraining Epoch: 8 [21504/50000]\tLoss: 0.4313\tLR: 0.015000\nTraining Epoch: 8 [21632/50000]\tLoss: 0.3346\tLR: 0.015000\nTraining Epoch: 8 [21760/50000]\tLoss: 0.3903\tLR: 0.015000\nTraining Epoch: 8 [21888/50000]\tLoss: 0.5255\tLR: 0.015000\nTraining Epoch: 8 [22016/50000]\tLoss: 0.3767\tLR: 0.015000\nTraining Epoch: 8 [22144/50000]\tLoss: 0.4430\tLR: 0.015000\nTraining Epoch: 8 [22272/50000]\tLoss: 0.2990\tLR: 0.015000\nTraining Epoch: 8 [22400/50000]\tLoss: 0.3318\tLR: 0.015000\nTraining Epoch: 8 [22528/50000]\tLoss: 0.4582\tLR: 0.015000\nTraining Epoch: 8 [22656/50000]\tLoss: 0.3695\tLR: 0.015000\nTraining Epoch: 8 [22784/50000]\tLoss: 0.4224\tLR: 0.015000\nTraining Epoch: 8 [22912/50000]\tLoss: 0.4056\tLR: 0.015000\nTraining Epoch: 8 [23040/50000]\tLoss: 0.4502\tLR: 0.015000\nTraining Epoch: 8 [23168/50000]\tLoss: 0.5243\tLR: 0.015000\nTraining Epoch: 8 [23296/50000]\tLoss: 0.6387\tLR: 0.015000\nTraining Epoch: 8 [23424/50000]\tLoss: 0.3514\tLR: 0.015000\nTraining Epoch: 8 [23552/50000]\tLoss: 0.6338\tLR: 0.015000\nTraining Epoch: 8 [23680/50000]\tLoss: 0.2816\tLR: 0.015000\nTraining Epoch: 8 [23808/50000]\tLoss: 0.4409\tLR: 0.015000\nTraining Epoch: 8 [23936/50000]\tLoss: 0.4192\tLR: 0.015000\nTraining Epoch: 8 [24064/50000]\tLoss: 0.4456\tLR: 0.015000\nTraining Epoch: 8 [24192/50000]\tLoss: 0.5040\tLR: 0.015000\nTraining Epoch: 8 [24320/50000]\tLoss: 0.4254\tLR: 0.015000\nTraining Epoch: 8 [24448/50000]\tLoss: 0.4842\tLR: 0.015000\nTraining Epoch: 8 [24576/50000]\tLoss: 0.4439\tLR: 0.015000\nTraining Epoch: 8 [24704/50000]\tLoss: 0.4449\tLR: 0.015000\nTraining Epoch: 8 [24832/50000]\tLoss: 0.3994\tLR: 0.015000\nTraining Epoch: 8 [24960/50000]\tLoss: 0.3968\tLR: 0.015000\nTraining Epoch: 8 [25088/50000]\tLoss: 0.4095\tLR: 0.015000\nTraining Epoch: 8 [25216/50000]\tLoss: 0.4430\tLR: 0.015000\nTraining Epoch: 8 [25344/50000]\tLoss: 0.4007\tLR: 0.015000\nTraining Epoch: 8 [25472/50000]\tLoss: 0.5245\tLR: 0.015000\nTraining Epoch: 8 [25600/50000]\tLoss: 0.6271\tLR: 0.015000\nTraining Epoch: 8 [25728/50000]\tLoss: 0.3972\tLR: 0.015000\nTraining Epoch: 8 [25856/50000]\tLoss: 0.5269\tLR: 0.015000\nTraining Epoch: 8 [25984/50000]\tLoss: 0.4086\tLR: 0.015000\nTraining Epoch: 8 [26112/50000]\tLoss: 0.3489\tLR: 0.015000\nTraining Epoch: 8 [26240/50000]\tLoss: 0.4504\tLR: 0.015000\nTraining Epoch: 8 [26368/50000]\tLoss: 0.3104\tLR: 0.015000\nTraining Epoch: 8 [26496/50000]\tLoss: 0.4683\tLR: 0.015000\nTraining Epoch: 8 [26624/50000]\tLoss: 0.5458\tLR: 0.015000\nTraining Epoch: 8 [26752/50000]\tLoss: 0.3839\tLR: 0.015000\nTraining Epoch: 8 [26880/50000]\tLoss: 0.3427\tLR: 0.015000\nTraining Epoch: 8 [27008/50000]\tLoss: 0.3593\tLR: 0.015000\nTraining Epoch: 8 [27136/50000]\tLoss: 0.4697\tLR: 0.015000\nTraining Epoch: 8 [27264/50000]\tLoss: 0.4660\tLR: 0.015000\nTraining Epoch: 8 [27392/50000]\tLoss: 0.4191\tLR: 0.015000\nTraining Epoch: 8 [27520/50000]\tLoss: 0.4208\tLR: 0.015000\nTraining Epoch: 8 [27648/50000]\tLoss: 0.4548\tLR: 0.015000\nTraining Epoch: 8 [27776/50000]\tLoss: 0.3744\tLR: 0.015000\nTraining Epoch: 8 [27904/50000]\tLoss: 0.4850\tLR: 0.015000\nTraining Epoch: 8 [28032/50000]\tLoss: 0.5871\tLR: 0.015000\nTraining Epoch: 8 [28160/50000]\tLoss: 0.3867\tLR: 0.015000\nTraining Epoch: 8 [28288/50000]\tLoss: 0.3999\tLR: 0.015000\nTraining Epoch: 8 [28416/50000]\tLoss: 0.3780\tLR: 0.015000\nTraining Epoch: 8 [28544/50000]\tLoss: 0.4600\tLR: 0.015000\nTraining Epoch: 8 [28672/50000]\tLoss: 0.4015\tLR: 0.015000\nTraining Epoch: 8 [28800/50000]\tLoss: 0.4362\tLR: 0.015000\nTraining Epoch: 8 [28928/50000]\tLoss: 0.4733\tLR: 0.015000\nTraining Epoch: 8 [29056/50000]\tLoss: 0.3557\tLR: 0.015000\nTraining Epoch: 8 [29184/50000]\tLoss: 0.4004\tLR: 0.015000\nTraining Epoch: 8 [29312/50000]\tLoss: 0.5085\tLR: 0.015000\nTraining Epoch: 8 [29440/50000]\tLoss: 0.3196\tLR: 0.015000\nTraining Epoch: 8 [29568/50000]\tLoss: 0.5224\tLR: 0.015000\nTraining Epoch: 8 [29696/50000]\tLoss: 0.4213\tLR: 0.015000\nTraining Epoch: 8 [29824/50000]\tLoss: 0.3977\tLR: 0.015000\nTraining Epoch: 8 [29952/50000]\tLoss: 0.5620\tLR: 0.015000\nTraining Epoch: 8 [30080/50000]\tLoss: 0.4542\tLR: 0.015000\nTraining Epoch: 8 [30208/50000]\tLoss: 0.2674\tLR: 0.015000\nTraining Epoch: 8 [30336/50000]\tLoss: 0.3525\tLR: 0.015000\nTraining Epoch: 8 [30464/50000]\tLoss: 0.3833\tLR: 0.015000\nTraining Epoch: 8 [30592/50000]\tLoss: 0.3172\tLR: 0.015000\nTraining Epoch: 8 [30720/50000]\tLoss: 0.4551\tLR: 0.015000\nTraining Epoch: 8 [30848/50000]\tLoss: 0.4812\tLR: 0.015000\nTraining Epoch: 8 [30976/50000]\tLoss: 0.4235\tLR: 0.015000\nTraining Epoch: 8 [31104/50000]\tLoss: 0.3730\tLR: 0.015000\nTraining Epoch: 8 [31232/50000]\tLoss: 0.3310\tLR: 0.015000\nTraining Epoch: 8 [31360/50000]\tLoss: 0.4247\tLR: 0.015000\nTraining Epoch: 8 [31488/50000]\tLoss: 0.4783\tLR: 0.015000\nTraining Epoch: 8 [31616/50000]\tLoss: 0.4236\tLR: 0.015000\nTraining Epoch: 8 [31744/50000]\tLoss: 0.5226\tLR: 0.015000\nTraining Epoch: 8 [31872/50000]\tLoss: 0.4007\tLR: 0.015000\nTraining Epoch: 8 [32000/50000]\tLoss: 0.5425\tLR: 0.015000\nTraining Epoch: 8 [32128/50000]\tLoss: 0.3149\tLR: 0.015000\nTraining Epoch: 8 [32256/50000]\tLoss: 0.4501\tLR: 0.015000\nTraining Epoch: 8 [32384/50000]\tLoss: 0.4136\tLR: 0.015000\nTraining Epoch: 8 [32512/50000]\tLoss: 0.4178\tLR: 0.015000\nTraining Epoch: 8 [32640/50000]\tLoss: 0.5217\tLR: 0.015000\nTraining Epoch: 8 [32768/50000]\tLoss: 0.3422\tLR: 0.015000\nTraining Epoch: 8 [32896/50000]\tLoss: 0.4332\tLR: 0.015000\nTraining Epoch: 8 [33024/50000]\tLoss: 0.5082\tLR: 0.015000\nTraining Epoch: 8 [33152/50000]\tLoss: 0.4699\tLR: 0.015000\nTraining Epoch: 8 [33280/50000]\tLoss: 0.4812\tLR: 0.015000\nTraining Epoch: 8 [33408/50000]\tLoss: 0.5636\tLR: 0.015000\nTraining Epoch: 8 [33536/50000]\tLoss: 0.4124\tLR: 0.015000\nTraining Epoch: 8 [33664/50000]\tLoss: 0.5783\tLR: 0.015000\nTraining Epoch: 8 [33792/50000]\tLoss: 0.4149\tLR: 0.015000\nTraining Epoch: 8 [33920/50000]\tLoss: 0.4405\tLR: 0.015000\nTraining Epoch: 8 [34048/50000]\tLoss: 0.4636\tLR: 0.015000\nTraining Epoch: 8 [34176/50000]\tLoss: 0.4444\tLR: 0.015000\nTraining Epoch: 8 [34304/50000]\tLoss: 0.5170\tLR: 0.015000\nTraining Epoch: 8 [34432/50000]\tLoss: 0.4708\tLR: 0.015000\nTraining Epoch: 8 [34560/50000]\tLoss: 0.3232\tLR: 0.015000\nTraining Epoch: 8 [34688/50000]\tLoss: 0.4000\tLR: 0.015000\nTraining Epoch: 8 [34816/50000]\tLoss: 0.4543\tLR: 0.015000\nTraining Epoch: 8 [34944/50000]\tLoss: 0.2997\tLR: 0.015000\nTraining Epoch: 8 [35072/50000]\tLoss: 0.4463\tLR: 0.015000\nTraining Epoch: 8 [35200/50000]\tLoss: 0.3770\tLR: 0.015000\nTraining Epoch: 8 [35328/50000]\tLoss: 0.5677\tLR: 0.015000\nTraining Epoch: 8 [35456/50000]\tLoss: 0.4517\tLR: 0.015000\nTraining Epoch: 8 [35584/50000]\tLoss: 0.3131\tLR: 0.015000\nTraining Epoch: 8 [35712/50000]\tLoss: 0.3476\tLR: 0.015000\nTraining Epoch: 8 [35840/50000]\tLoss: 0.5629\tLR: 0.015000\nTraining Epoch: 8 [35968/50000]\tLoss: 0.4780\tLR: 0.015000\nTraining Epoch: 8 [36096/50000]\tLoss: 0.5061\tLR: 0.015000\nTraining Epoch: 8 [36224/50000]\tLoss: 0.3051\tLR: 0.015000\nTraining Epoch: 8 [36352/50000]\tLoss: 0.4600\tLR: 0.015000\nTraining Epoch: 8 [36480/50000]\tLoss: 0.4533\tLR: 0.015000\nTraining Epoch: 8 [36608/50000]\tLoss: 0.3725\tLR: 0.015000\nTraining Epoch: 8 [36736/50000]\tLoss: 0.4521\tLR: 0.015000\nTraining Epoch: 8 [36864/50000]\tLoss: 0.4073\tLR: 0.015000\nTraining Epoch: 8 [36992/50000]\tLoss: 0.3754\tLR: 0.015000\nTraining Epoch: 8 [37120/50000]\tLoss: 0.4692\tLR: 0.015000\nTraining Epoch: 8 [37248/50000]\tLoss: 0.4829\tLR: 0.015000\nTraining Epoch: 8 [37376/50000]\tLoss: 0.4820\tLR: 0.015000\nTraining Epoch: 8 [37504/50000]\tLoss: 0.4336\tLR: 0.015000\nTraining Epoch: 8 [37632/50000]\tLoss: 0.3351\tLR: 0.015000\nTraining Epoch: 8 [37760/50000]\tLoss: 0.3487\tLR: 0.015000\nTraining Epoch: 8 [37888/50000]\tLoss: 0.3707\tLR: 0.015000\nTraining Epoch: 8 [38016/50000]\tLoss: 0.3434\tLR: 0.015000\nTraining Epoch: 8 [38144/50000]\tLoss: 0.4699\tLR: 0.015000\nTraining Epoch: 8 [38272/50000]\tLoss: 0.4146\tLR: 0.015000\nTraining Epoch: 8 [38400/50000]\tLoss: 0.4836\tLR: 0.015000\nTraining Epoch: 8 [38528/50000]\tLoss: 0.4221\tLR: 0.015000\nTraining Epoch: 8 [38656/50000]\tLoss: 0.5429\tLR: 0.015000\nTraining Epoch: 8 [38784/50000]\tLoss: 0.4364\tLR: 0.015000\nTraining Epoch: 8 [38912/50000]\tLoss: 0.4116\tLR: 0.015000\nTraining Epoch: 8 [39040/50000]\tLoss: 0.5319\tLR: 0.015000\nTraining Epoch: 8 [39168/50000]\tLoss: 0.3841\tLR: 0.015000\nTraining Epoch: 8 [39296/50000]\tLoss: 0.2439\tLR: 0.015000\nTraining Epoch: 8 [39424/50000]\tLoss: 0.2977\tLR: 0.015000\nTraining Epoch: 8 [39552/50000]\tLoss: 0.4529\tLR: 0.015000\nTraining Epoch: 8 [39680/50000]\tLoss: 0.4195\tLR: 0.015000\nTraining Epoch: 8 [39808/50000]\tLoss: 0.3890\tLR: 0.015000\nTraining Epoch: 8 [39936/50000]\tLoss: 0.5832\tLR: 0.015000\nTraining Epoch: 8 [40064/50000]\tLoss: 0.3958\tLR: 0.015000\nTraining Epoch: 8 [40192/50000]\tLoss: 0.4154\tLR: 0.015000\nTraining Epoch: 8 [40320/50000]\tLoss: 0.4627\tLR: 0.015000\nTraining Epoch: 8 [40448/50000]\tLoss: 0.2733\tLR: 0.015000\nTraining Epoch: 8 [40576/50000]\tLoss: 0.4591\tLR: 0.015000\nTraining Epoch: 8 [40704/50000]\tLoss: 0.4762\tLR: 0.015000\nTraining Epoch: 8 [40832/50000]\tLoss: 0.5736\tLR: 0.015000\nTraining Epoch: 8 [40960/50000]\tLoss: 0.5431\tLR: 0.015000\nTraining Epoch: 8 [41088/50000]\tLoss: 0.5571\tLR: 0.015000\nTraining Epoch: 8 [41216/50000]\tLoss: 0.5105\tLR: 0.015000\nTraining Epoch: 8 [41344/50000]\tLoss: 0.6006\tLR: 0.015000\nTraining Epoch: 8 [41472/50000]\tLoss: 0.4593\tLR: 0.015000\nTraining Epoch: 8 [41600/50000]\tLoss: 0.4810\tLR: 0.015000\nTraining Epoch: 8 [41728/50000]\tLoss: 0.5328\tLR: 0.015000\nTraining Epoch: 8 [41856/50000]\tLoss: 0.4464\tLR: 0.015000\nTraining Epoch: 8 [41984/50000]\tLoss: 0.4836\tLR: 0.015000\nTraining Epoch: 8 [42112/50000]\tLoss: 0.3633\tLR: 0.015000\nTraining Epoch: 8 [42240/50000]\tLoss: 0.2753\tLR: 0.015000\nTraining Epoch: 8 [42368/50000]\tLoss: 0.4421\tLR: 0.015000\nTraining Epoch: 8 [42496/50000]\tLoss: 0.4553\tLR: 0.015000\nTraining Epoch: 8 [42624/50000]\tLoss: 0.5442\tLR: 0.015000\nTraining Epoch: 8 [42752/50000]\tLoss: 0.4787\tLR: 0.015000\nTraining Epoch: 8 [42880/50000]\tLoss: 0.3722\tLR: 0.015000\nTraining Epoch: 8 [43008/50000]\tLoss: 0.3917\tLR: 0.015000\nTraining Epoch: 8 [43136/50000]\tLoss: 0.4339\tLR: 0.015000\nTraining Epoch: 8 [43264/50000]\tLoss: 0.4180\tLR: 0.015000\nTraining Epoch: 8 [43392/50000]\tLoss: 0.3191\tLR: 0.015000\nTraining Epoch: 8 [43520/50000]\tLoss: 0.4283\tLR: 0.015000\nTraining Epoch: 8 [43648/50000]\tLoss: 0.5172\tLR: 0.015000\nTraining Epoch: 8 [43776/50000]\tLoss: 0.3282\tLR: 0.015000\nTraining Epoch: 8 [43904/50000]\tLoss: 0.4449\tLR: 0.015000\nTraining Epoch: 8 [44032/50000]\tLoss: 0.4468\tLR: 0.015000\nTraining Epoch: 8 [44160/50000]\tLoss: 0.4697\tLR: 0.015000\nTraining Epoch: 8 [44288/50000]\tLoss: 0.3357\tLR: 0.015000\nTraining Epoch: 8 [44416/50000]\tLoss: 0.4177\tLR: 0.015000\nTraining Epoch: 8 [44544/50000]\tLoss: 0.4011\tLR: 0.015000\nTraining Epoch: 8 [44672/50000]\tLoss: 0.4360\tLR: 0.015000\nTraining Epoch: 8 [44800/50000]\tLoss: 0.5173\tLR: 0.015000\nTraining Epoch: 8 [44928/50000]\tLoss: 0.3575\tLR: 0.015000\nTraining Epoch: 8 [45056/50000]\tLoss: 0.3784\tLR: 0.015000\nTraining Epoch: 8 [45184/50000]\tLoss: 0.4094\tLR: 0.015000\nTraining Epoch: 8 [45312/50000]\tLoss: 0.5241\tLR: 0.015000\nTraining Epoch: 8 [45440/50000]\tLoss: 0.3160\tLR: 0.015000\nTraining Epoch: 8 [45568/50000]\tLoss: 0.4558\tLR: 0.015000\nTraining Epoch: 8 [45696/50000]\tLoss: 0.4252\tLR: 0.015000\nTraining Epoch: 8 [45824/50000]\tLoss: 0.4431\tLR: 0.015000\nTraining Epoch: 8 [45952/50000]\tLoss: 0.4109\tLR: 0.015000\nTraining Epoch: 8 [46080/50000]\tLoss: 0.3554\tLR: 0.015000\nTraining Epoch: 8 [46208/50000]\tLoss: 0.4199\tLR: 0.015000\nTraining Epoch: 8 [46336/50000]\tLoss: 0.2763\tLR: 0.015000\nTraining Epoch: 8 [46464/50000]\tLoss: 0.4290\tLR: 0.015000\nTraining Epoch: 8 [46592/50000]\tLoss: 0.5654\tLR: 0.015000\nTraining Epoch: 8 [46720/50000]\tLoss: 0.4508\tLR: 0.015000\nTraining Epoch: 8 [46848/50000]\tLoss: 0.3735\tLR: 0.015000\nTraining Epoch: 8 [46976/50000]\tLoss: 0.3873\tLR: 0.015000\nTraining Epoch: 8 [47104/50000]\tLoss: 0.5010\tLR: 0.015000\nTraining Epoch: 8 [47232/50000]\tLoss: 0.3778\tLR: 0.015000\nTraining Epoch: 8 [47360/50000]\tLoss: 0.4089\tLR: 0.015000\nTraining Epoch: 8 [47488/50000]\tLoss: 0.4604\tLR: 0.015000\nTraining Epoch: 8 [47616/50000]\tLoss: 0.4021\tLR: 0.015000\nTraining Epoch: 8 [47744/50000]\tLoss: 0.3319\tLR: 0.015000\nTraining Epoch: 8 [47872/50000]\tLoss: 0.4488\tLR: 0.015000\nTraining Epoch: 8 [48000/50000]\tLoss: 0.2635\tLR: 0.015000\nTraining Epoch: 8 [48128/50000]\tLoss: 0.4517\tLR: 0.015000\nTraining Epoch: 8 [48256/50000]\tLoss: 0.4942\tLR: 0.015000\nTraining Epoch: 8 [48384/50000]\tLoss: 0.4516\tLR: 0.015000\nTraining Epoch: 8 [48512/50000]\tLoss: 0.4035\tLR: 0.015000\nTraining Epoch: 8 [48640/50000]\tLoss: 0.4835\tLR: 0.015000\nTraining Epoch: 8 [48768/50000]\tLoss: 0.3980\tLR: 0.015000\nTraining Epoch: 8 [48896/50000]\tLoss: 0.3619\tLR: 0.015000\nTraining Epoch: 8 [49024/50000]\tLoss: 0.4669\tLR: 0.015000\nTraining Epoch: 8 [49152/50000]\tLoss: 0.3843\tLR: 0.015000\nTraining Epoch: 8 [49280/50000]\tLoss: 0.3553\tLR: 0.015000\nTraining Epoch: 8 [49408/50000]\tLoss: 0.3363\tLR: 0.015000\nTraining Epoch: 8 [49536/50000]\tLoss: 0.4470\tLR: 0.015000\nTraining Epoch: 8 [49664/50000]\tLoss: 0.3269\tLR: 0.015000\nTraining Epoch: 8 [49792/50000]\tLoss: 0.3700\tLR: 0.015000\nTraining Epoch: 8 [49920/50000]\tLoss: 0.5352\tLR: 0.015000\nTraining Epoch: 8 [50000/50000]\tLoss: 0.4133\tLR: 0.015000\nTest set: Average loss: 0.0031, Accuracy: 0.8640\n\nTraining Epoch: 9 [128/50000]\tLoss: 0.5105\tLR: 0.015000\nTraining Epoch: 9 [256/50000]\tLoss: 0.4096\tLR: 0.015000\nTraining Epoch: 9 [384/50000]\tLoss: 0.4294\tLR: 0.015000\nTraining Epoch: 9 [512/50000]\tLoss: 0.4183\tLR: 0.015000\nTraining Epoch: 9 [640/50000]\tLoss: 0.3298\tLR: 0.015000\nTraining Epoch: 9 [768/50000]\tLoss: 0.4153\tLR: 0.015000\nTraining Epoch: 9 [896/50000]\tLoss: 0.2966\tLR: 0.015000\nTraining Epoch: 9 [1024/50000]\tLoss: 0.4379\tLR: 0.015000\nTraining Epoch: 9 [1152/50000]\tLoss: 0.4400\tLR: 0.015000\nTraining Epoch: 9 [1280/50000]\tLoss: 0.4820\tLR: 0.015000\nTraining Epoch: 9 [1408/50000]\tLoss: 0.3669\tLR: 0.015000\nTraining Epoch: 9 [1536/50000]\tLoss: 0.4997\tLR: 0.015000\nTraining Epoch: 9 [1664/50000]\tLoss: 0.4421\tLR: 0.015000\nTraining Epoch: 9 [1792/50000]\tLoss: 0.3659\tLR: 0.015000\nTraining Epoch: 9 [1920/50000]\tLoss: 0.4264\tLR: 0.015000\nTraining Epoch: 9 [2048/50000]\tLoss: 0.4344\tLR: 0.015000\nTraining Epoch: 9 [2176/50000]\tLoss: 0.3907\tLR: 0.015000\nTraining Epoch: 9 [2304/50000]\tLoss: 0.4291\tLR: 0.015000\nTraining Epoch: 9 [2432/50000]\tLoss: 0.3887\tLR: 0.015000\nTraining Epoch: 9 [2560/50000]\tLoss: 0.3956\tLR: 0.015000\nTraining Epoch: 9 [2688/50000]\tLoss: 0.5379\tLR: 0.015000\nTraining Epoch: 9 [2816/50000]\tLoss: 0.4910\tLR: 0.015000\nTraining Epoch: 9 [2944/50000]\tLoss: 0.4253\tLR: 0.015000\nTraining Epoch: 9 [3072/50000]\tLoss: 0.3396\tLR: 0.015000\nTraining Epoch: 9 [3200/50000]\tLoss: 0.3423\tLR: 0.015000\nTraining Epoch: 9 [3328/50000]\tLoss: 0.3819\tLR: 0.015000\nTraining Epoch: 9 [3456/50000]\tLoss: 0.5384\tLR: 0.015000\nTraining Epoch: 9 [3584/50000]\tLoss: 0.3425\tLR: 0.015000\nTraining Epoch: 9 [3712/50000]\tLoss: 0.4502\tLR: 0.015000\nTraining Epoch: 9 [3840/50000]\tLoss: 0.3402\tLR: 0.015000\nTraining Epoch: 9 [3968/50000]\tLoss: 0.2601\tLR: 0.015000\nTraining Epoch: 9 [4096/50000]\tLoss: 0.3598\tLR: 0.015000\nTraining Epoch: 9 [4224/50000]\tLoss: 0.4626\tLR: 0.015000\nTraining Epoch: 9 [4352/50000]\tLoss: 0.4546\tLR: 0.015000\nTraining Epoch: 9 [4480/50000]\tLoss: 0.3646\tLR: 0.015000\nTraining Epoch: 9 [4608/50000]\tLoss: 0.3764\tLR: 0.015000\nTraining Epoch: 9 [4736/50000]\tLoss: 0.3835\tLR: 0.015000\nTraining Epoch: 9 [4864/50000]\tLoss: 0.4487\tLR: 0.015000\nTraining Epoch: 9 [4992/50000]\tLoss: 0.4700\tLR: 0.015000\nTraining Epoch: 9 [5120/50000]\tLoss: 0.4892\tLR: 0.015000\nTraining Epoch: 9 [5248/50000]\tLoss: 0.5434\tLR: 0.015000\nTraining Epoch: 9 [5376/50000]\tLoss: 0.3511\tLR: 0.015000\nTraining Epoch: 9 [5504/50000]\tLoss: 0.3510\tLR: 0.015000\nTraining Epoch: 9 [5632/50000]\tLoss: 0.3000\tLR: 0.015000\nTraining Epoch: 9 [5760/50000]\tLoss: 0.3250\tLR: 0.015000\nTraining Epoch: 9 [5888/50000]\tLoss: 0.4450\tLR: 0.015000\nTraining Epoch: 9 [6016/50000]\tLoss: 0.3832\tLR: 0.015000\nTraining Epoch: 9 [6144/50000]\tLoss: 0.2841\tLR: 0.015000\nTraining Epoch: 9 [6272/50000]\tLoss: 0.5296\tLR: 0.015000\nTraining Epoch: 9 [6400/50000]\tLoss: 0.2872\tLR: 0.015000\nTraining Epoch: 9 [6528/50000]\tLoss: 0.4768\tLR: 0.015000\nTraining Epoch: 9 [6656/50000]\tLoss: 0.3990\tLR: 0.015000\nTraining Epoch: 9 [6784/50000]\tLoss: 0.3107\tLR: 0.015000\nTraining Epoch: 9 [6912/50000]\tLoss: 0.3452\tLR: 0.015000\nTraining Epoch: 9 [7040/50000]\tLoss: 0.4486\tLR: 0.015000\nTraining Epoch: 9 [7168/50000]\tLoss: 0.2087\tLR: 0.015000\nTraining Epoch: 9 [7296/50000]\tLoss: 0.4258\tLR: 0.015000\nTraining Epoch: 9 [7424/50000]\tLoss: 0.4806\tLR: 0.015000\nTraining Epoch: 9 [7552/50000]\tLoss: 0.5922\tLR: 0.015000\nTraining Epoch: 9 [7680/50000]\tLoss: 0.3753\tLR: 0.015000\nTraining Epoch: 9 [7808/50000]\tLoss: 0.3600\tLR: 0.015000\nTraining Epoch: 9 [7936/50000]\tLoss: 0.3656\tLR: 0.015000\nTraining Epoch: 9 [8064/50000]\tLoss: 0.3732\tLR: 0.015000\nTraining Epoch: 9 [8192/50000]\tLoss: 0.4157\tLR: 0.015000\nTraining Epoch: 9 [8320/50000]\tLoss: 0.4895\tLR: 0.015000\nTraining Epoch: 9 [8448/50000]\tLoss: 0.3862\tLR: 0.015000\nTraining Epoch: 9 [8576/50000]\tLoss: 0.3221\tLR: 0.015000\nTraining Epoch: 9 [8704/50000]\tLoss: 0.4295\tLR: 0.015000\nTraining Epoch: 9 [8832/50000]\tLoss: 0.3851\tLR: 0.015000\nTraining Epoch: 9 [8960/50000]\tLoss: 0.3599\tLR: 0.015000\nTraining Epoch: 9 [9088/50000]\tLoss: 0.3238\tLR: 0.015000\nTraining Epoch: 9 [9216/50000]\tLoss: 0.4701\tLR: 0.015000\nTraining Epoch: 9 [9344/50000]\tLoss: 0.3903\tLR: 0.015000\nTraining Epoch: 9 [9472/50000]\tLoss: 0.4333\tLR: 0.015000\nTraining Epoch: 9 [9600/50000]\tLoss: 0.3815\tLR: 0.015000\nTraining Epoch: 9 [9728/50000]\tLoss: 0.4276\tLR: 0.015000\nTraining Epoch: 9 [9856/50000]\tLoss: 0.4518\tLR: 0.015000\nTraining Epoch: 9 [9984/50000]\tLoss: 0.3292\tLR: 0.015000\nTraining Epoch: 9 [10112/50000]\tLoss: 0.3788\tLR: 0.015000\nTraining Epoch: 9 [10240/50000]\tLoss: 0.4367\tLR: 0.015000\nTraining Epoch: 9 [10368/50000]\tLoss: 0.3106\tLR: 0.015000\nTraining Epoch: 9 [10496/50000]\tLoss: 0.4347\tLR: 0.015000\nTraining Epoch: 9 [10624/50000]\tLoss: 0.4178\tLR: 0.015000\nTraining Epoch: 9 [10752/50000]\tLoss: 0.4424\tLR: 0.015000\nTraining Epoch: 9 [10880/50000]\tLoss: 0.3728\tLR: 0.015000\nTraining Epoch: 9 [11008/50000]\tLoss: 0.3078\tLR: 0.015000\nTraining Epoch: 9 [11136/50000]\tLoss: 0.4349\tLR: 0.015000\nTraining Epoch: 9 [11264/50000]\tLoss: 0.4627\tLR: 0.015000\nTraining Epoch: 9 [11392/50000]\tLoss: 0.5301\tLR: 0.015000\nTraining Epoch: 9 [11520/50000]\tLoss: 0.4426\tLR: 0.015000\nTraining Epoch: 9 [11648/50000]\tLoss: 0.3574\tLR: 0.015000\nTraining Epoch: 9 [11776/50000]\tLoss: 0.4181\tLR: 0.015000\nTraining Epoch: 9 [11904/50000]\tLoss: 0.3719\tLR: 0.015000\nTraining Epoch: 9 [12032/50000]\tLoss: 0.4467\tLR: 0.015000\nTraining Epoch: 9 [12160/50000]\tLoss: 0.3423\tLR: 0.015000\nTraining Epoch: 9 [12288/50000]\tLoss: 0.3999\tLR: 0.015000\nTraining Epoch: 9 [12416/50000]\tLoss: 0.3059\tLR: 0.015000\nTraining Epoch: 9 [12544/50000]\tLoss: 0.3413\tLR: 0.015000\nTraining Epoch: 9 [12672/50000]\tLoss: 0.5727\tLR: 0.015000\nTraining Epoch: 9 [12800/50000]\tLoss: 0.3854\tLR: 0.015000\nTraining Epoch: 9 [12928/50000]\tLoss: 0.4593\tLR: 0.015000\nTraining Epoch: 9 [13056/50000]\tLoss: 0.2992\tLR: 0.015000\nTraining Epoch: 9 [13184/50000]\tLoss: 0.4177\tLR: 0.015000\nTraining Epoch: 9 [13312/50000]\tLoss: 0.7805\tLR: 0.015000\nTraining Epoch: 9 [13440/50000]\tLoss: 0.5942\tLR: 0.015000\nTraining Epoch: 9 [13568/50000]\tLoss: 0.3326\tLR: 0.015000\nTraining Epoch: 9 [13696/50000]\tLoss: 0.3822\tLR: 0.015000\nTraining Epoch: 9 [13824/50000]\tLoss: 0.3669\tLR: 0.015000\nTraining Epoch: 9 [13952/50000]\tLoss: 0.3206\tLR: 0.015000\nTraining Epoch: 9 [14080/50000]\tLoss: 0.3983\tLR: 0.015000\nTraining Epoch: 9 [14208/50000]\tLoss: 0.3557\tLR: 0.015000\nTraining Epoch: 9 [14336/50000]\tLoss: 0.4220\tLR: 0.015000\nTraining Epoch: 9 [14464/50000]\tLoss: 0.3158\tLR: 0.015000\nTraining Epoch: 9 [14592/50000]\tLoss: 0.4070\tLR: 0.015000\nTraining Epoch: 9 [14720/50000]\tLoss: 0.4008\tLR: 0.015000\nTraining Epoch: 9 [14848/50000]\tLoss: 0.5054\tLR: 0.015000\nTraining Epoch: 9 [14976/50000]\tLoss: 0.4003\tLR: 0.015000\nTraining Epoch: 9 [15104/50000]\tLoss: 0.3932\tLR: 0.015000\nTraining Epoch: 9 [15232/50000]\tLoss: 0.3598\tLR: 0.015000\nTraining Epoch: 9 [15360/50000]\tLoss: 0.5166\tLR: 0.015000\nTraining Epoch: 9 [15488/50000]\tLoss: 0.3748\tLR: 0.015000\nTraining Epoch: 9 [15616/50000]\tLoss: 0.3616\tLR: 0.015000\nTraining Epoch: 9 [15744/50000]\tLoss: 0.3986\tLR: 0.015000\nTraining Epoch: 9 [15872/50000]\tLoss: 0.4749\tLR: 0.015000\nTraining Epoch: 9 [16000/50000]\tLoss: 0.3815\tLR: 0.015000\nTraining Epoch: 9 [16128/50000]\tLoss: 0.4784\tLR: 0.015000\nTraining Epoch: 9 [16256/50000]\tLoss: 0.3527\tLR: 0.015000\nTraining Epoch: 9 [16384/50000]\tLoss: 0.3676\tLR: 0.015000\nTraining Epoch: 9 [16512/50000]\tLoss: 0.3484\tLR: 0.015000\nTraining Epoch: 9 [16640/50000]\tLoss: 0.3721\tLR: 0.015000\nTraining Epoch: 9 [16768/50000]\tLoss: 0.4753\tLR: 0.015000\nTraining Epoch: 9 [16896/50000]\tLoss: 0.4103\tLR: 0.015000\nTraining Epoch: 9 [17024/50000]\tLoss: 0.4375\tLR: 0.015000\nTraining Epoch: 9 [17152/50000]\tLoss: 0.4103\tLR: 0.015000\nTraining Epoch: 9 [17280/50000]\tLoss: 0.3577\tLR: 0.015000\nTraining Epoch: 9 [17408/50000]\tLoss: 0.3214\tLR: 0.015000\nTraining Epoch: 9 [17536/50000]\tLoss: 0.3685\tLR: 0.015000\nTraining Epoch: 9 [17664/50000]\tLoss: 0.2734\tLR: 0.015000\nTraining Epoch: 9 [17792/50000]\tLoss: 0.3516\tLR: 0.015000\nTraining Epoch: 9 [17920/50000]\tLoss: 0.3452\tLR: 0.015000\nTraining Epoch: 9 [18048/50000]\tLoss: 0.5658\tLR: 0.015000\nTraining Epoch: 9 [18176/50000]\tLoss: 0.3615\tLR: 0.015000\nTraining Epoch: 9 [18304/50000]\tLoss: 0.4402\tLR: 0.015000\nTraining Epoch: 9 [18432/50000]\tLoss: 0.3874\tLR: 0.015000\nTraining Epoch: 9 [18560/50000]\tLoss: 0.3309\tLR: 0.015000\nTraining Epoch: 9 [18688/50000]\tLoss: 0.5152\tLR: 0.015000\nTraining Epoch: 9 [18816/50000]\tLoss: 0.3585\tLR: 0.015000\nTraining Epoch: 9 [18944/50000]\tLoss: 0.5061\tLR: 0.015000\nTraining Epoch: 9 [19072/50000]\tLoss: 0.2539\tLR: 0.015000\nTraining Epoch: 9 [19200/50000]\tLoss: 0.3497\tLR: 0.015000\nTraining Epoch: 9 [19328/50000]\tLoss: 0.3410\tLR: 0.015000\nTraining Epoch: 9 [19456/50000]\tLoss: 0.4077\tLR: 0.015000\nTraining Epoch: 9 [19584/50000]\tLoss: 0.3702\tLR: 0.015000\nTraining Epoch: 9 [19712/50000]\tLoss: 0.3565\tLR: 0.015000\nTraining Epoch: 9 [19840/50000]\tLoss: 0.3882\tLR: 0.015000\nTraining Epoch: 9 [19968/50000]\tLoss: 0.3710\tLR: 0.015000\nTraining Epoch: 9 [20096/50000]\tLoss: 0.2826\tLR: 0.015000\nTraining Epoch: 9 [20224/50000]\tLoss: 0.5100\tLR: 0.015000\nTraining Epoch: 9 [20352/50000]\tLoss: 0.4329\tLR: 0.015000\nTraining Epoch: 9 [20480/50000]\tLoss: 0.4982\tLR: 0.015000\nTraining Epoch: 9 [20608/50000]\tLoss: 0.3941\tLR: 0.015000\nTraining Epoch: 9 [20736/50000]\tLoss: 0.4477\tLR: 0.015000\nTraining Epoch: 9 [20864/50000]\tLoss: 0.3492\tLR: 0.015000\nTraining Epoch: 9 [20992/50000]\tLoss: 0.3173\tLR: 0.015000\nTraining Epoch: 9 [21120/50000]\tLoss: 0.3888\tLR: 0.015000\nTraining Epoch: 9 [21248/50000]\tLoss: 0.2581\tLR: 0.015000\nTraining Epoch: 9 [21376/50000]\tLoss: 0.3503\tLR: 0.015000\nTraining Epoch: 9 [21504/50000]\tLoss: 0.4149\tLR: 0.015000\nTraining Epoch: 9 [21632/50000]\tLoss: 0.5522\tLR: 0.015000\nTraining Epoch: 9 [21760/50000]\tLoss: 0.3661\tLR: 0.015000\nTraining Epoch: 9 [21888/50000]\tLoss: 0.3798\tLR: 0.015000\nTraining Epoch: 9 [22016/50000]\tLoss: 0.3808\tLR: 0.015000\nTraining Epoch: 9 [22144/50000]\tLoss: 0.3120\tLR: 0.015000\nTraining Epoch: 9 [22272/50000]\tLoss: 0.4571\tLR: 0.015000\nTraining Epoch: 9 [22400/50000]\tLoss: 0.3743\tLR: 0.015000\nTraining Epoch: 9 [22528/50000]\tLoss: 0.4056\tLR: 0.015000\nTraining Epoch: 9 [22656/50000]\tLoss: 0.4776\tLR: 0.015000\nTraining Epoch: 9 [22784/50000]\tLoss: 0.5091\tLR: 0.015000\nTraining Epoch: 9 [22912/50000]\tLoss: 0.3924\tLR: 0.015000\nTraining Epoch: 9 [23040/50000]\tLoss: 0.2390\tLR: 0.015000\nTraining Epoch: 9 [23168/50000]\tLoss: 0.6042\tLR: 0.015000\nTraining Epoch: 9 [23296/50000]\tLoss: 0.4824\tLR: 0.015000\nTraining Epoch: 9 [23424/50000]\tLoss: 0.3936\tLR: 0.015000\nTraining Epoch: 9 [23552/50000]\tLoss: 0.3620\tLR: 0.015000\nTraining Epoch: 9 [23680/50000]\tLoss: 0.3309\tLR: 0.015000\nTraining Epoch: 9 [23808/50000]\tLoss: 0.3176\tLR: 0.015000\nTraining Epoch: 9 [23936/50000]\tLoss: 0.4770\tLR: 0.015000\nTraining Epoch: 9 [24064/50000]\tLoss: 0.3741\tLR: 0.015000\nTraining Epoch: 9 [24192/50000]\tLoss: 0.3751\tLR: 0.015000\nTraining Epoch: 9 [24320/50000]\tLoss: 0.4508\tLR: 0.015000\nTraining Epoch: 9 [24448/50000]\tLoss: 0.4044\tLR: 0.015000\nTraining Epoch: 9 [24576/50000]\tLoss: 0.2744\tLR: 0.015000\nTraining Epoch: 9 [24704/50000]\tLoss: 0.2636\tLR: 0.015000\nTraining Epoch: 9 [24832/50000]\tLoss: 0.5123\tLR: 0.015000\nTraining Epoch: 9 [24960/50000]\tLoss: 0.4153\tLR: 0.015000\nTraining Epoch: 9 [25088/50000]\tLoss: 0.3625\tLR: 0.015000\nTraining Epoch: 9 [25216/50000]\tLoss: 0.3683\tLR: 0.015000\nTraining Epoch: 9 [25344/50000]\tLoss: 0.3547\tLR: 0.015000\nTraining Epoch: 9 [25472/50000]\tLoss: 0.3283\tLR: 0.015000\nTraining Epoch: 9 [25600/50000]\tLoss: 0.5374\tLR: 0.015000\nTraining Epoch: 9 [25728/50000]\tLoss: 0.4197\tLR: 0.015000\nTraining Epoch: 9 [25856/50000]\tLoss: 0.3526\tLR: 0.015000\nTraining Epoch: 9 [25984/50000]\tLoss: 0.4977\tLR: 0.015000\nTraining Epoch: 9 [26112/50000]\tLoss: 0.2405\tLR: 0.015000\nTraining Epoch: 9 [26240/50000]\tLoss: 0.3829\tLR: 0.015000\nTraining Epoch: 9 [26368/50000]\tLoss: 0.3218\tLR: 0.015000\nTraining Epoch: 9 [26496/50000]\tLoss: 0.2794\tLR: 0.015000\nTraining Epoch: 9 [26624/50000]\tLoss: 0.2584\tLR: 0.015000\nTraining Epoch: 9 [26752/50000]\tLoss: 0.4464\tLR: 0.015000\nTraining Epoch: 9 [26880/50000]\tLoss: 0.2440\tLR: 0.015000\nTraining Epoch: 9 [27008/50000]\tLoss: 0.4471\tLR: 0.015000\nTraining Epoch: 9 [27136/50000]\tLoss: 0.4467\tLR: 0.015000\nTraining Epoch: 9 [27264/50000]\tLoss: 0.5609\tLR: 0.015000\nTraining Epoch: 9 [27392/50000]\tLoss: 0.4517\tLR: 0.015000\nTraining Epoch: 9 [27520/50000]\tLoss: 0.4189\tLR: 0.015000\nTraining Epoch: 9 [27648/50000]\tLoss: 0.4663\tLR: 0.015000\nTraining Epoch: 9 [27776/50000]\tLoss: 0.3313\tLR: 0.015000\nTraining Epoch: 9 [27904/50000]\tLoss: 0.3240\tLR: 0.015000\nTraining Epoch: 9 [28032/50000]\tLoss: 0.3968\tLR: 0.015000\nTraining Epoch: 9 [28160/50000]\tLoss: 0.5295\tLR: 0.015000\nTraining Epoch: 9 [28288/50000]\tLoss: 0.3150\tLR: 0.015000\nTraining Epoch: 9 [28416/50000]\tLoss: 0.3145\tLR: 0.015000\nTraining Epoch: 9 [28544/50000]\tLoss: 0.4682\tLR: 0.015000\nTraining Epoch: 9 [28672/50000]\tLoss: 0.3583\tLR: 0.015000\nTraining Epoch: 9 [28800/50000]\tLoss: 0.4320\tLR: 0.015000\nTraining Epoch: 9 [28928/50000]\tLoss: 0.4259\tLR: 0.015000\nTraining Epoch: 9 [29056/50000]\tLoss: 0.2422\tLR: 0.015000\nTraining Epoch: 9 [29184/50000]\tLoss: 0.4089\tLR: 0.015000\nTraining Epoch: 9 [29312/50000]\tLoss: 0.3525\tLR: 0.015000\nTraining Epoch: 9 [29440/50000]\tLoss: 0.2941\tLR: 0.015000\nTraining Epoch: 9 [29568/50000]\tLoss: 0.2840\tLR: 0.015000\nTraining Epoch: 9 [29696/50000]\tLoss: 0.4600\tLR: 0.015000\nTraining Epoch: 9 [29824/50000]\tLoss: 0.4803\tLR: 0.015000\nTraining Epoch: 9 [29952/50000]\tLoss: 0.3865\tLR: 0.015000\nTraining Epoch: 9 [30080/50000]\tLoss: 0.2964\tLR: 0.015000\nTraining Epoch: 9 [30208/50000]\tLoss: 0.3642\tLR: 0.015000\nTraining Epoch: 9 [30336/50000]\tLoss: 0.4265\tLR: 0.015000\nTraining Epoch: 9 [30464/50000]\tLoss: 0.3654\tLR: 0.015000\nTraining Epoch: 9 [30592/50000]\tLoss: 0.4948\tLR: 0.015000\nTraining Epoch: 9 [30720/50000]\tLoss: 0.4350\tLR: 0.015000\nTraining Epoch: 9 [30848/50000]\tLoss: 0.3543\tLR: 0.015000\nTraining Epoch: 9 [30976/50000]\tLoss: 0.2520\tLR: 0.015000\nTraining Epoch: 9 [31104/50000]\tLoss: 0.3848\tLR: 0.015000\nTraining Epoch: 9 [31232/50000]\tLoss: 0.4559\tLR: 0.015000\nTraining Epoch: 9 [31360/50000]\tLoss: 0.3959\tLR: 0.015000\nTraining Epoch: 9 [31488/50000]\tLoss: 0.4068\tLR: 0.015000\nTraining Epoch: 9 [31616/50000]\tLoss: 0.3044\tLR: 0.015000\nTraining Epoch: 9 [31744/50000]\tLoss: 0.4850\tLR: 0.015000\nTraining Epoch: 9 [31872/50000]\tLoss: 0.5771\tLR: 0.015000\nTraining Epoch: 9 [32000/50000]\tLoss: 0.4902\tLR: 0.015000\nTraining Epoch: 9 [32128/50000]\tLoss: 0.4537\tLR: 0.015000\nTraining Epoch: 9 [32256/50000]\tLoss: 0.3743\tLR: 0.015000\nTraining Epoch: 9 [32384/50000]\tLoss: 0.2941\tLR: 0.015000\nTraining Epoch: 9 [32512/50000]\tLoss: 0.3765\tLR: 0.015000\nTraining Epoch: 9 [32640/50000]\tLoss: 0.3631\tLR: 0.015000\nTraining Epoch: 9 [32768/50000]\tLoss: 0.4143\tLR: 0.015000\nTraining Epoch: 9 [32896/50000]\tLoss: 0.3423\tLR: 0.015000\nTraining Epoch: 9 [33024/50000]\tLoss: 0.3725\tLR: 0.015000\nTraining Epoch: 9 [33152/50000]\tLoss: 0.2964\tLR: 0.015000\nTraining Epoch: 9 [33280/50000]\tLoss: 0.4125\tLR: 0.015000\nTraining Epoch: 9 [33408/50000]\tLoss: 0.4358\tLR: 0.015000\nTraining Epoch: 9 [33536/50000]\tLoss: 0.4816\tLR: 0.015000\nTraining Epoch: 9 [33664/50000]\tLoss: 0.3689\tLR: 0.015000\nTraining Epoch: 9 [33792/50000]\tLoss: 0.3847\tLR: 0.015000\nTraining Epoch: 9 [33920/50000]\tLoss: 0.5054\tLR: 0.015000\nTraining Epoch: 9 [34048/50000]\tLoss: 0.3451\tLR: 0.015000\nTraining Epoch: 9 [34176/50000]\tLoss: 0.2938\tLR: 0.015000\nTraining Epoch: 9 [34304/50000]\tLoss: 0.4630\tLR: 0.015000\nTraining Epoch: 9 [34432/50000]\tLoss: 0.3666\tLR: 0.015000\nTraining Epoch: 9 [34560/50000]\tLoss: 0.4868\tLR: 0.015000\nTraining Epoch: 9 [34688/50000]\tLoss: 0.3051\tLR: 0.015000\nTraining Epoch: 9 [34816/50000]\tLoss: 0.4481\tLR: 0.015000\nTraining Epoch: 9 [34944/50000]\tLoss: 0.3615\tLR: 0.015000\nTraining Epoch: 9 [35072/50000]\tLoss: 0.4061\tLR: 0.015000\nTraining Epoch: 9 [35200/50000]\tLoss: 0.4681\tLR: 0.015000\nTraining Epoch: 9 [35328/50000]\tLoss: 0.3295\tLR: 0.015000\nTraining Epoch: 9 [35456/50000]\tLoss: 0.4811\tLR: 0.015000\nTraining Epoch: 9 [35584/50000]\tLoss: 0.4213\tLR: 0.015000\nTraining Epoch: 9 [35712/50000]\tLoss: 0.4458\tLR: 0.015000\nTraining Epoch: 9 [35840/50000]\tLoss: 0.4069\tLR: 0.015000\nTraining Epoch: 9 [35968/50000]\tLoss: 0.4016\tLR: 0.015000\nTraining Epoch: 9 [36096/50000]\tLoss: 0.5460\tLR: 0.015000\nTraining Epoch: 9 [36224/50000]\tLoss: 0.3410\tLR: 0.015000\nTraining Epoch: 9 [36352/50000]\tLoss: 0.3529\tLR: 0.015000\nTraining Epoch: 9 [36480/50000]\tLoss: 0.3883\tLR: 0.015000\nTraining Epoch: 9 [36608/50000]\tLoss: 0.3639\tLR: 0.015000\nTraining Epoch: 9 [36736/50000]\tLoss: 0.5272\tLR: 0.015000\nTraining Epoch: 9 [36864/50000]\tLoss: 0.4094\tLR: 0.015000\nTraining Epoch: 9 [36992/50000]\tLoss: 0.4177\tLR: 0.015000\nTraining Epoch: 9 [37120/50000]\tLoss: 0.3684\tLR: 0.015000\nTraining Epoch: 9 [37248/50000]\tLoss: 0.3452\tLR: 0.015000\nTraining Epoch: 9 [37376/50000]\tLoss: 0.3540\tLR: 0.015000\nTraining Epoch: 9 [37504/50000]\tLoss: 0.4314\tLR: 0.015000\nTraining Epoch: 9 [37632/50000]\tLoss: 0.3934\tLR: 0.015000\nTraining Epoch: 9 [37760/50000]\tLoss: 0.4389\tLR: 0.015000\nTraining Epoch: 9 [37888/50000]\tLoss: 0.4791\tLR: 0.015000\nTraining Epoch: 9 [38016/50000]\tLoss: 0.3584\tLR: 0.015000\nTraining Epoch: 9 [38144/50000]\tLoss: 0.3394\tLR: 0.015000\nTraining Epoch: 9 [38272/50000]\tLoss: 0.4532\tLR: 0.015000\nTraining Epoch: 9 [38400/50000]\tLoss: 0.4360\tLR: 0.015000\nTraining Epoch: 9 [38528/50000]\tLoss: 0.3972\tLR: 0.015000\nTraining Epoch: 9 [38656/50000]\tLoss: 0.3575\tLR: 0.015000\nTraining Epoch: 9 [38784/50000]\tLoss: 0.2625\tLR: 0.015000\nTraining Epoch: 9 [38912/50000]\tLoss: 0.3838\tLR: 0.015000\nTraining Epoch: 9 [39040/50000]\tLoss: 0.3754\tLR: 0.015000\nTraining Epoch: 9 [39168/50000]\tLoss: 0.3793\tLR: 0.015000\nTraining Epoch: 9 [39296/50000]\tLoss: 0.4406\tLR: 0.015000\nTraining Epoch: 9 [39424/50000]\tLoss: 0.5131\tLR: 0.015000\nTraining Epoch: 9 [39552/50000]\tLoss: 0.4466\tLR: 0.015000\nTraining Epoch: 9 [39680/50000]\tLoss: 0.3163\tLR: 0.015000\nTraining Epoch: 9 [39808/50000]\tLoss: 0.3554\tLR: 0.015000\nTraining Epoch: 9 [39936/50000]\tLoss: 0.3598\tLR: 0.015000\nTraining Epoch: 9 [40064/50000]\tLoss: 0.4182\tLR: 0.015000\nTraining Epoch: 9 [40192/50000]\tLoss: 0.4233\tLR: 0.015000\nTraining Epoch: 9 [40320/50000]\tLoss: 0.4218\tLR: 0.015000\nTraining Epoch: 9 [40448/50000]\tLoss: 0.3620\tLR: 0.015000\nTraining Epoch: 9 [40576/50000]\tLoss: 0.5356\tLR: 0.015000\nTraining Epoch: 9 [40704/50000]\tLoss: 0.4509\tLR: 0.015000\nTraining Epoch: 9 [40832/50000]\tLoss: 0.4171\tLR: 0.015000\nTraining Epoch: 9 [40960/50000]\tLoss: 0.4272\tLR: 0.015000\nTraining Epoch: 9 [41088/50000]\tLoss: 0.3780\tLR: 0.015000\nTraining Epoch: 9 [41216/50000]\tLoss: 0.4219\tLR: 0.015000\nTraining Epoch: 9 [41344/50000]\tLoss: 0.3881\tLR: 0.015000\nTraining Epoch: 9 [41472/50000]\tLoss: 0.3706\tLR: 0.015000\nTraining Epoch: 9 [41600/50000]\tLoss: 0.4889\tLR: 0.015000\nTraining Epoch: 9 [41728/50000]\tLoss: 0.4486\tLR: 0.015000\nTraining Epoch: 9 [41856/50000]\tLoss: 0.4950\tLR: 0.015000\nTraining Epoch: 9 [41984/50000]\tLoss: 0.3323\tLR: 0.015000\nTraining Epoch: 9 [42112/50000]\tLoss: 0.3102\tLR: 0.015000\nTraining Epoch: 9 [42240/50000]\tLoss: 0.2692\tLR: 0.015000\nTraining Epoch: 9 [42368/50000]\tLoss: 0.4150\tLR: 0.015000\nTraining Epoch: 9 [42496/50000]\tLoss: 0.2434\tLR: 0.015000\nTraining Epoch: 9 [42624/50000]\tLoss: 0.4035\tLR: 0.015000\nTraining Epoch: 9 [42752/50000]\tLoss: 0.4874\tLR: 0.015000\nTraining Epoch: 9 [42880/50000]\tLoss: 0.3875\tLR: 0.015000\nTraining Epoch: 9 [43008/50000]\tLoss: 0.5671\tLR: 0.015000\nTraining Epoch: 9 [43136/50000]\tLoss: 0.4780\tLR: 0.015000\nTraining Epoch: 9 [43264/50000]\tLoss: 0.4136\tLR: 0.015000\nTraining Epoch: 9 [43392/50000]\tLoss: 0.4074\tLR: 0.015000\nTraining Epoch: 9 [43520/50000]\tLoss: 0.3850\tLR: 0.015000\nTraining Epoch: 9 [43648/50000]\tLoss: 0.4863\tLR: 0.015000\nTraining Epoch: 9 [43776/50000]\tLoss: 0.4639\tLR: 0.015000\nTraining Epoch: 9 [43904/50000]\tLoss: 0.4002\tLR: 0.015000\nTraining Epoch: 9 [44032/50000]\tLoss: 0.2702\tLR: 0.015000\nTraining Epoch: 9 [44160/50000]\tLoss: 0.4985\tLR: 0.015000\nTraining Epoch: 9 [44288/50000]\tLoss: 0.3826\tLR: 0.015000\nTraining Epoch: 9 [44416/50000]\tLoss: 0.4019\tLR: 0.015000\nTraining Epoch: 9 [44544/50000]\tLoss: 0.4248\tLR: 0.015000\nTraining Epoch: 9 [44672/50000]\tLoss: 0.2798\tLR: 0.015000\nTraining Epoch: 9 [44800/50000]\tLoss: 0.3778\tLR: 0.015000\nTraining Epoch: 9 [44928/50000]\tLoss: 0.3498\tLR: 0.015000\nTraining Epoch: 9 [45056/50000]\tLoss: 0.5318\tLR: 0.015000\nTraining Epoch: 9 [45184/50000]\tLoss: 0.4565\tLR: 0.015000\nTraining Epoch: 9 [45312/50000]\tLoss: 0.4188\tLR: 0.015000\nTraining Epoch: 9 [45440/50000]\tLoss: 0.2955\tLR: 0.015000\nTraining Epoch: 9 [45568/50000]\tLoss: 0.4374\tLR: 0.015000\nTraining Epoch: 9 [45696/50000]\tLoss: 0.4419\tLR: 0.015000\nTraining Epoch: 9 [45824/50000]\tLoss: 0.3341\tLR: 0.015000\nTraining Epoch: 9 [45952/50000]\tLoss: 0.3246\tLR: 0.015000\nTraining Epoch: 9 [46080/50000]\tLoss: 0.4307\tLR: 0.015000\nTraining Epoch: 9 [46208/50000]\tLoss: 0.4204\tLR: 0.015000\nTraining Epoch: 9 [46336/50000]\tLoss: 0.3981\tLR: 0.015000\nTraining Epoch: 9 [46464/50000]\tLoss: 0.4390\tLR: 0.015000\nTraining Epoch: 9 [46592/50000]\tLoss: 0.3331\tLR: 0.015000\nTraining Epoch: 9 [46720/50000]\tLoss: 0.4773\tLR: 0.015000\nTraining Epoch: 9 [46848/50000]\tLoss: 0.3890\tLR: 0.015000\nTraining Epoch: 9 [46976/50000]\tLoss: 0.1706\tLR: 0.015000\nTraining Epoch: 9 [47104/50000]\tLoss: 0.4079\tLR: 0.015000\nTraining Epoch: 9 [47232/50000]\tLoss: 0.4420\tLR: 0.015000\nTraining Epoch: 9 [47360/50000]\tLoss: 0.4977\tLR: 0.015000\nTraining Epoch: 9 [47488/50000]\tLoss: 0.5202\tLR: 0.015000\nTraining Epoch: 9 [47616/50000]\tLoss: 0.5396\tLR: 0.015000\nTraining Epoch: 9 [47744/50000]\tLoss: 0.3663\tLR: 0.015000\nTraining Epoch: 9 [47872/50000]\tLoss: 0.3305\tLR: 0.015000\nTraining Epoch: 9 [48000/50000]\tLoss: 0.3477\tLR: 0.015000\nTraining Epoch: 9 [48128/50000]\tLoss: 0.4069\tLR: 0.015000\nTraining Epoch: 9 [48256/50000]\tLoss: 0.5044\tLR: 0.015000\nTraining Epoch: 9 [48384/50000]\tLoss: 0.4122\tLR: 0.015000\nTraining Epoch: 9 [48512/50000]\tLoss: 0.4729\tLR: 0.015000\nTraining Epoch: 9 [48640/50000]\tLoss: 0.3524\tLR: 0.015000\nTraining Epoch: 9 [48768/50000]\tLoss: 0.5537\tLR: 0.015000\nTraining Epoch: 9 [48896/50000]\tLoss: 0.3051\tLR: 0.015000\nTraining Epoch: 9 [49024/50000]\tLoss: 0.3311\tLR: 0.015000\nTraining Epoch: 9 [49152/50000]\tLoss: 0.3681\tLR: 0.015000\nTraining Epoch: 9 [49280/50000]\tLoss: 0.4134\tLR: 0.015000\nTraining Epoch: 9 [49408/50000]\tLoss: 0.4776\tLR: 0.015000\nTraining Epoch: 9 [49536/50000]\tLoss: 0.3768\tLR: 0.015000\nTraining Epoch: 9 [49664/50000]\tLoss: 0.4560\tLR: 0.015000\nTraining Epoch: 9 [49792/50000]\tLoss: 0.5059\tLR: 0.015000\nTraining Epoch: 9 [49920/50000]\tLoss: 0.4720\tLR: 0.015000\nTraining Epoch: 9 [50000/50000]\tLoss: 0.3740\tLR: 0.015000\nTest set: Average loss: 0.0030, Accuracy: 0.8675\n\nTraining Epoch: 10 [128/50000]\tLoss: 0.3433\tLR: 0.015000\nTraining Epoch: 10 [256/50000]\tLoss: 0.4977\tLR: 0.015000\nTraining Epoch: 10 [384/50000]\tLoss: 0.2340\tLR: 0.015000\nTraining Epoch: 10 [512/50000]\tLoss: 0.4163\tLR: 0.015000\nTraining Epoch: 10 [640/50000]\tLoss: 0.3291\tLR: 0.015000\nTraining Epoch: 10 [768/50000]\tLoss: 0.4753\tLR: 0.015000\nTraining Epoch: 10 [896/50000]\tLoss: 0.3607\tLR: 0.015000\nTraining Epoch: 10 [1024/50000]\tLoss: 0.3470\tLR: 0.015000\nTraining Epoch: 10 [1152/50000]\tLoss: 0.3755\tLR: 0.015000\nTraining Epoch: 10 [1280/50000]\tLoss: 0.4214\tLR: 0.015000\nTraining Epoch: 10 [1408/50000]\tLoss: 0.3073\tLR: 0.015000\nTraining Epoch: 10 [1536/50000]\tLoss: 0.3305\tLR: 0.015000\nTraining Epoch: 10 [1664/50000]\tLoss: 0.3543\tLR: 0.015000\nTraining Epoch: 10 [1792/50000]\tLoss: 0.4588\tLR: 0.015000\nTraining Epoch: 10 [1920/50000]\tLoss: 0.3113\tLR: 0.015000\nTraining Epoch: 10 [2048/50000]\tLoss: 0.2897\tLR: 0.015000\nTraining Epoch: 10 [2176/50000]\tLoss: 0.3928\tLR: 0.015000\nTraining Epoch: 10 [2304/50000]\tLoss: 0.3244\tLR: 0.015000\nTraining Epoch: 10 [2432/50000]\tLoss: 0.2974\tLR: 0.015000\nTraining Epoch: 10 [2560/50000]\tLoss: 0.4309\tLR: 0.015000\nTraining Epoch: 10 [2688/50000]\tLoss: 0.4141\tLR: 0.015000\nTraining Epoch: 10 [2816/50000]\tLoss: 0.4049\tLR: 0.015000\nTraining Epoch: 10 [2944/50000]\tLoss: 0.3854\tLR: 0.015000\nTraining Epoch: 10 [3072/50000]\tLoss: 0.3794\tLR: 0.015000\nTraining Epoch: 10 [3200/50000]\tLoss: 0.3109\tLR: 0.015000\nTraining Epoch: 10 [3328/50000]\tLoss: 0.4119\tLR: 0.015000\nTraining Epoch: 10 [3456/50000]\tLoss: 0.3866\tLR: 0.015000\nTraining Epoch: 10 [3584/50000]\tLoss: 0.3530\tLR: 0.015000\nTraining Epoch: 10 [3712/50000]\tLoss: 0.4017\tLR: 0.015000\nTraining Epoch: 10 [3840/50000]\tLoss: 0.2664\tLR: 0.015000\nTraining Epoch: 10 [3968/50000]\tLoss: 0.5886\tLR: 0.015000\nTraining Epoch: 10 [4096/50000]\tLoss: 0.4000\tLR: 0.015000\nTraining Epoch: 10 [4224/50000]\tLoss: 0.3821\tLR: 0.015000\nTraining Epoch: 10 [4352/50000]\tLoss: 0.3704\tLR: 0.015000\nTraining Epoch: 10 [4480/50000]\tLoss: 0.4933\tLR: 0.015000\nTraining Epoch: 10 [4608/50000]\tLoss: 0.3767\tLR: 0.015000\nTraining Epoch: 10 [4736/50000]\tLoss: 0.4882\tLR: 0.015000\nTraining Epoch: 10 [4864/50000]\tLoss: 0.3939\tLR: 0.015000\nTraining Epoch: 10 [4992/50000]\tLoss: 0.4783\tLR: 0.015000\nTraining Epoch: 10 [5120/50000]\tLoss: 0.6035\tLR: 0.015000\nTraining Epoch: 10 [5248/50000]\tLoss: 0.3386\tLR: 0.015000\nTraining Epoch: 10 [5376/50000]\tLoss: 0.2244\tLR: 0.015000\nTraining Epoch: 10 [5504/50000]\tLoss: 0.3301\tLR: 0.015000\nTraining Epoch: 10 [5632/50000]\tLoss: 0.3806\tLR: 0.015000\nTraining Epoch: 10 [5760/50000]\tLoss: 0.3094\tLR: 0.015000\nTraining Epoch: 10 [5888/50000]\tLoss: 0.3845\tLR: 0.015000\nTraining Epoch: 10 [6016/50000]\tLoss: 0.2218\tLR: 0.015000\nTraining Epoch: 10 [6144/50000]\tLoss: 0.4785\tLR: 0.015000\nTraining Epoch: 10 [6272/50000]\tLoss: 0.4503\tLR: 0.015000\nTraining Epoch: 10 [6400/50000]\tLoss: 0.3618\tLR: 0.015000\nTraining Epoch: 10 [6528/50000]\tLoss: 0.3037\tLR: 0.015000\nTraining Epoch: 10 [6656/50000]\tLoss: 0.3131\tLR: 0.015000\nTraining Epoch: 10 [6784/50000]\tLoss: 0.4274\tLR: 0.015000\nTraining Epoch: 10 [6912/50000]\tLoss: 0.3797\tLR: 0.015000\nTraining Epoch: 10 [7040/50000]\tLoss: 0.3561\tLR: 0.015000\nTraining Epoch: 10 [7168/50000]\tLoss: 0.4134\tLR: 0.015000\nTraining Epoch: 10 [7296/50000]\tLoss: 0.4423\tLR: 0.015000\nTraining Epoch: 10 [7424/50000]\tLoss: 0.4642\tLR: 0.015000\nTraining Epoch: 10 [7552/50000]\tLoss: 0.3546\tLR: 0.015000\nTraining Epoch: 10 [7680/50000]\tLoss: 0.4192\tLR: 0.015000\nTraining Epoch: 10 [7808/50000]\tLoss: 0.2431\tLR: 0.015000\nTraining Epoch: 10 [7936/50000]\tLoss: 0.5017\tLR: 0.015000\nTraining Epoch: 10 [8064/50000]\tLoss: 0.4138\tLR: 0.015000\nTraining Epoch: 10 [8192/50000]\tLoss: 0.3008\tLR: 0.015000\nTraining Epoch: 10 [8320/50000]\tLoss: 0.4689\tLR: 0.015000\nTraining Epoch: 10 [8448/50000]\tLoss: 0.3658\tLR: 0.015000\nTraining Epoch: 10 [8576/50000]\tLoss: 0.3672\tLR: 0.015000\nTraining Epoch: 10 [8704/50000]\tLoss: 0.3554\tLR: 0.015000\nTraining Epoch: 10 [8832/50000]\tLoss: 0.3633\tLR: 0.015000\nTraining Epoch: 10 [8960/50000]\tLoss: 0.2611\tLR: 0.015000\nTraining Epoch: 10 [9088/50000]\tLoss: 0.3851\tLR: 0.015000\nTraining Epoch: 10 [9216/50000]\tLoss: 0.5014\tLR: 0.015000\nTraining Epoch: 10 [9344/50000]\tLoss: 0.4058\tLR: 0.015000\nTraining Epoch: 10 [9472/50000]\tLoss: 0.2980\tLR: 0.015000\nTraining Epoch: 10 [9600/50000]\tLoss: 0.3991\tLR: 0.015000\nTraining Epoch: 10 [9728/50000]\tLoss: 0.3473\tLR: 0.015000\nTraining Epoch: 10 [9856/50000]\tLoss: 0.4292\tLR: 0.015000\nTraining Epoch: 10 [9984/50000]\tLoss: 0.3957\tLR: 0.015000\nTraining Epoch: 10 [10112/50000]\tLoss: 0.2852\tLR: 0.015000\nTraining Epoch: 10 [10240/50000]\tLoss: 0.3927\tLR: 0.015000\nTraining Epoch: 10 [10368/50000]\tLoss: 0.3636\tLR: 0.015000\nTraining Epoch: 10 [10496/50000]\tLoss: 0.5629\tLR: 0.015000\nTraining Epoch: 10 [10624/50000]\tLoss: 0.3222\tLR: 0.015000\nTraining Epoch: 10 [10752/50000]\tLoss: 0.5403\tLR: 0.015000\nTraining Epoch: 10 [10880/50000]\tLoss: 0.3227\tLR: 0.015000\nTraining Epoch: 10 [11008/50000]\tLoss: 0.3844\tLR: 0.015000\nTraining Epoch: 10 [11136/50000]\tLoss: 0.4610\tLR: 0.015000\nTraining Epoch: 10 [11264/50000]\tLoss: 0.3522\tLR: 0.015000\nTraining Epoch: 10 [11392/50000]\tLoss: 0.3370\tLR: 0.015000\nTraining Epoch: 10 [11520/50000]\tLoss: 0.4508\tLR: 0.015000\nTraining Epoch: 10 [11648/50000]\tLoss: 0.2995\tLR: 0.015000\nTraining Epoch: 10 [11776/50000]\tLoss: 0.6217\tLR: 0.015000\nTraining Epoch: 10 [11904/50000]\tLoss: 0.4412\tLR: 0.015000\nTraining Epoch: 10 [12032/50000]\tLoss: 0.2729\tLR: 0.015000\nTraining Epoch: 10 [12160/50000]\tLoss: 0.3530\tLR: 0.015000\nTraining Epoch: 10 [12288/50000]\tLoss: 0.3826\tLR: 0.015000\nTraining Epoch: 10 [12416/50000]\tLoss: 0.4195\tLR: 0.015000\nTraining Epoch: 10 [12544/50000]\tLoss: 0.3228\tLR: 0.015000\nTraining Epoch: 10 [12672/50000]\tLoss: 0.3040\tLR: 0.015000\nTraining Epoch: 10 [12800/50000]\tLoss: 0.3375\tLR: 0.015000\nTraining Epoch: 10 [12928/50000]\tLoss: 0.4016\tLR: 0.015000\nTraining Epoch: 10 [13056/50000]\tLoss: 0.4363\tLR: 0.015000\nTraining Epoch: 10 [13184/50000]\tLoss: 0.3514\tLR: 0.015000\nTraining Epoch: 10 [13312/50000]\tLoss: 0.3419\tLR: 0.015000\nTraining Epoch: 10 [13440/50000]\tLoss: 0.4743\tLR: 0.015000\nTraining Epoch: 10 [13568/50000]\tLoss: 0.4041\tLR: 0.015000\nTraining Epoch: 10 [13696/50000]\tLoss: 0.3937\tLR: 0.015000\nTraining Epoch: 10 [13824/50000]\tLoss: 0.3747\tLR: 0.015000\nTraining Epoch: 10 [13952/50000]\tLoss: 0.3073\tLR: 0.015000\nTraining Epoch: 10 [14080/50000]\tLoss: 0.3181\tLR: 0.015000\nTraining Epoch: 10 [14208/50000]\tLoss: 0.3000\tLR: 0.015000\nTraining Epoch: 10 [14336/50000]\tLoss: 0.4954\tLR: 0.015000\nTraining Epoch: 10 [14464/50000]\tLoss: 0.3984\tLR: 0.015000\nTraining Epoch: 10 [14592/50000]\tLoss: 0.5344\tLR: 0.015000\nTraining Epoch: 10 [14720/50000]\tLoss: 0.3388\tLR: 0.015000\nTraining Epoch: 10 [14848/50000]\tLoss: 0.4380\tLR: 0.015000\nTraining Epoch: 10 [14976/50000]\tLoss: 0.4106\tLR: 0.015000\nTraining Epoch: 10 [15104/50000]\tLoss: 0.3138\tLR: 0.015000\nTraining Epoch: 10 [15232/50000]\tLoss: 0.4898\tLR: 0.015000\nTraining Epoch: 10 [15360/50000]\tLoss: 0.4348\tLR: 0.015000\nTraining Epoch: 10 [15488/50000]\tLoss: 0.4435\tLR: 0.015000\nTraining Epoch: 10 [15616/50000]\tLoss: 0.4270\tLR: 0.015000\nTraining Epoch: 10 [15744/50000]\tLoss: 0.3837\tLR: 0.015000\nTraining Epoch: 10 [15872/50000]\tLoss: 0.2625\tLR: 0.015000\nTraining Epoch: 10 [16000/50000]\tLoss: 0.3226\tLR: 0.015000\nTraining Epoch: 10 [16128/50000]\tLoss: 0.3678\tLR: 0.015000\nTraining Epoch: 10 [16256/50000]\tLoss: 0.4929\tLR: 0.015000\nTraining Epoch: 10 [16384/50000]\tLoss: 0.4333\tLR: 0.015000\nTraining Epoch: 10 [16512/50000]\tLoss: 0.4388\tLR: 0.015000\nTraining Epoch: 10 [16640/50000]\tLoss: 0.4014\tLR: 0.015000\nTraining Epoch: 10 [16768/50000]\tLoss: 0.4570\tLR: 0.015000\nTraining Epoch: 10 [16896/50000]\tLoss: 0.3078\tLR: 0.015000\nTraining Epoch: 10 [17024/50000]\tLoss: 0.3450\tLR: 0.015000\nTraining Epoch: 10 [17152/50000]\tLoss: 0.3802\tLR: 0.015000\nTraining Epoch: 10 [17280/50000]\tLoss: 0.3588\tLR: 0.015000\nTraining Epoch: 10 [17408/50000]\tLoss: 0.3513\tLR: 0.015000\nTraining Epoch: 10 [17536/50000]\tLoss: 0.4887\tLR: 0.015000\nTraining Epoch: 10 [17664/50000]\tLoss: 0.3634\tLR: 0.015000\nTraining Epoch: 10 [17792/50000]\tLoss: 0.3344\tLR: 0.015000\nTraining Epoch: 10 [17920/50000]\tLoss: 0.4309\tLR: 0.015000\nTraining Epoch: 10 [18048/50000]\tLoss: 0.3682\tLR: 0.015000\nTraining Epoch: 10 [18176/50000]\tLoss: 0.4365\tLR: 0.015000\nTraining Epoch: 10 [18304/50000]\tLoss: 0.3929\tLR: 0.015000\nTraining Epoch: 10 [18432/50000]\tLoss: 0.2270\tLR: 0.015000\nTraining Epoch: 10 [18560/50000]\tLoss: 0.4037\tLR: 0.015000\nTraining Epoch: 10 [18688/50000]\tLoss: 0.4040\tLR: 0.015000\nTraining Epoch: 10 [18816/50000]\tLoss: 0.4605\tLR: 0.015000\nTraining Epoch: 10 [18944/50000]\tLoss: 0.5429\tLR: 0.015000\nTraining Epoch: 10 [19072/50000]\tLoss: 0.3569\tLR: 0.015000\nTraining Epoch: 10 [19200/50000]\tLoss: 0.4560\tLR: 0.015000\nTraining Epoch: 10 [19328/50000]\tLoss: 0.3801\tLR: 0.015000\nTraining Epoch: 10 [19456/50000]\tLoss: 0.2956\tLR: 0.015000\nTraining Epoch: 10 [19584/50000]\tLoss: 0.3736\tLR: 0.015000\nTraining Epoch: 10 [19712/50000]\tLoss: 0.5445\tLR: 0.015000\nTraining Epoch: 10 [19840/50000]\tLoss: 0.4868\tLR: 0.015000\nTraining Epoch: 10 [19968/50000]\tLoss: 0.3931\tLR: 0.015000\nTraining Epoch: 10 [20096/50000]\tLoss: 0.4183\tLR: 0.015000\nTraining Epoch: 10 [20224/50000]\tLoss: 0.3359\tLR: 0.015000\nTraining Epoch: 10 [20352/50000]\tLoss: 0.2775\tLR: 0.015000\nTraining Epoch: 10 [20480/50000]\tLoss: 0.2446\tLR: 0.015000\nTraining Epoch: 10 [20608/50000]\tLoss: 0.4954\tLR: 0.015000\nTraining Epoch: 10 [20736/50000]\tLoss: 0.4396\tLR: 0.015000\nTraining Epoch: 10 [20864/50000]\tLoss: 0.3338\tLR: 0.015000\nTraining Epoch: 10 [20992/50000]\tLoss: 0.4655\tLR: 0.015000\nTraining Epoch: 10 [21120/50000]\tLoss: 0.5444\tLR: 0.015000\nTraining Epoch: 10 [21248/50000]\tLoss: 0.3064\tLR: 0.015000\nTraining Epoch: 10 [21376/50000]\tLoss: 0.2923\tLR: 0.015000\nTraining Epoch: 10 [21504/50000]\tLoss: 0.4792\tLR: 0.015000\nTraining Epoch: 10 [21632/50000]\tLoss: 0.3276\tLR: 0.015000\nTraining Epoch: 10 [21760/50000]\tLoss: 0.3190\tLR: 0.015000\nTraining Epoch: 10 [21888/50000]\tLoss: 0.3759\tLR: 0.015000\nTraining Epoch: 10 [22016/50000]\tLoss: 0.4064\tLR: 0.015000\nTraining Epoch: 10 [22144/50000]\tLoss: 0.3610\tLR: 0.015000\nTraining Epoch: 10 [22272/50000]\tLoss: 0.3774\tLR: 0.015000\nTraining Epoch: 10 [22400/50000]\tLoss: 0.3393\tLR: 0.015000\nTraining Epoch: 10 [22528/50000]\tLoss: 0.3507\tLR: 0.015000\nTraining Epoch: 10 [22656/50000]\tLoss: 0.3246\tLR: 0.015000\nTraining Epoch: 10 [22784/50000]\tLoss: 0.2898\tLR: 0.015000\nTraining Epoch: 10 [22912/50000]\tLoss: 0.4348\tLR: 0.015000\nTraining Epoch: 10 [23040/50000]\tLoss: 0.3449\tLR: 0.015000\nTraining Epoch: 10 [23168/50000]\tLoss: 0.3461\tLR: 0.015000\nTraining Epoch: 10 [23296/50000]\tLoss: 0.3302\tLR: 0.015000\nTraining Epoch: 10 [23424/50000]\tLoss: 0.4675\tLR: 0.015000\nTraining Epoch: 10 [23552/50000]\tLoss: 0.5057\tLR: 0.015000\nTraining Epoch: 10 [23680/50000]\tLoss: 0.4244\tLR: 0.015000\nTraining Epoch: 10 [23808/50000]\tLoss: 0.3379\tLR: 0.015000\nTraining Epoch: 10 [23936/50000]\tLoss: 0.3882\tLR: 0.015000\nTraining Epoch: 10 [24064/50000]\tLoss: 0.4307\tLR: 0.015000\nTraining Epoch: 10 [24192/50000]\tLoss: 0.4218\tLR: 0.015000\nTraining Epoch: 10 [24320/50000]\tLoss: 0.4050\tLR: 0.015000\nTraining Epoch: 10 [24448/50000]\tLoss: 0.3106\tLR: 0.015000\nTraining Epoch: 10 [24576/50000]\tLoss: 0.3818\tLR: 0.015000\nTraining Epoch: 10 [24704/50000]\tLoss: 0.3987\tLR: 0.015000\nTraining Epoch: 10 [24832/50000]\tLoss: 0.4108\tLR: 0.015000\nTraining Epoch: 10 [24960/50000]\tLoss: 0.4137\tLR: 0.015000\nTraining Epoch: 10 [25088/50000]\tLoss: 0.3578\tLR: 0.015000\nTraining Epoch: 10 [25216/50000]\tLoss: 0.4476\tLR: 0.015000\nTraining Epoch: 10 [25344/50000]\tLoss: 0.3084\tLR: 0.015000\nTraining Epoch: 10 [25472/50000]\tLoss: 0.3233\tLR: 0.015000\nTraining Epoch: 10 [25600/50000]\tLoss: 0.3294\tLR: 0.015000\nTraining Epoch: 10 [25728/50000]\tLoss: 0.4079\tLR: 0.015000\nTraining Epoch: 10 [25856/50000]\tLoss: 0.3933\tLR: 0.015000\nTraining Epoch: 10 [25984/50000]\tLoss: 0.4802\tLR: 0.015000\nTraining Epoch: 10 [26112/50000]\tLoss: 0.3550\tLR: 0.015000\nTraining Epoch: 10 [26240/50000]\tLoss: 0.3760\tLR: 0.015000\nTraining Epoch: 10 [26368/50000]\tLoss: 0.3885\tLR: 0.015000\nTraining Epoch: 10 [26496/50000]\tLoss: 0.4578\tLR: 0.015000\nTraining Epoch: 10 [26624/50000]\tLoss: 0.4374\tLR: 0.015000\nTraining Epoch: 10 [26752/50000]\tLoss: 0.3171\tLR: 0.015000\nTraining Epoch: 10 [26880/50000]\tLoss: 0.5692\tLR: 0.015000\nTraining Epoch: 10 [27008/50000]\tLoss: 0.3842\tLR: 0.015000\nTraining Epoch: 10 [27136/50000]\tLoss: 0.3693\tLR: 0.015000\nTraining Epoch: 10 [27264/50000]\tLoss: 0.3897\tLR: 0.015000\nTraining Epoch: 10 [27392/50000]\tLoss: 0.3804\tLR: 0.015000\nTraining Epoch: 10 [27520/50000]\tLoss: 0.2692\tLR: 0.015000\nTraining Epoch: 10 [27648/50000]\tLoss: 0.4876\tLR: 0.015000\nTraining Epoch: 10 [27776/50000]\tLoss: 0.3652\tLR: 0.015000\nTraining Epoch: 10 [27904/50000]\tLoss: 0.3478\tLR: 0.015000\nTraining Epoch: 10 [28032/50000]\tLoss: 0.2907\tLR: 0.015000\nTraining Epoch: 10 [28160/50000]\tLoss: 0.3246\tLR: 0.015000\nTraining Epoch: 10 [28288/50000]\tLoss: 0.3093\tLR: 0.015000\nTraining Epoch: 10 [28416/50000]\tLoss: 0.4702\tLR: 0.015000\nTraining Epoch: 10 [28544/50000]\tLoss: 0.4053\tLR: 0.015000\nTraining Epoch: 10 [28672/50000]\tLoss: 0.4197\tLR: 0.015000\nTraining Epoch: 10 [28800/50000]\tLoss: 0.4832\tLR: 0.015000\nTraining Epoch: 10 [28928/50000]\tLoss: 0.3370\tLR: 0.015000\nTraining Epoch: 10 [29056/50000]\tLoss: 0.4112\tLR: 0.015000\nTraining Epoch: 10 [29184/50000]\tLoss: 0.3719\tLR: 0.015000\nTraining Epoch: 10 [29312/50000]\tLoss: 0.3172\tLR: 0.015000\nTraining Epoch: 10 [29440/50000]\tLoss: 0.4306\tLR: 0.015000\nTraining Epoch: 10 [29568/50000]\tLoss: 0.2837\tLR: 0.015000\nTraining Epoch: 10 [29696/50000]\tLoss: 0.3389\tLR: 0.015000\nTraining Epoch: 10 [29824/50000]\tLoss: 0.3322\tLR: 0.015000\nTraining Epoch: 10 [29952/50000]\tLoss: 0.4258\tLR: 0.015000\nTraining Epoch: 10 [30080/50000]\tLoss: 0.4730\tLR: 0.015000\nTraining Epoch: 10 [30208/50000]\tLoss: 0.3189\tLR: 0.015000\nTraining Epoch: 10 [30336/50000]\tLoss: 0.2863\tLR: 0.015000\nTraining Epoch: 10 [30464/50000]\tLoss: 0.2916\tLR: 0.015000\nTraining Epoch: 10 [30592/50000]\tLoss: 0.3306\tLR: 0.015000\nTraining Epoch: 10 [30720/50000]\tLoss: 0.2483\tLR: 0.015000\nTraining Epoch: 10 [30848/50000]\tLoss: 0.3683\tLR: 0.015000\nTraining Epoch: 10 [30976/50000]\tLoss: 0.4048\tLR: 0.015000\nTraining Epoch: 10 [31104/50000]\tLoss: 0.3871\tLR: 0.015000\nTraining Epoch: 10 [31232/50000]\tLoss: 0.3413\tLR: 0.015000\nTraining Epoch: 10 [31360/50000]\tLoss: 0.4651\tLR: 0.015000\nTraining Epoch: 10 [31488/50000]\tLoss: 0.3853\tLR: 0.015000\nTraining Epoch: 10 [31616/50000]\tLoss: 0.4008\tLR: 0.015000\nTraining Epoch: 10 [31744/50000]\tLoss: 0.3790\tLR: 0.015000\nTraining Epoch: 10 [31872/50000]\tLoss: 0.3035\tLR: 0.015000\nTraining Epoch: 10 [32000/50000]\tLoss: 0.3812\tLR: 0.015000\nTraining Epoch: 10 [32128/50000]\tLoss: 0.4411\tLR: 0.015000\nTraining Epoch: 10 [32256/50000]\tLoss: 0.3475\tLR: 0.015000\nTraining Epoch: 10 [32384/50000]\tLoss: 0.4755\tLR: 0.015000\nTraining Epoch: 10 [32512/50000]\tLoss: 0.3550\tLR: 0.015000\nTraining Epoch: 10 [32640/50000]\tLoss: 0.3046\tLR: 0.015000\nTraining Epoch: 10 [32768/50000]\tLoss: 0.3498\tLR: 0.015000\nTraining Epoch: 10 [32896/50000]\tLoss: 0.2894\tLR: 0.015000\nTraining Epoch: 10 [33024/50000]\tLoss: 0.3846\tLR: 0.015000\nTraining Epoch: 10 [33152/50000]\tLoss: 0.4163\tLR: 0.015000\nTraining Epoch: 10 [33280/50000]\tLoss: 0.4058\tLR: 0.015000\nTraining Epoch: 10 [33408/50000]\tLoss: 0.4434\tLR: 0.015000\nTraining Epoch: 10 [33536/50000]\tLoss: 0.4778\tLR: 0.015000\nTraining Epoch: 10 [33664/50000]\tLoss: 0.3613\tLR: 0.015000\nTraining Epoch: 10 [33792/50000]\tLoss: 0.3568\tLR: 0.015000\nTraining Epoch: 10 [33920/50000]\tLoss: 0.3072\tLR: 0.015000\nTraining Epoch: 10 [34048/50000]\tLoss: 0.3441\tLR: 0.015000\nTraining Epoch: 10 [34176/50000]\tLoss: 0.5272\tLR: 0.015000\nTraining Epoch: 10 [34304/50000]\tLoss: 0.3785\tLR: 0.015000\nTraining Epoch: 10 [34432/50000]\tLoss: 0.4736\tLR: 0.015000\nTraining Epoch: 10 [34560/50000]\tLoss: 0.4631\tLR: 0.015000\nTraining Epoch: 10 [34688/50000]\tLoss: 0.3607\tLR: 0.015000\nTraining Epoch: 10 [34816/50000]\tLoss: 0.2807\tLR: 0.015000\nTraining Epoch: 10 [34944/50000]\tLoss: 0.3296\tLR: 0.015000\nTraining Epoch: 10 [35072/50000]\tLoss: 0.3545\tLR: 0.015000\nTraining Epoch: 10 [35200/50000]\tLoss: 0.3964\tLR: 0.015000\nTraining Epoch: 10 [35328/50000]\tLoss: 0.3974\tLR: 0.015000\nTraining Epoch: 10 [35456/50000]\tLoss: 0.4020\tLR: 0.015000\nTraining Epoch: 10 [35584/50000]\tLoss: 0.4088\tLR: 0.015000\nTraining Epoch: 10 [35712/50000]\tLoss: 0.4142\tLR: 0.015000\nTraining Epoch: 10 [35840/50000]\tLoss: 0.3837\tLR: 0.015000\nTraining Epoch: 10 [35968/50000]\tLoss: 0.4714\tLR: 0.015000\nTraining Epoch: 10 [36096/50000]\tLoss: 0.3172\tLR: 0.015000\nTraining Epoch: 10 [36224/50000]\tLoss: 0.4695\tLR: 0.015000\nTraining Epoch: 10 [36352/50000]\tLoss: 0.3557\tLR: 0.015000\nTraining Epoch: 10 [36480/50000]\tLoss: 0.4671\tLR: 0.015000\nTraining Epoch: 10 [36608/50000]\tLoss: 0.3972\tLR: 0.015000\nTraining Epoch: 10 [36736/50000]\tLoss: 0.3658\tLR: 0.015000\nTraining Epoch: 10 [36864/50000]\tLoss: 0.2729\tLR: 0.015000\nTraining Epoch: 10 [36992/50000]\tLoss: 0.3617\tLR: 0.015000\nTraining Epoch: 10 [37120/50000]\tLoss: 0.3632\tLR: 0.015000\nTraining Epoch: 10 [37248/50000]\tLoss: 0.3516\tLR: 0.015000\nTraining Epoch: 10 [37376/50000]\tLoss: 0.3479\tLR: 0.015000\nTraining Epoch: 10 [37504/50000]\tLoss: 0.3279\tLR: 0.015000\nTraining Epoch: 10 [37632/50000]\tLoss: 0.3780\tLR: 0.015000\nTraining Epoch: 10 [37760/50000]\tLoss: 0.3999\tLR: 0.015000\nTraining Epoch: 10 [37888/50000]\tLoss: 0.3264\tLR: 0.015000\nTraining Epoch: 10 [38016/50000]\tLoss: 0.3696\tLR: 0.015000\nTraining Epoch: 10 [38144/50000]\tLoss: 0.2910\tLR: 0.015000\nTraining Epoch: 10 [38272/50000]\tLoss: 0.4060\tLR: 0.015000\nTraining Epoch: 10 [38400/50000]\tLoss: 0.5161\tLR: 0.015000\nTraining Epoch: 10 [38528/50000]\tLoss: 0.4027\tLR: 0.015000\nTraining Epoch: 10 [38656/50000]\tLoss: 0.4605\tLR: 0.015000\nTraining Epoch: 10 [38784/50000]\tLoss: 0.3420\tLR: 0.015000\nTraining Epoch: 10 [38912/50000]\tLoss: 0.3551\tLR: 0.015000\nTraining Epoch: 10 [39040/50000]\tLoss: 0.3664\tLR: 0.015000\nTraining Epoch: 10 [39168/50000]\tLoss: 0.3379\tLR: 0.015000\nTraining Epoch: 10 [39296/50000]\tLoss: 0.3876\tLR: 0.015000\nTraining Epoch: 10 [39424/50000]\tLoss: 0.4473\tLR: 0.015000\nTraining Epoch: 10 [39552/50000]\tLoss: 0.3249\tLR: 0.015000\nTraining Epoch: 10 [39680/50000]\tLoss: 0.3950\tLR: 0.015000\nTraining Epoch: 10 [39808/50000]\tLoss: 0.3249\tLR: 0.015000\nTraining Epoch: 10 [39936/50000]\tLoss: 0.3704\tLR: 0.015000\nTraining Epoch: 10 [40064/50000]\tLoss: 0.2799\tLR: 0.015000\nTraining Epoch: 10 [40192/50000]\tLoss: 0.3976\tLR: 0.015000\nTraining Epoch: 10 [40320/50000]\tLoss: 0.4783\tLR: 0.015000\nTraining Epoch: 10 [40448/50000]\tLoss: 0.4862\tLR: 0.015000\nTraining Epoch: 10 [40576/50000]\tLoss: 0.4152\tLR: 0.015000\nTraining Epoch: 10 [40704/50000]\tLoss: 0.4978\tLR: 0.015000\nTraining Epoch: 10 [40832/50000]\tLoss: 0.4978\tLR: 0.015000\nTraining Epoch: 10 [40960/50000]\tLoss: 0.3611\tLR: 0.015000\nTraining Epoch: 10 [41088/50000]\tLoss: 0.4289\tLR: 0.015000\nTraining Epoch: 10 [41216/50000]\tLoss: 0.3165\tLR: 0.015000\nTraining Epoch: 10 [41344/50000]\tLoss: 0.4036\tLR: 0.015000\nTraining Epoch: 10 [41472/50000]\tLoss: 0.4483\tLR: 0.015000\nTraining Epoch: 10 [41600/50000]\tLoss: 0.3080\tLR: 0.015000\nTraining Epoch: 10 [41728/50000]\tLoss: 0.3435\tLR: 0.015000\nTraining Epoch: 10 [41856/50000]\tLoss: 0.4008\tLR: 0.015000\nTraining Epoch: 10 [41984/50000]\tLoss: 0.4229\tLR: 0.015000\nTraining Epoch: 10 [42112/50000]\tLoss: 0.3656\tLR: 0.015000\nTraining Epoch: 10 [42240/50000]\tLoss: 0.4432\tLR: 0.015000\nTraining Epoch: 10 [42368/50000]\tLoss: 0.3814\tLR: 0.015000\nTraining Epoch: 10 [42496/50000]\tLoss: 0.3451\tLR: 0.015000\nTraining Epoch: 10 [42624/50000]\tLoss: 0.2973\tLR: 0.015000\nTraining Epoch: 10 [42752/50000]\tLoss: 0.3971\tLR: 0.015000\nTraining Epoch: 10 [42880/50000]\tLoss: 0.3976\tLR: 0.015000\nTraining Epoch: 10 [43008/50000]\tLoss: 0.4634\tLR: 0.015000\nTraining Epoch: 10 [43136/50000]\tLoss: 0.4810\tLR: 0.015000\nTraining Epoch: 10 [43264/50000]\tLoss: 0.4026\tLR: 0.015000\nTraining Epoch: 10 [43392/50000]\tLoss: 0.4712\tLR: 0.015000\nTraining Epoch: 10 [43520/50000]\tLoss: 0.3530\tLR: 0.015000\nTraining Epoch: 10 [43648/50000]\tLoss: 0.3434\tLR: 0.015000\nTraining Epoch: 10 [43776/50000]\tLoss: 0.4785\tLR: 0.015000\nTraining Epoch: 10 [43904/50000]\tLoss: 0.3603\tLR: 0.015000\nTraining Epoch: 10 [44032/50000]\tLoss: 0.2513\tLR: 0.015000\nTraining Epoch: 10 [44160/50000]\tLoss: 0.3810\tLR: 0.015000\nTraining Epoch: 10 [44288/50000]\tLoss: 0.3261\tLR: 0.015000\nTraining Epoch: 10 [44416/50000]\tLoss: 0.2575\tLR: 0.015000\nTraining Epoch: 10 [44544/50000]\tLoss: 0.3213\tLR: 0.015000\nTraining Epoch: 10 [44672/50000]\tLoss: 0.4193\tLR: 0.015000\nTraining Epoch: 10 [44800/50000]\tLoss: 0.5301\tLR: 0.015000\nTraining Epoch: 10 [44928/50000]\tLoss: 0.4690\tLR: 0.015000\nTraining Epoch: 10 [45056/50000]\tLoss: 0.3391\tLR: 0.015000\nTraining Epoch: 10 [45184/50000]\tLoss: 0.4273\tLR: 0.015000\nTraining Epoch: 10 [45312/50000]\tLoss: 0.5447\tLR: 0.015000\nTraining Epoch: 10 [45440/50000]\tLoss: 0.2984\tLR: 0.015000\nTraining Epoch: 10 [45568/50000]\tLoss: 0.3158\tLR: 0.015000\nTraining Epoch: 10 [45696/50000]\tLoss: 0.4132\tLR: 0.015000\nTraining Epoch: 10 [45824/50000]\tLoss: 0.3735\tLR: 0.015000\nTraining Epoch: 10 [45952/50000]\tLoss: 0.3732\tLR: 0.015000\nTraining Epoch: 10 [46080/50000]\tLoss: 0.4408\tLR: 0.015000\nTraining Epoch: 10 [46208/50000]\tLoss: 0.3461\tLR: 0.015000\nTraining Epoch: 10 [46336/50000]\tLoss: 0.4772\tLR: 0.015000\nTraining Epoch: 10 [46464/50000]\tLoss: 0.3478\tLR: 0.015000\nTraining Epoch: 10 [46592/50000]\tLoss: 0.6147\tLR: 0.015000\nTraining Epoch: 10 [46720/50000]\tLoss: 0.3581\tLR: 0.015000\nTraining Epoch: 10 [46848/50000]\tLoss: 0.3397\tLR: 0.015000\nTraining Epoch: 10 [46976/50000]\tLoss: 0.3800\tLR: 0.015000\nTraining Epoch: 10 [47104/50000]\tLoss: 0.3752\tLR: 0.015000\nTraining Epoch: 10 [47232/50000]\tLoss: 0.3703\tLR: 0.015000\nTraining Epoch: 10 [47360/50000]\tLoss: 0.3397\tLR: 0.015000\nTraining Epoch: 10 [47488/50000]\tLoss: 0.3809\tLR: 0.015000\nTraining Epoch: 10 [47616/50000]\tLoss: 0.2989\tLR: 0.015000\nTraining Epoch: 10 [47744/50000]\tLoss: 0.3002\tLR: 0.015000\nTraining Epoch: 10 [47872/50000]\tLoss: 0.4024\tLR: 0.015000\nTraining Epoch: 10 [48000/50000]\tLoss: 0.4917\tLR: 0.015000\nTraining Epoch: 10 [48128/50000]\tLoss: 0.4444\tLR: 0.015000\nTraining Epoch: 10 [48256/50000]\tLoss: 0.4427\tLR: 0.015000\nTraining Epoch: 10 [48384/50000]\tLoss: 0.5216\tLR: 0.015000\nTraining Epoch: 10 [48512/50000]\tLoss: 0.1973\tLR: 0.015000\nTraining Epoch: 10 [48640/50000]\tLoss: 0.3280\tLR: 0.015000\nTraining Epoch: 10 [48768/50000]\tLoss: 0.4419\tLR: 0.015000\nTraining Epoch: 10 [48896/50000]\tLoss: 0.5824\tLR: 0.015000\nTraining Epoch: 10 [49024/50000]\tLoss: 0.4240\tLR: 0.015000\nTraining Epoch: 10 [49152/50000]\tLoss: 0.3742\tLR: 0.015000\nTraining Epoch: 10 [49280/50000]\tLoss: 0.4845\tLR: 0.015000\nTraining Epoch: 10 [49408/50000]\tLoss: 0.2846\tLR: 0.015000\nTraining Epoch: 10 [49536/50000]\tLoss: 0.4394\tLR: 0.015000\nTraining Epoch: 10 [49664/50000]\tLoss: 0.4563\tLR: 0.015000\nTraining Epoch: 10 [49792/50000]\tLoss: 0.3262\tLR: 0.015000\nTraining Epoch: 10 [49920/50000]\tLoss: 0.4808\tLR: 0.015000\nTraining Epoch: 10 [50000/50000]\tLoss: 0.5405\tLR: 0.015000\nTest set: Average loss: 0.0030, Accuracy: 0.8701\n\nTraining Epoch: 11 [128/50000]\tLoss: 0.3762\tLR: 0.015000\nTraining Epoch: 11 [256/50000]\tLoss: 0.3418\tLR: 0.015000\nTraining Epoch: 11 [384/50000]\tLoss: 0.3549\tLR: 0.015000\nTraining Epoch: 11 [512/50000]\tLoss: 0.3345\tLR: 0.015000\nTraining Epoch: 11 [640/50000]\tLoss: 0.2752\tLR: 0.015000\nTraining Epoch: 11 [768/50000]\tLoss: 0.4402\tLR: 0.015000\nTraining Epoch: 11 [896/50000]\tLoss: 0.4321\tLR: 0.015000\nTraining Epoch: 11 [1024/50000]\tLoss: 0.3367\tLR: 0.015000\nTraining Epoch: 11 [1152/50000]\tLoss: 0.3639\tLR: 0.015000\nTraining Epoch: 11 [1280/50000]\tLoss: 0.3620\tLR: 0.015000\nTraining Epoch: 11 [1408/50000]\tLoss: 0.2527\tLR: 0.015000\nTraining Epoch: 11 [1536/50000]\tLoss: 0.3591\tLR: 0.015000\nTraining Epoch: 11 [1664/50000]\tLoss: 0.4913\tLR: 0.015000\nTraining Epoch: 11 [1792/50000]\tLoss: 0.2515\tLR: 0.015000\nTraining Epoch: 11 [1920/50000]\tLoss: 0.3308\tLR: 0.015000\nTraining Epoch: 11 [2048/50000]\tLoss: 0.3075\tLR: 0.015000\nTraining Epoch: 11 [2176/50000]\tLoss: 0.2632\tLR: 0.015000\nTraining Epoch: 11 [2304/50000]\tLoss: 0.2861\tLR: 0.015000\nTraining Epoch: 11 [2432/50000]\tLoss: 0.3456\tLR: 0.015000\nTraining Epoch: 11 [2560/50000]\tLoss: 0.4795\tLR: 0.015000\nTraining Epoch: 11 [2688/50000]\tLoss: 0.3201\tLR: 0.015000\nTraining Epoch: 11 [2816/50000]\tLoss: 0.3467\tLR: 0.015000\nTraining Epoch: 11 [2944/50000]\tLoss: 0.2636\tLR: 0.015000\nTraining Epoch: 11 [3072/50000]\tLoss: 0.4116\tLR: 0.015000\nTraining Epoch: 11 [3200/50000]\tLoss: 0.3648\tLR: 0.015000\nTraining Epoch: 11 [3328/50000]\tLoss: 0.3387\tLR: 0.015000\nTraining Epoch: 11 [3456/50000]\tLoss: 0.4841\tLR: 0.015000\nTraining Epoch: 11 [3584/50000]\tLoss: 0.4366\tLR: 0.015000\nTraining Epoch: 11 [3712/50000]\tLoss: 0.3147\tLR: 0.015000\nTraining Epoch: 11 [3840/50000]\tLoss: 0.4219\tLR: 0.015000\nTraining Epoch: 11 [3968/50000]\tLoss: 0.4064\tLR: 0.015000\nTraining Epoch: 11 [4096/50000]\tLoss: 0.2970\tLR: 0.015000\nTraining Epoch: 11 [4224/50000]\tLoss: 0.3665\tLR: 0.015000\nTraining Epoch: 11 [4352/50000]\tLoss: 0.2942\tLR: 0.015000\nTraining Epoch: 11 [4480/50000]\tLoss: 0.3171\tLR: 0.015000\nTraining Epoch: 11 [4608/50000]\tLoss: 0.3480\tLR: 0.015000\nTraining Epoch: 11 [4736/50000]\tLoss: 0.3582\tLR: 0.015000\nTraining Epoch: 11 [4864/50000]\tLoss: 0.5124\tLR: 0.015000\nTraining Epoch: 11 [4992/50000]\tLoss: 0.3322\tLR: 0.015000\nTraining Epoch: 11 [5120/50000]\tLoss: 0.3714\tLR: 0.015000\nTraining Epoch: 11 [5248/50000]\tLoss: 0.3899\tLR: 0.015000\nTraining Epoch: 11 [5376/50000]\tLoss: 0.4852\tLR: 0.015000\nTraining Epoch: 11 [5504/50000]\tLoss: 0.4393\tLR: 0.015000\nTraining Epoch: 11 [5632/50000]\tLoss: 0.4374\tLR: 0.015000\nTraining Epoch: 11 [5760/50000]\tLoss: 0.3309\tLR: 0.015000\nTraining Epoch: 11 [5888/50000]\tLoss: 0.4106\tLR: 0.015000\nTraining Epoch: 11 [6016/50000]\tLoss: 0.3125\tLR: 0.015000\nTraining Epoch: 11 [6144/50000]\tLoss: 0.3714\tLR: 0.015000\nTraining Epoch: 11 [6272/50000]\tLoss: 0.5249\tLR: 0.015000\nTraining Epoch: 11 [6400/50000]\tLoss: 0.3048\tLR: 0.015000\nTraining Epoch: 11 [6528/50000]\tLoss: 0.3506\tLR: 0.015000\nTraining Epoch: 11 [6656/50000]\tLoss: 0.3407\tLR: 0.015000\nTraining Epoch: 11 [6784/50000]\tLoss: 0.3128\tLR: 0.015000\nTraining Epoch: 11 [6912/50000]\tLoss: 0.3249\tLR: 0.015000\nTraining Epoch: 11 [7040/50000]\tLoss: 0.3203\tLR: 0.015000\nTraining Epoch: 11 [7168/50000]\tLoss: 0.3051\tLR: 0.015000\nTraining Epoch: 11 [7296/50000]\tLoss: 0.3365\tLR: 0.015000\nTraining Epoch: 11 [7424/50000]\tLoss: 0.3143\tLR: 0.015000\nTraining Epoch: 11 [7552/50000]\tLoss: 0.3036\tLR: 0.015000\nTraining Epoch: 11 [7680/50000]\tLoss: 0.3195\tLR: 0.015000\nTraining Epoch: 11 [7808/50000]\tLoss: 0.3931\tLR: 0.015000\nTraining Epoch: 11 [7936/50000]\tLoss: 0.4463\tLR: 0.015000\nTraining Epoch: 11 [8064/50000]\tLoss: 0.3305\tLR: 0.015000\nTraining Epoch: 11 [8192/50000]\tLoss: 0.3801\tLR: 0.015000\nTraining Epoch: 11 [8320/50000]\tLoss: 0.3734\tLR: 0.015000\nTraining Epoch: 11 [8448/50000]\tLoss: 0.2785\tLR: 0.015000\nTraining Epoch: 11 [8576/50000]\tLoss: 0.3168\tLR: 0.015000\nTraining Epoch: 11 [8704/50000]\tLoss: 0.4274\tLR: 0.015000\nTraining Epoch: 11 [8832/50000]\tLoss: 0.4036\tLR: 0.015000\nTraining Epoch: 11 [8960/50000]\tLoss: 0.2733\tLR: 0.015000\nTraining Epoch: 11 [9088/50000]\tLoss: 0.3617\tLR: 0.015000\nTraining Epoch: 11 [9216/50000]\tLoss: 0.3883\tLR: 0.015000\nTraining Epoch: 11 [9344/50000]\tLoss: 0.3482\tLR: 0.015000\nTraining Epoch: 11 [9472/50000]\tLoss: 0.3715\tLR: 0.015000\nTraining Epoch: 11 [9600/50000]\tLoss: 0.2492\tLR: 0.015000\nTraining Epoch: 11 [9728/50000]\tLoss: 0.2971\tLR: 0.015000\nTraining Epoch: 11 [9856/50000]\tLoss: 0.2701\tLR: 0.015000\nTraining Epoch: 11 [9984/50000]\tLoss: 0.4183\tLR: 0.015000\nTraining Epoch: 11 [10112/50000]\tLoss: 0.5069\tLR: 0.015000\nTraining Epoch: 11 [10240/50000]\tLoss: 0.1742\tLR: 0.015000\nTraining Epoch: 11 [10368/50000]\tLoss: 0.3243\tLR: 0.015000\nTraining Epoch: 11 [10496/50000]\tLoss: 0.3878\tLR: 0.015000\nTraining Epoch: 11 [10624/50000]\tLoss: 0.5059\tLR: 0.015000\nTraining Epoch: 11 [10752/50000]\tLoss: 0.3890\tLR: 0.015000\nTraining Epoch: 11 [10880/50000]\tLoss: 0.4155\tLR: 0.015000\nTraining Epoch: 11 [11008/50000]\tLoss: 0.3538\tLR: 0.015000\nTraining Epoch: 11 [11136/50000]\tLoss: 0.3066\tLR: 0.015000\nTraining Epoch: 11 [11264/50000]\tLoss: 0.3444\tLR: 0.015000\nTraining Epoch: 11 [11392/50000]\tLoss: 0.3222\tLR: 0.015000\nTraining Epoch: 11 [11520/50000]\tLoss: 0.3471\tLR: 0.015000\nTraining Epoch: 11 [11648/50000]\tLoss: 0.2716\tLR: 0.015000\nTraining Epoch: 11 [11776/50000]\tLoss: 0.3736\tLR: 0.015000\nTraining Epoch: 11 [11904/50000]\tLoss: 0.5561\tLR: 0.015000\nTraining Epoch: 11 [12032/50000]\tLoss: 0.4220\tLR: 0.015000\nTraining Epoch: 11 [12160/50000]\tLoss: 0.3301\tLR: 0.015000\nTraining Epoch: 11 [12288/50000]\tLoss: 0.4538\tLR: 0.015000\nTraining Epoch: 11 [12416/50000]\tLoss: 0.3902\tLR: 0.015000\nTraining Epoch: 11 [12544/50000]\tLoss: 0.3504\tLR: 0.015000\nTraining Epoch: 11 [12672/50000]\tLoss: 0.2706\tLR: 0.015000\nTraining Epoch: 11 [12800/50000]\tLoss: 0.3785\tLR: 0.015000\nTraining Epoch: 11 [12928/50000]\tLoss: 0.2634\tLR: 0.015000\nTraining Epoch: 11 [13056/50000]\tLoss: 0.4397\tLR: 0.015000\nTraining Epoch: 11 [13184/50000]\tLoss: 0.4490\tLR: 0.015000\nTraining Epoch: 11 [13312/50000]\tLoss: 0.4927\tLR: 0.015000\nTraining Epoch: 11 [13440/50000]\tLoss: 0.3248\tLR: 0.015000\nTraining Epoch: 11 [13568/50000]\tLoss: 0.3616\tLR: 0.015000\nTraining Epoch: 11 [13696/50000]\tLoss: 0.4370\tLR: 0.015000\nTraining Epoch: 11 [13824/50000]\tLoss: 0.2937\tLR: 0.015000\nTraining Epoch: 11 [13952/50000]\tLoss: 0.3748\tLR: 0.015000\nTraining Epoch: 11 [14080/50000]\tLoss: 0.4655\tLR: 0.015000\nTraining Epoch: 11 [14208/50000]\tLoss: 0.5049\tLR: 0.015000\nTraining Epoch: 11 [14336/50000]\tLoss: 0.4080\tLR: 0.015000\nTraining Epoch: 11 [14464/50000]\tLoss: 0.3957\tLR: 0.015000\nTraining Epoch: 11 [14592/50000]\tLoss: 0.3648\tLR: 0.015000\nTraining Epoch: 11 [14720/50000]\tLoss: 0.3527\tLR: 0.015000\nTraining Epoch: 11 [14848/50000]\tLoss: 0.2525\tLR: 0.015000\nTraining Epoch: 11 [14976/50000]\tLoss: 0.2873\tLR: 0.015000\nTraining Epoch: 11 [15104/50000]\tLoss: 0.4173\tLR: 0.015000\nTraining Epoch: 11 [15232/50000]\tLoss: 0.3962\tLR: 0.015000\nTraining Epoch: 11 [15360/50000]\tLoss: 0.3731\tLR: 0.015000\nTraining Epoch: 11 [15488/50000]\tLoss: 0.3910\tLR: 0.015000\nTraining Epoch: 11 [15616/50000]\tLoss: 0.4139\tLR: 0.015000\nTraining Epoch: 11 [15744/50000]\tLoss: 0.4765\tLR: 0.015000\nTraining Epoch: 11 [15872/50000]\tLoss: 0.2960\tLR: 0.015000\nTraining Epoch: 11 [16000/50000]\tLoss: 0.2547\tLR: 0.015000\nTraining Epoch: 11 [16128/50000]\tLoss: 0.3278\tLR: 0.015000\nTraining Epoch: 11 [16256/50000]\tLoss: 0.4433\tLR: 0.015000\nTraining Epoch: 11 [16384/50000]\tLoss: 0.3611\tLR: 0.015000\nTraining Epoch: 11 [16512/50000]\tLoss: 0.3364\tLR: 0.015000\nTraining Epoch: 11 [16640/50000]\tLoss: 0.4052\tLR: 0.015000\nTraining Epoch: 11 [16768/50000]\tLoss: 0.4079\tLR: 0.015000\nTraining Epoch: 11 [16896/50000]\tLoss: 0.4472\tLR: 0.015000\nTraining Epoch: 11 [17024/50000]\tLoss: 0.3998\tLR: 0.015000\nTraining Epoch: 11 [17152/50000]\tLoss: 0.3633\tLR: 0.015000\nTraining Epoch: 11 [17280/50000]\tLoss: 0.4341\tLR: 0.015000\nTraining Epoch: 11 [17408/50000]\tLoss: 0.3512\tLR: 0.015000\nTraining Epoch: 11 [17536/50000]\tLoss: 0.3828\tLR: 0.015000\nTraining Epoch: 11 [17664/50000]\tLoss: 0.4840\tLR: 0.015000\nTraining Epoch: 11 [17792/50000]\tLoss: 0.3252\tLR: 0.015000\nTraining Epoch: 11 [17920/50000]\tLoss: 0.3369\tLR: 0.015000\nTraining Epoch: 11 [18048/50000]\tLoss: 0.4211\tLR: 0.015000\nTraining Epoch: 11 [18176/50000]\tLoss: 0.3592\tLR: 0.015000\nTraining Epoch: 11 [18304/50000]\tLoss: 0.4121\tLR: 0.015000\nTraining Epoch: 11 [18432/50000]\tLoss: 0.4334\tLR: 0.015000\nTraining Epoch: 11 [18560/50000]\tLoss: 0.3150\tLR: 0.015000\nTraining Epoch: 11 [18688/50000]\tLoss: 0.3873\tLR: 0.015000\nTraining Epoch: 11 [18816/50000]\tLoss: 0.3215\tLR: 0.015000\nTraining Epoch: 11 [18944/50000]\tLoss: 0.4061\tLR: 0.015000\nTraining Epoch: 11 [19072/50000]\tLoss: 0.3294\tLR: 0.015000\nTraining Epoch: 11 [19200/50000]\tLoss: 0.4294\tLR: 0.015000\nTraining Epoch: 11 [19328/50000]\tLoss: 0.4298\tLR: 0.015000\nTraining Epoch: 11 [19456/50000]\tLoss: 0.4146\tLR: 0.015000\nTraining Epoch: 11 [19584/50000]\tLoss: 0.2559\tLR: 0.015000\nTraining Epoch: 11 [19712/50000]\tLoss: 0.4268\tLR: 0.015000\nTraining Epoch: 11 [19840/50000]\tLoss: 0.3132\tLR: 0.015000\nTraining Epoch: 11 [19968/50000]\tLoss: 0.2698\tLR: 0.015000\nTraining Epoch: 11 [20096/50000]\tLoss: 0.3654\tLR: 0.015000\nTraining Epoch: 11 [20224/50000]\tLoss: 0.3963\tLR: 0.015000\nTraining Epoch: 11 [20352/50000]\tLoss: 0.3570\tLR: 0.015000\nTraining Epoch: 11 [20480/50000]\tLoss: 0.2801\tLR: 0.015000\nTraining Epoch: 11 [20608/50000]\tLoss: 0.3967\tLR: 0.015000\nTraining Epoch: 11 [20736/50000]\tLoss: 0.3779\tLR: 0.015000\nTraining Epoch: 11 [20864/50000]\tLoss: 0.4407\tLR: 0.015000\nTraining Epoch: 11 [20992/50000]\tLoss: 0.2559\tLR: 0.015000\nTraining Epoch: 11 [21120/50000]\tLoss: 0.3478\tLR: 0.015000\nTraining Epoch: 11 [21248/50000]\tLoss: 0.3877\tLR: 0.015000\nTraining Epoch: 11 [21376/50000]\tLoss: 0.4149\tLR: 0.015000\nTraining Epoch: 11 [21504/50000]\tLoss: 0.3728\tLR: 0.015000\nTraining Epoch: 11 [21632/50000]\tLoss: 0.3462\tLR: 0.015000\nTraining Epoch: 11 [21760/50000]\tLoss: 0.4174\tLR: 0.015000\nTraining Epoch: 11 [21888/50000]\tLoss: 0.3015\tLR: 0.015000\nTraining Epoch: 11 [22016/50000]\tLoss: 0.4052\tLR: 0.015000\nTraining Epoch: 11 [22144/50000]\tLoss: 0.4389\tLR: 0.015000\nTraining Epoch: 11 [22272/50000]\tLoss: 0.3669\tLR: 0.015000\nTraining Epoch: 11 [22400/50000]\tLoss: 0.5236\tLR: 0.015000\nTraining Epoch: 11 [22528/50000]\tLoss: 0.3166\tLR: 0.015000\nTraining Epoch: 11 [22656/50000]\tLoss: 0.3568\tLR: 0.015000\nTraining Epoch: 11 [22784/50000]\tLoss: 0.4160\tLR: 0.015000\nTraining Epoch: 11 [22912/50000]\tLoss: 0.4386\tLR: 0.015000\nTraining Epoch: 11 [23040/50000]\tLoss: 0.3814\tLR: 0.015000\nTraining Epoch: 11 [23168/50000]\tLoss: 0.5035\tLR: 0.015000\nTraining Epoch: 11 [23296/50000]\tLoss: 0.3781\tLR: 0.015000\nTraining Epoch: 11 [23424/50000]\tLoss: 0.4272\tLR: 0.015000\nTraining Epoch: 11 [23552/50000]\tLoss: 0.2855\tLR: 0.015000\nTraining Epoch: 11 [23680/50000]\tLoss: 0.3176\tLR: 0.015000\nTraining Epoch: 11 [23808/50000]\tLoss: 0.2764\tLR: 0.015000\nTraining Epoch: 11 [23936/50000]\tLoss: 0.2674\tLR: 0.015000\nTraining Epoch: 11 [24064/50000]\tLoss: 0.3402\tLR: 0.015000\nTraining Epoch: 11 [24192/50000]\tLoss: 0.4308\tLR: 0.015000\nTraining Epoch: 11 [24320/50000]\tLoss: 0.4208\tLR: 0.015000\nTraining Epoch: 11 [24448/50000]\tLoss: 0.3740\tLR: 0.015000\nTraining Epoch: 11 [24576/50000]\tLoss: 0.3027\tLR: 0.015000\nTraining Epoch: 11 [24704/50000]\tLoss: 0.3815\tLR: 0.015000\nTraining Epoch: 11 [24832/50000]\tLoss: 0.3241\tLR: 0.015000\nTraining Epoch: 11 [24960/50000]\tLoss: 0.3788\tLR: 0.015000\nTraining Epoch: 11 [25088/50000]\tLoss: 0.4002\tLR: 0.015000\nTraining Epoch: 11 [25216/50000]\tLoss: 0.3249\tLR: 0.015000\nTraining Epoch: 11 [25344/50000]\tLoss: 0.2518\tLR: 0.015000\nTraining Epoch: 11 [25472/50000]\tLoss: 0.4174\tLR: 0.015000\nTraining Epoch: 11 [25600/50000]\tLoss: 0.2327\tLR: 0.015000\nTraining Epoch: 11 [25728/50000]\tLoss: 0.3411\tLR: 0.015000\nTraining Epoch: 11 [25856/50000]\tLoss: 0.3570\tLR: 0.015000\nTraining Epoch: 11 [25984/50000]\tLoss: 0.3696\tLR: 0.015000\nTraining Epoch: 11 [26112/50000]\tLoss: 0.3391\tLR: 0.015000\nTraining Epoch: 11 [26240/50000]\tLoss: 0.2827\tLR: 0.015000\nTraining Epoch: 11 [26368/50000]\tLoss: 0.3028\tLR: 0.015000\nTraining Epoch: 11 [26496/50000]\tLoss: 0.3267\tLR: 0.015000\nTraining Epoch: 11 [26624/50000]\tLoss: 0.3129\tLR: 0.015000\nTraining Epoch: 11 [26752/50000]\tLoss: 0.4529\tLR: 0.015000\nTraining Epoch: 11 [26880/50000]\tLoss: 0.3483\tLR: 0.015000\nTraining Epoch: 11 [27008/50000]\tLoss: 0.2594\tLR: 0.015000\nTraining Epoch: 11 [27136/50000]\tLoss: 0.4562\tLR: 0.015000\nTraining Epoch: 11 [27264/50000]\tLoss: 0.3321\tLR: 0.015000\nTraining Epoch: 11 [27392/50000]\tLoss: 0.3765\tLR: 0.015000\nTraining Epoch: 11 [27520/50000]\tLoss: 0.3145\tLR: 0.015000\nTraining Epoch: 11 [27648/50000]\tLoss: 0.4285\tLR: 0.015000\nTraining Epoch: 11 [27776/50000]\tLoss: 0.2906\tLR: 0.015000\nTraining Epoch: 11 [27904/50000]\tLoss: 0.4969\tLR: 0.015000\nTraining Epoch: 11 [28032/50000]\tLoss: 0.3736\tLR: 0.015000\nTraining Epoch: 11 [28160/50000]\tLoss: 0.5819\tLR: 0.015000\nTraining Epoch: 11 [28288/50000]\tLoss: 0.3509\tLR: 0.015000\nTraining Epoch: 11 [28416/50000]\tLoss: 0.2778\tLR: 0.015000\nTraining Epoch: 11 [28544/50000]\tLoss: 0.4260\tLR: 0.015000\nTraining Epoch: 11 [28672/50000]\tLoss: 0.3793\tLR: 0.015000\nTraining Epoch: 11 [28800/50000]\tLoss: 0.2930\tLR: 0.015000\nTraining Epoch: 11 [28928/50000]\tLoss: 0.3172\tLR: 0.015000\nTraining Epoch: 11 [29056/50000]\tLoss: 0.3362\tLR: 0.015000\nTraining Epoch: 11 [29184/50000]\tLoss: 0.3833\tLR: 0.015000\nTraining Epoch: 11 [29312/50000]\tLoss: 0.2388\tLR: 0.015000\nTraining Epoch: 11 [29440/50000]\tLoss: 0.3420\tLR: 0.015000\nTraining Epoch: 11 [29568/50000]\tLoss: 0.3668\tLR: 0.015000\nTraining Epoch: 11 [29696/50000]\tLoss: 0.5159\tLR: 0.015000\nTraining Epoch: 11 [29824/50000]\tLoss: 0.3975\tLR: 0.015000\nTraining Epoch: 11 [29952/50000]\tLoss: 0.3069\tLR: 0.015000\nTraining Epoch: 11 [30080/50000]\tLoss: 0.2742\tLR: 0.015000\nTraining Epoch: 11 [30208/50000]\tLoss: 0.2363\tLR: 0.015000\nTraining Epoch: 11 [30336/50000]\tLoss: 0.3283\tLR: 0.015000\nTraining Epoch: 11 [30464/50000]\tLoss: 0.3993\tLR: 0.015000\nTraining Epoch: 11 [30592/50000]\tLoss: 0.5729\tLR: 0.015000\nTraining Epoch: 11 [30720/50000]\tLoss: 0.3532\tLR: 0.015000\nTraining Epoch: 11 [30848/50000]\tLoss: 0.2794\tLR: 0.015000\nTraining Epoch: 11 [30976/50000]\tLoss: 0.3762\tLR: 0.015000\nTraining Epoch: 11 [31104/50000]\tLoss: 0.4059\tLR: 0.015000\nTraining Epoch: 11 [31232/50000]\tLoss: 0.5031\tLR: 0.015000\nTraining Epoch: 11 [31360/50000]\tLoss: 0.3396\tLR: 0.015000\nTraining Epoch: 11 [31488/50000]\tLoss: 0.3755\tLR: 0.015000\nTraining Epoch: 11 [31616/50000]\tLoss: 0.3991\tLR: 0.015000\nTraining Epoch: 11 [31744/50000]\tLoss: 0.4940\tLR: 0.015000\nTraining Epoch: 11 [31872/50000]\tLoss: 0.3606\tLR: 0.015000\nTraining Epoch: 11 [32000/50000]\tLoss: 0.4507\tLR: 0.015000\nTraining Epoch: 11 [32128/50000]\tLoss: 0.3572\tLR: 0.015000\nTraining Epoch: 11 [32256/50000]\tLoss: 0.2835\tLR: 0.015000\nTraining Epoch: 11 [32384/50000]\tLoss: 0.3704\tLR: 0.015000\nTraining Epoch: 11 [32512/50000]\tLoss: 0.4045\tLR: 0.015000\nTraining Epoch: 11 [32640/50000]\tLoss: 0.2519\tLR: 0.015000\nTraining Epoch: 11 [32768/50000]\tLoss: 0.4884\tLR: 0.015000\nTraining Epoch: 11 [32896/50000]\tLoss: 0.2773\tLR: 0.015000\nTraining Epoch: 11 [33024/50000]\tLoss: 0.3370\tLR: 0.015000\nTraining Epoch: 11 [33152/50000]\tLoss: 0.5599\tLR: 0.015000\nTraining Epoch: 11 [33280/50000]\tLoss: 0.3431\tLR: 0.015000\nTraining Epoch: 11 [33408/50000]\tLoss: 0.3689\tLR: 0.015000\nTraining Epoch: 11 [33536/50000]\tLoss: 0.4803\tLR: 0.015000\nTraining Epoch: 11 [33664/50000]\tLoss: 0.3943\tLR: 0.015000\nTraining Epoch: 11 [33792/50000]\tLoss: 0.5274\tLR: 0.015000\nTraining Epoch: 11 [33920/50000]\tLoss: 0.2780\tLR: 0.015000\nTraining Epoch: 11 [34048/50000]\tLoss: 0.2951\tLR: 0.015000\nTraining Epoch: 11 [34176/50000]\tLoss: 0.4691\tLR: 0.015000\nTraining Epoch: 11 [34304/50000]\tLoss: 0.3716\tLR: 0.015000\nTraining Epoch: 11 [34432/50000]\tLoss: 0.4355\tLR: 0.015000\nTraining Epoch: 11 [34560/50000]\tLoss: 0.3522\tLR: 0.015000\nTraining Epoch: 11 [34688/50000]\tLoss: 0.3259\tLR: 0.015000\nTraining Epoch: 11 [34816/50000]\tLoss: 0.4346\tLR: 0.015000\nTraining Epoch: 11 [34944/50000]\tLoss: 0.2946\tLR: 0.015000\nTraining Epoch: 11 [35072/50000]\tLoss: 0.3806\tLR: 0.015000\nTraining Epoch: 11 [35200/50000]\tLoss: 0.3599\tLR: 0.015000\nTraining Epoch: 11 [35328/50000]\tLoss: 0.5139\tLR: 0.015000\nTraining Epoch: 11 [35456/50000]\tLoss: 0.4582\tLR: 0.015000\nTraining Epoch: 11 [35584/50000]\tLoss: 0.3747\tLR: 0.015000\nTraining Epoch: 11 [35712/50000]\tLoss: 0.4468\tLR: 0.015000\nTraining Epoch: 11 [35840/50000]\tLoss: 0.3668\tLR: 0.015000\nTraining Epoch: 11 [35968/50000]\tLoss: 0.3463\tLR: 0.015000\nTraining Epoch: 11 [36096/50000]\tLoss: 0.3495\tLR: 0.015000\nTraining Epoch: 11 [36224/50000]\tLoss: 0.3247\tLR: 0.015000\nTraining Epoch: 11 [36352/50000]\tLoss: 0.5108\tLR: 0.015000\nTraining Epoch: 11 [36480/50000]\tLoss: 0.3619\tLR: 0.015000\nTraining Epoch: 11 [36608/50000]\tLoss: 0.3355\tLR: 0.015000\nTraining Epoch: 11 [36736/50000]\tLoss: 0.3725\tLR: 0.015000\nTraining Epoch: 11 [36864/50000]\tLoss: 0.5322\tLR: 0.015000\nTraining Epoch: 11 [36992/50000]\tLoss: 0.3757\tLR: 0.015000\nTraining Epoch: 11 [37120/50000]\tLoss: 0.4785\tLR: 0.015000\nTraining Epoch: 11 [37248/50000]\tLoss: 0.4142\tLR: 0.015000\nTraining Epoch: 11 [37376/50000]\tLoss: 0.4089\tLR: 0.015000\nTraining Epoch: 11 [37504/50000]\tLoss: 0.4157\tLR: 0.015000\nTraining Epoch: 11 [37632/50000]\tLoss: 0.2264\tLR: 0.015000\nTraining Epoch: 11 [37760/50000]\tLoss: 0.3660\tLR: 0.015000\nTraining Epoch: 11 [37888/50000]\tLoss: 0.3961\tLR: 0.015000\nTraining Epoch: 11 [38016/50000]\tLoss: 0.3218\tLR: 0.015000\nTraining Epoch: 11 [38144/50000]\tLoss: 0.3871\tLR: 0.015000\nTraining Epoch: 11 [38272/50000]\tLoss: 0.5841\tLR: 0.015000\nTraining Epoch: 11 [38400/50000]\tLoss: 0.3209\tLR: 0.015000\nTraining Epoch: 11 [38528/50000]\tLoss: 0.3724\tLR: 0.015000\nTraining Epoch: 11 [38656/50000]\tLoss: 0.3655\tLR: 0.015000\nTraining Epoch: 11 [38784/50000]\tLoss: 0.2856\tLR: 0.015000\nTraining Epoch: 11 [38912/50000]\tLoss: 0.4532\tLR: 0.015000\nTraining Epoch: 11 [39040/50000]\tLoss: 0.3952\tLR: 0.015000\nTraining Epoch: 11 [39168/50000]\tLoss: 0.5080\tLR: 0.015000\nTraining Epoch: 11 [39296/50000]\tLoss: 0.2886\tLR: 0.015000\nTraining Epoch: 11 [39424/50000]\tLoss: 0.4125\tLR: 0.015000\nTraining Epoch: 11 [39552/50000]\tLoss: 0.2134\tLR: 0.015000\nTraining Epoch: 11 [39680/50000]\tLoss: 0.3965\tLR: 0.015000\nTraining Epoch: 11 [39808/50000]\tLoss: 0.5090\tLR: 0.015000\nTraining Epoch: 11 [39936/50000]\tLoss: 0.3701\tLR: 0.015000\nTraining Epoch: 11 [40064/50000]\tLoss: 0.3236\tLR: 0.015000\nTraining Epoch: 11 [40192/50000]\tLoss: 0.3436\tLR: 0.015000\nTraining Epoch: 11 [40320/50000]\tLoss: 0.4474\tLR: 0.015000\nTraining Epoch: 11 [40448/50000]\tLoss: 0.3782\tLR: 0.015000\nTraining Epoch: 11 [40576/50000]\tLoss: 0.3411\tLR: 0.015000\nTraining Epoch: 11 [40704/50000]\tLoss: 0.3302\tLR: 0.015000\nTraining Epoch: 11 [40832/50000]\tLoss: 0.3830\tLR: 0.015000\nTraining Epoch: 11 [40960/50000]\tLoss: 0.4288\tLR: 0.015000\nTraining Epoch: 11 [41088/50000]\tLoss: 0.3358\tLR: 0.015000\nTraining Epoch: 11 [41216/50000]\tLoss: 0.4092\tLR: 0.015000\nTraining Epoch: 11 [41344/50000]\tLoss: 0.3456\tLR: 0.015000\nTraining Epoch: 11 [41472/50000]\tLoss: 0.3383\tLR: 0.015000\nTraining Epoch: 11 [41600/50000]\tLoss: 0.3647\tLR: 0.015000\nTraining Epoch: 11 [41728/50000]\tLoss: 0.4900\tLR: 0.015000\nTraining Epoch: 11 [41856/50000]\tLoss: 0.3770\tLR: 0.015000\nTraining Epoch: 11 [41984/50000]\tLoss: 0.2882\tLR: 0.015000\nTraining Epoch: 11 [42112/50000]\tLoss: 0.2956\tLR: 0.015000\nTraining Epoch: 11 [42240/50000]\tLoss: 0.5136\tLR: 0.015000\nTraining Epoch: 11 [42368/50000]\tLoss: 0.2494\tLR: 0.015000\nTraining Epoch: 11 [42496/50000]\tLoss: 0.3946\tLR: 0.015000\nTraining Epoch: 11 [42624/50000]\tLoss: 0.3561\tLR: 0.015000\nTraining Epoch: 11 [42752/50000]\tLoss: 0.3960\tLR: 0.015000\nTraining Epoch: 11 [42880/50000]\tLoss: 0.3542\tLR: 0.015000\nTraining Epoch: 11 [43008/50000]\tLoss: 0.2919\tLR: 0.015000\nTraining Epoch: 11 [43136/50000]\tLoss: 0.3477\tLR: 0.015000\nTraining Epoch: 11 [43264/50000]\tLoss: 0.3601\tLR: 0.015000\nTraining Epoch: 11 [43392/50000]\tLoss: 0.3439\tLR: 0.015000\nTraining Epoch: 11 [43520/50000]\tLoss: 0.3381\tLR: 0.015000\nTraining Epoch: 11 [43648/50000]\tLoss: 0.3512\tLR: 0.015000\nTraining Epoch: 11 [43776/50000]\tLoss: 0.4189\tLR: 0.015000\nTraining Epoch: 11 [43904/50000]\tLoss: 0.4011\tLR: 0.015000\nTraining Epoch: 11 [44032/50000]\tLoss: 0.3973\tLR: 0.015000\nTraining Epoch: 11 [44160/50000]\tLoss: 0.3772\tLR: 0.015000\nTraining Epoch: 11 [44288/50000]\tLoss: 0.3246\tLR: 0.015000\nTraining Epoch: 11 [44416/50000]\tLoss: 0.3819\tLR: 0.015000\nTraining Epoch: 11 [44544/50000]\tLoss: 0.4174\tLR: 0.015000\nTraining Epoch: 11 [44672/50000]\tLoss: 0.3690\tLR: 0.015000\nTraining Epoch: 11 [44800/50000]\tLoss: 0.3998\tLR: 0.015000\nTraining Epoch: 11 [44928/50000]\tLoss: 0.2620\tLR: 0.015000\nTraining Epoch: 11 [45056/50000]\tLoss: 0.4882\tLR: 0.015000\nTraining Epoch: 11 [45184/50000]\tLoss: 0.4508\tLR: 0.015000\nTraining Epoch: 11 [45312/50000]\tLoss: 0.2696\tLR: 0.015000\nTraining Epoch: 11 [45440/50000]\tLoss: 0.3091\tLR: 0.015000\nTraining Epoch: 11 [45568/50000]\tLoss: 0.4356\tLR: 0.015000\nTraining Epoch: 11 [45696/50000]\tLoss: 0.3461\tLR: 0.015000\nTraining Epoch: 11 [45824/50000]\tLoss: 0.3075\tLR: 0.015000\nTraining Epoch: 11 [45952/50000]\tLoss: 0.3126\tLR: 0.015000\nTraining Epoch: 11 [46080/50000]\tLoss: 0.3063\tLR: 0.015000\nTraining Epoch: 11 [46208/50000]\tLoss: 0.3154\tLR: 0.015000\nTraining Epoch: 11 [46336/50000]\tLoss: 0.2464\tLR: 0.015000\nTraining Epoch: 11 [46464/50000]\tLoss: 0.3068\tLR: 0.015000\nTraining Epoch: 11 [46592/50000]\tLoss: 0.2940\tLR: 0.015000\nTraining Epoch: 11 [46720/50000]\tLoss: 0.2437\tLR: 0.015000\nTraining Epoch: 11 [46848/50000]\tLoss: 0.3252\tLR: 0.015000\nTraining Epoch: 11 [46976/50000]\tLoss: 0.4750\tLR: 0.015000\nTraining Epoch: 11 [47104/50000]\tLoss: 0.4266\tLR: 0.015000\nTraining Epoch: 11 [47232/50000]\tLoss: 0.3339\tLR: 0.015000\nTraining Epoch: 11 [47360/50000]\tLoss: 0.1996\tLR: 0.015000\nTraining Epoch: 11 [47488/50000]\tLoss: 0.3198\tLR: 0.015000\nTraining Epoch: 11 [47616/50000]\tLoss: 0.3885\tLR: 0.015000\nTraining Epoch: 11 [47744/50000]\tLoss: 0.3066\tLR: 0.015000\nTraining Epoch: 11 [47872/50000]\tLoss: 0.3754\tLR: 0.015000\nTraining Epoch: 11 [48000/50000]\tLoss: 0.3363\tLR: 0.015000\nTraining Epoch: 11 [48128/50000]\tLoss: 0.3175\tLR: 0.015000\nTraining Epoch: 11 [48256/50000]\tLoss: 0.3110\tLR: 0.015000\nTraining Epoch: 11 [48384/50000]\tLoss: 0.4154\tLR: 0.015000\nTraining Epoch: 11 [48512/50000]\tLoss: 0.5021\tLR: 0.015000\nTraining Epoch: 11 [48640/50000]\tLoss: 0.3725\tLR: 0.015000\nTraining Epoch: 11 [48768/50000]\tLoss: 0.3371\tLR: 0.015000\nTraining Epoch: 11 [48896/50000]\tLoss: 0.3650\tLR: 0.015000\nTraining Epoch: 11 [49024/50000]\tLoss: 0.3294\tLR: 0.015000\nTraining Epoch: 11 [49152/50000]\tLoss: 0.4600\tLR: 0.015000\nTraining Epoch: 11 [49280/50000]\tLoss: 0.4897\tLR: 0.015000\nTraining Epoch: 11 [49408/50000]\tLoss: 0.5261\tLR: 0.015000\nTraining Epoch: 11 [49536/50000]\tLoss: 0.4095\tLR: 0.015000\nTraining Epoch: 11 [49664/50000]\tLoss: 0.4602\tLR: 0.015000\nTraining Epoch: 11 [49792/50000]\tLoss: 0.4549\tLR: 0.015000\nTraining Epoch: 11 [49920/50000]\tLoss: 0.5158\tLR: 0.015000\nTraining Epoch: 11 [50000/50000]\tLoss: 0.3837\tLR: 0.015000\nTest set: Average loss: 0.0029, Accuracy: 0.8751\n\nTraining Epoch: 12 [128/50000]\tLoss: 0.4077\tLR: 0.002250\nTraining Epoch: 12 [256/50000]\tLoss: 0.2546\tLR: 0.002250\nTraining Epoch: 12 [384/50000]\tLoss: 0.3024\tLR: 0.002250\nTraining Epoch: 12 [512/50000]\tLoss: 0.4380\tLR: 0.002250\nTraining Epoch: 12 [640/50000]\tLoss: 0.3495\tLR: 0.002250\nTraining Epoch: 12 [768/50000]\tLoss: 0.4295\tLR: 0.002250\nTraining Epoch: 12 [896/50000]\tLoss: 0.3260\tLR: 0.002250\nTraining Epoch: 12 [1024/50000]\tLoss: 0.2800\tLR: 0.002250\nTraining Epoch: 12 [1152/50000]\tLoss: 0.4056\tLR: 0.002250\nTraining Epoch: 12 [1280/50000]\tLoss: 0.2596\tLR: 0.002250\nTraining Epoch: 12 [1408/50000]\tLoss: 0.3053\tLR: 0.002250\nTraining Epoch: 12 [1536/50000]\tLoss: 0.2822\tLR: 0.002250\nTraining Epoch: 12 [1664/50000]\tLoss: 0.4254\tLR: 0.002250\nTraining Epoch: 12 [1792/50000]\tLoss: 0.3465\tLR: 0.002250\nTraining Epoch: 12 [1920/50000]\tLoss: 0.3883\tLR: 0.002250\nTraining Epoch: 12 [2048/50000]\tLoss: 0.2601\tLR: 0.002250\nTraining Epoch: 12 [2176/50000]\tLoss: 0.3155\tLR: 0.002250\nTraining Epoch: 12 [2304/50000]\tLoss: 0.3310\tLR: 0.002250\nTraining Epoch: 12 [2432/50000]\tLoss: 0.4523\tLR: 0.002250\nTraining Epoch: 12 [2560/50000]\tLoss: 0.2635\tLR: 0.002250\nTraining Epoch: 12 [2688/50000]\tLoss: 0.2532\tLR: 0.002250\nTraining Epoch: 12 [2816/50000]\tLoss: 0.3138\tLR: 0.002250\nTraining Epoch: 12 [2944/50000]\tLoss: 0.3313\tLR: 0.002250\nTraining Epoch: 12 [3072/50000]\tLoss: 0.4497\tLR: 0.002250\nTraining Epoch: 12 [3200/50000]\tLoss: 0.2569\tLR: 0.002250\nTraining Epoch: 12 [3328/50000]\tLoss: 0.3164\tLR: 0.002250\nTraining Epoch: 12 [3456/50000]\tLoss: 0.3226\tLR: 0.002250\nTraining Epoch: 12 [3584/50000]\tLoss: 0.3379\tLR: 0.002250\nTraining Epoch: 12 [3712/50000]\tLoss: 0.2445\tLR: 0.002250\nTraining Epoch: 12 [3840/50000]\tLoss: 0.3913\tLR: 0.002250\nTraining Epoch: 12 [3968/50000]\tLoss: 0.2952\tLR: 0.002250\nTraining Epoch: 12 [4096/50000]\tLoss: 0.4062\tLR: 0.002250\nTraining Epoch: 12 [4224/50000]\tLoss: 0.2953\tLR: 0.002250\nTraining Epoch: 12 [4352/50000]\tLoss: 0.3119\tLR: 0.002250\nTraining Epoch: 12 [4480/50000]\tLoss: 0.2834\tLR: 0.002250\nTraining Epoch: 12 [4608/50000]\tLoss: 0.2645\tLR: 0.002250\nTraining Epoch: 12 [4736/50000]\tLoss: 0.2845\tLR: 0.002250\nTraining Epoch: 12 [4864/50000]\tLoss: 0.3605\tLR: 0.002250\nTraining Epoch: 12 [4992/50000]\tLoss: 0.2611\tLR: 0.002250\nTraining Epoch: 12 [5120/50000]\tLoss: 0.3523\tLR: 0.002250\nTraining Epoch: 12 [5248/50000]\tLoss: 0.3723\tLR: 0.002250\nTraining Epoch: 12 [5376/50000]\tLoss: 0.4919\tLR: 0.002250\nTraining Epoch: 12 [5504/50000]\tLoss: 0.2494\tLR: 0.002250\nTraining Epoch: 12 [5632/50000]\tLoss: 0.2388\tLR: 0.002250\nTraining Epoch: 12 [5760/50000]\tLoss: 0.3082\tLR: 0.002250\nTraining Epoch: 12 [5888/50000]\tLoss: 0.4048\tLR: 0.002250\nTraining Epoch: 12 [6016/50000]\tLoss: 0.3072\tLR: 0.002250\nTraining Epoch: 12 [6144/50000]\tLoss: 0.3363\tLR: 0.002250\nTraining Epoch: 12 [6272/50000]\tLoss: 0.3919\tLR: 0.002250\nTraining Epoch: 12 [6400/50000]\tLoss: 0.2529\tLR: 0.002250\nTraining Epoch: 12 [6528/50000]\tLoss: 0.3955\tLR: 0.002250\nTraining Epoch: 12 [6656/50000]\tLoss: 0.2753\tLR: 0.002250\nTraining Epoch: 12 [6784/50000]\tLoss: 0.4262\tLR: 0.002250\nTraining Epoch: 12 [6912/50000]\tLoss: 0.3887\tLR: 0.002250\nTraining Epoch: 12 [7040/50000]\tLoss: 0.3936\tLR: 0.002250\nTraining Epoch: 12 [7168/50000]\tLoss: 0.3601\tLR: 0.002250\nTraining Epoch: 12 [7296/50000]\tLoss: 0.3475\tLR: 0.002250\nTraining Epoch: 12 [7424/50000]\tLoss: 0.3520\tLR: 0.002250\nTraining Epoch: 12 [7552/50000]\tLoss: 0.3559\tLR: 0.002250\nTraining Epoch: 12 [7680/50000]\tLoss: 0.2162\tLR: 0.002250\nTraining Epoch: 12 [7808/50000]\tLoss: 0.3455\tLR: 0.002250\nTraining Epoch: 12 [7936/50000]\tLoss: 0.2665\tLR: 0.002250\nTraining Epoch: 12 [8064/50000]\tLoss: 0.2856\tLR: 0.002250\nTraining Epoch: 12 [8192/50000]\tLoss: 0.2813\tLR: 0.002250\nTraining Epoch: 12 [8320/50000]\tLoss: 0.3603\tLR: 0.002250\nTraining Epoch: 12 [8448/50000]\tLoss: 0.2427\tLR: 0.002250\nTraining Epoch: 12 [8576/50000]\tLoss: 0.3557\tLR: 0.002250\nTraining Epoch: 12 [8704/50000]\tLoss: 0.3579\tLR: 0.002250\nTraining Epoch: 12 [8832/50000]\tLoss: 0.3771\tLR: 0.002250\nTraining Epoch: 12 [8960/50000]\tLoss: 0.3150\tLR: 0.002250\nTraining Epoch: 12 [9088/50000]\tLoss: 0.3459\tLR: 0.002250\nTraining Epoch: 12 [9216/50000]\tLoss: 0.2512\tLR: 0.002250\nTraining Epoch: 12 [9344/50000]\tLoss: 0.2601\tLR: 0.002250\nTraining Epoch: 12 [9472/50000]\tLoss: 0.2517\tLR: 0.002250\nTraining Epoch: 12 [9600/50000]\tLoss: 0.2883\tLR: 0.002250\nTraining Epoch: 12 [9728/50000]\tLoss: 0.3372\tLR: 0.002250\nTraining Epoch: 12 [9856/50000]\tLoss: 0.4163\tLR: 0.002250\nTraining Epoch: 12 [9984/50000]\tLoss: 0.2647\tLR: 0.002250\nTraining Epoch: 12 [10112/50000]\tLoss: 0.2921\tLR: 0.002250\nTraining Epoch: 12 [10240/50000]\tLoss: 0.4291\tLR: 0.002250\nTraining Epoch: 12 [10368/50000]\tLoss: 0.2663\tLR: 0.002250\nTraining Epoch: 12 [10496/50000]\tLoss: 0.3233\tLR: 0.002250\nTraining Epoch: 12 [10624/50000]\tLoss: 0.3391\tLR: 0.002250\nTraining Epoch: 12 [10752/50000]\tLoss: 0.3178\tLR: 0.002250\nTraining Epoch: 12 [10880/50000]\tLoss: 0.2773\tLR: 0.002250\nTraining Epoch: 12 [11008/50000]\tLoss: 0.3734\tLR: 0.002250\nTraining Epoch: 12 [11136/50000]\tLoss: 0.3586\tLR: 0.002250\nTraining Epoch: 12 [11264/50000]\tLoss: 0.3658\tLR: 0.002250\nTraining Epoch: 12 [11392/50000]\tLoss: 0.2606\tLR: 0.002250\nTraining Epoch: 12 [11520/50000]\tLoss: 0.2950\tLR: 0.002250\nTraining Epoch: 12 [11648/50000]\tLoss: 0.2742\tLR: 0.002250\nTraining Epoch: 12 [11776/50000]\tLoss: 0.2899\tLR: 0.002250\nTraining Epoch: 12 [11904/50000]\tLoss: 0.4088\tLR: 0.002250\nTraining Epoch: 12 [12032/50000]\tLoss: 0.4070\tLR: 0.002250\nTraining Epoch: 12 [12160/50000]\tLoss: 0.2977\tLR: 0.002250\nTraining Epoch: 12 [12288/50000]\tLoss: 0.4316\tLR: 0.002250\nTraining Epoch: 12 [12416/50000]\tLoss: 0.2697\tLR: 0.002250\nTraining Epoch: 12 [12544/50000]\tLoss: 0.2620\tLR: 0.002250\nTraining Epoch: 12 [12672/50000]\tLoss: 0.2741\tLR: 0.002250\nTraining Epoch: 12 [12800/50000]\tLoss: 0.2851\tLR: 0.002250\nTraining Epoch: 12 [12928/50000]\tLoss: 0.2439\tLR: 0.002250\nTraining Epoch: 12 [13056/50000]\tLoss: 0.2618\tLR: 0.002250\nTraining Epoch: 12 [13184/50000]\tLoss: 0.2047\tLR: 0.002250\nTraining Epoch: 12 [13312/50000]\tLoss: 0.4528\tLR: 0.002250\nTraining Epoch: 12 [13440/50000]\tLoss: 0.3835\tLR: 0.002250\nTraining Epoch: 12 [13568/50000]\tLoss: 0.2210\tLR: 0.002250\nTraining Epoch: 12 [13696/50000]\tLoss: 0.3916\tLR: 0.002250\nTraining Epoch: 12 [13824/50000]\tLoss: 0.2516\tLR: 0.002250\nTraining Epoch: 12 [13952/50000]\tLoss: 0.2589\tLR: 0.002250\nTraining Epoch: 12 [14080/50000]\tLoss: 0.4008\tLR: 0.002250\nTraining Epoch: 12 [14208/50000]\tLoss: 0.3156\tLR: 0.002250\nTraining Epoch: 12 [14336/50000]\tLoss: 0.3524\tLR: 0.002250\nTraining Epoch: 12 [14464/50000]\tLoss: 0.3331\tLR: 0.002250\nTraining Epoch: 12 [14592/50000]\tLoss: 0.2562\tLR: 0.002250\nTraining Epoch: 12 [14720/50000]\tLoss: 0.3095\tLR: 0.002250\nTraining Epoch: 12 [14848/50000]\tLoss: 0.3992\tLR: 0.002250\nTraining Epoch: 12 [14976/50000]\tLoss: 0.2297\tLR: 0.002250\nTraining Epoch: 12 [15104/50000]\tLoss: 0.2781\tLR: 0.002250\nTraining Epoch: 12 [15232/50000]\tLoss: 0.3676\tLR: 0.002250\nTraining Epoch: 12 [15360/50000]\tLoss: 0.2696\tLR: 0.002250\nTraining Epoch: 12 [15488/50000]\tLoss: 0.2817\tLR: 0.002250\nTraining Epoch: 12 [15616/50000]\tLoss: 0.2511\tLR: 0.002250\nTraining Epoch: 12 [15744/50000]\tLoss: 0.3300\tLR: 0.002250\nTraining Epoch: 12 [15872/50000]\tLoss: 0.3840\tLR: 0.002250\nTraining Epoch: 12 [16000/50000]\tLoss: 0.2510\tLR: 0.002250\nTraining Epoch: 12 [16128/50000]\tLoss: 0.3480\tLR: 0.002250\nTraining Epoch: 12 [16256/50000]\tLoss: 0.2737\tLR: 0.002250\nTraining Epoch: 12 [16384/50000]\tLoss: 0.3252\tLR: 0.002250\nTraining Epoch: 12 [16512/50000]\tLoss: 0.2556\tLR: 0.002250\nTraining Epoch: 12 [16640/50000]\tLoss: 0.3732\tLR: 0.002250\nTraining Epoch: 12 [16768/50000]\tLoss: 0.3649\tLR: 0.002250\nTraining Epoch: 12 [16896/50000]\tLoss: 0.2405\tLR: 0.002250\nTraining Epoch: 12 [17024/50000]\tLoss: 0.2588\tLR: 0.002250\nTraining Epoch: 12 [17152/50000]\tLoss: 0.3771\tLR: 0.002250\nTraining Epoch: 12 [17280/50000]\tLoss: 0.2950\tLR: 0.002250\nTraining Epoch: 12 [17408/50000]\tLoss: 0.3967\tLR: 0.002250\nTraining Epoch: 12 [17536/50000]\tLoss: 0.3015\tLR: 0.002250\nTraining Epoch: 12 [17664/50000]\tLoss: 0.2514\tLR: 0.002250\nTraining Epoch: 12 [17792/50000]\tLoss: 0.3337\tLR: 0.002250\nTraining Epoch: 12 [17920/50000]\tLoss: 0.3195\tLR: 0.002250\nTraining Epoch: 12 [18048/50000]\tLoss: 0.2472\tLR: 0.002250\nTraining Epoch: 12 [18176/50000]\tLoss: 0.3162\tLR: 0.002250\nTraining Epoch: 12 [18304/50000]\tLoss: 0.3133\tLR: 0.002250\nTraining Epoch: 12 [18432/50000]\tLoss: 0.3837\tLR: 0.002250\nTraining Epoch: 12 [18560/50000]\tLoss: 0.5043\tLR: 0.002250\nTraining Epoch: 12 [18688/50000]\tLoss: 0.2961\tLR: 0.002250\nTraining Epoch: 12 [18816/50000]\tLoss: 0.2754\tLR: 0.002250\nTraining Epoch: 12 [18944/50000]\tLoss: 0.4191\tLR: 0.002250\nTraining Epoch: 12 [19072/50000]\tLoss: 0.3552\tLR: 0.002250\nTraining Epoch: 12 [19200/50000]\tLoss: 0.3242\tLR: 0.002250\nTraining Epoch: 12 [19328/50000]\tLoss: 0.2554\tLR: 0.002250\nTraining Epoch: 12 [19456/50000]\tLoss: 0.3369\tLR: 0.002250\nTraining Epoch: 12 [19584/50000]\tLoss: 0.2480\tLR: 0.002250\nTraining Epoch: 12 [19712/50000]\tLoss: 0.3242\tLR: 0.002250\nTraining Epoch: 12 [19840/50000]\tLoss: 0.4129\tLR: 0.002250\nTraining Epoch: 12 [19968/50000]\tLoss: 0.2239\tLR: 0.002250\nTraining Epoch: 12 [20096/50000]\tLoss: 0.3307\tLR: 0.002250\nTraining Epoch: 12 [20224/50000]\tLoss: 0.2404\tLR: 0.002250\nTraining Epoch: 12 [20352/50000]\tLoss: 0.3564\tLR: 0.002250\nTraining Epoch: 12 [20480/50000]\tLoss: 0.3559\tLR: 0.002250\nTraining Epoch: 12 [20608/50000]\tLoss: 0.3043\tLR: 0.002250\nTraining Epoch: 12 [20736/50000]\tLoss: 0.2878\tLR: 0.002250\nTraining Epoch: 12 [20864/50000]\tLoss: 0.3190\tLR: 0.002250\nTraining Epoch: 12 [20992/50000]\tLoss: 0.2707\tLR: 0.002250\nTraining Epoch: 12 [21120/50000]\tLoss: 0.3088\tLR: 0.002250\nTraining Epoch: 12 [21248/50000]\tLoss: 0.2582\tLR: 0.002250\nTraining Epoch: 12 [21376/50000]\tLoss: 0.2211\tLR: 0.002250\nTraining Epoch: 12 [21504/50000]\tLoss: 0.3712\tLR: 0.002250\nTraining Epoch: 12 [21632/50000]\tLoss: 0.4005\tLR: 0.002250\nTraining Epoch: 12 [21760/50000]\tLoss: 0.3064\tLR: 0.002250\nTraining Epoch: 12 [21888/50000]\tLoss: 0.2306\tLR: 0.002250\nTraining Epoch: 12 [22016/50000]\tLoss: 0.3288\tLR: 0.002250\nTraining Epoch: 12 [22144/50000]\tLoss: 0.3971\tLR: 0.002250\nTraining Epoch: 12 [22272/50000]\tLoss: 0.3627\tLR: 0.002250\nTraining Epoch: 12 [22400/50000]\tLoss: 0.3480\tLR: 0.002250\nTraining Epoch: 12 [22528/50000]\tLoss: 0.2266\tLR: 0.002250\nTraining Epoch: 12 [22656/50000]\tLoss: 0.2796\tLR: 0.002250\nTraining Epoch: 12 [22784/50000]\tLoss: 0.2764\tLR: 0.002250\nTraining Epoch: 12 [22912/50000]\tLoss: 0.2382\tLR: 0.002250\nTraining Epoch: 12 [23040/50000]\tLoss: 0.3569\tLR: 0.002250\nTraining Epoch: 12 [23168/50000]\tLoss: 0.2315\tLR: 0.002250\nTraining Epoch: 12 [23296/50000]\tLoss: 0.2816\tLR: 0.002250\nTraining Epoch: 12 [23424/50000]\tLoss: 0.2518\tLR: 0.002250\nTraining Epoch: 12 [23552/50000]\tLoss: 0.3138\tLR: 0.002250\nTraining Epoch: 12 [23680/50000]\tLoss: 0.2949\tLR: 0.002250\nTraining Epoch: 12 [23808/50000]\tLoss: 0.3485\tLR: 0.002250\nTraining Epoch: 12 [23936/50000]\tLoss: 0.2967\tLR: 0.002250\nTraining Epoch: 12 [24064/50000]\tLoss: 0.2622\tLR: 0.002250\nTraining Epoch: 12 [24192/50000]\tLoss: 0.2772\tLR: 0.002250\nTraining Epoch: 12 [24320/50000]\tLoss: 0.2476\tLR: 0.002250\nTraining Epoch: 12 [24448/50000]\tLoss: 0.3157\tLR: 0.002250\nTraining Epoch: 12 [24576/50000]\tLoss: 0.3602\tLR: 0.002250\nTraining Epoch: 12 [24704/50000]\tLoss: 0.2525\tLR: 0.002250\nTraining Epoch: 12 [24832/50000]\tLoss: 0.2027\tLR: 0.002250\nTraining Epoch: 12 [24960/50000]\tLoss: 0.3114\tLR: 0.002250\nTraining Epoch: 12 [25088/50000]\tLoss: 0.2709\tLR: 0.002250\nTraining Epoch: 12 [25216/50000]\tLoss: 0.3344\tLR: 0.002250\nTraining Epoch: 12 [25344/50000]\tLoss: 0.3769\tLR: 0.002250\nTraining Epoch: 12 [25472/50000]\tLoss: 0.3423\tLR: 0.002250\nTraining Epoch: 12 [25600/50000]\tLoss: 0.2378\tLR: 0.002250\nTraining Epoch: 12 [25728/50000]\tLoss: 0.2615\tLR: 0.002250\nTraining Epoch: 12 [25856/50000]\tLoss: 0.2049\tLR: 0.002250\nTraining Epoch: 12 [25984/50000]\tLoss: 0.3987\tLR: 0.002250\nTraining Epoch: 12 [26112/50000]\tLoss: 0.2651\tLR: 0.002250\nTraining Epoch: 12 [26240/50000]\tLoss: 0.3264\tLR: 0.002250\nTraining Epoch: 12 [26368/50000]\tLoss: 0.2455\tLR: 0.002250\nTraining Epoch: 12 [26496/50000]\tLoss: 0.4372\tLR: 0.002250\nTraining Epoch: 12 [26624/50000]\tLoss: 0.3199\tLR: 0.002250\nTraining Epoch: 12 [26752/50000]\tLoss: 0.2204\tLR: 0.002250\nTraining Epoch: 12 [26880/50000]\tLoss: 0.2538\tLR: 0.002250\nTraining Epoch: 12 [27008/50000]\tLoss: 0.2900\tLR: 0.002250\nTraining Epoch: 12 [27136/50000]\tLoss: 0.3099\tLR: 0.002250\nTraining Epoch: 12 [27264/50000]\tLoss: 0.2885\tLR: 0.002250\nTraining Epoch: 12 [27392/50000]\tLoss: 0.2502\tLR: 0.002250\nTraining Epoch: 12 [27520/50000]\tLoss: 0.2497\tLR: 0.002250\nTraining Epoch: 12 [27648/50000]\tLoss: 0.2918\tLR: 0.002250\nTraining Epoch: 12 [27776/50000]\tLoss: 0.4172\tLR: 0.002250\nTraining Epoch: 12 [27904/50000]\tLoss: 0.2750\tLR: 0.002250\nTraining Epoch: 12 [28032/50000]\tLoss: 0.2117\tLR: 0.002250\nTraining Epoch: 12 [28160/50000]\tLoss: 0.3546\tLR: 0.002250\nTraining Epoch: 12 [28288/50000]\tLoss: 0.3197\tLR: 0.002250\nTraining Epoch: 12 [28416/50000]\tLoss: 0.5094\tLR: 0.002250\nTraining Epoch: 12 [28544/50000]\tLoss: 0.2531\tLR: 0.002250\nTraining Epoch: 12 [28672/50000]\tLoss: 0.2219\tLR: 0.002250\nTraining Epoch: 12 [28800/50000]\tLoss: 0.4745\tLR: 0.002250\nTraining Epoch: 12 [28928/50000]\tLoss: 0.2424\tLR: 0.002250\nTraining Epoch: 12 [29056/50000]\tLoss: 0.3038\tLR: 0.002250\nTraining Epoch: 12 [29184/50000]\tLoss: 0.2421\tLR: 0.002250\nTraining Epoch: 12 [29312/50000]\tLoss: 0.3317\tLR: 0.002250\nTraining Epoch: 12 [29440/50000]\tLoss: 0.3815\tLR: 0.002250\nTraining Epoch: 12 [29568/50000]\tLoss: 0.3216\tLR: 0.002250\nTraining Epoch: 12 [29696/50000]\tLoss: 0.2787\tLR: 0.002250\nTraining Epoch: 12 [29824/50000]\tLoss: 0.2790\tLR: 0.002250\nTraining Epoch: 12 [29952/50000]\tLoss: 0.3007\tLR: 0.002250\nTraining Epoch: 12 [30080/50000]\tLoss: 0.2463\tLR: 0.002250\nTraining Epoch: 12 [30208/50000]\tLoss: 0.2872\tLR: 0.002250\nTraining Epoch: 12 [30336/50000]\tLoss: 0.3634\tLR: 0.002250\nTraining Epoch: 12 [30464/50000]\tLoss: 0.2928\tLR: 0.002250\nTraining Epoch: 12 [30592/50000]\tLoss: 0.2292\tLR: 0.002250\nTraining Epoch: 12 [30720/50000]\tLoss: 0.4200\tLR: 0.002250\nTraining Epoch: 12 [30848/50000]\tLoss: 0.3657\tLR: 0.002250\nTraining Epoch: 12 [30976/50000]\tLoss: 0.3205\tLR: 0.002250\nTraining Epoch: 12 [31104/50000]\tLoss: 0.2768\tLR: 0.002250\nTraining Epoch: 12 [31232/50000]\tLoss: 0.3079\tLR: 0.002250\nTraining Epoch: 12 [31360/50000]\tLoss: 0.3538\tLR: 0.002250\nTraining Epoch: 12 [31488/50000]\tLoss: 0.3235\tLR: 0.002250\nTraining Epoch: 12 [31616/50000]\tLoss: 0.3983\tLR: 0.002250\nTraining Epoch: 12 [31744/50000]\tLoss: 0.2862\tLR: 0.002250\nTraining Epoch: 12 [31872/50000]\tLoss: 0.3171\tLR: 0.002250\nTraining Epoch: 12 [32000/50000]\tLoss: 0.3335\tLR: 0.002250\nTraining Epoch: 12 [32128/50000]\tLoss: 0.2143\tLR: 0.002250\nTraining Epoch: 12 [32256/50000]\tLoss: 0.2210\tLR: 0.002250\nTraining Epoch: 12 [32384/50000]\tLoss: 0.2311\tLR: 0.002250\nTraining Epoch: 12 [32512/50000]\tLoss: 0.2717\tLR: 0.002250\nTraining Epoch: 12 [32640/50000]\tLoss: 0.3064\tLR: 0.002250\nTraining Epoch: 12 [32768/50000]\tLoss: 0.3381\tLR: 0.002250\nTraining Epoch: 12 [32896/50000]\tLoss: 0.3055\tLR: 0.002250\nTraining Epoch: 12 [33024/50000]\tLoss: 0.4369\tLR: 0.002250\nTraining Epoch: 12 [33152/50000]\tLoss: 0.2278\tLR: 0.002250\nTraining Epoch: 12 [33280/50000]\tLoss: 0.2086\tLR: 0.002250\nTraining Epoch: 12 [33408/50000]\tLoss: 0.2781\tLR: 0.002250\nTraining Epoch: 12 [33536/50000]\tLoss: 0.2990\tLR: 0.002250\nTraining Epoch: 12 [33664/50000]\tLoss: 0.3295\tLR: 0.002250\nTraining Epoch: 12 [33792/50000]\tLoss: 0.2986\tLR: 0.002250\nTraining Epoch: 12 [33920/50000]\tLoss: 0.3632\tLR: 0.002250\nTraining Epoch: 12 [34048/50000]\tLoss: 0.2612\tLR: 0.002250\nTraining Epoch: 12 [34176/50000]\tLoss: 0.1805\tLR: 0.002250\nTraining Epoch: 12 [34304/50000]\tLoss: 0.2956\tLR: 0.002250\nTraining Epoch: 12 [34432/50000]\tLoss: 0.3773\tLR: 0.002250\nTraining Epoch: 12 [34560/50000]\tLoss: 0.3835\tLR: 0.002250\nTraining Epoch: 12 [34688/50000]\tLoss: 0.4250\tLR: 0.002250\nTraining Epoch: 12 [34816/50000]\tLoss: 0.2119\tLR: 0.002250\nTraining Epoch: 12 [34944/50000]\tLoss: 0.2967\tLR: 0.002250\nTraining Epoch: 12 [35072/50000]\tLoss: 0.3569\tLR: 0.002250\nTraining Epoch: 12 [35200/50000]\tLoss: 0.2904\tLR: 0.002250\nTraining Epoch: 12 [35328/50000]\tLoss: 0.1936\tLR: 0.002250\nTraining Epoch: 12 [35456/50000]\tLoss: 0.2905\tLR: 0.002250\nTraining Epoch: 12 [35584/50000]\tLoss: 0.2963\tLR: 0.002250\nTraining Epoch: 12 [35712/50000]\tLoss: 0.2862\tLR: 0.002250\nTraining Epoch: 12 [35840/50000]\tLoss: 0.2518\tLR: 0.002250\nTraining Epoch: 12 [35968/50000]\tLoss: 0.2611\tLR: 0.002250\nTraining Epoch: 12 [36096/50000]\tLoss: 0.1781\tLR: 0.002250\nTraining Epoch: 12 [36224/50000]\tLoss: 0.3532\tLR: 0.002250\nTraining Epoch: 12 [36352/50000]\tLoss: 0.4434\tLR: 0.002250\nTraining Epoch: 12 [36480/50000]\tLoss: 0.3513\tLR: 0.002250\nTraining Epoch: 12 [36608/50000]\tLoss: 0.2465\tLR: 0.002250\nTraining Epoch: 12 [36736/50000]\tLoss: 0.2966\tLR: 0.002250\nTraining Epoch: 12 [36864/50000]\tLoss: 0.3039\tLR: 0.002250\nTraining Epoch: 12 [36992/50000]\tLoss: 0.3597\tLR: 0.002250\nTraining Epoch: 12 [37120/50000]\tLoss: 0.2811\tLR: 0.002250\nTraining Epoch: 12 [37248/50000]\tLoss: 0.4876\tLR: 0.002250\nTraining Epoch: 12 [37376/50000]\tLoss: 0.2501\tLR: 0.002250\nTraining Epoch: 12 [37504/50000]\tLoss: 0.2151\tLR: 0.002250\nTraining Epoch: 12 [37632/50000]\tLoss: 0.2236\tLR: 0.002250\nTraining Epoch: 12 [37760/50000]\tLoss: 0.2330\tLR: 0.002250\nTraining Epoch: 12 [37888/50000]\tLoss: 0.2102\tLR: 0.002250\nTraining Epoch: 12 [38016/50000]\tLoss: 0.3751\tLR: 0.002250\nTraining Epoch: 12 [38144/50000]\tLoss: 0.3227\tLR: 0.002250\nTraining Epoch: 12 [38272/50000]\tLoss: 0.3646\tLR: 0.002250\nTraining Epoch: 12 [38400/50000]\tLoss: 0.2495\tLR: 0.002250\nTraining Epoch: 12 [38528/50000]\tLoss: 0.4295\tLR: 0.002250\nTraining Epoch: 12 [38656/50000]\tLoss: 0.2607\tLR: 0.002250\nTraining Epoch: 12 [38784/50000]\tLoss: 0.2803\tLR: 0.002250\nTraining Epoch: 12 [38912/50000]\tLoss: 0.3659\tLR: 0.002250\nTraining Epoch: 12 [39040/50000]\tLoss: 0.3283\tLR: 0.002250\nTraining Epoch: 12 [39168/50000]\tLoss: 0.2982\tLR: 0.002250\nTraining Epoch: 12 [39296/50000]\tLoss: 0.2966\tLR: 0.002250\nTraining Epoch: 12 [39424/50000]\tLoss: 0.3253\tLR: 0.002250\nTraining Epoch: 12 [39552/50000]\tLoss: 0.3809\tLR: 0.002250\nTraining Epoch: 12 [39680/50000]\tLoss: 0.3157\tLR: 0.002250\nTraining Epoch: 12 [39808/50000]\tLoss: 0.2491\tLR: 0.002250\nTraining Epoch: 12 [39936/50000]\tLoss: 0.3516\tLR: 0.002250\nTraining Epoch: 12 [40064/50000]\tLoss: 0.2579\tLR: 0.002250\nTraining Epoch: 12 [40192/50000]\tLoss: 0.3724\tLR: 0.002250\nTraining Epoch: 12 [40320/50000]\tLoss: 0.3295\tLR: 0.002250\nTraining Epoch: 12 [40448/50000]\tLoss: 0.2741\tLR: 0.002250\nTraining Epoch: 12 [40576/50000]\tLoss: 0.2839\tLR: 0.002250\nTraining Epoch: 12 [40704/50000]\tLoss: 0.2255\tLR: 0.002250\nTraining Epoch: 12 [40832/50000]\tLoss: 0.2007\tLR: 0.002250\nTraining Epoch: 12 [40960/50000]\tLoss: 0.3928\tLR: 0.002250\nTraining Epoch: 12 [41088/50000]\tLoss: 0.3040\tLR: 0.002250\nTraining Epoch: 12 [41216/50000]\tLoss: 0.4345\tLR: 0.002250\nTraining Epoch: 12 [41344/50000]\tLoss: 0.3500\tLR: 0.002250\nTraining Epoch: 12 [41472/50000]\tLoss: 0.2440\tLR: 0.002250\nTraining Epoch: 12 [41600/50000]\tLoss: 0.3209\tLR: 0.002250\nTraining Epoch: 12 [41728/50000]\tLoss: 0.3267\tLR: 0.002250\nTraining Epoch: 12 [41856/50000]\tLoss: 0.3107\tLR: 0.002250\nTraining Epoch: 12 [41984/50000]\tLoss: 0.2815\tLR: 0.002250\nTraining Epoch: 12 [42112/50000]\tLoss: 0.2711\tLR: 0.002250\nTraining Epoch: 12 [42240/50000]\tLoss: 0.1925\tLR: 0.002250\nTraining Epoch: 12 [42368/50000]\tLoss: 0.3515\tLR: 0.002250\nTraining Epoch: 12 [42496/50000]\tLoss: 0.3115\tLR: 0.002250\nTraining Epoch: 12 [42624/50000]\tLoss: 0.1888\tLR: 0.002250\nTraining Epoch: 12 [42752/50000]\tLoss: 0.2900\tLR: 0.002250\nTraining Epoch: 12 [42880/50000]\tLoss: 0.4230\tLR: 0.002250\nTraining Epoch: 12 [43008/50000]\tLoss: 0.1858\tLR: 0.002250\nTraining Epoch: 12 [43136/50000]\tLoss: 0.4127\tLR: 0.002250\nTraining Epoch: 12 [43264/50000]\tLoss: 0.4054\tLR: 0.002250\nTraining Epoch: 12 [43392/50000]\tLoss: 0.2866\tLR: 0.002250\nTraining Epoch: 12 [43520/50000]\tLoss: 0.4007\tLR: 0.002250\nTraining Epoch: 12 [43648/50000]\tLoss: 0.2924\tLR: 0.002250\nTraining Epoch: 12 [43776/50000]\tLoss: 0.2638\tLR: 0.002250\nTraining Epoch: 12 [43904/50000]\tLoss: 0.2840\tLR: 0.002250\nTraining Epoch: 12 [44032/50000]\tLoss: 0.4010\tLR: 0.002250\nTraining Epoch: 12 [44160/50000]\tLoss: 0.3658\tLR: 0.002250\nTraining Epoch: 12 [44288/50000]\tLoss: 0.2565\tLR: 0.002250\nTraining Epoch: 12 [44416/50000]\tLoss: 0.3409\tLR: 0.002250\nTraining Epoch: 12 [44544/50000]\tLoss: 0.3248\tLR: 0.002250\nTraining Epoch: 12 [44672/50000]\tLoss: 0.2616\tLR: 0.002250\nTraining Epoch: 12 [44800/50000]\tLoss: 0.3587\tLR: 0.002250\nTraining Epoch: 12 [44928/50000]\tLoss: 0.2731\tLR: 0.002250\nTraining Epoch: 12 [45056/50000]\tLoss: 0.2363\tLR: 0.002250\nTraining Epoch: 12 [45184/50000]\tLoss: 0.4155\tLR: 0.002250\nTraining Epoch: 12 [45312/50000]\tLoss: 0.3194\tLR: 0.002250\nTraining Epoch: 12 [45440/50000]\tLoss: 0.3569\tLR: 0.002250\nTraining Epoch: 12 [45568/50000]\tLoss: 0.3574\tLR: 0.002250\nTraining Epoch: 12 [45696/50000]\tLoss: 0.3264\tLR: 0.002250\nTraining Epoch: 12 [45824/50000]\tLoss: 0.2984\tLR: 0.002250\nTraining Epoch: 12 [45952/50000]\tLoss: 0.1751\tLR: 0.002250\nTraining Epoch: 12 [46080/50000]\tLoss: 0.3283\tLR: 0.002250\nTraining Epoch: 12 [46208/50000]\tLoss: 0.2984\tLR: 0.002250\nTraining Epoch: 12 [46336/50000]\tLoss: 0.2748\tLR: 0.002250\nTraining Epoch: 12 [46464/50000]\tLoss: 0.3058\tLR: 0.002250\nTraining Epoch: 12 [46592/50000]\tLoss: 0.3129\tLR: 0.002250\nTraining Epoch: 12 [46720/50000]\tLoss: 0.3293\tLR: 0.002250\nTraining Epoch: 12 [46848/50000]\tLoss: 0.3184\tLR: 0.002250\nTraining Epoch: 12 [46976/50000]\tLoss: 0.2557\tLR: 0.002250\nTraining Epoch: 12 [47104/50000]\tLoss: 0.2380\tLR: 0.002250\nTraining Epoch: 12 [47232/50000]\tLoss: 0.4034\tLR: 0.002250\nTraining Epoch: 12 [47360/50000]\tLoss: 0.3009\tLR: 0.002250\nTraining Epoch: 12 [47488/50000]\tLoss: 0.3487\tLR: 0.002250\nTraining Epoch: 12 [47616/50000]\tLoss: 0.3204\tLR: 0.002250\nTraining Epoch: 12 [47744/50000]\tLoss: 0.1755\tLR: 0.002250\nTraining Epoch: 12 [47872/50000]\tLoss: 0.2773\tLR: 0.002250\nTraining Epoch: 12 [48000/50000]\tLoss: 0.2566\tLR: 0.002250\nTraining Epoch: 12 [48128/50000]\tLoss: 0.4394\tLR: 0.002250\nTraining Epoch: 12 [48256/50000]\tLoss: 0.3960\tLR: 0.002250\nTraining Epoch: 12 [48384/50000]\tLoss: 0.4291\tLR: 0.002250\nTraining Epoch: 12 [48512/50000]\tLoss: 0.3831\tLR: 0.002250\nTraining Epoch: 12 [48640/50000]\tLoss: 0.3332\tLR: 0.002250\nTraining Epoch: 12 [48768/50000]\tLoss: 0.3025\tLR: 0.002250\nTraining Epoch: 12 [48896/50000]\tLoss: 0.2662\tLR: 0.002250\nTraining Epoch: 12 [49024/50000]\tLoss: 0.2934\tLR: 0.002250\nTraining Epoch: 12 [49152/50000]\tLoss: 0.3079\tLR: 0.002250\nTraining Epoch: 12 [49280/50000]\tLoss: 0.3135\tLR: 0.002250\nTraining Epoch: 12 [49408/50000]\tLoss: 0.2797\tLR: 0.002250\nTraining Epoch: 12 [49536/50000]\tLoss: 0.1825\tLR: 0.002250\nTraining Epoch: 12 [49664/50000]\tLoss: 0.2404\tLR: 0.002250\nTraining Epoch: 12 [49792/50000]\tLoss: 0.1857\tLR: 0.002250\nTraining Epoch: 12 [49920/50000]\tLoss: 0.2353\tLR: 0.002250\nTraining Epoch: 12 [50000/50000]\tLoss: 0.4149\tLR: 0.002250\nTest set: Average loss: 0.0025, Accuracy: 0.8905\n\nTraining Epoch: 13 [128/50000]\tLoss: 0.2604\tLR: 0.002250\nTraining Epoch: 13 [256/50000]\tLoss: 0.3706\tLR: 0.002250\nTraining Epoch: 13 [384/50000]\tLoss: 0.3075\tLR: 0.002250\nTraining Epoch: 13 [512/50000]\tLoss: 0.4136\tLR: 0.002250\nTraining Epoch: 13 [640/50000]\tLoss: 0.2959\tLR: 0.002250\nTraining Epoch: 13 [768/50000]\tLoss: 0.2931\tLR: 0.002250\nTraining Epoch: 13 [896/50000]\tLoss: 0.2924\tLR: 0.002250\nTraining Epoch: 13 [1024/50000]\tLoss: 0.2866\tLR: 0.002250\nTraining Epoch: 13 [1152/50000]\tLoss: 0.1757\tLR: 0.002250\nTraining Epoch: 13 [1280/50000]\tLoss: 0.1988\tLR: 0.002250\nTraining Epoch: 13 [1408/50000]\tLoss: 0.2506\tLR: 0.002250\nTraining Epoch: 13 [1536/50000]\tLoss: 0.2024\tLR: 0.002250\nTraining Epoch: 13 [1664/50000]\tLoss: 0.3135\tLR: 0.002250\nTraining Epoch: 13 [1792/50000]\tLoss: 0.2702\tLR: 0.002250\nTraining Epoch: 13 [1920/50000]\tLoss: 0.2458\tLR: 0.002250\nTraining Epoch: 13 [2048/50000]\tLoss: 0.3295\tLR: 0.002250\nTraining Epoch: 13 [2176/50000]\tLoss: 0.3732\tLR: 0.002250\nTraining Epoch: 13 [2304/50000]\tLoss: 0.1918\tLR: 0.002250\nTraining Epoch: 13 [2432/50000]\tLoss: 0.2468\tLR: 0.002250\nTraining Epoch: 13 [2560/50000]\tLoss: 0.2595\tLR: 0.002250\nTraining Epoch: 13 [2688/50000]\tLoss: 0.3116\tLR: 0.002250\nTraining Epoch: 13 [2816/50000]\tLoss: 0.3935\tLR: 0.002250\nTraining Epoch: 13 [2944/50000]\tLoss: 0.2676\tLR: 0.002250\nTraining Epoch: 13 [3072/50000]\tLoss: 0.2757\tLR: 0.002250\nTraining Epoch: 13 [3200/50000]\tLoss: 0.2671\tLR: 0.002250\nTraining Epoch: 13 [3328/50000]\tLoss: 0.2940\tLR: 0.002250\nTraining Epoch: 13 [3456/50000]\tLoss: 0.2469\tLR: 0.002250\nTraining Epoch: 13 [3584/50000]\tLoss: 0.2776\tLR: 0.002250\nTraining Epoch: 13 [3712/50000]\tLoss: 0.2875\tLR: 0.002250\nTraining Epoch: 13 [3840/50000]\tLoss: 0.4179\tLR: 0.002250\nTraining Epoch: 13 [3968/50000]\tLoss: 0.2561\tLR: 0.002250\nTraining Epoch: 13 [4096/50000]\tLoss: 0.2270\tLR: 0.002250\nTraining Epoch: 13 [4224/50000]\tLoss: 0.2818\tLR: 0.002250\nTraining Epoch: 13 [4352/50000]\tLoss: 0.4097\tLR: 0.002250\nTraining Epoch: 13 [4480/50000]\tLoss: 0.2436\tLR: 0.002250\nTraining Epoch: 13 [4608/50000]\tLoss: 0.3283\tLR: 0.002250\nTraining Epoch: 13 [4736/50000]\tLoss: 0.2024\tLR: 0.002250\nTraining Epoch: 13 [4864/50000]\tLoss: 0.3078\tLR: 0.002250\nTraining Epoch: 13 [4992/50000]\tLoss: 0.2275\tLR: 0.002250\nTraining Epoch: 13 [5120/50000]\tLoss: 0.2688\tLR: 0.002250\nTraining Epoch: 13 [5248/50000]\tLoss: 0.2571\tLR: 0.002250\nTraining Epoch: 13 [5376/50000]\tLoss: 0.1996\tLR: 0.002250\nTraining Epoch: 13 [5504/50000]\tLoss: 0.3300\tLR: 0.002250\nTraining Epoch: 13 [5632/50000]\tLoss: 0.2460\tLR: 0.002250\nTraining Epoch: 13 [5760/50000]\tLoss: 0.2573\tLR: 0.002250\nTraining Epoch: 13 [5888/50000]\tLoss: 0.2567\tLR: 0.002250\nTraining Epoch: 13 [6016/50000]\tLoss: 0.2142\tLR: 0.002250\nTraining Epoch: 13 [6144/50000]\tLoss: 0.2541\tLR: 0.002250\nTraining Epoch: 13 [6272/50000]\tLoss: 0.3250\tLR: 0.002250\nTraining Epoch: 13 [6400/50000]\tLoss: 0.2097\tLR: 0.002250\nTraining Epoch: 13 [6528/50000]\tLoss: 0.2630\tLR: 0.002250\nTraining Epoch: 13 [6656/50000]\tLoss: 0.3832\tLR: 0.002250\nTraining Epoch: 13 [6784/50000]\tLoss: 0.2220\tLR: 0.002250\nTraining Epoch: 13 [6912/50000]\tLoss: 0.4494\tLR: 0.002250\nTraining Epoch: 13 [7040/50000]\tLoss: 0.2049\tLR: 0.002250\nTraining Epoch: 13 [7168/50000]\tLoss: 0.3118\tLR: 0.002250\nTraining Epoch: 13 [7296/50000]\tLoss: 0.3421\tLR: 0.002250\nTraining Epoch: 13 [7424/50000]\tLoss: 0.2947\tLR: 0.002250\nTraining Epoch: 13 [7552/50000]\tLoss: 0.2072\tLR: 0.002250\nTraining Epoch: 13 [7680/50000]\tLoss: 0.2596\tLR: 0.002250\nTraining Epoch: 13 [7808/50000]\tLoss: 0.4127\tLR: 0.002250\nTraining Epoch: 13 [7936/50000]\tLoss: 0.3124\tLR: 0.002250\nTraining Epoch: 13 [8064/50000]\tLoss: 0.3148\tLR: 0.002250\nTraining Epoch: 13 [8192/50000]\tLoss: 0.1878\tLR: 0.002250\nTraining Epoch: 13 [8320/50000]\tLoss: 0.3692\tLR: 0.002250\nTraining Epoch: 13 [8448/50000]\tLoss: 0.2402\tLR: 0.002250\nTraining Epoch: 13 [8576/50000]\tLoss: 0.2518\tLR: 0.002250\nTraining Epoch: 13 [8704/50000]\tLoss: 0.4311\tLR: 0.002250\nTraining Epoch: 13 [8832/50000]\tLoss: 0.2308\tLR: 0.002250\nTraining Epoch: 13 [8960/50000]\tLoss: 0.2618\tLR: 0.002250\nTraining Epoch: 13 [9088/50000]\tLoss: 0.4713\tLR: 0.002250\nTraining Epoch: 13 [9216/50000]\tLoss: 0.3361\tLR: 0.002250\nTraining Epoch: 13 [9344/50000]\tLoss: 0.2634\tLR: 0.002250\nTraining Epoch: 13 [9472/50000]\tLoss: 0.3497\tLR: 0.002250\nTraining Epoch: 13 [9600/50000]\tLoss: 0.2259\tLR: 0.002250\nTraining Epoch: 13 [9728/50000]\tLoss: 0.3142\tLR: 0.002250\nTraining Epoch: 13 [9856/50000]\tLoss: 0.2301\tLR: 0.002250\nTraining Epoch: 13 [9984/50000]\tLoss: 0.3589\tLR: 0.002250\nTraining Epoch: 13 [10112/50000]\tLoss: 0.3582\tLR: 0.002250\nTraining Epoch: 13 [10240/50000]\tLoss: 0.2478\tLR: 0.002250\nTraining Epoch: 13 [10368/50000]\tLoss: 0.2383\tLR: 0.002250\nTraining Epoch: 13 [10496/50000]\tLoss: 0.2714\tLR: 0.002250\nTraining Epoch: 13 [10624/50000]\tLoss: 0.3471\tLR: 0.002250\nTraining Epoch: 13 [10752/50000]\tLoss: 0.2045\tLR: 0.002250\nTraining Epoch: 13 [10880/50000]\tLoss: 0.2938\tLR: 0.002250\nTraining Epoch: 13 [11008/50000]\tLoss: 0.4015\tLR: 0.002250\nTraining Epoch: 13 [11136/50000]\tLoss: 0.2975\tLR: 0.002250\nTraining Epoch: 13 [11264/50000]\tLoss: 0.2797\tLR: 0.002250\nTraining Epoch: 13 [11392/50000]\tLoss: 0.2688\tLR: 0.002250\nTraining Epoch: 13 [11520/50000]\tLoss: 0.2680\tLR: 0.002250\nTraining Epoch: 13 [11648/50000]\tLoss: 0.2767\tLR: 0.002250\nTraining Epoch: 13 [11776/50000]\tLoss: 0.4304\tLR: 0.002250\nTraining Epoch: 13 [11904/50000]\tLoss: 0.2958\tLR: 0.002250\nTraining Epoch: 13 [12032/50000]\tLoss: 0.3130\tLR: 0.002250\nTraining Epoch: 13 [12160/50000]\tLoss: 0.3434\tLR: 0.002250\nTraining Epoch: 13 [12288/50000]\tLoss: 0.2264\tLR: 0.002250\nTraining Epoch: 13 [12416/50000]\tLoss: 0.3467\tLR: 0.002250\nTraining Epoch: 13 [12544/50000]\tLoss: 0.2037\tLR: 0.002250\nTraining Epoch: 13 [12672/50000]\tLoss: 0.3365\tLR: 0.002250\nTraining Epoch: 13 [12800/50000]\tLoss: 0.2074\tLR: 0.002250\nTraining Epoch: 13 [12928/50000]\tLoss: 0.3280\tLR: 0.002250\nTraining Epoch: 13 [13056/50000]\tLoss: 0.3135\tLR: 0.002250\nTraining Epoch: 13 [13184/50000]\tLoss: 0.3084\tLR: 0.002250\nTraining Epoch: 13 [13312/50000]\tLoss: 0.3521\tLR: 0.002250\nTraining Epoch: 13 [13440/50000]\tLoss: 0.3298\tLR: 0.002250\nTraining Epoch: 13 [13568/50000]\tLoss: 0.3220\tLR: 0.002250\nTraining Epoch: 13 [13696/50000]\tLoss: 0.2960\tLR: 0.002250\nTraining Epoch: 13 [13824/50000]\tLoss: 0.1946\tLR: 0.002250\nTraining Epoch: 13 [13952/50000]\tLoss: 0.3024\tLR: 0.002250\nTraining Epoch: 13 [14080/50000]\tLoss: 0.2619\tLR: 0.002250\nTraining Epoch: 13 [14208/50000]\tLoss: 0.2231\tLR: 0.002250\nTraining Epoch: 13 [14336/50000]\tLoss: 0.2553\tLR: 0.002250\nTraining Epoch: 13 [14464/50000]\tLoss: 0.2679\tLR: 0.002250\nTraining Epoch: 13 [14592/50000]\tLoss: 0.2601\tLR: 0.002250\nTraining Epoch: 13 [14720/50000]\tLoss: 0.2263\tLR: 0.002250\nTraining Epoch: 13 [14848/50000]\tLoss: 0.2978\tLR: 0.002250\nTraining Epoch: 13 [14976/50000]\tLoss: 0.2819\tLR: 0.002250\nTraining Epoch: 13 [15104/50000]\tLoss: 0.1769\tLR: 0.002250\nTraining Epoch: 13 [15232/50000]\tLoss: 0.3530\tLR: 0.002250\nTraining Epoch: 13 [15360/50000]\tLoss: 0.3626\tLR: 0.002250\nTraining Epoch: 13 [15488/50000]\tLoss: 0.2955\tLR: 0.002250\nTraining Epoch: 13 [15616/50000]\tLoss: 0.3462\tLR: 0.002250\nTraining Epoch: 13 [15744/50000]\tLoss: 0.1939\tLR: 0.002250\nTraining Epoch: 13 [15872/50000]\tLoss: 0.4021\tLR: 0.002250\nTraining Epoch: 13 [16000/50000]\tLoss: 0.2822\tLR: 0.002250\nTraining Epoch: 13 [16128/50000]\tLoss: 0.2087\tLR: 0.002250\nTraining Epoch: 13 [16256/50000]\tLoss: 0.2906\tLR: 0.002250\nTraining Epoch: 13 [16384/50000]\tLoss: 0.2799\tLR: 0.002250\nTraining Epoch: 13 [16512/50000]\tLoss: 0.3122\tLR: 0.002250\nTraining Epoch: 13 [16640/50000]\tLoss: 0.4259\tLR: 0.002250\nTraining Epoch: 13 [16768/50000]\tLoss: 0.3204\tLR: 0.002250\nTraining Epoch: 13 [16896/50000]\tLoss: 0.1959\tLR: 0.002250\nTraining Epoch: 13 [17024/50000]\tLoss: 0.2565\tLR: 0.002250\nTraining Epoch: 13 [17152/50000]\tLoss: 0.1925\tLR: 0.002250\nTraining Epoch: 13 [17280/50000]\tLoss: 0.4539\tLR: 0.002250\nTraining Epoch: 13 [17408/50000]\tLoss: 0.2785\tLR: 0.002250\nTraining Epoch: 13 [17536/50000]\tLoss: 0.1910\tLR: 0.002250\nTraining Epoch: 13 [17664/50000]\tLoss: 0.3609\tLR: 0.002250\nTraining Epoch: 13 [17792/50000]\tLoss: 0.4182\tLR: 0.002250\nTraining Epoch: 13 [17920/50000]\tLoss: 0.2957\tLR: 0.002250\nTraining Epoch: 13 [18048/50000]\tLoss: 0.2915\tLR: 0.002250\nTraining Epoch: 13 [18176/50000]\tLoss: 0.2212\tLR: 0.002250\nTraining Epoch: 13 [18304/50000]\tLoss: 0.2378\tLR: 0.002250\nTraining Epoch: 13 [18432/50000]\tLoss: 0.3447\tLR: 0.002250\nTraining Epoch: 13 [18560/50000]\tLoss: 0.3215\tLR: 0.002250\nTraining Epoch: 13 [18688/50000]\tLoss: 0.4259\tLR: 0.002250\nTraining Epoch: 13 [18816/50000]\tLoss: 0.2777\tLR: 0.002250\nTraining Epoch: 13 [18944/50000]\tLoss: 0.3902\tLR: 0.002250\nTraining Epoch: 13 [19072/50000]\tLoss: 0.2369\tLR: 0.002250\nTraining Epoch: 13 [19200/50000]\tLoss: 0.1788\tLR: 0.002250\nTraining Epoch: 13 [19328/50000]\tLoss: 0.3542\tLR: 0.002250\nTraining Epoch: 13 [19456/50000]\tLoss: 0.3498\tLR: 0.002250\nTraining Epoch: 13 [19584/50000]\tLoss: 0.3858\tLR: 0.002250\nTraining Epoch: 13 [19712/50000]\tLoss: 0.2436\tLR: 0.002250\nTraining Epoch: 13 [19840/50000]\tLoss: 0.3559\tLR: 0.002250\nTraining Epoch: 13 [19968/50000]\tLoss: 0.2698\tLR: 0.002250\nTraining Epoch: 13 [20096/50000]\tLoss: 0.2039\tLR: 0.002250\nTraining Epoch: 13 [20224/50000]\tLoss: 0.2127\tLR: 0.002250\nTraining Epoch: 13 [20352/50000]\tLoss: 0.4097\tLR: 0.002250\nTraining Epoch: 13 [20480/50000]\tLoss: 0.2770\tLR: 0.002250\nTraining Epoch: 13 [20608/50000]\tLoss: 0.2980\tLR: 0.002250\nTraining Epoch: 13 [20736/50000]\tLoss: 0.4314\tLR: 0.002250\nTraining Epoch: 13 [20864/50000]\tLoss: 0.2203\tLR: 0.002250\nTraining Epoch: 13 [20992/50000]\tLoss: 0.2863\tLR: 0.002250\nTraining Epoch: 13 [21120/50000]\tLoss: 0.3119\tLR: 0.002250\nTraining Epoch: 13 [21248/50000]\tLoss: 0.2949\tLR: 0.002250\nTraining Epoch: 13 [21376/50000]\tLoss: 0.3654\tLR: 0.002250\nTraining Epoch: 13 [21504/50000]\tLoss: 0.3303\tLR: 0.002250\nTraining Epoch: 13 [21632/50000]\tLoss: 0.3615\tLR: 0.002250\nTraining Epoch: 13 [21760/50000]\tLoss: 0.2727\tLR: 0.002250\nTraining Epoch: 13 [21888/50000]\tLoss: 0.2692\tLR: 0.002250\nTraining Epoch: 13 [22016/50000]\tLoss: 0.3608\tLR: 0.002250\nTraining Epoch: 13 [22144/50000]\tLoss: 0.2846\tLR: 0.002250\nTraining Epoch: 13 [22272/50000]\tLoss: 0.2673\tLR: 0.002250\nTraining Epoch: 13 [22400/50000]\tLoss: 0.2429\tLR: 0.002250\nTraining Epoch: 13 [22528/50000]\tLoss: 0.2812\tLR: 0.002250\nTraining Epoch: 13 [22656/50000]\tLoss: 0.3284\tLR: 0.002250\nTraining Epoch: 13 [22784/50000]\tLoss: 0.4089\tLR: 0.002250\nTraining Epoch: 13 [22912/50000]\tLoss: 0.2693\tLR: 0.002250\nTraining Epoch: 13 [23040/50000]\tLoss: 0.1974\tLR: 0.002250\nTraining Epoch: 13 [23168/50000]\tLoss: 0.1884\tLR: 0.002250\nTraining Epoch: 13 [23296/50000]\tLoss: 0.3708\tLR: 0.002250\nTraining Epoch: 13 [23424/50000]\tLoss: 0.1923\tLR: 0.002250\nTraining Epoch: 13 [23552/50000]\tLoss: 0.2683\tLR: 0.002250\nTraining Epoch: 13 [23680/50000]\tLoss: 0.4160\tLR: 0.002250\nTraining Epoch: 13 [23808/50000]\tLoss: 0.2026\tLR: 0.002250\nTraining Epoch: 13 [23936/50000]\tLoss: 0.2141\tLR: 0.002250\nTraining Epoch: 13 [24064/50000]\tLoss: 0.2597\tLR: 0.002250\nTraining Epoch: 13 [24192/50000]\tLoss: 0.5088\tLR: 0.002250\nTraining Epoch: 13 [24320/50000]\tLoss: 0.3280\tLR: 0.002250\nTraining Epoch: 13 [24448/50000]\tLoss: 0.2460\tLR: 0.002250\nTraining Epoch: 13 [24576/50000]\tLoss: 0.3262\tLR: 0.002250\nTraining Epoch: 13 [24704/50000]\tLoss: 0.3845\tLR: 0.002250\nTraining Epoch: 13 [24832/50000]\tLoss: 0.2153\tLR: 0.002250\nTraining Epoch: 13 [24960/50000]\tLoss: 0.2654\tLR: 0.002250\nTraining Epoch: 13 [25088/50000]\tLoss: 0.3238\tLR: 0.002250\nTraining Epoch: 13 [25216/50000]\tLoss: 0.1994\tLR: 0.002250\nTraining Epoch: 13 [25344/50000]\tLoss: 0.2311\tLR: 0.002250\nTraining Epoch: 13 [25472/50000]\tLoss: 0.4233\tLR: 0.002250\nTraining Epoch: 13 [25600/50000]\tLoss: 0.2298\tLR: 0.002250\nTraining Epoch: 13 [25728/50000]\tLoss: 0.2018\tLR: 0.002250\nTraining Epoch: 13 [25856/50000]\tLoss: 0.2159\tLR: 0.002250\nTraining Epoch: 13 [25984/50000]\tLoss: 0.3038\tLR: 0.002250\nTraining Epoch: 13 [26112/50000]\tLoss: 0.1902\tLR: 0.002250\nTraining Epoch: 13 [26240/50000]\tLoss: 0.2399\tLR: 0.002250\nTraining Epoch: 13 [26368/50000]\tLoss: 0.1898\tLR: 0.002250\nTraining Epoch: 13 [26496/50000]\tLoss: 0.2578\tLR: 0.002250\nTraining Epoch: 13 [26624/50000]\tLoss: 0.3413\tLR: 0.002250\nTraining Epoch: 13 [26752/50000]\tLoss: 0.3930\tLR: 0.002250\nTraining Epoch: 13 [26880/50000]\tLoss: 0.3072\tLR: 0.002250\nTraining Epoch: 13 [27008/50000]\tLoss: 0.3214\tLR: 0.002250\nTraining Epoch: 13 [27136/50000]\tLoss: 0.3056\tLR: 0.002250\nTraining Epoch: 13 [27264/50000]\tLoss: 0.2787\tLR: 0.002250\nTraining Epoch: 13 [27392/50000]\tLoss: 0.1924\tLR: 0.002250\nTraining Epoch: 13 [27520/50000]\tLoss: 0.2834\tLR: 0.002250\nTraining Epoch: 13 [27648/50000]\tLoss: 0.1953\tLR: 0.002250\nTraining Epoch: 13 [27776/50000]\tLoss: 0.2446\tLR: 0.002250\nTraining Epoch: 13 [27904/50000]\tLoss: 0.3247\tLR: 0.002250\nTraining Epoch: 13 [28032/50000]\tLoss: 0.2593\tLR: 0.002250\nTraining Epoch: 13 [28160/50000]\tLoss: 0.2702\tLR: 0.002250\nTraining Epoch: 13 [28288/50000]\tLoss: 0.2325\tLR: 0.002250\nTraining Epoch: 13 [28416/50000]\tLoss: 0.3357\tLR: 0.002250\nTraining Epoch: 13 [28544/50000]\tLoss: 0.2713\tLR: 0.002250\nTraining Epoch: 13 [28672/50000]\tLoss: 0.2285\tLR: 0.002250\nTraining Epoch: 13 [28800/50000]\tLoss: 0.3332\tLR: 0.002250\nTraining Epoch: 13 [28928/50000]\tLoss: 0.2635\tLR: 0.002250\nTraining Epoch: 13 [29056/50000]\tLoss: 0.2843\tLR: 0.002250\nTraining Epoch: 13 [29184/50000]\tLoss: 0.2694\tLR: 0.002250\nTraining Epoch: 13 [29312/50000]\tLoss: 0.3104\tLR: 0.002250\nTraining Epoch: 13 [29440/50000]\tLoss: 0.3169\tLR: 0.002250\nTraining Epoch: 13 [29568/50000]\tLoss: 0.2679\tLR: 0.002250\nTraining Epoch: 13 [29696/50000]\tLoss: 0.2371\tLR: 0.002250\nTraining Epoch: 13 [29824/50000]\tLoss: 0.4198\tLR: 0.002250\nTraining Epoch: 13 [29952/50000]\tLoss: 0.2707\tLR: 0.002250\nTraining Epoch: 13 [30080/50000]\tLoss: 0.3138\tLR: 0.002250\nTraining Epoch: 13 [30208/50000]\tLoss: 0.3747\tLR: 0.002250\nTraining Epoch: 13 [30336/50000]\tLoss: 0.3103\tLR: 0.002250\nTraining Epoch: 13 [30464/50000]\tLoss: 0.3108\tLR: 0.002250\nTraining Epoch: 13 [30592/50000]\tLoss: 0.3135\tLR: 0.002250\nTraining Epoch: 13 [30720/50000]\tLoss: 0.3851\tLR: 0.002250\nTraining Epoch: 13 [30848/50000]\tLoss: 0.1903\tLR: 0.002250\nTraining Epoch: 13 [30976/50000]\tLoss: 0.2715\tLR: 0.002250\nTraining Epoch: 13 [31104/50000]\tLoss: 0.3687\tLR: 0.002250\nTraining Epoch: 13 [31232/50000]\tLoss: 0.3425\tLR: 0.002250\nTraining Epoch: 13 [31360/50000]\tLoss: 0.3871\tLR: 0.002250\nTraining Epoch: 13 [31488/50000]\tLoss: 0.2855\tLR: 0.002250\nTraining Epoch: 13 [31616/50000]\tLoss: 0.3314\tLR: 0.002250\nTraining Epoch: 13 [31744/50000]\tLoss: 0.3935\tLR: 0.002250\nTraining Epoch: 13 [31872/50000]\tLoss: 0.3544\tLR: 0.002250\nTraining Epoch: 13 [32000/50000]\tLoss: 0.2224\tLR: 0.002250\nTraining Epoch: 13 [32128/50000]\tLoss: 0.3176\tLR: 0.002250\nTraining Epoch: 13 [32256/50000]\tLoss: 0.3192\tLR: 0.002250\nTraining Epoch: 13 [32384/50000]\tLoss: 0.1892\tLR: 0.002250\nTraining Epoch: 13 [32512/50000]\tLoss: 0.2338\tLR: 0.002250\nTraining Epoch: 13 [32640/50000]\tLoss: 0.2681\tLR: 0.002250\nTraining Epoch: 13 [32768/50000]\tLoss: 0.2051\tLR: 0.002250\nTraining Epoch: 13 [32896/50000]\tLoss: 0.1955\tLR: 0.002250\nTraining Epoch: 13 [33024/50000]\tLoss: 0.2611\tLR: 0.002250\nTraining Epoch: 13 [33152/50000]\tLoss: 0.2618\tLR: 0.002250\nTraining Epoch: 13 [33280/50000]\tLoss: 0.2989\tLR: 0.002250\nTraining Epoch: 13 [33408/50000]\tLoss: 0.2302\tLR: 0.002250\nTraining Epoch: 13 [33536/50000]\tLoss: 0.2487\tLR: 0.002250\nTraining Epoch: 13 [33664/50000]\tLoss: 0.3477\tLR: 0.002250\nTraining Epoch: 13 [33792/50000]\tLoss: 0.1468\tLR: 0.002250\nTraining Epoch: 13 [33920/50000]\tLoss: 0.3394\tLR: 0.002250\nTraining Epoch: 13 [34048/50000]\tLoss: 0.3151\tLR: 0.002250\nTraining Epoch: 13 [34176/50000]\tLoss: 0.3452\tLR: 0.002250\nTraining Epoch: 13 [34304/50000]\tLoss: 0.1924\tLR: 0.002250\nTraining Epoch: 13 [34432/50000]\tLoss: 0.2848\tLR: 0.002250\nTraining Epoch: 13 [34560/50000]\tLoss: 0.3407\tLR: 0.002250\nTraining Epoch: 13 [34688/50000]\tLoss: 0.2592\tLR: 0.002250\nTraining Epoch: 13 [34816/50000]\tLoss: 0.2034\tLR: 0.002250\nTraining Epoch: 13 [34944/50000]\tLoss: 0.2371\tLR: 0.002250\nTraining Epoch: 13 [35072/50000]\tLoss: 0.2916\tLR: 0.002250\nTraining Epoch: 13 [35200/50000]\tLoss: 0.3222\tLR: 0.002250\nTraining Epoch: 13 [35328/50000]\tLoss: 0.4660\tLR: 0.002250\nTraining Epoch: 13 [35456/50000]\tLoss: 0.2081\tLR: 0.002250\nTraining Epoch: 13 [35584/50000]\tLoss: 0.2407\tLR: 0.002250\nTraining Epoch: 13 [35712/50000]\tLoss: 0.1912\tLR: 0.002250\nTraining Epoch: 13 [35840/50000]\tLoss: 0.3433\tLR: 0.002250\nTraining Epoch: 13 [35968/50000]\tLoss: 0.3494\tLR: 0.002250\nTraining Epoch: 13 [36096/50000]\tLoss: 0.2727\tLR: 0.002250\nTraining Epoch: 13 [36224/50000]\tLoss: 0.2658\tLR: 0.002250\nTraining Epoch: 13 [36352/50000]\tLoss: 0.2247\tLR: 0.002250\nTraining Epoch: 13 [36480/50000]\tLoss: 0.3131\tLR: 0.002250\nTraining Epoch: 13 [36608/50000]\tLoss: 0.3219\tLR: 0.002250\nTraining Epoch: 13 [36736/50000]\tLoss: 0.2757\tLR: 0.002250\nTraining Epoch: 13 [36864/50000]\tLoss: 0.3356\tLR: 0.002250\nTraining Epoch: 13 [36992/50000]\tLoss: 0.3061\tLR: 0.002250\nTraining Epoch: 13 [37120/50000]\tLoss: 0.2872\tLR: 0.002250\nTraining Epoch: 13 [37248/50000]\tLoss: 0.2289\tLR: 0.002250\nTraining Epoch: 13 [37376/50000]\tLoss: 0.3398\tLR: 0.002250\nTraining Epoch: 13 [37504/50000]\tLoss: 0.3217\tLR: 0.002250\nTraining Epoch: 13 [37632/50000]\tLoss: 0.4688\tLR: 0.002250\nTraining Epoch: 13 [37760/50000]\tLoss: 0.3066\tLR: 0.002250\nTraining Epoch: 13 [37888/50000]\tLoss: 0.3030\tLR: 0.002250\nTraining Epoch: 13 [38016/50000]\tLoss: 0.3465\tLR: 0.002250\nTraining Epoch: 13 [38144/50000]\tLoss: 0.1695\tLR: 0.002250\nTraining Epoch: 13 [38272/50000]\tLoss: 0.3346\tLR: 0.002250\nTraining Epoch: 13 [38400/50000]\tLoss: 0.2409\tLR: 0.002250\nTraining Epoch: 13 [38528/50000]\tLoss: 0.3551\tLR: 0.002250\nTraining Epoch: 13 [38656/50000]\tLoss: 0.2052\tLR: 0.002250\nTraining Epoch: 13 [38784/50000]\tLoss: 0.3216\tLR: 0.002250\nTraining Epoch: 13 [38912/50000]\tLoss: 0.2176\tLR: 0.002250\nTraining Epoch: 13 [39040/50000]\tLoss: 0.4132\tLR: 0.002250\nTraining Epoch: 13 [39168/50000]\tLoss: 0.4150\tLR: 0.002250\nTraining Epoch: 13 [39296/50000]\tLoss: 0.3644\tLR: 0.002250\nTraining Epoch: 13 [39424/50000]\tLoss: 0.3172\tLR: 0.002250\nTraining Epoch: 13 [39552/50000]\tLoss: 0.1974\tLR: 0.002250\nTraining Epoch: 13 [39680/50000]\tLoss: 0.2525\tLR: 0.002250\nTraining Epoch: 13 [39808/50000]\tLoss: 0.3067\tLR: 0.002250\nTraining Epoch: 13 [39936/50000]\tLoss: 0.1732\tLR: 0.002250\nTraining Epoch: 13 [40064/50000]\tLoss: 0.2776\tLR: 0.002250\nTraining Epoch: 13 [40192/50000]\tLoss: 0.2610\tLR: 0.002250\nTraining Epoch: 13 [40320/50000]\tLoss: 0.3692\tLR: 0.002250\nTraining Epoch: 13 [40448/50000]\tLoss: 0.4776\tLR: 0.002250\nTraining Epoch: 13 [40576/50000]\tLoss: 0.3999\tLR: 0.002250\nTraining Epoch: 13 [40704/50000]\tLoss: 0.2925\tLR: 0.002250\nTraining Epoch: 13 [40832/50000]\tLoss: 0.3578\tLR: 0.002250\nTraining Epoch: 13 [40960/50000]\tLoss: 0.2343\tLR: 0.002250\nTraining Epoch: 13 [41088/50000]\tLoss: 0.2719\tLR: 0.002250\nTraining Epoch: 13 [41216/50000]\tLoss: 0.4067\tLR: 0.002250\nTraining Epoch: 13 [41344/50000]\tLoss: 0.3618\tLR: 0.002250\nTraining Epoch: 13 [41472/50000]\tLoss: 0.3026\tLR: 0.002250\nTraining Epoch: 13 [41600/50000]\tLoss: 0.2501\tLR: 0.002250\nTraining Epoch: 13 [41728/50000]\tLoss: 0.4135\tLR: 0.002250\nTraining Epoch: 13 [41856/50000]\tLoss: 0.2460\tLR: 0.002250\nTraining Epoch: 13 [41984/50000]\tLoss: 0.3125\tLR: 0.002250\nTraining Epoch: 13 [42112/50000]\tLoss: 0.2247\tLR: 0.002250\nTraining Epoch: 13 [42240/50000]\tLoss: 0.3464\tLR: 0.002250\nTraining Epoch: 13 [42368/50000]\tLoss: 0.2475\tLR: 0.002250\nTraining Epoch: 13 [42496/50000]\tLoss: 0.1751\tLR: 0.002250\nTraining Epoch: 13 [42624/50000]\tLoss: 0.3120\tLR: 0.002250\nTraining Epoch: 13 [42752/50000]\tLoss: 0.2605\tLR: 0.002250\nTraining Epoch: 13 [42880/50000]\tLoss: 0.2934\tLR: 0.002250\nTraining Epoch: 13 [43008/50000]\tLoss: 0.2679\tLR: 0.002250\nTraining Epoch: 13 [43136/50000]\tLoss: 0.3120\tLR: 0.002250\nTraining Epoch: 13 [43264/50000]\tLoss: 0.3132\tLR: 0.002250\nTraining Epoch: 13 [43392/50000]\tLoss: 0.3288\tLR: 0.002250\nTraining Epoch: 13 [43520/50000]\tLoss: 0.3231\tLR: 0.002250\nTraining Epoch: 13 [43648/50000]\tLoss: 0.1983\tLR: 0.002250\nTraining Epoch: 13 [43776/50000]\tLoss: 0.3601\tLR: 0.002250\nTraining Epoch: 13 [43904/50000]\tLoss: 0.2360\tLR: 0.002250\nTraining Epoch: 13 [44032/50000]\tLoss: 0.4402\tLR: 0.002250\nTraining Epoch: 13 [44160/50000]\tLoss: 0.3005\tLR: 0.002250\nTraining Epoch: 13 [44288/50000]\tLoss: 0.2523\tLR: 0.002250\nTraining Epoch: 13 [44416/50000]\tLoss: 0.2826\tLR: 0.002250\nTraining Epoch: 13 [44544/50000]\tLoss: 0.2672\tLR: 0.002250\nTraining Epoch: 13 [44672/50000]\tLoss: 0.2460\tLR: 0.002250\nTraining Epoch: 13 [44800/50000]\tLoss: 0.2607\tLR: 0.002250\nTraining Epoch: 13 [44928/50000]\tLoss: 0.2774\tLR: 0.002250\nTraining Epoch: 13 [45056/50000]\tLoss: 0.2644\tLR: 0.002250\nTraining Epoch: 13 [45184/50000]\tLoss: 0.2502\tLR: 0.002250\nTraining Epoch: 13 [45312/50000]\tLoss: 0.2229\tLR: 0.002250\nTraining Epoch: 13 [45440/50000]\tLoss: 0.2700\tLR: 0.002250\nTraining Epoch: 13 [45568/50000]\tLoss: 0.3363\tLR: 0.002250\nTraining Epoch: 13 [45696/50000]\tLoss: 0.3002\tLR: 0.002250\nTraining Epoch: 13 [45824/50000]\tLoss: 0.2545\tLR: 0.002250\nTraining Epoch: 13 [45952/50000]\tLoss: 0.2199\tLR: 0.002250\nTraining Epoch: 13 [46080/50000]\tLoss: 0.3099\tLR: 0.002250\nTraining Epoch: 13 [46208/50000]\tLoss: 0.2729\tLR: 0.002250\nTraining Epoch: 13 [46336/50000]\tLoss: 0.2682\tLR: 0.002250\nTraining Epoch: 13 [46464/50000]\tLoss: 0.2674\tLR: 0.002250\nTraining Epoch: 13 [46592/50000]\tLoss: 0.3241\tLR: 0.002250\nTraining Epoch: 13 [46720/50000]\tLoss: 0.3614\tLR: 0.002250\nTraining Epoch: 13 [46848/50000]\tLoss: 0.3652\tLR: 0.002250\nTraining Epoch: 13 [46976/50000]\tLoss: 0.1565\tLR: 0.002250\nTraining Epoch: 13 [47104/50000]\tLoss: 0.3830\tLR: 0.002250\nTraining Epoch: 13 [47232/50000]\tLoss: 0.2125\tLR: 0.002250\nTraining Epoch: 13 [47360/50000]\tLoss: 0.3222\tLR: 0.002250\nTraining Epoch: 13 [47488/50000]\tLoss: 0.3080\tLR: 0.002250\nTraining Epoch: 13 [47616/50000]\tLoss: 0.2490\tLR: 0.002250\nTraining Epoch: 13 [47744/50000]\tLoss: 0.2434\tLR: 0.002250\nTraining Epoch: 13 [47872/50000]\tLoss: 0.2585\tLR: 0.002250\nTraining Epoch: 13 [48000/50000]\tLoss: 0.3059\tLR: 0.002250\nTraining Epoch: 13 [48128/50000]\tLoss: 0.2352\tLR: 0.002250\nTraining Epoch: 13 [48256/50000]\tLoss: 0.2899\tLR: 0.002250\nTraining Epoch: 13 [48384/50000]\tLoss: 0.2975\tLR: 0.002250\nTraining Epoch: 13 [48512/50000]\tLoss: 0.2633\tLR: 0.002250\nTraining Epoch: 13 [48640/50000]\tLoss: 0.3009\tLR: 0.002250\nTraining Epoch: 13 [48768/50000]\tLoss: 0.2689\tLR: 0.002250\nTraining Epoch: 13 [48896/50000]\tLoss: 0.1919\tLR: 0.002250\nTraining Epoch: 13 [49024/50000]\tLoss: 0.4351\tLR: 0.002250\nTraining Epoch: 13 [49152/50000]\tLoss: 0.2120\tLR: 0.002250\nTraining Epoch: 13 [49280/50000]\tLoss: 0.2288\tLR: 0.002250\nTraining Epoch: 13 [49408/50000]\tLoss: 0.3751\tLR: 0.002250\nTraining Epoch: 13 [49536/50000]\tLoss: 0.3197\tLR: 0.002250\nTraining Epoch: 13 [49664/50000]\tLoss: 0.3405\tLR: 0.002250\nTraining Epoch: 13 [49792/50000]\tLoss: 0.2958\tLR: 0.002250\nTraining Epoch: 13 [49920/50000]\tLoss: 0.3463\tLR: 0.002250\nTraining Epoch: 13 [50000/50000]\tLoss: 0.2486\tLR: 0.002250\nTest set: Average loss: 0.0025, Accuracy: 0.8917\n\nTraining Epoch: 14 [128/50000]\tLoss: 0.2750\tLR: 0.002250\nTraining Epoch: 14 [256/50000]\tLoss: 0.2878\tLR: 0.002250\nTraining Epoch: 14 [384/50000]\tLoss: 0.1775\tLR: 0.002250\nTraining Epoch: 14 [512/50000]\tLoss: 0.2861\tLR: 0.002250\nTraining Epoch: 14 [640/50000]\tLoss: 0.2844\tLR: 0.002250\nTraining Epoch: 14 [768/50000]\tLoss: 0.2349\tLR: 0.002250\nTraining Epoch: 14 [896/50000]\tLoss: 0.2723\tLR: 0.002250\nTraining Epoch: 14 [1024/50000]\tLoss: 0.3412\tLR: 0.002250\nTraining Epoch: 14 [1152/50000]\tLoss: 0.3616\tLR: 0.002250\nTraining Epoch: 14 [1280/50000]\tLoss: 0.2792\tLR: 0.002250\nTraining Epoch: 14 [1408/50000]\tLoss: 0.2772\tLR: 0.002250\nTraining Epoch: 14 [1536/50000]\tLoss: 0.2742\tLR: 0.002250\nTraining Epoch: 14 [1664/50000]\tLoss: 0.3766\tLR: 0.002250\nTraining Epoch: 14 [1792/50000]\tLoss: 0.3474\tLR: 0.002250\nTraining Epoch: 14 [1920/50000]\tLoss: 0.2676\tLR: 0.002250\nTraining Epoch: 14 [2048/50000]\tLoss: 0.3272\tLR: 0.002250\nTraining Epoch: 14 [2176/50000]\tLoss: 0.1964\tLR: 0.002250\nTraining Epoch: 14 [2304/50000]\tLoss: 0.3324\tLR: 0.002250\nTraining Epoch: 14 [2432/50000]\tLoss: 0.2196\tLR: 0.002250\nTraining Epoch: 14 [2560/50000]\tLoss: 0.3092\tLR: 0.002250\nTraining Epoch: 14 [2688/50000]\tLoss: 0.3371\tLR: 0.002250\nTraining Epoch: 14 [2816/50000]\tLoss: 0.2227\tLR: 0.002250\nTraining Epoch: 14 [2944/50000]\tLoss: 0.2620\tLR: 0.002250\nTraining Epoch: 14 [3072/50000]\tLoss: 0.3224\tLR: 0.002250\nTraining Epoch: 14 [3200/50000]\tLoss: 0.2432\tLR: 0.002250\nTraining Epoch: 14 [3328/50000]\tLoss: 0.3192\tLR: 0.002250\nTraining Epoch: 14 [3456/50000]\tLoss: 0.3674\tLR: 0.002250\nTraining Epoch: 14 [3584/50000]\tLoss: 0.2555\tLR: 0.002250\nTraining Epoch: 14 [3712/50000]\tLoss: 0.1874\tLR: 0.002250\nTraining Epoch: 14 [3840/50000]\tLoss: 0.2402\tLR: 0.002250\nTraining Epoch: 14 [3968/50000]\tLoss: 0.2524\tLR: 0.002250\nTraining Epoch: 14 [4096/50000]\tLoss: 0.2464\tLR: 0.002250\nTraining Epoch: 14 [4224/50000]\tLoss: 0.2618\tLR: 0.002250\nTraining Epoch: 14 [4352/50000]\tLoss: 0.2277\tLR: 0.002250\nTraining Epoch: 14 [4480/50000]\tLoss: 0.1862\tLR: 0.002250\nTraining Epoch: 14 [4608/50000]\tLoss: 0.2651\tLR: 0.002250\nTraining Epoch: 14 [4736/50000]\tLoss: 0.3571\tLR: 0.002250\nTraining Epoch: 14 [4864/50000]\tLoss: 0.2316\tLR: 0.002250\nTraining Epoch: 14 [4992/50000]\tLoss: 0.2115\tLR: 0.002250\nTraining Epoch: 14 [5120/50000]\tLoss: 0.3187\tLR: 0.002250\nTraining Epoch: 14 [5248/50000]\tLoss: 0.2708\tLR: 0.002250\nTraining Epoch: 14 [5376/50000]\tLoss: 0.3631\tLR: 0.002250\nTraining Epoch: 14 [5504/50000]\tLoss: 0.3396\tLR: 0.002250\nTraining Epoch: 14 [5632/50000]\tLoss: 0.3154\tLR: 0.002250\nTraining Epoch: 14 [5760/50000]\tLoss: 0.1833\tLR: 0.002250\nTraining Epoch: 14 [5888/50000]\tLoss: 0.2275\tLR: 0.002250\nTraining Epoch: 14 [6016/50000]\tLoss: 0.4150\tLR: 0.002250\nTraining Epoch: 14 [6144/50000]\tLoss: 0.2819\tLR: 0.002250\nTraining Epoch: 14 [6272/50000]\tLoss: 0.3327\tLR: 0.002250\nTraining Epoch: 14 [6400/50000]\tLoss: 0.2344\tLR: 0.002250\nTraining Epoch: 14 [6528/50000]\tLoss: 0.2827\tLR: 0.002250\nTraining Epoch: 14 [6656/50000]\tLoss: 0.2650\tLR: 0.002250\nTraining Epoch: 14 [6784/50000]\tLoss: 0.2746\tLR: 0.002250\nTraining Epoch: 14 [6912/50000]\tLoss: 0.2921\tLR: 0.002250\nTraining Epoch: 14 [7040/50000]\tLoss: 0.1920\tLR: 0.002250\nTraining Epoch: 14 [7168/50000]\tLoss: 0.2954\tLR: 0.002250\nTraining Epoch: 14 [7296/50000]\tLoss: 0.2546\tLR: 0.002250\nTraining Epoch: 14 [7424/50000]\tLoss: 0.2260\tLR: 0.002250\nTraining Epoch: 14 [7552/50000]\tLoss: 0.3464\tLR: 0.002250\nTraining Epoch: 14 [7680/50000]\tLoss: 0.3016\tLR: 0.002250\nTraining Epoch: 14 [7808/50000]\tLoss: 0.3709\tLR: 0.002250\nTraining Epoch: 14 [7936/50000]\tLoss: 0.3683\tLR: 0.002250\nTraining Epoch: 14 [8064/50000]\tLoss: 0.2732\tLR: 0.002250\nTraining Epoch: 14 [8192/50000]\tLoss: 0.2662\tLR: 0.002250\nTraining Epoch: 14 [8320/50000]\tLoss: 0.3132\tLR: 0.002250\nTraining Epoch: 14 [8448/50000]\tLoss: 0.2796\tLR: 0.002250\nTraining Epoch: 14 [8576/50000]\tLoss: 0.2840\tLR: 0.002250\nTraining Epoch: 14 [8704/50000]\tLoss: 0.2922\tLR: 0.002250\nTraining Epoch: 14 [8832/50000]\tLoss: 0.1973\tLR: 0.002250\nTraining Epoch: 14 [8960/50000]\tLoss: 0.2170\tLR: 0.002250\nTraining Epoch: 14 [9088/50000]\tLoss: 0.1794\tLR: 0.002250\nTraining Epoch: 14 [9216/50000]\tLoss: 0.4748\tLR: 0.002250\nTraining Epoch: 14 [9344/50000]\tLoss: 0.3014\tLR: 0.002250\nTraining Epoch: 14 [9472/50000]\tLoss: 0.2672\tLR: 0.002250\nTraining Epoch: 14 [9600/50000]\tLoss: 0.2068\tLR: 0.002250\nTraining Epoch: 14 [9728/50000]\tLoss: 0.2589\tLR: 0.002250\nTraining Epoch: 14 [9856/50000]\tLoss: 0.3147\tLR: 0.002250\nTraining Epoch: 14 [9984/50000]\tLoss: 0.2833\tLR: 0.002250\nTraining Epoch: 14 [10112/50000]\tLoss: 0.3236\tLR: 0.002250\nTraining Epoch: 14 [10240/50000]\tLoss: 0.2295\tLR: 0.002250\nTraining Epoch: 14 [10368/50000]\tLoss: 0.1933\tLR: 0.002250\nTraining Epoch: 14 [10496/50000]\tLoss: 0.2831\tLR: 0.002250\nTraining Epoch: 14 [10624/50000]\tLoss: 0.2885\tLR: 0.002250\nTraining Epoch: 14 [10752/50000]\tLoss: 0.2076\tLR: 0.002250\nTraining Epoch: 14 [10880/50000]\tLoss: 0.2981\tLR: 0.002250\nTraining Epoch: 14 [11008/50000]\tLoss: 0.2442\tLR: 0.002250\nTraining Epoch: 14 [11136/50000]\tLoss: 0.3283\tLR: 0.002250\nTraining Epoch: 14 [11264/50000]\tLoss: 0.2588\tLR: 0.002250\nTraining Epoch: 14 [11392/50000]\tLoss: 0.2946\tLR: 0.002250\nTraining Epoch: 14 [11520/50000]\tLoss: 0.3459\tLR: 0.002250\nTraining Epoch: 14 [11648/50000]\tLoss: 0.2111\tLR: 0.002250\nTraining Epoch: 14 [11776/50000]\tLoss: 0.2749\tLR: 0.002250\nTraining Epoch: 14 [11904/50000]\tLoss: 0.2541\tLR: 0.002250\nTraining Epoch: 14 [12032/50000]\tLoss: 0.3558\tLR: 0.002250\nTraining Epoch: 14 [12160/50000]\tLoss: 0.3218\tLR: 0.002250\nTraining Epoch: 14 [12288/50000]\tLoss: 0.2618\tLR: 0.002250\nTraining Epoch: 14 [12416/50000]\tLoss: 0.2885\tLR: 0.002250\nTraining Epoch: 14 [12544/50000]\tLoss: 0.2161\tLR: 0.002250\nTraining Epoch: 14 [12672/50000]\tLoss: 0.2410\tLR: 0.002250\nTraining Epoch: 14 [12800/50000]\tLoss: 0.2652\tLR: 0.002250\nTraining Epoch: 14 [12928/50000]\tLoss: 0.2166\tLR: 0.002250\nTraining Epoch: 14 [13056/50000]\tLoss: 0.3134\tLR: 0.002250\nTraining Epoch: 14 [13184/50000]\tLoss: 0.1938\tLR: 0.002250\nTraining Epoch: 14 [13312/50000]\tLoss: 0.2187\tLR: 0.002250\nTraining Epoch: 14 [13440/50000]\tLoss: 0.2759\tLR: 0.002250\nTraining Epoch: 14 [13568/50000]\tLoss: 0.2020\tLR: 0.002250\nTraining Epoch: 14 [13696/50000]\tLoss: 0.2570\tLR: 0.002250\nTraining Epoch: 14 [13824/50000]\tLoss: 0.2319\tLR: 0.002250\nTraining Epoch: 14 [13952/50000]\tLoss: 0.3063\tLR: 0.002250\nTraining Epoch: 14 [14080/50000]\tLoss: 0.2304\tLR: 0.002250\nTraining Epoch: 14 [14208/50000]\tLoss: 0.2748\tLR: 0.002250\nTraining Epoch: 14 [14336/50000]\tLoss: 0.1665\tLR: 0.002250\nTraining Epoch: 14 [14464/50000]\tLoss: 0.2983\tLR: 0.002250\nTraining Epoch: 14 [14592/50000]\tLoss: 0.3160\tLR: 0.002250\nTraining Epoch: 14 [14720/50000]\tLoss: 0.2952\tLR: 0.002250\nTraining Epoch: 14 [14848/50000]\tLoss: 0.3046\tLR: 0.002250\nTraining Epoch: 14 [14976/50000]\tLoss: 0.3120\tLR: 0.002250\nTraining Epoch: 14 [15104/50000]\tLoss: 0.3206\tLR: 0.002250\nTraining Epoch: 14 [15232/50000]\tLoss: 0.2808\tLR: 0.002250\nTraining Epoch: 14 [15360/50000]\tLoss: 0.3153\tLR: 0.002250\nTraining Epoch: 14 [15488/50000]\tLoss: 0.2607\tLR: 0.002250\nTraining Epoch: 14 [15616/50000]\tLoss: 0.3810\tLR: 0.002250\nTraining Epoch: 14 [15744/50000]\tLoss: 0.1917\tLR: 0.002250\nTraining Epoch: 14 [15872/50000]\tLoss: 0.3002\tLR: 0.002250\nTraining Epoch: 14 [16000/50000]\tLoss: 0.3407\tLR: 0.002250\nTraining Epoch: 14 [16128/50000]\tLoss: 0.2484\tLR: 0.002250\nTraining Epoch: 14 [16256/50000]\tLoss: 0.1990\tLR: 0.002250\nTraining Epoch: 14 [16384/50000]\tLoss: 0.3424\tLR: 0.002250\nTraining Epoch: 14 [16512/50000]\tLoss: 0.3298\tLR: 0.002250\nTraining Epoch: 14 [16640/50000]\tLoss: 0.3003\tLR: 0.002250\nTraining Epoch: 14 [16768/50000]\tLoss: 0.2297\tLR: 0.002250\nTraining Epoch: 14 [16896/50000]\tLoss: 0.3038\tLR: 0.002250\nTraining Epoch: 14 [17024/50000]\tLoss: 0.3792\tLR: 0.002250\nTraining Epoch: 14 [17152/50000]\tLoss: 0.2487\tLR: 0.002250\nTraining Epoch: 14 [17280/50000]\tLoss: 0.3789\tLR: 0.002250\nTraining Epoch: 14 [17408/50000]\tLoss: 0.3480\tLR: 0.002250\nTraining Epoch: 14 [17536/50000]\tLoss: 0.2869\tLR: 0.002250\nTraining Epoch: 14 [17664/50000]\tLoss: 0.3902\tLR: 0.002250\nTraining Epoch: 14 [17792/50000]\tLoss: 0.3128\tLR: 0.002250\nTraining Epoch: 14 [17920/50000]\tLoss: 0.3376\tLR: 0.002250\nTraining Epoch: 14 [18048/50000]\tLoss: 0.2741\tLR: 0.002250\nTraining Epoch: 14 [18176/50000]\tLoss: 0.2510\tLR: 0.002250\nTraining Epoch: 14 [18304/50000]\tLoss: 0.2077\tLR: 0.002250\nTraining Epoch: 14 [18432/50000]\tLoss: 0.1874\tLR: 0.002250\nTraining Epoch: 14 [18560/50000]\tLoss: 0.3979\tLR: 0.002250\nTraining Epoch: 14 [18688/50000]\tLoss: 0.2853\tLR: 0.002250\nTraining Epoch: 14 [18816/50000]\tLoss: 0.1857\tLR: 0.002250\nTraining Epoch: 14 [18944/50000]\tLoss: 0.2272\tLR: 0.002250\nTraining Epoch: 14 [19072/50000]\tLoss: 0.2973\tLR: 0.002250\nTraining Epoch: 14 [19200/50000]\tLoss: 0.3585\tLR: 0.002250\nTraining Epoch: 14 [19328/50000]\tLoss: 0.2970\tLR: 0.002250\nTraining Epoch: 14 [19456/50000]\tLoss: 0.2338\tLR: 0.002250\nTraining Epoch: 14 [19584/50000]\tLoss: 0.2266\tLR: 0.002250\nTraining Epoch: 14 [19712/50000]\tLoss: 0.2820\tLR: 0.002250\nTraining Epoch: 14 [19840/50000]\tLoss: 0.2783\tLR: 0.002250\nTraining Epoch: 14 [19968/50000]\tLoss: 0.3633\tLR: 0.002250\nTraining Epoch: 14 [20096/50000]\tLoss: 0.2399\tLR: 0.002250\nTraining Epoch: 14 [20224/50000]\tLoss: 0.2323\tLR: 0.002250\nTraining Epoch: 14 [20352/50000]\tLoss: 0.2091\tLR: 0.002250\nTraining Epoch: 14 [20480/50000]\tLoss: 0.2151\tLR: 0.002250\nTraining Epoch: 14 [20608/50000]\tLoss: 0.3274\tLR: 0.002250\nTraining Epoch: 14 [20736/50000]\tLoss: 0.3969\tLR: 0.002250\nTraining Epoch: 14 [20864/50000]\tLoss: 0.2275\tLR: 0.002250\nTraining Epoch: 14 [20992/50000]\tLoss: 0.1934\tLR: 0.002250\nTraining Epoch: 14 [21120/50000]\tLoss: 0.2146\tLR: 0.002250\nTraining Epoch: 14 [21248/50000]\tLoss: 0.3488\tLR: 0.002250\nTraining Epoch: 14 [21376/50000]\tLoss: 0.2080\tLR: 0.002250\nTraining Epoch: 14 [21504/50000]\tLoss: 0.3284\tLR: 0.002250\nTraining Epoch: 14 [21632/50000]\tLoss: 0.2720\tLR: 0.002250\nTraining Epoch: 14 [21760/50000]\tLoss: 0.3207\tLR: 0.002250\nTraining Epoch: 14 [21888/50000]\tLoss: 0.3567\tLR: 0.002250\nTraining Epoch: 14 [22016/50000]\tLoss: 0.2418\tLR: 0.002250\nTraining Epoch: 14 [22144/50000]\tLoss: 0.1711\tLR: 0.002250\nTraining Epoch: 14 [22272/50000]\tLoss: 0.2500\tLR: 0.002250\nTraining Epoch: 14 [22400/50000]\tLoss: 0.3201\tLR: 0.002250\nTraining Epoch: 14 [22528/50000]\tLoss: 0.2104\tLR: 0.002250\nTraining Epoch: 14 [22656/50000]\tLoss: 0.3588\tLR: 0.002250\nTraining Epoch: 14 [22784/50000]\tLoss: 0.4180\tLR: 0.002250\nTraining Epoch: 14 [22912/50000]\tLoss: 0.3247\tLR: 0.002250\nTraining Epoch: 14 [23040/50000]\tLoss: 0.3507\tLR: 0.002250\nTraining Epoch: 14 [23168/50000]\tLoss: 0.4420\tLR: 0.002250\nTraining Epoch: 14 [23296/50000]\tLoss: 0.2879\tLR: 0.002250\nTraining Epoch: 14 [23424/50000]\tLoss: 0.2836\tLR: 0.002250\nTraining Epoch: 14 [23552/50000]\tLoss: 0.3219\tLR: 0.002250\nTraining Epoch: 14 [23680/50000]\tLoss: 0.2571\tLR: 0.002250\nTraining Epoch: 14 [23808/50000]\tLoss: 0.2475\tLR: 0.002250\nTraining Epoch: 14 [23936/50000]\tLoss: 0.2497\tLR: 0.002250\nTraining Epoch: 14 [24064/50000]\tLoss: 0.2920\tLR: 0.002250\nTraining Epoch: 14 [24192/50000]\tLoss: 0.2459\tLR: 0.002250\nTraining Epoch: 14 [24320/50000]\tLoss: 0.2940\tLR: 0.002250\nTraining Epoch: 14 [24448/50000]\tLoss: 0.1485\tLR: 0.002250\nTraining Epoch: 14 [24576/50000]\tLoss: 0.3951\tLR: 0.002250\nTraining Epoch: 14 [24704/50000]\tLoss: 0.4084\tLR: 0.002250\nTraining Epoch: 14 [24832/50000]\tLoss: 0.2906\tLR: 0.002250\nTraining Epoch: 14 [24960/50000]\tLoss: 0.2688\tLR: 0.002250\nTraining Epoch: 14 [25088/50000]\tLoss: 0.2022\tLR: 0.002250\nTraining Epoch: 14 [25216/50000]\tLoss: 0.2936\tLR: 0.002250\nTraining Epoch: 14 [25344/50000]\tLoss: 0.3089\tLR: 0.002250\nTraining Epoch: 14 [25472/50000]\tLoss: 0.3005\tLR: 0.002250\nTraining Epoch: 14 [25600/50000]\tLoss: 0.2001\tLR: 0.002250\nTraining Epoch: 14 [25728/50000]\tLoss: 0.3076\tLR: 0.002250\nTraining Epoch: 14 [25856/50000]\tLoss: 0.2261\tLR: 0.002250\nTraining Epoch: 14 [25984/50000]\tLoss: 0.2018\tLR: 0.002250\nTraining Epoch: 14 [26112/50000]\tLoss: 0.3021\tLR: 0.002250\nTraining Epoch: 14 [26240/50000]\tLoss: 0.3204\tLR: 0.002250\nTraining Epoch: 14 [26368/50000]\tLoss: 0.2379\tLR: 0.002250\nTraining Epoch: 14 [26496/50000]\tLoss: 0.2277\tLR: 0.002250\nTraining Epoch: 14 [26624/50000]\tLoss: 0.3671\tLR: 0.002250\nTraining Epoch: 14 [26752/50000]\tLoss: 0.2282\tLR: 0.002250\nTraining Epoch: 14 [26880/50000]\tLoss: 0.2296\tLR: 0.002250\nTraining Epoch: 14 [27008/50000]\tLoss: 0.3014\tLR: 0.002250\nTraining Epoch: 14 [27136/50000]\tLoss: 0.2838\tLR: 0.002250\nTraining Epoch: 14 [27264/50000]\tLoss: 0.2586\tLR: 0.002250\nTraining Epoch: 14 [27392/50000]\tLoss: 0.2861\tLR: 0.002250\nTraining Epoch: 14 [27520/50000]\tLoss: 0.2529\tLR: 0.002250\nTraining Epoch: 14 [27648/50000]\tLoss: 0.2678\tLR: 0.002250\nTraining Epoch: 14 [27776/50000]\tLoss: 0.2281\tLR: 0.002250\nTraining Epoch: 14 [27904/50000]\tLoss: 0.2821\tLR: 0.002250\nTraining Epoch: 14 [28032/50000]\tLoss: 0.2449\tLR: 0.002250\nTraining Epoch: 14 [28160/50000]\tLoss: 0.2478\tLR: 0.002250\nTraining Epoch: 14 [28288/50000]\tLoss: 0.2380\tLR: 0.002250\nTraining Epoch: 14 [28416/50000]\tLoss: 0.1899\tLR: 0.002250\nTraining Epoch: 14 [28544/50000]\tLoss: 0.2322\tLR: 0.002250\nTraining Epoch: 14 [28672/50000]\tLoss: 0.2317\tLR: 0.002250\nTraining Epoch: 14 [28800/50000]\tLoss: 0.2874\tLR: 0.002250\nTraining Epoch: 14 [28928/50000]\tLoss: 0.2503\tLR: 0.002250\nTraining Epoch: 14 [29056/50000]\tLoss: 0.2713\tLR: 0.002250\nTraining Epoch: 14 [29184/50000]\tLoss: 0.3236\tLR: 0.002250\nTraining Epoch: 14 [29312/50000]\tLoss: 0.3523\tLR: 0.002250\nTraining Epoch: 14 [29440/50000]\tLoss: 0.2372\tLR: 0.002250\nTraining Epoch: 14 [29568/50000]\tLoss: 0.1964\tLR: 0.002250\nTraining Epoch: 14 [29696/50000]\tLoss: 0.2806\tLR: 0.002250\nTraining Epoch: 14 [29824/50000]\tLoss: 0.3717\tLR: 0.002250\nTraining Epoch: 14 [29952/50000]\tLoss: 0.2654\tLR: 0.002250\nTraining Epoch: 14 [30080/50000]\tLoss: 0.3496\tLR: 0.002250\nTraining Epoch: 14 [30208/50000]\tLoss: 0.2899\tLR: 0.002250\nTraining Epoch: 14 [30336/50000]\tLoss: 0.2545\tLR: 0.002250\nTraining Epoch: 14 [30464/50000]\tLoss: 0.2417\tLR: 0.002250\nTraining Epoch: 14 [30592/50000]\tLoss: 0.3201\tLR: 0.002250\nTraining Epoch: 14 [30720/50000]\tLoss: 0.3831\tLR: 0.002250\nTraining Epoch: 14 [30848/50000]\tLoss: 0.3634\tLR: 0.002250\nTraining Epoch: 14 [30976/50000]\tLoss: 0.2080\tLR: 0.002250\nTraining Epoch: 14 [31104/50000]\tLoss: 0.2526\tLR: 0.002250\nTraining Epoch: 14 [31232/50000]\tLoss: 0.3324\tLR: 0.002250\nTraining Epoch: 14 [31360/50000]\tLoss: 0.2616\tLR: 0.002250\nTraining Epoch: 14 [31488/50000]\tLoss: 0.2669\tLR: 0.002250\nTraining Epoch: 14 [31616/50000]\tLoss: 0.3281\tLR: 0.002250\nTraining Epoch: 14 [31744/50000]\tLoss: 0.2741\tLR: 0.002250\nTraining Epoch: 14 [31872/50000]\tLoss: 0.1925\tLR: 0.002250\nTraining Epoch: 14 [32000/50000]\tLoss: 0.2603\tLR: 0.002250\nTraining Epoch: 14 [32128/50000]\tLoss: 0.1601\tLR: 0.002250\nTraining Epoch: 14 [32256/50000]\tLoss: 0.2232\tLR: 0.002250\nTraining Epoch: 14 [32384/50000]\tLoss: 0.2947\tLR: 0.002250\nTraining Epoch: 14 [32512/50000]\tLoss: 0.2328\tLR: 0.002250\nTraining Epoch: 14 [32640/50000]\tLoss: 0.2649\tLR: 0.002250\nTraining Epoch: 14 [32768/50000]\tLoss: 0.2910\tLR: 0.002250\nTraining Epoch: 14 [32896/50000]\tLoss: 0.2677\tLR: 0.002250\nTraining Epoch: 14 [33024/50000]\tLoss: 0.2445\tLR: 0.002250\nTraining Epoch: 14 [33152/50000]\tLoss: 0.4101\tLR: 0.002250\nTraining Epoch: 14 [33280/50000]\tLoss: 0.3214\tLR: 0.002250\nTraining Epoch: 14 [33408/50000]\tLoss: 0.2869\tLR: 0.002250\nTraining Epoch: 14 [33536/50000]\tLoss: 0.1837\tLR: 0.002250\nTraining Epoch: 14 [33664/50000]\tLoss: 0.2659\tLR: 0.002250\nTraining Epoch: 14 [33792/50000]\tLoss: 0.2388\tLR: 0.002250\nTraining Epoch: 14 [33920/50000]\tLoss: 0.2109\tLR: 0.002250\nTraining Epoch: 14 [34048/50000]\tLoss: 0.3574\tLR: 0.002250\nTraining Epoch: 14 [34176/50000]\tLoss: 0.2892\tLR: 0.002250\nTraining Epoch: 14 [34304/50000]\tLoss: 0.2077\tLR: 0.002250\nTraining Epoch: 14 [34432/50000]\tLoss: 0.1940\tLR: 0.002250\nTraining Epoch: 14 [34560/50000]\tLoss: 0.3072\tLR: 0.002250\nTraining Epoch: 14 [34688/50000]\tLoss: 0.2230\tLR: 0.002250\nTraining Epoch: 14 [34816/50000]\tLoss: 0.2504\tLR: 0.002250\nTraining Epoch: 14 [34944/50000]\tLoss: 0.2271\tLR: 0.002250\nTraining Epoch: 14 [35072/50000]\tLoss: 0.3462\tLR: 0.002250\nTraining Epoch: 14 [35200/50000]\tLoss: 0.3095\tLR: 0.002250\nTraining Epoch: 14 [35328/50000]\tLoss: 0.2499\tLR: 0.002250\nTraining Epoch: 14 [35456/50000]\tLoss: 0.1762\tLR: 0.002250\nTraining Epoch: 14 [35584/50000]\tLoss: 0.2625\tLR: 0.002250\nTraining Epoch: 14 [35712/50000]\tLoss: 0.3424\tLR: 0.002250\nTraining Epoch: 14 [35840/50000]\tLoss: 0.3367\tLR: 0.002250\nTraining Epoch: 14 [35968/50000]\tLoss: 0.2195\tLR: 0.002250\nTraining Epoch: 14 [36096/50000]\tLoss: 0.2703\tLR: 0.002250\nTraining Epoch: 14 [36224/50000]\tLoss: 0.3493\tLR: 0.002250\nTraining Epoch: 14 [36352/50000]\tLoss: 0.2490\tLR: 0.002250\nTraining Epoch: 14 [36480/50000]\tLoss: 0.2966\tLR: 0.002250\nTraining Epoch: 14 [36608/50000]\tLoss: 0.3111\tLR: 0.002250\nTraining Epoch: 14 [36736/50000]\tLoss: 0.3391\tLR: 0.002250\nTraining Epoch: 14 [36864/50000]\tLoss: 0.2573\tLR: 0.002250\nTraining Epoch: 14 [36992/50000]\tLoss: 0.2305\tLR: 0.002250\nTraining Epoch: 14 [37120/50000]\tLoss: 0.2552\tLR: 0.002250\nTraining Epoch: 14 [37248/50000]\tLoss: 0.1972\tLR: 0.002250\nTraining Epoch: 14 [37376/50000]\tLoss: 0.2495\tLR: 0.002250\nTraining Epoch: 14 [37504/50000]\tLoss: 0.2086\tLR: 0.002250\nTraining Epoch: 14 [37632/50000]\tLoss: 0.2526\tLR: 0.002250\nTraining Epoch: 14 [37760/50000]\tLoss: 0.2460\tLR: 0.002250\nTraining Epoch: 14 [37888/50000]\tLoss: 0.3808\tLR: 0.002250\nTraining Epoch: 14 [38016/50000]\tLoss: 0.4227\tLR: 0.002250\nTraining Epoch: 14 [38144/50000]\tLoss: 0.2707\tLR: 0.002250\nTraining Epoch: 14 [38272/50000]\tLoss: 0.3045\tLR: 0.002250\nTraining Epoch: 14 [38400/50000]\tLoss: 0.3586\tLR: 0.002250\nTraining Epoch: 14 [38528/50000]\tLoss: 0.2133\tLR: 0.002250\nTraining Epoch: 14 [38656/50000]\tLoss: 0.2990\tLR: 0.002250\nTraining Epoch: 14 [38784/50000]\tLoss: 0.3812\tLR: 0.002250\nTraining Epoch: 14 [38912/50000]\tLoss: 0.2357\tLR: 0.002250\nTraining Epoch: 14 [39040/50000]\tLoss: 0.2807\tLR: 0.002250\nTraining Epoch: 14 [39168/50000]\tLoss: 0.4257\tLR: 0.002250\nTraining Epoch: 14 [39296/50000]\tLoss: 0.1841\tLR: 0.002250\nTraining Epoch: 14 [39424/50000]\tLoss: 0.1962\tLR: 0.002250\nTraining Epoch: 14 [39552/50000]\tLoss: 0.3711\tLR: 0.002250\nTraining Epoch: 14 [39680/50000]\tLoss: 0.2799\tLR: 0.002250\nTraining Epoch: 14 [39808/50000]\tLoss: 0.3511\tLR: 0.002250\nTraining Epoch: 14 [39936/50000]\tLoss: 0.3448\tLR: 0.002250\nTraining Epoch: 14 [40064/50000]\tLoss: 0.4341\tLR: 0.002250\nTraining Epoch: 14 [40192/50000]\tLoss: 0.3644\tLR: 0.002250\nTraining Epoch: 14 [40320/50000]\tLoss: 0.2951\tLR: 0.002250\nTraining Epoch: 14 [40448/50000]\tLoss: 0.2104\tLR: 0.002250\nTraining Epoch: 14 [40576/50000]\tLoss: 0.3119\tLR: 0.002250\nTraining Epoch: 14 [40704/50000]\tLoss: 0.3137\tLR: 0.002250\nTraining Epoch: 14 [40832/50000]\tLoss: 0.2871\tLR: 0.002250\nTraining Epoch: 14 [40960/50000]\tLoss: 0.2389\tLR: 0.002250\nTraining Epoch: 14 [41088/50000]\tLoss: 0.3215\tLR: 0.002250\nTraining Epoch: 14 [41216/50000]\tLoss: 0.2942\tLR: 0.002250\nTraining Epoch: 14 [41344/50000]\tLoss: 0.2973\tLR: 0.002250\nTraining Epoch: 14 [41472/50000]\tLoss: 0.1772\tLR: 0.002250\nTraining Epoch: 14 [41600/50000]\tLoss: 0.2545\tLR: 0.002250\nTraining Epoch: 14 [41728/50000]\tLoss: 0.1946\tLR: 0.002250\nTraining Epoch: 14 [41856/50000]\tLoss: 0.2884\tLR: 0.002250\nTraining Epoch: 14 [41984/50000]\tLoss: 0.2905\tLR: 0.002250\nTraining Epoch: 14 [42112/50000]\tLoss: 0.2541\tLR: 0.002250\nTraining Epoch: 14 [42240/50000]\tLoss: 0.2265\tLR: 0.002250\nTraining Epoch: 14 [42368/50000]\tLoss: 0.2529\tLR: 0.002250\nTraining Epoch: 14 [42496/50000]\tLoss: 0.2972\tLR: 0.002250\nTraining Epoch: 14 [42624/50000]\tLoss: 0.4064\tLR: 0.002250\nTraining Epoch: 14 [42752/50000]\tLoss: 0.3261\tLR: 0.002250\nTraining Epoch: 14 [42880/50000]\tLoss: 0.2158\tLR: 0.002250\nTraining Epoch: 14 [43008/50000]\tLoss: 0.2548\tLR: 0.002250\nTraining Epoch: 14 [43136/50000]\tLoss: 0.1456\tLR: 0.002250\nTraining Epoch: 14 [43264/50000]\tLoss: 0.3262\tLR: 0.002250\nTraining Epoch: 14 [43392/50000]\tLoss: 0.2127\tLR: 0.002250\nTraining Epoch: 14 [43520/50000]\tLoss: 0.2588\tLR: 0.002250\nTraining Epoch: 14 [43648/50000]\tLoss: 0.3561\tLR: 0.002250\nTraining Epoch: 14 [43776/50000]\tLoss: 0.2213\tLR: 0.002250\nTraining Epoch: 14 [43904/50000]\tLoss: 0.4216\tLR: 0.002250\nTraining Epoch: 14 [44032/50000]\tLoss: 0.3494\tLR: 0.002250\nTraining Epoch: 14 [44160/50000]\tLoss: 0.2034\tLR: 0.002250\nTraining Epoch: 14 [44288/50000]\tLoss: 0.2692\tLR: 0.002250\nTraining Epoch: 14 [44416/50000]\tLoss: 0.2375\tLR: 0.002250\nTraining Epoch: 14 [44544/50000]\tLoss: 0.3003\tLR: 0.002250\nTraining Epoch: 14 [44672/50000]\tLoss: 0.2929\tLR: 0.002250\nTraining Epoch: 14 [44800/50000]\tLoss: 0.2676\tLR: 0.002250\nTraining Epoch: 14 [44928/50000]\tLoss: 0.2272\tLR: 0.002250\nTraining Epoch: 14 [45056/50000]\tLoss: 0.3414\tLR: 0.002250\nTraining Epoch: 14 [45184/50000]\tLoss: 0.2013\tLR: 0.002250\nTraining Epoch: 14 [45312/50000]\tLoss: 0.2662\tLR: 0.002250\nTraining Epoch: 14 [45440/50000]\tLoss: 0.2147\tLR: 0.002250\nTraining Epoch: 14 [45568/50000]\tLoss: 0.3140\tLR: 0.002250\nTraining Epoch: 14 [45696/50000]\tLoss: 0.4212\tLR: 0.002250\nTraining Epoch: 14 [45824/50000]\tLoss: 0.2459\tLR: 0.002250\nTraining Epoch: 14 [45952/50000]\tLoss: 0.2901\tLR: 0.002250\nTraining Epoch: 14 [46080/50000]\tLoss: 0.2216\tLR: 0.002250\nTraining Epoch: 14 [46208/50000]\tLoss: 0.2308\tLR: 0.002250\nTraining Epoch: 14 [46336/50000]\tLoss: 0.2814\tLR: 0.002250\nTraining Epoch: 14 [46464/50000]\tLoss: 0.1542\tLR: 0.002250\nTraining Epoch: 14 [46592/50000]\tLoss: 0.3181\tLR: 0.002250\nTraining Epoch: 14 [46720/50000]\tLoss: 0.3345\tLR: 0.002250\nTraining Epoch: 14 [46848/50000]\tLoss: 0.2631\tLR: 0.002250\nTraining Epoch: 14 [46976/50000]\tLoss: 0.1906\tLR: 0.002250\nTraining Epoch: 14 [47104/50000]\tLoss: 0.1869\tLR: 0.002250\nTraining Epoch: 14 [47232/50000]\tLoss: 0.3052\tLR: 0.002250\nTraining Epoch: 14 [47360/50000]\tLoss: 0.3098\tLR: 0.002250\nTraining Epoch: 14 [47488/50000]\tLoss: 0.1921\tLR: 0.002250\nTraining Epoch: 14 [47616/50000]\tLoss: 0.2318\tLR: 0.002250\nTraining Epoch: 14 [47744/50000]\tLoss: 0.2260\tLR: 0.002250\nTraining Epoch: 14 [47872/50000]\tLoss: 0.2855\tLR: 0.002250\nTraining Epoch: 14 [48000/50000]\tLoss: 0.2692\tLR: 0.002250\nTraining Epoch: 14 [48128/50000]\tLoss: 0.2400\tLR: 0.002250\nTraining Epoch: 14 [48256/50000]\tLoss: 0.2119\tLR: 0.002250\nTraining Epoch: 14 [48384/50000]\tLoss: 0.2652\tLR: 0.002250\nTraining Epoch: 14 [48512/50000]\tLoss: 0.3021\tLR: 0.002250\nTraining Epoch: 14 [48640/50000]\tLoss: 0.3722\tLR: 0.002250\nTraining Epoch: 14 [48768/50000]\tLoss: 0.3095\tLR: 0.002250\nTraining Epoch: 14 [48896/50000]\tLoss: 0.3156\tLR: 0.002250\nTraining Epoch: 14 [49024/50000]\tLoss: 0.3038\tLR: 0.002250\nTraining Epoch: 14 [49152/50000]\tLoss: 0.2954\tLR: 0.002250\nTraining Epoch: 14 [49280/50000]\tLoss: 0.2577\tLR: 0.002250\nTraining Epoch: 14 [49408/50000]\tLoss: 0.2603\tLR: 0.002250\nTraining Epoch: 14 [49536/50000]\tLoss: 0.2672\tLR: 0.002250\nTraining Epoch: 14 [49664/50000]\tLoss: 0.1627\tLR: 0.002250\nTraining Epoch: 14 [49792/50000]\tLoss: 0.2277\tLR: 0.002250\nTraining Epoch: 14 [49920/50000]\tLoss: 0.2318\tLR: 0.002250\nTraining Epoch: 14 [50000/50000]\tLoss: 0.4251\tLR: 0.002250\nTest set: Average loss: 0.0025, Accuracy: 0.8943\n\nTraining Epoch: 15 [128/50000]\tLoss: 0.2248\tLR: 0.002250\nTraining Epoch: 15 [256/50000]\tLoss: 0.2546\tLR: 0.002250\nTraining Epoch: 15 [384/50000]\tLoss: 0.2879\tLR: 0.002250\nTraining Epoch: 15 [512/50000]\tLoss: 0.3005\tLR: 0.002250\nTraining Epoch: 15 [640/50000]\tLoss: 0.2657\tLR: 0.002250\nTraining Epoch: 15 [768/50000]\tLoss: 0.2212\tLR: 0.002250\nTraining Epoch: 15 [896/50000]\tLoss: 0.3092\tLR: 0.002250\nTraining Epoch: 15 [1024/50000]\tLoss: 0.2598\tLR: 0.002250\nTraining Epoch: 15 [1152/50000]\tLoss: 0.2488\tLR: 0.002250\nTraining Epoch: 15 [1280/50000]\tLoss: 0.2675\tLR: 0.002250\nTraining Epoch: 15 [1408/50000]\tLoss: 0.2145\tLR: 0.002250\nTraining Epoch: 15 [1536/50000]\tLoss: 0.2292\tLR: 0.002250\nTraining Epoch: 15 [1664/50000]\tLoss: 0.2502\tLR: 0.002250\nTraining Epoch: 15 [1792/50000]\tLoss: 0.2630\tLR: 0.002250\nTraining Epoch: 15 [1920/50000]\tLoss: 0.4822\tLR: 0.002250\nTraining Epoch: 15 [2048/50000]\tLoss: 0.2085\tLR: 0.002250\nTraining Epoch: 15 [2176/50000]\tLoss: 0.2257\tLR: 0.002250\nTraining Epoch: 15 [2304/50000]\tLoss: 0.3349\tLR: 0.002250\nTraining Epoch: 15 [2432/50000]\tLoss: 0.2748\tLR: 0.002250\nTraining Epoch: 15 [2560/50000]\tLoss: 0.3274\tLR: 0.002250\nTraining Epoch: 15 [2688/50000]\tLoss: 0.2116\tLR: 0.002250\nTraining Epoch: 15 [2816/50000]\tLoss: 0.2010\tLR: 0.002250\nTraining Epoch: 15 [2944/50000]\tLoss: 0.2754\tLR: 0.002250\nTraining Epoch: 15 [3072/50000]\tLoss: 0.1801\tLR: 0.002250\nTraining Epoch: 15 [3200/50000]\tLoss: 0.2259\tLR: 0.002250\nTraining Epoch: 15 [3328/50000]\tLoss: 0.1983\tLR: 0.002250\nTraining Epoch: 15 [3456/50000]\tLoss: 0.2915\tLR: 0.002250\nTraining Epoch: 15 [3584/50000]\tLoss: 0.1900\tLR: 0.002250\nTraining Epoch: 15 [3712/50000]\tLoss: 0.3736\tLR: 0.002250\nTraining Epoch: 15 [3840/50000]\tLoss: 0.2093\tLR: 0.002250\nTraining Epoch: 15 [3968/50000]\tLoss: 0.3317\tLR: 0.002250\nTraining Epoch: 15 [4096/50000]\tLoss: 0.3795\tLR: 0.002250\nTraining Epoch: 15 [4224/50000]\tLoss: 0.3295\tLR: 0.002250\nTraining Epoch: 15 [4352/50000]\tLoss: 0.2299\tLR: 0.002250\nTraining Epoch: 15 [4480/50000]\tLoss: 0.3119\tLR: 0.002250\nTraining Epoch: 15 [4608/50000]\tLoss: 0.2859\tLR: 0.002250\nTraining Epoch: 15 [4736/50000]\tLoss: 0.1782\tLR: 0.002250\nTraining Epoch: 15 [4864/50000]\tLoss: 0.2500\tLR: 0.002250\nTraining Epoch: 15 [4992/50000]\tLoss: 0.2473\tLR: 0.002250\nTraining Epoch: 15 [5120/50000]\tLoss: 0.2189\tLR: 0.002250\nTraining Epoch: 15 [5248/50000]\tLoss: 0.2384\tLR: 0.002250\nTraining Epoch: 15 [5376/50000]\tLoss: 0.1778\tLR: 0.002250\nTraining Epoch: 15 [5504/50000]\tLoss: 0.2490\tLR: 0.002250\nTraining Epoch: 15 [5632/50000]\tLoss: 0.3185\tLR: 0.002250\nTraining Epoch: 15 [5760/50000]\tLoss: 0.3013\tLR: 0.002250\nTraining Epoch: 15 [5888/50000]\tLoss: 0.2207\tLR: 0.002250\nTraining Epoch: 15 [6016/50000]\tLoss: 0.2829\tLR: 0.002250\nTraining Epoch: 15 [6144/50000]\tLoss: 0.3033\tLR: 0.002250\nTraining Epoch: 15 [6272/50000]\tLoss: 0.2587\tLR: 0.002250\nTraining Epoch: 15 [6400/50000]\tLoss: 0.2948\tLR: 0.002250\nTraining Epoch: 15 [6528/50000]\tLoss: 0.2256\tLR: 0.002250\nTraining Epoch: 15 [6656/50000]\tLoss: 0.2316\tLR: 0.002250\nTraining Epoch: 15 [6784/50000]\tLoss: 0.2443\tLR: 0.002250\nTraining Epoch: 15 [6912/50000]\tLoss: 0.3491\tLR: 0.002250\nTraining Epoch: 15 [7040/50000]\tLoss: 0.2094\tLR: 0.002250\nTraining Epoch: 15 [7168/50000]\tLoss: 0.3364\tLR: 0.002250\nTraining Epoch: 15 [7296/50000]\tLoss: 0.2544\tLR: 0.002250\nTraining Epoch: 15 [7424/50000]\tLoss: 0.1487\tLR: 0.002250\nTraining Epoch: 15 [7552/50000]\tLoss: 0.3550\tLR: 0.002250\nTraining Epoch: 15 [7680/50000]\tLoss: 0.2767\tLR: 0.002250\nTraining Epoch: 15 [7808/50000]\tLoss: 0.2629\tLR: 0.002250\nTraining Epoch: 15 [7936/50000]\tLoss: 0.3304\tLR: 0.002250\nTraining Epoch: 15 [8064/50000]\tLoss: 0.3372\tLR: 0.002250\nTraining Epoch: 15 [8192/50000]\tLoss: 0.3274\tLR: 0.002250\nTraining Epoch: 15 [8320/50000]\tLoss: 0.1988\tLR: 0.002250\nTraining Epoch: 15 [8448/50000]\tLoss: 0.3286\tLR: 0.002250\nTraining Epoch: 15 [8576/50000]\tLoss: 0.1818\tLR: 0.002250\nTraining Epoch: 15 [8704/50000]\tLoss: 0.3009\tLR: 0.002250\nTraining Epoch: 15 [8832/50000]\tLoss: 0.2660\tLR: 0.002250\nTraining Epoch: 15 [8960/50000]\tLoss: 0.2623\tLR: 0.002250\nTraining Epoch: 15 [9088/50000]\tLoss: 0.2455\tLR: 0.002250\nTraining Epoch: 15 [9216/50000]\tLoss: 0.2329\tLR: 0.002250\nTraining Epoch: 15 [9344/50000]\tLoss: 0.3426\tLR: 0.002250\nTraining Epoch: 15 [9472/50000]\tLoss: 0.2492\tLR: 0.002250\nTraining Epoch: 15 [9600/50000]\tLoss: 0.3212\tLR: 0.002250\nTraining Epoch: 15 [9728/50000]\tLoss: 0.2806\tLR: 0.002250\nTraining Epoch: 15 [9856/50000]\tLoss: 0.3166\tLR: 0.002250\nTraining Epoch: 15 [9984/50000]\tLoss: 0.1334\tLR: 0.002250\nTraining Epoch: 15 [10112/50000]\tLoss: 0.5261\tLR: 0.002250\nTraining Epoch: 15 [10240/50000]\tLoss: 0.2387\tLR: 0.002250\nTraining Epoch: 15 [10368/50000]\tLoss: 0.2237\tLR: 0.002250\nTraining Epoch: 15 [10496/50000]\tLoss: 0.2474\tLR: 0.002250\nTraining Epoch: 15 [10624/50000]\tLoss: 0.2444\tLR: 0.002250\nTraining Epoch: 15 [10752/50000]\tLoss: 0.3338\tLR: 0.002250\nTraining Epoch: 15 [10880/50000]\tLoss: 0.1924\tLR: 0.002250\nTraining Epoch: 15 [11008/50000]\tLoss: 0.1534\tLR: 0.002250\nTraining Epoch: 15 [11136/50000]\tLoss: 0.3474\tLR: 0.002250\nTraining Epoch: 15 [11264/50000]\tLoss: 0.3461\tLR: 0.002250\nTraining Epoch: 15 [11392/50000]\tLoss: 0.2127\tLR: 0.002250\nTraining Epoch: 15 [11520/50000]\tLoss: 0.2591\tLR: 0.002250\nTraining Epoch: 15 [11648/50000]\tLoss: 0.2632\tLR: 0.002250\nTraining Epoch: 15 [11776/50000]\tLoss: 0.3993\tLR: 0.002250\nTraining Epoch: 15 [11904/50000]\tLoss: 0.1827\tLR: 0.002250\nTraining Epoch: 15 [12032/50000]\tLoss: 0.1557\tLR: 0.002250\nTraining Epoch: 15 [12160/50000]\tLoss: 0.1573\tLR: 0.002250\nTraining Epoch: 15 [12288/50000]\tLoss: 0.2640\tLR: 0.002250\nTraining Epoch: 15 [12416/50000]\tLoss: 0.2384\tLR: 0.002250\nTraining Epoch: 15 [12544/50000]\tLoss: 0.2083\tLR: 0.002250\nTraining Epoch: 15 [12672/50000]\tLoss: 0.3881\tLR: 0.002250\nTraining Epoch: 15 [12800/50000]\tLoss: 0.4245\tLR: 0.002250\nTraining Epoch: 15 [12928/50000]\tLoss: 0.2565\tLR: 0.002250\nTraining Epoch: 15 [13056/50000]\tLoss: 0.2651\tLR: 0.002250\nTraining Epoch: 15 [13184/50000]\tLoss: 0.1760\tLR: 0.002250\nTraining Epoch: 15 [13312/50000]\tLoss: 0.2828\tLR: 0.002250\nTraining Epoch: 15 [13440/50000]\tLoss: 0.3904\tLR: 0.002250\nTraining Epoch: 15 [13568/50000]\tLoss: 0.3659\tLR: 0.002250\nTraining Epoch: 15 [13696/50000]\tLoss: 0.2698\tLR: 0.002250\nTraining Epoch: 15 [13824/50000]\tLoss: 0.3173\tLR: 0.002250\nTraining Epoch: 15 [13952/50000]\tLoss: 0.2334\tLR: 0.002250\nTraining Epoch: 15 [14080/50000]\tLoss: 0.2644\tLR: 0.002250\nTraining Epoch: 15 [14208/50000]\tLoss: 0.2523\tLR: 0.002250\nTraining Epoch: 15 [14336/50000]\tLoss: 0.1936\tLR: 0.002250\nTraining Epoch: 15 [14464/50000]\tLoss: 0.2678\tLR: 0.002250\nTraining Epoch: 15 [14592/50000]\tLoss: 0.3382\tLR: 0.002250\nTraining Epoch: 15 [14720/50000]\tLoss: 0.2068\tLR: 0.002250\nTraining Epoch: 15 [14848/50000]\tLoss: 0.2304\tLR: 0.002250\nTraining Epoch: 15 [14976/50000]\tLoss: 0.2983\tLR: 0.002250\nTraining Epoch: 15 [15104/50000]\tLoss: 0.2201\tLR: 0.002250\nTraining Epoch: 15 [15232/50000]\tLoss: 0.1951\tLR: 0.002250\nTraining Epoch: 15 [15360/50000]\tLoss: 0.2455\tLR: 0.002250\nTraining Epoch: 15 [15488/50000]\tLoss: 0.3373\tLR: 0.002250\nTraining Epoch: 15 [15616/50000]\tLoss: 0.1530\tLR: 0.002250\nTraining Epoch: 15 [15744/50000]\tLoss: 0.2197\tLR: 0.002250\nTraining Epoch: 15 [15872/50000]\tLoss: 0.2402\tLR: 0.002250\nTraining Epoch: 15 [16000/50000]\tLoss: 0.3085\tLR: 0.002250\nTraining Epoch: 15 [16128/50000]\tLoss: 0.2353\tLR: 0.002250\nTraining Epoch: 15 [16256/50000]\tLoss: 0.3551\tLR: 0.002250\nTraining Epoch: 15 [16384/50000]\tLoss: 0.3028\tLR: 0.002250\nTraining Epoch: 15 [16512/50000]\tLoss: 0.2945\tLR: 0.002250\nTraining Epoch: 15 [16640/50000]\tLoss: 0.2681\tLR: 0.002250\nTraining Epoch: 15 [16768/50000]\tLoss: 0.2635\tLR: 0.002250\nTraining Epoch: 15 [16896/50000]\tLoss: 0.2324\tLR: 0.002250\nTraining Epoch: 15 [17024/50000]\tLoss: 0.2740\tLR: 0.002250\nTraining Epoch: 15 [17152/50000]\tLoss: 0.3003\tLR: 0.002250\nTraining Epoch: 15 [17280/50000]\tLoss: 0.1754\tLR: 0.002250\nTraining Epoch: 15 [17408/50000]\tLoss: 0.2745\tLR: 0.002250\nTraining Epoch: 15 [17536/50000]\tLoss: 0.2729\tLR: 0.002250\nTraining Epoch: 15 [17664/50000]\tLoss: 0.2457\tLR: 0.002250\nTraining Epoch: 15 [17792/50000]\tLoss: 0.1884\tLR: 0.002250\nTraining Epoch: 15 [17920/50000]\tLoss: 0.2876\tLR: 0.002250\nTraining Epoch: 15 [18048/50000]\tLoss: 0.2477\tLR: 0.002250\nTraining Epoch: 15 [18176/50000]\tLoss: 0.2993\tLR: 0.002250\nTraining Epoch: 15 [18304/50000]\tLoss: 0.1787\tLR: 0.002250\nTraining Epoch: 15 [18432/50000]\tLoss: 0.3186\tLR: 0.002250\nTraining Epoch: 15 [18560/50000]\tLoss: 0.2520\tLR: 0.002250\nTraining Epoch: 15 [18688/50000]\tLoss: 0.2790\tLR: 0.002250\nTraining Epoch: 15 [18816/50000]\tLoss: 0.3239\tLR: 0.002250\nTraining Epoch: 15 [18944/50000]\tLoss: 0.3293\tLR: 0.002250\nTraining Epoch: 15 [19072/50000]\tLoss: 0.3038\tLR: 0.002250\nTraining Epoch: 15 [19200/50000]\tLoss: 0.2673\tLR: 0.002250\nTraining Epoch: 15 [19328/50000]\tLoss: 0.3397\tLR: 0.002250\nTraining Epoch: 15 [19456/50000]\tLoss: 0.2411\tLR: 0.002250\nTraining Epoch: 15 [19584/50000]\tLoss: 0.3548\tLR: 0.002250\nTraining Epoch: 15 [19712/50000]\tLoss: 0.2265\tLR: 0.002250\nTraining Epoch: 15 [19840/50000]\tLoss: 0.2793\tLR: 0.002250\nTraining Epoch: 15 [19968/50000]\tLoss: 0.2009\tLR: 0.002250\nTraining Epoch: 15 [20096/50000]\tLoss: 0.2206\tLR: 0.002250\nTraining Epoch: 15 [20224/50000]\tLoss: 0.4593\tLR: 0.002250\nTraining Epoch: 15 [20352/50000]\tLoss: 0.2326\tLR: 0.002250\nTraining Epoch: 15 [20480/50000]\tLoss: 0.2934\tLR: 0.002250\nTraining Epoch: 15 [20608/50000]\tLoss: 0.3094\tLR: 0.002250\nTraining Epoch: 15 [20736/50000]\tLoss: 0.2283\tLR: 0.002250\nTraining Epoch: 15 [20864/50000]\tLoss: 0.2349\tLR: 0.002250\nTraining Epoch: 15 [20992/50000]\tLoss: 0.2774\tLR: 0.002250\nTraining Epoch: 15 [21120/50000]\tLoss: 0.2660\tLR: 0.002250\nTraining Epoch: 15 [21248/50000]\tLoss: 0.3311\tLR: 0.002250\nTraining Epoch: 15 [21376/50000]\tLoss: 0.3112\tLR: 0.002250\nTraining Epoch: 15 [21504/50000]\tLoss: 0.2003\tLR: 0.002250\nTraining Epoch: 15 [21632/50000]\tLoss: 0.2244\tLR: 0.002250\nTraining Epoch: 15 [21760/50000]\tLoss: 0.2250\tLR: 0.002250\nTraining Epoch: 15 [21888/50000]\tLoss: 0.2887\tLR: 0.002250\nTraining Epoch: 15 [22016/50000]\tLoss: 0.2601\tLR: 0.002250\nTraining Epoch: 15 [22144/50000]\tLoss: 0.2219\tLR: 0.002250\nTraining Epoch: 15 [22272/50000]\tLoss: 0.4043\tLR: 0.002250\nTraining Epoch: 15 [22400/50000]\tLoss: 0.1592\tLR: 0.002250\nTraining Epoch: 15 [22528/50000]\tLoss: 0.2248\tLR: 0.002250\nTraining Epoch: 15 [22656/50000]\tLoss: 0.2222\tLR: 0.002250\nTraining Epoch: 15 [22784/50000]\tLoss: 0.2949\tLR: 0.002250\nTraining Epoch: 15 [22912/50000]\tLoss: 0.2005\tLR: 0.002250\nTraining Epoch: 15 [23040/50000]\tLoss: 0.2168\tLR: 0.002250\nTraining Epoch: 15 [23168/50000]\tLoss: 0.3612\tLR: 0.002250\nTraining Epoch: 15 [23296/50000]\tLoss: 0.3186\tLR: 0.002250\nTraining Epoch: 15 [23424/50000]\tLoss: 0.1920\tLR: 0.002250\nTraining Epoch: 15 [23552/50000]\tLoss: 0.3020\tLR: 0.002250\nTraining Epoch: 15 [23680/50000]\tLoss: 0.3044\tLR: 0.002250\nTraining Epoch: 15 [23808/50000]\tLoss: 0.3305\tLR: 0.002250\nTraining Epoch: 15 [23936/50000]\tLoss: 0.2974\tLR: 0.002250\nTraining Epoch: 15 [24064/50000]\tLoss: 0.3894\tLR: 0.002250\nTraining Epoch: 15 [24192/50000]\tLoss: 0.3686\tLR: 0.002250\nTraining Epoch: 15 [24320/50000]\tLoss: 0.2388\tLR: 0.002250\nTraining Epoch: 15 [24448/50000]\tLoss: 0.3565\tLR: 0.002250\nTraining Epoch: 15 [24576/50000]\tLoss: 0.1656\tLR: 0.002250\nTraining Epoch: 15 [24704/50000]\tLoss: 0.3621\tLR: 0.002250\nTraining Epoch: 15 [24832/50000]\tLoss: 0.1940\tLR: 0.002250\nTraining Epoch: 15 [24960/50000]\tLoss: 0.2333\tLR: 0.002250\nTraining Epoch: 15 [25088/50000]\tLoss: 0.2239\tLR: 0.002250\nTraining Epoch: 15 [25216/50000]\tLoss: 0.1958\tLR: 0.002250\nTraining Epoch: 15 [25344/50000]\tLoss: 0.2032\tLR: 0.002250\nTraining Epoch: 15 [25472/50000]\tLoss: 0.2463\tLR: 0.002250\nTraining Epoch: 15 [25600/50000]\tLoss: 0.2637\tLR: 0.002250\nTraining Epoch: 15 [25728/50000]\tLoss: 0.2268\tLR: 0.002250\nTraining Epoch: 15 [25856/50000]\tLoss: 0.2487\tLR: 0.002250\nTraining Epoch: 15 [25984/50000]\tLoss: 0.2317\tLR: 0.002250\nTraining Epoch: 15 [26112/50000]\tLoss: 0.2191\tLR: 0.002250\nTraining Epoch: 15 [26240/50000]\tLoss: 0.2730\tLR: 0.002250\nTraining Epoch: 15 [26368/50000]\tLoss: 0.3062\tLR: 0.002250\nTraining Epoch: 15 [26496/50000]\tLoss: 0.2838\tLR: 0.002250\nTraining Epoch: 15 [26624/50000]\tLoss: 0.2966\tLR: 0.002250\nTraining Epoch: 15 [26752/50000]\tLoss: 0.2770\tLR: 0.002250\nTraining Epoch: 15 [26880/50000]\tLoss: 0.3313\tLR: 0.002250\nTraining Epoch: 15 [27008/50000]\tLoss: 0.2010\tLR: 0.002250\nTraining Epoch: 15 [27136/50000]\tLoss: 0.2310\tLR: 0.002250\nTraining Epoch: 15 [27264/50000]\tLoss: 0.2898\tLR: 0.002250\nTraining Epoch: 15 [27392/50000]\tLoss: 0.2202\tLR: 0.002250\nTraining Epoch: 15 [27520/50000]\tLoss: 0.2623\tLR: 0.002250\nTraining Epoch: 15 [27648/50000]\tLoss: 0.2121\tLR: 0.002250\nTraining Epoch: 15 [27776/50000]\tLoss: 0.3547\tLR: 0.002250\nTraining Epoch: 15 [27904/50000]\tLoss: 0.1890\tLR: 0.002250\nTraining Epoch: 15 [28032/50000]\tLoss: 0.2102\tLR: 0.002250\nTraining Epoch: 15 [28160/50000]\tLoss: 0.2679\tLR: 0.002250\nTraining Epoch: 15 [28288/50000]\tLoss: 0.2819\tLR: 0.002250\nTraining Epoch: 15 [28416/50000]\tLoss: 0.2304\tLR: 0.002250\nTraining Epoch: 15 [28544/50000]\tLoss: 0.3554\tLR: 0.002250\nTraining Epoch: 15 [28672/50000]\tLoss: 0.3488\tLR: 0.002250\nTraining Epoch: 15 [28800/50000]\tLoss: 0.1943\tLR: 0.002250\nTraining Epoch: 15 [28928/50000]\tLoss: 0.2603\tLR: 0.002250\nTraining Epoch: 15 [29056/50000]\tLoss: 0.2989\tLR: 0.002250\nTraining Epoch: 15 [29184/50000]\tLoss: 0.2917\tLR: 0.002250\nTraining Epoch: 15 [29312/50000]\tLoss: 0.2360\tLR: 0.002250\nTraining Epoch: 15 [29440/50000]\tLoss: 0.3492\tLR: 0.002250\nTraining Epoch: 15 [29568/50000]\tLoss: 0.1887\tLR: 0.002250\nTraining Epoch: 15 [29696/50000]\tLoss: 0.2360\tLR: 0.002250\nTraining Epoch: 15 [29824/50000]\tLoss: 0.1728\tLR: 0.002250\nTraining Epoch: 15 [29952/50000]\tLoss: 0.4081\tLR: 0.002250\nTraining Epoch: 15 [30080/50000]\tLoss: 0.2790\tLR: 0.002250\nTraining Epoch: 15 [30208/50000]\tLoss: 0.3026\tLR: 0.002250\nTraining Epoch: 15 [30336/50000]\tLoss: 0.2989\tLR: 0.002250\nTraining Epoch: 15 [30464/50000]\tLoss: 0.1415\tLR: 0.002250\nTraining Epoch: 15 [30592/50000]\tLoss: 0.1984\tLR: 0.002250\nTraining Epoch: 15 [30720/50000]\tLoss: 0.2200\tLR: 0.002250\nTraining Epoch: 15 [30848/50000]\tLoss: 0.3362\tLR: 0.002250\nTraining Epoch: 15 [30976/50000]\tLoss: 0.4173\tLR: 0.002250\nTraining Epoch: 15 [31104/50000]\tLoss: 0.2858\tLR: 0.002250\nTraining Epoch: 15 [31232/50000]\tLoss: 0.2805\tLR: 0.002250\nTraining Epoch: 15 [31360/50000]\tLoss: 0.3206\tLR: 0.002250\nTraining Epoch: 15 [31488/50000]\tLoss: 0.3686\tLR: 0.002250\nTraining Epoch: 15 [31616/50000]\tLoss: 0.1991\tLR: 0.002250\nTraining Epoch: 15 [31744/50000]\tLoss: 0.2445\tLR: 0.002250\nTraining Epoch: 15 [31872/50000]\tLoss: 0.3265\tLR: 0.002250\nTraining Epoch: 15 [32000/50000]\tLoss: 0.2138\tLR: 0.002250\nTraining Epoch: 15 [32128/50000]\tLoss: 0.2905\tLR: 0.002250\nTraining Epoch: 15 [32256/50000]\tLoss: 0.2905\tLR: 0.002250\nTraining Epoch: 15 [32384/50000]\tLoss: 0.2864\tLR: 0.002250\nTraining Epoch: 15 [32512/50000]\tLoss: 0.3878\tLR: 0.002250\nTraining Epoch: 15 [32640/50000]\tLoss: 0.2695\tLR: 0.002250\nTraining Epoch: 15 [32768/50000]\tLoss: 0.3160\tLR: 0.002250\nTraining Epoch: 15 [32896/50000]\tLoss: 0.2217\tLR: 0.002250\nTraining Epoch: 15 [33024/50000]\tLoss: 0.2749\tLR: 0.002250\nTraining Epoch: 15 [33152/50000]\tLoss: 0.2711\tLR: 0.002250\nTraining Epoch: 15 [33280/50000]\tLoss: 0.3137\tLR: 0.002250\nTraining Epoch: 15 [33408/50000]\tLoss: 0.2823\tLR: 0.002250\nTraining Epoch: 15 [33536/50000]\tLoss: 0.1169\tLR: 0.002250\nTraining Epoch: 15 [33664/50000]\tLoss: 0.2014\tLR: 0.002250\nTraining Epoch: 15 [33792/50000]\tLoss: 0.2769\tLR: 0.002250\nTraining Epoch: 15 [33920/50000]\tLoss: 0.2662\tLR: 0.002250\nTraining Epoch: 15 [34048/50000]\tLoss: 0.2978\tLR: 0.002250\nTraining Epoch: 15 [34176/50000]\tLoss: 0.1679\tLR: 0.002250\nTraining Epoch: 15 [34304/50000]\tLoss: 0.2499\tLR: 0.002250\nTraining Epoch: 15 [34432/50000]\tLoss: 0.2905\tLR: 0.002250\nTraining Epoch: 15 [34560/50000]\tLoss: 0.2223\tLR: 0.002250\nTraining Epoch: 15 [34688/50000]\tLoss: 0.3137\tLR: 0.002250\nTraining Epoch: 15 [34816/50000]\tLoss: 0.2933\tLR: 0.002250\nTraining Epoch: 15 [34944/50000]\tLoss: 0.1544\tLR: 0.002250\nTraining Epoch: 15 [35072/50000]\tLoss: 0.1495\tLR: 0.002250\nTraining Epoch: 15 [35200/50000]\tLoss: 0.3059\tLR: 0.002250\nTraining Epoch: 15 [35328/50000]\tLoss: 0.2397\tLR: 0.002250\nTraining Epoch: 15 [35456/50000]\tLoss: 0.2496\tLR: 0.002250\nTraining Epoch: 15 [35584/50000]\tLoss: 0.2623\tLR: 0.002250\nTraining Epoch: 15 [35712/50000]\tLoss: 0.2812\tLR: 0.002250\nTraining Epoch: 15 [35840/50000]\tLoss: 0.2746\tLR: 0.002250\nTraining Epoch: 15 [35968/50000]\tLoss: 0.3067\tLR: 0.002250\nTraining Epoch: 15 [36096/50000]\tLoss: 0.2163\tLR: 0.002250\nTraining Epoch: 15 [36224/50000]\tLoss: 0.2100\tLR: 0.002250\nTraining Epoch: 15 [36352/50000]\tLoss: 0.2631\tLR: 0.002250\nTraining Epoch: 15 [36480/50000]\tLoss: 0.2308\tLR: 0.002250\nTraining Epoch: 15 [36608/50000]\tLoss: 0.3216\tLR: 0.002250\nTraining Epoch: 15 [36736/50000]\tLoss: 0.3058\tLR: 0.002250\nTraining Epoch: 15 [36864/50000]\tLoss: 0.1692\tLR: 0.002250\nTraining Epoch: 15 [36992/50000]\tLoss: 0.3041\tLR: 0.002250\nTraining Epoch: 15 [37120/50000]\tLoss: 0.2764\tLR: 0.002250\nTraining Epoch: 15 [37248/50000]\tLoss: 0.3288\tLR: 0.002250\nTraining Epoch: 15 [37376/50000]\tLoss: 0.3654\tLR: 0.002250\nTraining Epoch: 15 [37504/50000]\tLoss: 0.2991\tLR: 0.002250\nTraining Epoch: 15 [37632/50000]\tLoss: 0.2803\tLR: 0.002250\nTraining Epoch: 15 [37760/50000]\tLoss: 0.3128\tLR: 0.002250\nTraining Epoch: 15 [37888/50000]\tLoss: 0.2947\tLR: 0.002250\nTraining Epoch: 15 [38016/50000]\tLoss: 0.2384\tLR: 0.002250\nTraining Epoch: 15 [38144/50000]\tLoss: 0.3143\tLR: 0.002250\nTraining Epoch: 15 [38272/50000]\tLoss: 0.2540\tLR: 0.002250\nTraining Epoch: 15 [38400/50000]\tLoss: 0.2634\tLR: 0.002250\nTraining Epoch: 15 [38528/50000]\tLoss: 0.2018\tLR: 0.002250\nTraining Epoch: 15 [38656/50000]\tLoss: 0.2957\tLR: 0.002250\nTraining Epoch: 15 [38784/50000]\tLoss: 0.2510\tLR: 0.002250\nTraining Epoch: 15 [38912/50000]\tLoss: 0.2340\tLR: 0.002250\nTraining Epoch: 15 [39040/50000]\tLoss: 0.2910\tLR: 0.002250\nTraining Epoch: 15 [39168/50000]\tLoss: 0.2721\tLR: 0.002250\nTraining Epoch: 15 [39296/50000]\tLoss: 0.2967\tLR: 0.002250\nTraining Epoch: 15 [39424/50000]\tLoss: 0.2014\tLR: 0.002250\nTraining Epoch: 15 [39552/50000]\tLoss: 0.1663\tLR: 0.002250\nTraining Epoch: 15 [39680/50000]\tLoss: 0.2948\tLR: 0.002250\nTraining Epoch: 15 [39808/50000]\tLoss: 0.3086\tLR: 0.002250\nTraining Epoch: 15 [39936/50000]\tLoss: 0.2662\tLR: 0.002250\nTraining Epoch: 15 [40064/50000]\tLoss: 0.2574\tLR: 0.002250\nTraining Epoch: 15 [40192/50000]\tLoss: 0.2747\tLR: 0.002250\nTraining Epoch: 15 [40320/50000]\tLoss: 0.3120\tLR: 0.002250\nTraining Epoch: 15 [40448/50000]\tLoss: 0.1365\tLR: 0.002250\nTraining Epoch: 15 [40576/50000]\tLoss: 0.3317\tLR: 0.002250\nTraining Epoch: 15 [40704/50000]\tLoss: 0.2562\tLR: 0.002250\nTraining Epoch: 15 [40832/50000]\tLoss: 0.2081\tLR: 0.002250\nTraining Epoch: 15 [40960/50000]\tLoss: 0.3410\tLR: 0.002250\nTraining Epoch: 15 [41088/50000]\tLoss: 0.2189\tLR: 0.002250\nTraining Epoch: 15 [41216/50000]\tLoss: 0.3533\tLR: 0.002250\nTraining Epoch: 15 [41344/50000]\tLoss: 0.3487\tLR: 0.002250\nTraining Epoch: 15 [41472/50000]\tLoss: 0.2583\tLR: 0.002250\nTraining Epoch: 15 [41600/50000]\tLoss: 0.3074\tLR: 0.002250\nTraining Epoch: 15 [41728/50000]\tLoss: 0.1451\tLR: 0.002250\nTraining Epoch: 15 [41856/50000]\tLoss: 0.1740\tLR: 0.002250\nTraining Epoch: 15 [41984/50000]\tLoss: 0.3344\tLR: 0.002250\nTraining Epoch: 15 [42112/50000]\tLoss: 0.1235\tLR: 0.002250\nTraining Epoch: 15 [42240/50000]\tLoss: 0.1321\tLR: 0.002250\nTraining Epoch: 15 [42368/50000]\tLoss: 0.2616\tLR: 0.002250\nTraining Epoch: 15 [42496/50000]\tLoss: 0.2984\tLR: 0.002250\nTraining Epoch: 15 [42624/50000]\tLoss: 0.2894\tLR: 0.002250\nTraining Epoch: 15 [42752/50000]\tLoss: 0.3475\tLR: 0.002250\nTraining Epoch: 15 [42880/50000]\tLoss: 0.1948\tLR: 0.002250\nTraining Epoch: 15 [43008/50000]\tLoss: 0.3372\tLR: 0.002250\nTraining Epoch: 15 [43136/50000]\tLoss: 0.3088\tLR: 0.002250\nTraining Epoch: 15 [43264/50000]\tLoss: 0.3680\tLR: 0.002250\nTraining Epoch: 15 [43392/50000]\tLoss: 0.3111\tLR: 0.002250\nTraining Epoch: 15 [43520/50000]\tLoss: 0.3681\tLR: 0.002250\nTraining Epoch: 15 [43648/50000]\tLoss: 0.2885\tLR: 0.002250\nTraining Epoch: 15 [43776/50000]\tLoss: 0.3267\tLR: 0.002250\nTraining Epoch: 15 [43904/50000]\tLoss: 0.3267\tLR: 0.002250\nTraining Epoch: 15 [44032/50000]\tLoss: 0.3210\tLR: 0.002250\nTraining Epoch: 15 [44160/50000]\tLoss: 0.2927\tLR: 0.002250\nTraining Epoch: 15 [44288/50000]\tLoss: 0.2484\tLR: 0.002250\nTraining Epoch: 15 [44416/50000]\tLoss: 0.2178\tLR: 0.002250\nTraining Epoch: 15 [44544/50000]\tLoss: 0.2666\tLR: 0.002250\nTraining Epoch: 15 [44672/50000]\tLoss: 0.2368\tLR: 0.002250\nTraining Epoch: 15 [44800/50000]\tLoss: 0.2448\tLR: 0.002250\nTraining Epoch: 15 [44928/50000]\tLoss: 0.3570\tLR: 0.002250\nTraining Epoch: 15 [45056/50000]\tLoss: 0.2671\tLR: 0.002250\nTraining Epoch: 15 [45184/50000]\tLoss: 0.3200\tLR: 0.002250\nTraining Epoch: 15 [45312/50000]\tLoss: 0.2381\tLR: 0.002250\nTraining Epoch: 15 [45440/50000]\tLoss: 0.3577\tLR: 0.002250\nTraining Epoch: 15 [45568/50000]\tLoss: 0.2023\tLR: 0.002250\nTraining Epoch: 15 [45696/50000]\tLoss: 0.3133\tLR: 0.002250\nTraining Epoch: 15 [45824/50000]\tLoss: 0.3481\tLR: 0.002250\nTraining Epoch: 15 [45952/50000]\tLoss: 0.2247\tLR: 0.002250\nTraining Epoch: 15 [46080/50000]\tLoss: 0.2808\tLR: 0.002250\nTraining Epoch: 15 [46208/50000]\tLoss: 0.2512\tLR: 0.002250\nTraining Epoch: 15 [46336/50000]\tLoss: 0.3549\tLR: 0.002250\nTraining Epoch: 15 [46464/50000]\tLoss: 0.2375\tLR: 0.002250\nTraining Epoch: 15 [46592/50000]\tLoss: 0.2438\tLR: 0.002250\nTraining Epoch: 15 [46720/50000]\tLoss: 0.2158\tLR: 0.002250\nTraining Epoch: 15 [46848/50000]\tLoss: 0.2795\tLR: 0.002250\nTraining Epoch: 15 [46976/50000]\tLoss: 0.2279\tLR: 0.002250\nTraining Epoch: 15 [47104/50000]\tLoss: 0.3088\tLR: 0.002250\nTraining Epoch: 15 [47232/50000]\tLoss: 0.2356\tLR: 0.002250\nTraining Epoch: 15 [47360/50000]\tLoss: 0.2450\tLR: 0.002250\nTraining Epoch: 15 [47488/50000]\tLoss: 0.2653\tLR: 0.002250\nTraining Epoch: 15 [47616/50000]\tLoss: 0.3728\tLR: 0.002250\nTraining Epoch: 15 [47744/50000]\tLoss: 0.3394\tLR: 0.002250\nTraining Epoch: 15 [47872/50000]\tLoss: 0.1773\tLR: 0.002250\nTraining Epoch: 15 [48000/50000]\tLoss: 0.3555\tLR: 0.002250\nTraining Epoch: 15 [48128/50000]\tLoss: 0.2909\tLR: 0.002250\nTraining Epoch: 15 [48256/50000]\tLoss: 0.2299\tLR: 0.002250\nTraining Epoch: 15 [48384/50000]\tLoss: 0.3745\tLR: 0.002250\nTraining Epoch: 15 [48512/50000]\tLoss: 0.4313\tLR: 0.002250\nTraining Epoch: 15 [48640/50000]\tLoss: 0.1914\tLR: 0.002250\nTraining Epoch: 15 [48768/50000]\tLoss: 0.2870\tLR: 0.002250\nTraining Epoch: 15 [48896/50000]\tLoss: 0.2497\tLR: 0.002250\nTraining Epoch: 15 [49024/50000]\tLoss: 0.2319\tLR: 0.002250\nTraining Epoch: 15 [49152/50000]\tLoss: 0.3216\tLR: 0.002250\nTraining Epoch: 15 [49280/50000]\tLoss: 0.2751\tLR: 0.002250\nTraining Epoch: 15 [49408/50000]\tLoss: 0.3250\tLR: 0.002250\nTraining Epoch: 15 [49536/50000]\tLoss: 0.3033\tLR: 0.002250\nTraining Epoch: 15 [49664/50000]\tLoss: 0.3312\tLR: 0.002250\nTraining Epoch: 15 [49792/50000]\tLoss: 0.2066\tLR: 0.002250\nTraining Epoch: 15 [49920/50000]\tLoss: 0.2847\tLR: 0.002250\nTraining Epoch: 15 [50000/50000]\tLoss: 0.2634\tLR: 0.002250\nTest set: Average loss: 0.0024, Accuracy: 0.8972\n\nTraining Epoch: 16 [128/50000]\tLoss: 0.1883\tLR: 0.000337\nTraining Epoch: 16 [256/50000]\tLoss: 0.2350\tLR: 0.000337\nTraining Epoch: 16 [384/50000]\tLoss: 0.2013\tLR: 0.000337\nTraining Epoch: 16 [512/50000]\tLoss: 0.2997\tLR: 0.000337\nTraining Epoch: 16 [640/50000]\tLoss: 0.2624\tLR: 0.000337\nTraining Epoch: 16 [768/50000]\tLoss: 0.2962\tLR: 0.000337\nTraining Epoch: 16 [896/50000]\tLoss: 0.3404\tLR: 0.000337\nTraining Epoch: 16 [1024/50000]\tLoss: 0.2934\tLR: 0.000337\nTraining Epoch: 16 [1152/50000]\tLoss: 0.1934\tLR: 0.000337\nTraining Epoch: 16 [1280/50000]\tLoss: 0.2543\tLR: 0.000337\nTraining Epoch: 16 [1408/50000]\tLoss: 0.2507\tLR: 0.000337\nTraining Epoch: 16 [1536/50000]\tLoss: 0.1476\tLR: 0.000337\nTraining Epoch: 16 [1664/50000]\tLoss: 0.3830\tLR: 0.000337\nTraining Epoch: 16 [1792/50000]\tLoss: 0.2193\tLR: 0.000337\nTraining Epoch: 16 [1920/50000]\tLoss: 0.2855\tLR: 0.000337\nTraining Epoch: 16 [2048/50000]\tLoss: 0.1977\tLR: 0.000337\nTraining Epoch: 16 [2176/50000]\tLoss: 0.2509\tLR: 0.000337\nTraining Epoch: 16 [2304/50000]\tLoss: 0.2443\tLR: 0.000337\nTraining Epoch: 16 [2432/50000]\tLoss: 0.2967\tLR: 0.000337\nTraining Epoch: 16 [2560/50000]\tLoss: 0.3661\tLR: 0.000337\nTraining Epoch: 16 [2688/50000]\tLoss: 0.2720\tLR: 0.000337\nTraining Epoch: 16 [2816/50000]\tLoss: 0.2297\tLR: 0.000337\nTraining Epoch: 16 [2944/50000]\tLoss: 0.2382\tLR: 0.000337\nTraining Epoch: 16 [3072/50000]\tLoss: 0.3888\tLR: 0.000337\nTraining Epoch: 16 [3200/50000]\tLoss: 0.2726\tLR: 0.000337\nTraining Epoch: 16 [3328/50000]\tLoss: 0.2696\tLR: 0.000337\nTraining Epoch: 16 [3456/50000]\tLoss: 0.2706\tLR: 0.000337\nTraining Epoch: 16 [3584/50000]\tLoss: 0.1924\tLR: 0.000337\nTraining Epoch: 16 [3712/50000]\tLoss: 0.2936\tLR: 0.000337\nTraining Epoch: 16 [3840/50000]\tLoss: 0.2609\tLR: 0.000337\nTraining Epoch: 16 [3968/50000]\tLoss: 0.2414\tLR: 0.000337\nTraining Epoch: 16 [4096/50000]\tLoss: 0.4529\tLR: 0.000337\nTraining Epoch: 16 [4224/50000]\tLoss: 0.3005\tLR: 0.000337\nTraining Epoch: 16 [4352/50000]\tLoss: 0.1715\tLR: 0.000337\nTraining Epoch: 16 [4480/50000]\tLoss: 0.1983\tLR: 0.000337\nTraining Epoch: 16 [4608/50000]\tLoss: 0.2510\tLR: 0.000337\nTraining Epoch: 16 [4736/50000]\tLoss: 0.1926\tLR: 0.000337\nTraining Epoch: 16 [4864/50000]\tLoss: 0.2151\tLR: 0.000337\nTraining Epoch: 16 [4992/50000]\tLoss: 0.2751\tLR: 0.000337\nTraining Epoch: 16 [5120/50000]\tLoss: 0.2556\tLR: 0.000337\nTraining Epoch: 16 [5248/50000]\tLoss: 0.2390\tLR: 0.000337\nTraining Epoch: 16 [5376/50000]\tLoss: 0.2648\tLR: 0.000337\nTraining Epoch: 16 [5504/50000]\tLoss: 0.2559\tLR: 0.000337\nTraining Epoch: 16 [5632/50000]\tLoss: 0.2237\tLR: 0.000337\nTraining Epoch: 16 [5760/50000]\tLoss: 0.2415\tLR: 0.000337\nTraining Epoch: 16 [5888/50000]\tLoss: 0.1601\tLR: 0.000337\nTraining Epoch: 16 [6016/50000]\tLoss: 0.3328\tLR: 0.000337\nTraining Epoch: 16 [6144/50000]\tLoss: 0.3365\tLR: 0.000337\nTraining Epoch: 16 [6272/50000]\tLoss: 0.1961\tLR: 0.000337\nTraining Epoch: 16 [6400/50000]\tLoss: 0.2988\tLR: 0.000337\nTraining Epoch: 16 [6528/50000]\tLoss: 0.2432\tLR: 0.000337\nTraining Epoch: 16 [6656/50000]\tLoss: 0.2250\tLR: 0.000337\nTraining Epoch: 16 [6784/50000]\tLoss: 0.3200\tLR: 0.000337\nTraining Epoch: 16 [6912/50000]\tLoss: 0.2268\tLR: 0.000337\nTraining Epoch: 16 [7040/50000]\tLoss: 0.1756\tLR: 0.000337\nTraining Epoch: 16 [7168/50000]\tLoss: 0.2139\tLR: 0.000337\nTraining Epoch: 16 [7296/50000]\tLoss: 0.2872\tLR: 0.000337\nTraining Epoch: 16 [7424/50000]\tLoss: 0.2302\tLR: 0.000337\nTraining Epoch: 16 [7552/50000]\tLoss: 0.2180\tLR: 0.000337\nTraining Epoch: 16 [7680/50000]\tLoss: 0.3135\tLR: 0.000337\nTraining Epoch: 16 [7808/50000]\tLoss: 0.1798\tLR: 0.000337\nTraining Epoch: 16 [7936/50000]\tLoss: 0.2082\tLR: 0.000337\nTraining Epoch: 16 [8064/50000]\tLoss: 0.1688\tLR: 0.000337\nTraining Epoch: 16 [8192/50000]\tLoss: 0.3155\tLR: 0.000337\nTraining Epoch: 16 [8320/50000]\tLoss: 0.2833\tLR: 0.000337\nTraining Epoch: 16 [8448/50000]\tLoss: 0.2391\tLR: 0.000337\nTraining Epoch: 16 [8576/50000]\tLoss: 0.2246\tLR: 0.000337\nTraining Epoch: 16 [8704/50000]\tLoss: 0.2952\tLR: 0.000337\nTraining Epoch: 16 [8832/50000]\tLoss: 0.2128\tLR: 0.000337\nTraining Epoch: 16 [8960/50000]\tLoss: 0.3380\tLR: 0.000337\nTraining Epoch: 16 [9088/50000]\tLoss: 0.3074\tLR: 0.000337\nTraining Epoch: 16 [9216/50000]\tLoss: 0.2256\tLR: 0.000337\nTraining Epoch: 16 [9344/50000]\tLoss: 0.2626\tLR: 0.000337\nTraining Epoch: 16 [9472/50000]\tLoss: 0.2197\tLR: 0.000337\nTraining Epoch: 16 [9600/50000]\tLoss: 0.2765\tLR: 0.000337\nTraining Epoch: 16 [9728/50000]\tLoss: 0.2862\tLR: 0.000337\nTraining Epoch: 16 [9856/50000]\tLoss: 0.2994\tLR: 0.000337\nTraining Epoch: 16 [9984/50000]\tLoss: 0.1592\tLR: 0.000337\nTraining Epoch: 16 [10112/50000]\tLoss: 0.3304\tLR: 0.000337\nTraining Epoch: 16 [10240/50000]\tLoss: 0.3349\tLR: 0.000337\nTraining Epoch: 16 [10368/50000]\tLoss: 0.2509\tLR: 0.000337\nTraining Epoch: 16 [10496/50000]\tLoss: 0.3255\tLR: 0.000337\nTraining Epoch: 16 [10624/50000]\tLoss: 0.1863\tLR: 0.000337\nTraining Epoch: 16 [10752/50000]\tLoss: 0.2380\tLR: 0.000337\nTraining Epoch: 16 [10880/50000]\tLoss: 0.1730\tLR: 0.000337\nTraining Epoch: 16 [11008/50000]\tLoss: 0.3121\tLR: 0.000337\nTraining Epoch: 16 [11136/50000]\tLoss: 0.2742\tLR: 0.000337\nTraining Epoch: 16 [11264/50000]\tLoss: 0.2436\tLR: 0.000337\nTraining Epoch: 16 [11392/50000]\tLoss: 0.1882\tLR: 0.000337\nTraining Epoch: 16 [11520/50000]\tLoss: 0.3378\tLR: 0.000337\nTraining Epoch: 16 [11648/50000]\tLoss: 0.3417\tLR: 0.000337\nTraining Epoch: 16 [11776/50000]\tLoss: 0.1804\tLR: 0.000337\nTraining Epoch: 16 [11904/50000]\tLoss: 0.3475\tLR: 0.000337\nTraining Epoch: 16 [12032/50000]\tLoss: 0.3428\tLR: 0.000337\nTraining Epoch: 16 [12160/50000]\tLoss: 0.1542\tLR: 0.000337\nTraining Epoch: 16 [12288/50000]\tLoss: 0.2731\tLR: 0.000337\nTraining Epoch: 16 [12416/50000]\tLoss: 0.1859\tLR: 0.000337\nTraining Epoch: 16 [12544/50000]\tLoss: 0.2073\tLR: 0.000337\nTraining Epoch: 16 [12672/50000]\tLoss: 0.2373\tLR: 0.000337\nTraining Epoch: 16 [12800/50000]\tLoss: 0.2945\tLR: 0.000337\nTraining Epoch: 16 [12928/50000]\tLoss: 0.3006\tLR: 0.000337\nTraining Epoch: 16 [13056/50000]\tLoss: 0.2460\tLR: 0.000337\nTraining Epoch: 16 [13184/50000]\tLoss: 0.4040\tLR: 0.000337\nTraining Epoch: 16 [13312/50000]\tLoss: 0.2118\tLR: 0.000337\nTraining Epoch: 16 [13440/50000]\tLoss: 0.3348\tLR: 0.000337\nTraining Epoch: 16 [13568/50000]\tLoss: 0.3423\tLR: 0.000337\nTraining Epoch: 16 [13696/50000]\tLoss: 0.2374\tLR: 0.000337\nTraining Epoch: 16 [13824/50000]\tLoss: 0.2178\tLR: 0.000337\nTraining Epoch: 16 [13952/50000]\tLoss: 0.2565\tLR: 0.000337\nTraining Epoch: 16 [14080/50000]\tLoss: 0.2092\tLR: 0.000337\nTraining Epoch: 16 [14208/50000]\tLoss: 0.2205\tLR: 0.000337\nTraining Epoch: 16 [14336/50000]\tLoss: 0.3098\tLR: 0.000337\nTraining Epoch: 16 [14464/50000]\tLoss: 0.3849\tLR: 0.000337\nTraining Epoch: 16 [14592/50000]\tLoss: 0.1640\tLR: 0.000337\nTraining Epoch: 16 [14720/50000]\tLoss: 0.1943\tLR: 0.000337\nTraining Epoch: 16 [14848/50000]\tLoss: 0.2604\tLR: 0.000337\nTraining Epoch: 16 [14976/50000]\tLoss: 0.3347\tLR: 0.000337\nTraining Epoch: 16 [15104/50000]\tLoss: 0.1803\tLR: 0.000337\nTraining Epoch: 16 [15232/50000]\tLoss: 0.4744\tLR: 0.000337\nTraining Epoch: 16 [15360/50000]\tLoss: 0.2007\tLR: 0.000337\nTraining Epoch: 16 [15488/50000]\tLoss: 0.2733\tLR: 0.000337\nTraining Epoch: 16 [15616/50000]\tLoss: 0.2812\tLR: 0.000337\nTraining Epoch: 16 [15744/50000]\tLoss: 0.1776\tLR: 0.000337\nTraining Epoch: 16 [15872/50000]\tLoss: 0.2683\tLR: 0.000337\nTraining Epoch: 16 [16000/50000]\tLoss: 0.2287\tLR: 0.000337\nTraining Epoch: 16 [16128/50000]\tLoss: 0.2426\tLR: 0.000337\nTraining Epoch: 16 [16256/50000]\tLoss: 0.1945\tLR: 0.000337\nTraining Epoch: 16 [16384/50000]\tLoss: 0.3081\tLR: 0.000337\nTraining Epoch: 16 [16512/50000]\tLoss: 0.2173\tLR: 0.000337\nTraining Epoch: 16 [16640/50000]\tLoss: 0.1816\tLR: 0.000337\nTraining Epoch: 16 [16768/50000]\tLoss: 0.3123\tLR: 0.000337\nTraining Epoch: 16 [16896/50000]\tLoss: 0.3041\tLR: 0.000337\nTraining Epoch: 16 [17024/50000]\tLoss: 0.1933\tLR: 0.000337\nTraining Epoch: 16 [17152/50000]\tLoss: 0.2878\tLR: 0.000337\nTraining Epoch: 16 [17280/50000]\tLoss: 0.3224\tLR: 0.000337\nTraining Epoch: 16 [17408/50000]\tLoss: 0.2582\tLR: 0.000337\nTraining Epoch: 16 [17536/50000]\tLoss: 0.3115\tLR: 0.000337\nTraining Epoch: 16 [17664/50000]\tLoss: 0.2960\tLR: 0.000337\nTraining Epoch: 16 [17792/50000]\tLoss: 0.3072\tLR: 0.000337\nTraining Epoch: 16 [17920/50000]\tLoss: 0.1800\tLR: 0.000337\nTraining Epoch: 16 [18048/50000]\tLoss: 0.2892\tLR: 0.000337\nTraining Epoch: 16 [18176/50000]\tLoss: 0.1957\tLR: 0.000337\nTraining Epoch: 16 [18304/50000]\tLoss: 0.2014\tLR: 0.000337\nTraining Epoch: 16 [18432/50000]\tLoss: 0.2696\tLR: 0.000337\nTraining Epoch: 16 [18560/50000]\tLoss: 0.3021\tLR: 0.000337\nTraining Epoch: 16 [18688/50000]\tLoss: 0.2768\tLR: 0.000337\nTraining Epoch: 16 [18816/50000]\tLoss: 0.2401\tLR: 0.000337\nTraining Epoch: 16 [18944/50000]\tLoss: 0.1591\tLR: 0.000337\nTraining Epoch: 16 [19072/50000]\tLoss: 0.1665\tLR: 0.000337\nTraining Epoch: 16 [19200/50000]\tLoss: 0.3844\tLR: 0.000337\nTraining Epoch: 16 [19328/50000]\tLoss: 0.2310\tLR: 0.000337\nTraining Epoch: 16 [19456/50000]\tLoss: 0.2762\tLR: 0.000337\nTraining Epoch: 16 [19584/50000]\tLoss: 0.2688\tLR: 0.000337\nTraining Epoch: 16 [19712/50000]\tLoss: 0.3132\tLR: 0.000337\nTraining Epoch: 16 [19840/50000]\tLoss: 0.2589\tLR: 0.000337\nTraining Epoch: 16 [19968/50000]\tLoss: 0.2950\tLR: 0.000337\nTraining Epoch: 16 [20096/50000]\tLoss: 0.2815\tLR: 0.000337\nTraining Epoch: 16 [20224/50000]\tLoss: 0.3371\tLR: 0.000337\nTraining Epoch: 16 [20352/50000]\tLoss: 0.2547\tLR: 0.000337\nTraining Epoch: 16 [20480/50000]\tLoss: 0.2691\tLR: 0.000337\nTraining Epoch: 16 [20608/50000]\tLoss: 0.2296\tLR: 0.000337\nTraining Epoch: 16 [20736/50000]\tLoss: 0.2289\tLR: 0.000337\nTraining Epoch: 16 [20864/50000]\tLoss: 0.2520\tLR: 0.000337\nTraining Epoch: 16 [20992/50000]\tLoss: 0.3037\tLR: 0.000337\nTraining Epoch: 16 [21120/50000]\tLoss: 0.3400\tLR: 0.000337\nTraining Epoch: 16 [21248/50000]\tLoss: 0.3113\tLR: 0.000337\nTraining Epoch: 16 [21376/50000]\tLoss: 0.2987\tLR: 0.000337\nTraining Epoch: 16 [21504/50000]\tLoss: 0.1669\tLR: 0.000337\nTraining Epoch: 16 [21632/50000]\tLoss: 0.2056\tLR: 0.000337\nTraining Epoch: 16 [21760/50000]\tLoss: 0.2040\tLR: 0.000337\nTraining Epoch: 16 [21888/50000]\tLoss: 0.4267\tLR: 0.000337\nTraining Epoch: 16 [22016/50000]\tLoss: 0.2604\tLR: 0.000337\nTraining Epoch: 16 [22144/50000]\tLoss: 0.1482\tLR: 0.000337\nTraining Epoch: 16 [22272/50000]\tLoss: 0.2192\tLR: 0.000337\nTraining Epoch: 16 [22400/50000]\tLoss: 0.1803\tLR: 0.000337\nTraining Epoch: 16 [22528/50000]\tLoss: 0.3363\tLR: 0.000337\nTraining Epoch: 16 [22656/50000]\tLoss: 0.2074\tLR: 0.000337\nTraining Epoch: 16 [22784/50000]\tLoss: 0.2577\tLR: 0.000337\nTraining Epoch: 16 [22912/50000]\tLoss: 0.2370\tLR: 0.000337\nTraining Epoch: 16 [23040/50000]\tLoss: 0.2032\tLR: 0.000337\nTraining Epoch: 16 [23168/50000]\tLoss: 0.2496\tLR: 0.000337\nTraining Epoch: 16 [23296/50000]\tLoss: 0.2487\tLR: 0.000337\nTraining Epoch: 16 [23424/50000]\tLoss: 0.2818\tLR: 0.000337\nTraining Epoch: 16 [23552/50000]\tLoss: 0.3011\tLR: 0.000337\nTraining Epoch: 16 [23680/50000]\tLoss: 0.1521\tLR: 0.000337\nTraining Epoch: 16 [23808/50000]\tLoss: 0.2641\tLR: 0.000337\nTraining Epoch: 16 [23936/50000]\tLoss: 0.2881\tLR: 0.000337\nTraining Epoch: 16 [24064/50000]\tLoss: 0.2803\tLR: 0.000337\nTraining Epoch: 16 [24192/50000]\tLoss: 0.2353\tLR: 0.000337\nTraining Epoch: 16 [24320/50000]\tLoss: 0.2415\tLR: 0.000337\nTraining Epoch: 16 [24448/50000]\tLoss: 0.2962\tLR: 0.000337\nTraining Epoch: 16 [24576/50000]\tLoss: 0.2294\tLR: 0.000337\nTraining Epoch: 16 [24704/50000]\tLoss: 0.3862\tLR: 0.000337\nTraining Epoch: 16 [24832/50000]\tLoss: 0.2451\tLR: 0.000337\nTraining Epoch: 16 [24960/50000]\tLoss: 0.3058\tLR: 0.000337\nTraining Epoch: 16 [25088/50000]\tLoss: 0.3224\tLR: 0.000337\nTraining Epoch: 16 [25216/50000]\tLoss: 0.2191\tLR: 0.000337\nTraining Epoch: 16 [25344/50000]\tLoss: 0.4203\tLR: 0.000337\nTraining Epoch: 16 [25472/50000]\tLoss: 0.2492\tLR: 0.000337\nTraining Epoch: 16 [25600/50000]\tLoss: 0.2965\tLR: 0.000337\nTraining Epoch: 16 [25728/50000]\tLoss: 0.2035\tLR: 0.000337\nTraining Epoch: 16 [25856/50000]\tLoss: 0.2610\tLR: 0.000337\nTraining Epoch: 16 [25984/50000]\tLoss: 0.2343\tLR: 0.000337\nTraining Epoch: 16 [26112/50000]\tLoss: 0.1835\tLR: 0.000337\nTraining Epoch: 16 [26240/50000]\tLoss: 0.2449\tLR: 0.000337\nTraining Epoch: 16 [26368/50000]\tLoss: 0.1930\tLR: 0.000337\nTraining Epoch: 16 [26496/50000]\tLoss: 0.2830\tLR: 0.000337\nTraining Epoch: 16 [26624/50000]\tLoss: 0.1951\tLR: 0.000337\nTraining Epoch: 16 [26752/50000]\tLoss: 0.1774\tLR: 0.000337\nTraining Epoch: 16 [26880/50000]\tLoss: 0.2940\tLR: 0.000337\nTraining Epoch: 16 [27008/50000]\tLoss: 0.1810\tLR: 0.000337\nTraining Epoch: 16 [27136/50000]\tLoss: 0.2147\tLR: 0.000337\nTraining Epoch: 16 [27264/50000]\tLoss: 0.2023\tLR: 0.000337\nTraining Epoch: 16 [27392/50000]\tLoss: 0.2584\tLR: 0.000337\nTraining Epoch: 16 [27520/50000]\tLoss: 0.2664\tLR: 0.000337\nTraining Epoch: 16 [27648/50000]\tLoss: 0.2188\tLR: 0.000337\nTraining Epoch: 16 [27776/50000]\tLoss: 0.2534\tLR: 0.000337\nTraining Epoch: 16 [27904/50000]\tLoss: 0.2884\tLR: 0.000337\nTraining Epoch: 16 [28032/50000]\tLoss: 0.4016\tLR: 0.000337\nTraining Epoch: 16 [28160/50000]\tLoss: 0.3063\tLR: 0.000337\nTraining Epoch: 16 [28288/50000]\tLoss: 0.2377\tLR: 0.000337\nTraining Epoch: 16 [28416/50000]\tLoss: 0.3719\tLR: 0.000337\nTraining Epoch: 16 [28544/50000]\tLoss: 0.2406\tLR: 0.000337\nTraining Epoch: 16 [28672/50000]\tLoss: 0.3011\tLR: 0.000337\nTraining Epoch: 16 [28800/50000]\tLoss: 0.3388\tLR: 0.000337\nTraining Epoch: 16 [28928/50000]\tLoss: 0.1639\tLR: 0.000337\nTraining Epoch: 16 [29056/50000]\tLoss: 0.3080\tLR: 0.000337\nTraining Epoch: 16 [29184/50000]\tLoss: 0.1365\tLR: 0.000337\nTraining Epoch: 16 [29312/50000]\tLoss: 0.2852\tLR: 0.000337\nTraining Epoch: 16 [29440/50000]\tLoss: 0.2139\tLR: 0.000337\nTraining Epoch: 16 [29568/50000]\tLoss: 0.3463\tLR: 0.000337\nTraining Epoch: 16 [29696/50000]\tLoss: 0.2558\tLR: 0.000337\nTraining Epoch: 16 [29824/50000]\tLoss: 0.2479\tLR: 0.000337\nTraining Epoch: 16 [29952/50000]\tLoss: 0.1441\tLR: 0.000337\nTraining Epoch: 16 [30080/50000]\tLoss: 0.2255\tLR: 0.000337\nTraining Epoch: 16 [30208/50000]\tLoss: 0.1890\tLR: 0.000337\nTraining Epoch: 16 [30336/50000]\tLoss: 0.3256\tLR: 0.000337\nTraining Epoch: 16 [30464/50000]\tLoss: 0.2354\tLR: 0.000337\nTraining Epoch: 16 [30592/50000]\tLoss: 0.3778\tLR: 0.000337\nTraining Epoch: 16 [30720/50000]\tLoss: 0.2732\tLR: 0.000337\nTraining Epoch: 16 [30848/50000]\tLoss: 0.2276\tLR: 0.000337\nTraining Epoch: 16 [30976/50000]\tLoss: 0.2775\tLR: 0.000337\nTraining Epoch: 16 [31104/50000]\tLoss: 0.2961\tLR: 0.000337\nTraining Epoch: 16 [31232/50000]\tLoss: 0.2209\tLR: 0.000337\nTraining Epoch: 16 [31360/50000]\tLoss: 0.3789\tLR: 0.000337\nTraining Epoch: 16 [31488/50000]\tLoss: 0.3126\tLR: 0.000337\nTraining Epoch: 16 [31616/50000]\tLoss: 0.3393\tLR: 0.000337\nTraining Epoch: 16 [31744/50000]\tLoss: 0.2029\tLR: 0.000337\nTraining Epoch: 16 [31872/50000]\tLoss: 0.2507\tLR: 0.000337\nTraining Epoch: 16 [32000/50000]\tLoss: 0.1335\tLR: 0.000337\nTraining Epoch: 16 [32128/50000]\tLoss: 0.3009\tLR: 0.000337\nTraining Epoch: 16 [32256/50000]\tLoss: 0.2497\tLR: 0.000337\nTraining Epoch: 16 [32384/50000]\tLoss: 0.3154\tLR: 0.000337\nTraining Epoch: 16 [32512/50000]\tLoss: 0.2774\tLR: 0.000337\nTraining Epoch: 16 [32640/50000]\tLoss: 0.2107\tLR: 0.000337\nTraining Epoch: 16 [32768/50000]\tLoss: 0.2769\tLR: 0.000337\nTraining Epoch: 16 [32896/50000]\tLoss: 0.2348\tLR: 0.000337\nTraining Epoch: 16 [33024/50000]\tLoss: 0.2915\tLR: 0.000337\nTraining Epoch: 16 [33152/50000]\tLoss: 0.2573\tLR: 0.000337\nTraining Epoch: 16 [33280/50000]\tLoss: 0.2609\tLR: 0.000337\nTraining Epoch: 16 [33408/50000]\tLoss: 0.2190\tLR: 0.000337\nTraining Epoch: 16 [33536/50000]\tLoss: 0.2747\tLR: 0.000337\nTraining Epoch: 16 [33664/50000]\tLoss: 0.1672\tLR: 0.000337\nTraining Epoch: 16 [33792/50000]\tLoss: 0.3078\tLR: 0.000337\nTraining Epoch: 16 [33920/50000]\tLoss: 0.2708\tLR: 0.000337\nTraining Epoch: 16 [34048/50000]\tLoss: 0.3033\tLR: 0.000337\nTraining Epoch: 16 [34176/50000]\tLoss: 0.1827\tLR: 0.000337\nTraining Epoch: 16 [34304/50000]\tLoss: 0.2680\tLR: 0.000337\nTraining Epoch: 16 [34432/50000]\tLoss: 0.2217\tLR: 0.000337\nTraining Epoch: 16 [34560/50000]\tLoss: 0.2707\tLR: 0.000337\nTraining Epoch: 16 [34688/50000]\tLoss: 0.3397\tLR: 0.000337\nTraining Epoch: 16 [34816/50000]\tLoss: 0.2535\tLR: 0.000337\nTraining Epoch: 16 [34944/50000]\tLoss: 0.2887\tLR: 0.000337\nTraining Epoch: 16 [35072/50000]\tLoss: 0.2982\tLR: 0.000337\nTraining Epoch: 16 [35200/50000]\tLoss: 0.2107\tLR: 0.000337\nTraining Epoch: 16 [35328/50000]\tLoss: 0.2895\tLR: 0.000337\nTraining Epoch: 16 [35456/50000]\tLoss: 0.2058\tLR: 0.000337\nTraining Epoch: 16 [35584/50000]\tLoss: 0.2051\tLR: 0.000337\nTraining Epoch: 16 [35712/50000]\tLoss: 0.1947\tLR: 0.000337\nTraining Epoch: 16 [35840/50000]\tLoss: 0.2833\tLR: 0.000337\nTraining Epoch: 16 [35968/50000]\tLoss: 0.2909\tLR: 0.000337\nTraining Epoch: 16 [36096/50000]\tLoss: 0.2332\tLR: 0.000337\nTraining Epoch: 16 [36224/50000]\tLoss: 0.3890\tLR: 0.000337\nTraining Epoch: 16 [36352/50000]\tLoss: 0.2587\tLR: 0.000337\nTraining Epoch: 16 [36480/50000]\tLoss: 0.3791\tLR: 0.000337\nTraining Epoch: 16 [36608/50000]\tLoss: 0.1985\tLR: 0.000337\nTraining Epoch: 16 [36736/50000]\tLoss: 0.2988\tLR: 0.000337\nTraining Epoch: 16 [36864/50000]\tLoss: 0.2134\tLR: 0.000337\nTraining Epoch: 16 [36992/50000]\tLoss: 0.1933\tLR: 0.000337\nTraining Epoch: 16 [37120/50000]\tLoss: 0.2611\tLR: 0.000337\nTraining Epoch: 16 [37248/50000]\tLoss: 0.2815\tLR: 0.000337\nTraining Epoch: 16 [37376/50000]\tLoss: 0.2687\tLR: 0.000337\nTraining Epoch: 16 [37504/50000]\tLoss: 0.1775\tLR: 0.000337\nTraining Epoch: 16 [37632/50000]\tLoss: 0.2630\tLR: 0.000337\nTraining Epoch: 16 [37760/50000]\tLoss: 0.3633\tLR: 0.000337\nTraining Epoch: 16 [37888/50000]\tLoss: 0.3065\tLR: 0.000337\nTraining Epoch: 16 [38016/50000]\tLoss: 0.2210\tLR: 0.000337\nTraining Epoch: 16 [38144/50000]\tLoss: 0.3135\tLR: 0.000337\nTraining Epoch: 16 [38272/50000]\tLoss: 0.2070\tLR: 0.000337\nTraining Epoch: 16 [38400/50000]\tLoss: 0.1738\tLR: 0.000337\nTraining Epoch: 16 [38528/50000]\tLoss: 0.2278\tLR: 0.000337\nTraining Epoch: 16 [38656/50000]\tLoss: 0.3191\tLR: 0.000337\nTraining Epoch: 16 [38784/50000]\tLoss: 0.2013\tLR: 0.000337\nTraining Epoch: 16 [38912/50000]\tLoss: 0.3097\tLR: 0.000337\nTraining Epoch: 16 [39040/50000]\tLoss: 0.2217\tLR: 0.000337\nTraining Epoch: 16 [39168/50000]\tLoss: 0.1709\tLR: 0.000337\nTraining Epoch: 16 [39296/50000]\tLoss: 0.2804\tLR: 0.000337\nTraining Epoch: 16 [39424/50000]\tLoss: 0.2869\tLR: 0.000337\nTraining Epoch: 16 [39552/50000]\tLoss: 0.2732\tLR: 0.000337\nTraining Epoch: 16 [39680/50000]\tLoss: 0.2254\tLR: 0.000337\nTraining Epoch: 16 [39808/50000]\tLoss: 0.1443\tLR: 0.000337\nTraining Epoch: 16 [39936/50000]\tLoss: 0.2982\tLR: 0.000337\nTraining Epoch: 16 [40064/50000]\tLoss: 0.2275\tLR: 0.000337\nTraining Epoch: 16 [40192/50000]\tLoss: 0.2519\tLR: 0.000337\nTraining Epoch: 16 [40320/50000]\tLoss: 0.2693\tLR: 0.000337\nTraining Epoch: 16 [40448/50000]\tLoss: 0.3749\tLR: 0.000337\nTraining Epoch: 16 [40576/50000]\tLoss: 0.1767\tLR: 0.000337\nTraining Epoch: 16 [40704/50000]\tLoss: 0.1787\tLR: 0.000337\nTraining Epoch: 16 [40832/50000]\tLoss: 0.2598\tLR: 0.000337\nTraining Epoch: 16 [40960/50000]\tLoss: 0.2709\tLR: 0.000337\nTraining Epoch: 16 [41088/50000]\tLoss: 0.1854\tLR: 0.000337\nTraining Epoch: 16 [41216/50000]\tLoss: 0.2972\tLR: 0.000337\nTraining Epoch: 16 [41344/50000]\tLoss: 0.1960\tLR: 0.000337\nTraining Epoch: 16 [41472/50000]\tLoss: 0.3027\tLR: 0.000337\nTraining Epoch: 16 [41600/50000]\tLoss: 0.2849\tLR: 0.000337\nTraining Epoch: 16 [41728/50000]\tLoss: 0.2167\tLR: 0.000337\nTraining Epoch: 16 [41856/50000]\tLoss: 0.2848\tLR: 0.000337\nTraining Epoch: 16 [41984/50000]\tLoss: 0.2517\tLR: 0.000337\nTraining Epoch: 16 [42112/50000]\tLoss: 0.3955\tLR: 0.000337\nTraining Epoch: 16 [42240/50000]\tLoss: 0.1786\tLR: 0.000337\nTraining Epoch: 16 [42368/50000]\tLoss: 0.2967\tLR: 0.000337\nTraining Epoch: 16 [42496/50000]\tLoss: 0.1751\tLR: 0.000337\nTraining Epoch: 16 [42624/50000]\tLoss: 0.2134\tLR: 0.000337\nTraining Epoch: 16 [42752/50000]\tLoss: 0.1788\tLR: 0.000337\nTraining Epoch: 16 [42880/50000]\tLoss: 0.1688\tLR: 0.000337\nTraining Epoch: 16 [43008/50000]\tLoss: 0.3513\tLR: 0.000337\nTraining Epoch: 16 [43136/50000]\tLoss: 0.1735\tLR: 0.000337\nTraining Epoch: 16 [43264/50000]\tLoss: 0.2936\tLR: 0.000337\nTraining Epoch: 16 [43392/50000]\tLoss: 0.3079\tLR: 0.000337\nTraining Epoch: 16 [43520/50000]\tLoss: 0.2998\tLR: 0.000337\nTraining Epoch: 16 [43648/50000]\tLoss: 0.1781\tLR: 0.000337\nTraining Epoch: 16 [43776/50000]\tLoss: 0.1851\tLR: 0.000337\nTraining Epoch: 16 [43904/50000]\tLoss: 0.1926\tLR: 0.000337\nTraining Epoch: 16 [44032/50000]\tLoss: 0.2036\tLR: 0.000337\nTraining Epoch: 16 [44160/50000]\tLoss: 0.2684\tLR: 0.000337\nTraining Epoch: 16 [44288/50000]\tLoss: 0.2417\tLR: 0.000337\nTraining Epoch: 16 [44416/50000]\tLoss: 0.2551\tLR: 0.000337\nTraining Epoch: 16 [44544/50000]\tLoss: 0.2682\tLR: 0.000337\nTraining Epoch: 16 [44672/50000]\tLoss: 0.2973\tLR: 0.000337\nTraining Epoch: 16 [44800/50000]\tLoss: 0.2788\tLR: 0.000337\nTraining Epoch: 16 [44928/50000]\tLoss: 0.2325\tLR: 0.000337\nTraining Epoch: 16 [45056/50000]\tLoss: 0.2125\tLR: 0.000337\nTraining Epoch: 16 [45184/50000]\tLoss: 0.2732\tLR: 0.000337\nTraining Epoch: 16 [45312/50000]\tLoss: 0.2174\tLR: 0.000337\nTraining Epoch: 16 [45440/50000]\tLoss: 0.4403\tLR: 0.000337\nTraining Epoch: 16 [45568/50000]\tLoss: 0.2998\tLR: 0.000337\nTraining Epoch: 16 [45696/50000]\tLoss: 0.2515\tLR: 0.000337\nTraining Epoch: 16 [45824/50000]\tLoss: 0.2344\tLR: 0.000337\nTraining Epoch: 16 [45952/50000]\tLoss: 0.3086\tLR: 0.000337\nTraining Epoch: 16 [46080/50000]\tLoss: 0.3503\tLR: 0.000337\nTraining Epoch: 16 [46208/50000]\tLoss: 0.2831\tLR: 0.000337\nTraining Epoch: 16 [46336/50000]\tLoss: 0.1991\tLR: 0.000337\nTraining Epoch: 16 [46464/50000]\tLoss: 0.2041\tLR: 0.000337\nTraining Epoch: 16 [46592/50000]\tLoss: 0.2091\tLR: 0.000337\nTraining Epoch: 16 [46720/50000]\tLoss: 0.2811\tLR: 0.000337\nTraining Epoch: 16 [46848/50000]\tLoss: 0.2797\tLR: 0.000337\nTraining Epoch: 16 [46976/50000]\tLoss: 0.2629\tLR: 0.000337\nTraining Epoch: 16 [47104/50000]\tLoss: 0.2248\tLR: 0.000337\nTraining Epoch: 16 [47232/50000]\tLoss: 0.2527\tLR: 0.000337\nTraining Epoch: 16 [47360/50000]\tLoss: 0.2709\tLR: 0.000337\nTraining Epoch: 16 [47488/50000]\tLoss: 0.3296\tLR: 0.000337\nTraining Epoch: 16 [47616/50000]\tLoss: 0.2050\tLR: 0.000337\nTraining Epoch: 16 [47744/50000]\tLoss: 0.3336\tLR: 0.000337\nTraining Epoch: 16 [47872/50000]\tLoss: 0.2210\tLR: 0.000337\nTraining Epoch: 16 [48000/50000]\tLoss: 0.2208\tLR: 0.000337\nTraining Epoch: 16 [48128/50000]\tLoss: 0.1665\tLR: 0.000337\nTraining Epoch: 16 [48256/50000]\tLoss: 0.2258\tLR: 0.000337\nTraining Epoch: 16 [48384/50000]\tLoss: 0.2396\tLR: 0.000337\nTraining Epoch: 16 [48512/50000]\tLoss: 0.2764\tLR: 0.000337\nTraining Epoch: 16 [48640/50000]\tLoss: 0.2900\tLR: 0.000337\nTraining Epoch: 16 [48768/50000]\tLoss: 0.2070\tLR: 0.000337\nTraining Epoch: 16 [48896/50000]\tLoss: 0.2158\tLR: 0.000337\nTraining Epoch: 16 [49024/50000]\tLoss: 0.2345\tLR: 0.000337\nTraining Epoch: 16 [49152/50000]\tLoss: 0.2198\tLR: 0.000337\nTraining Epoch: 16 [49280/50000]\tLoss: 0.1562\tLR: 0.000337\nTraining Epoch: 16 [49408/50000]\tLoss: 0.2780\tLR: 0.000337\nTraining Epoch: 16 [49536/50000]\tLoss: 0.2519\tLR: 0.000337\nTraining Epoch: 16 [49664/50000]\tLoss: 0.3536\tLR: 0.000337\nTraining Epoch: 16 [49792/50000]\tLoss: 0.2165\tLR: 0.000337\nTraining Epoch: 16 [49920/50000]\tLoss: 0.2724\tLR: 0.000337\nTraining Epoch: 16 [50000/50000]\tLoss: 0.2819\tLR: 0.000337\nTest set: Average loss: 0.0024, Accuracy: 0.8977\n\nTraining Epoch: 17 [128/50000]\tLoss: 0.2013\tLR: 0.000337\nTraining Epoch: 17 [256/50000]\tLoss: 0.2586\tLR: 0.000337\nTraining Epoch: 17 [384/50000]\tLoss: 0.2097\tLR: 0.000337\nTraining Epoch: 17 [512/50000]\tLoss: 0.2282\tLR: 0.000337\nTraining Epoch: 17 [640/50000]\tLoss: 0.1822\tLR: 0.000337\nTraining Epoch: 17 [768/50000]\tLoss: 0.1657\tLR: 0.000337\nTraining Epoch: 17 [896/50000]\tLoss: 0.2586\tLR: 0.000337\nTraining Epoch: 17 [1024/50000]\tLoss: 0.3283\tLR: 0.000337\nTraining Epoch: 17 [1152/50000]\tLoss: 0.2565\tLR: 0.000337\nTraining Epoch: 17 [1280/50000]\tLoss: 0.2598\tLR: 0.000337\nTraining Epoch: 17 [1408/50000]\tLoss: 0.2926\tLR: 0.000337\nTraining Epoch: 17 [1536/50000]\tLoss: 0.3624\tLR: 0.000337\nTraining Epoch: 17 [1664/50000]\tLoss: 0.2253\tLR: 0.000337\nTraining Epoch: 17 [1792/50000]\tLoss: 0.1627\tLR: 0.000337\nTraining Epoch: 17 [1920/50000]\tLoss: 0.3296\tLR: 0.000337\nTraining Epoch: 17 [2048/50000]\tLoss: 0.1868\tLR: 0.000337\nTraining Epoch: 17 [2176/50000]\tLoss: 0.1942\tLR: 0.000337\nTraining Epoch: 17 [2304/50000]\tLoss: 0.1809\tLR: 0.000337\nTraining Epoch: 17 [2432/50000]\tLoss: 0.2961\tLR: 0.000337\nTraining Epoch: 17 [2560/50000]\tLoss: 0.3098\tLR: 0.000337\nTraining Epoch: 17 [2688/50000]\tLoss: 0.2127\tLR: 0.000337\nTraining Epoch: 17 [2816/50000]\tLoss: 0.3282\tLR: 0.000337\nTraining Epoch: 17 [2944/50000]\tLoss: 0.1151\tLR: 0.000337\nTraining Epoch: 17 [3072/50000]\tLoss: 0.3723\tLR: 0.000337\nTraining Epoch: 17 [3200/50000]\tLoss: 0.2527\tLR: 0.000337\nTraining Epoch: 17 [3328/50000]\tLoss: 0.1633\tLR: 0.000337\nTraining Epoch: 17 [3456/50000]\tLoss: 0.2096\tLR: 0.000337\nTraining Epoch: 17 [3584/50000]\tLoss: 0.2436\tLR: 0.000337\nTraining Epoch: 17 [3712/50000]\tLoss: 0.1993\tLR: 0.000337\nTraining Epoch: 17 [3840/50000]\tLoss: 0.1666\tLR: 0.000337\nTraining Epoch: 17 [3968/50000]\tLoss: 0.2399\tLR: 0.000337\nTraining Epoch: 17 [4096/50000]\tLoss: 0.2363\tLR: 0.000337\nTraining Epoch: 17 [4224/50000]\tLoss: 0.2140\tLR: 0.000337\nTraining Epoch: 17 [4352/50000]\tLoss: 0.4881\tLR: 0.000337\nTraining Epoch: 17 [4480/50000]\tLoss: 0.2934\tLR: 0.000337\nTraining Epoch: 17 [4608/50000]\tLoss: 0.1947\tLR: 0.000337\nTraining Epoch: 17 [4736/50000]\tLoss: 0.3419\tLR: 0.000337\nTraining Epoch: 17 [4864/50000]\tLoss: 0.1761\tLR: 0.000337\nTraining Epoch: 17 [4992/50000]\tLoss: 0.2283\tLR: 0.000337\nTraining Epoch: 17 [5120/50000]\tLoss: 0.2400\tLR: 0.000337\nTraining Epoch: 17 [5248/50000]\tLoss: 0.2324\tLR: 0.000337\nTraining Epoch: 17 [5376/50000]\tLoss: 0.1498\tLR: 0.000337\nTraining Epoch: 17 [5504/50000]\tLoss: 0.1867\tLR: 0.000337\nTraining Epoch: 17 [5632/50000]\tLoss: 0.3203\tLR: 0.000337\nTraining Epoch: 17 [5760/50000]\tLoss: 0.2982\tLR: 0.000337\nTraining Epoch: 17 [5888/50000]\tLoss: 0.2076\tLR: 0.000337\nTraining Epoch: 17 [6016/50000]\tLoss: 0.3593\tLR: 0.000337\nTraining Epoch: 17 [6144/50000]\tLoss: 0.2099\tLR: 0.000337\nTraining Epoch: 17 [6272/50000]\tLoss: 0.2642\tLR: 0.000337\nTraining Epoch: 17 [6400/50000]\tLoss: 0.1645\tLR: 0.000337\nTraining Epoch: 17 [6528/50000]\tLoss: 0.1636\tLR: 0.000337\nTraining Epoch: 17 [6656/50000]\tLoss: 0.1927\tLR: 0.000337\nTraining Epoch: 17 [6784/50000]\tLoss: 0.4433\tLR: 0.000337\nTraining Epoch: 17 [6912/50000]\tLoss: 0.3020\tLR: 0.000337\nTraining Epoch: 17 [7040/50000]\tLoss: 0.1229\tLR: 0.000337\nTraining Epoch: 17 [7168/50000]\tLoss: 0.2003\tLR: 0.000337\nTraining Epoch: 17 [7296/50000]\tLoss: 0.2567\tLR: 0.000337\nTraining Epoch: 17 [7424/50000]\tLoss: 0.2647\tLR: 0.000337\nTraining Epoch: 17 [7552/50000]\tLoss: 0.2396\tLR: 0.000337\nTraining Epoch: 17 [7680/50000]\tLoss: 0.3289\tLR: 0.000337\nTraining Epoch: 17 [7808/50000]\tLoss: 0.2421\tLR: 0.000337\nTraining Epoch: 17 [7936/50000]\tLoss: 0.2862\tLR: 0.000337\nTraining Epoch: 17 [8064/50000]\tLoss: 0.3213\tLR: 0.000337\nTraining Epoch: 17 [8192/50000]\tLoss: 0.2945\tLR: 0.000337\nTraining Epoch: 17 [8320/50000]\tLoss: 0.2851\tLR: 0.000337\nTraining Epoch: 17 [8448/50000]\tLoss: 0.1767\tLR: 0.000337\nTraining Epoch: 17 [8576/50000]\tLoss: 0.2536\tLR: 0.000337\nTraining Epoch: 17 [8704/50000]\tLoss: 0.1812\tLR: 0.000337\nTraining Epoch: 17 [8832/50000]\tLoss: 0.3722\tLR: 0.000337\nTraining Epoch: 17 [8960/50000]\tLoss: 0.1773\tLR: 0.000337\nTraining Epoch: 17 [9088/50000]\tLoss: 0.2516\tLR: 0.000337\nTraining Epoch: 17 [9216/50000]\tLoss: 0.3337\tLR: 0.000337\nTraining Epoch: 17 [9344/50000]\tLoss: 0.2197\tLR: 0.000337\nTraining Epoch: 17 [9472/50000]\tLoss: 0.2488\tLR: 0.000337\nTraining Epoch: 17 [9600/50000]\tLoss: 0.2189\tLR: 0.000337\nTraining Epoch: 17 [9728/50000]\tLoss: 0.1996\tLR: 0.000337\nTraining Epoch: 17 [9856/50000]\tLoss: 0.2488\tLR: 0.000337\nTraining Epoch: 17 [9984/50000]\tLoss: 0.2371\tLR: 0.000337\nTraining Epoch: 17 [10112/50000]\tLoss: 0.2020\tLR: 0.000337\nTraining Epoch: 17 [10240/50000]\tLoss: 0.2381\tLR: 0.000337\nTraining Epoch: 17 [10368/50000]\tLoss: 0.1852\tLR: 0.000337\nTraining Epoch: 17 [10496/50000]\tLoss: 0.1731\tLR: 0.000337\nTraining Epoch: 17 [10624/50000]\tLoss: 0.2391\tLR: 0.000337\nTraining Epoch: 17 [10752/50000]\tLoss: 0.2031\tLR: 0.000337\nTraining Epoch: 17 [10880/50000]\tLoss: 0.2150\tLR: 0.000337\nTraining Epoch: 17 [11008/50000]\tLoss: 0.2825\tLR: 0.000337\nTraining Epoch: 17 [11136/50000]\tLoss: 0.1826\tLR: 0.000337\nTraining Epoch: 17 [11264/50000]\tLoss: 0.2290\tLR: 0.000337\nTraining Epoch: 17 [11392/50000]\tLoss: 0.3305\tLR: 0.000337\nTraining Epoch: 17 [11520/50000]\tLoss: 0.2261\tLR: 0.000337\nTraining Epoch: 17 [11648/50000]\tLoss: 0.3827\tLR: 0.000337\nTraining Epoch: 17 [11776/50000]\tLoss: 0.3340\tLR: 0.000337\nTraining Epoch: 17 [11904/50000]\tLoss: 0.2086\tLR: 0.000337\nTraining Epoch: 17 [12032/50000]\tLoss: 0.2784\tLR: 0.000337\nTraining Epoch: 17 [12160/50000]\tLoss: 0.3512\tLR: 0.000337\nTraining Epoch: 17 [12288/50000]\tLoss: 0.2299\tLR: 0.000337\nTraining Epoch: 17 [12416/50000]\tLoss: 0.2385\tLR: 0.000337\nTraining Epoch: 17 [12544/50000]\tLoss: 0.3529\tLR: 0.000337\nTraining Epoch: 17 [12672/50000]\tLoss: 0.2006\tLR: 0.000337\nTraining Epoch: 17 [12800/50000]\tLoss: 0.2170\tLR: 0.000337\nTraining Epoch: 17 [12928/50000]\tLoss: 0.3581\tLR: 0.000337\nTraining Epoch: 17 [13056/50000]\tLoss: 0.3426\tLR: 0.000337\nTraining Epoch: 17 [13184/50000]\tLoss: 0.2949\tLR: 0.000337\nTraining Epoch: 17 [13312/50000]\tLoss: 0.3523\tLR: 0.000337\nTraining Epoch: 17 [13440/50000]\tLoss: 0.2862\tLR: 0.000337\nTraining Epoch: 17 [13568/50000]\tLoss: 0.2927\tLR: 0.000337\nTraining Epoch: 17 [13696/50000]\tLoss: 0.3264\tLR: 0.000337\nTraining Epoch: 17 [13824/50000]\tLoss: 0.2491\tLR: 0.000337\nTraining Epoch: 17 [13952/50000]\tLoss: 0.1622\tLR: 0.000337\nTraining Epoch: 17 [14080/50000]\tLoss: 0.2235\tLR: 0.000337\nTraining Epoch: 17 [14208/50000]\tLoss: 0.1955\tLR: 0.000337\nTraining Epoch: 17 [14336/50000]\tLoss: 0.2115\tLR: 0.000337\nTraining Epoch: 17 [14464/50000]\tLoss: 0.3326\tLR: 0.000337\nTraining Epoch: 17 [14592/50000]\tLoss: 0.2159\tLR: 0.000337\nTraining Epoch: 17 [14720/50000]\tLoss: 0.2265\tLR: 0.000337\nTraining Epoch: 17 [14848/50000]\tLoss: 0.2097\tLR: 0.000337\nTraining Epoch: 17 [14976/50000]\tLoss: 0.2089\tLR: 0.000337\nTraining Epoch: 17 [15104/50000]\tLoss: 0.3987\tLR: 0.000337\nTraining Epoch: 17 [15232/50000]\tLoss: 0.2269\tLR: 0.000337\nTraining Epoch: 17 [15360/50000]\tLoss: 0.2444\tLR: 0.000337\nTraining Epoch: 17 [15488/50000]\tLoss: 0.1573\tLR: 0.000337\nTraining Epoch: 17 [15616/50000]\tLoss: 0.2506\tLR: 0.000337\nTraining Epoch: 17 [15744/50000]\tLoss: 0.3592\tLR: 0.000337\nTraining Epoch: 17 [15872/50000]\tLoss: 0.3534\tLR: 0.000337\nTraining Epoch: 17 [16000/50000]\tLoss: 0.2907\tLR: 0.000337\nTraining Epoch: 17 [16128/50000]\tLoss: 0.2870\tLR: 0.000337\nTraining Epoch: 17 [16256/50000]\tLoss: 0.3500\tLR: 0.000337\nTraining Epoch: 17 [16384/50000]\tLoss: 0.2174\tLR: 0.000337\nTraining Epoch: 17 [16512/50000]\tLoss: 0.1876\tLR: 0.000337\nTraining Epoch: 17 [16640/50000]\tLoss: 0.2000\tLR: 0.000337\nTraining Epoch: 17 [16768/50000]\tLoss: 0.2861\tLR: 0.000337\nTraining Epoch: 17 [16896/50000]\tLoss: 0.3984\tLR: 0.000337\nTraining Epoch: 17 [17024/50000]\tLoss: 0.1634\tLR: 0.000337\nTraining Epoch: 17 [17152/50000]\tLoss: 0.2720\tLR: 0.000337\nTraining Epoch: 17 [17280/50000]\tLoss: 0.2002\tLR: 0.000337\nTraining Epoch: 17 [17408/50000]\tLoss: 0.2710\tLR: 0.000337\nTraining Epoch: 17 [17536/50000]\tLoss: 0.1885\tLR: 0.000337\nTraining Epoch: 17 [17664/50000]\tLoss: 0.1656\tLR: 0.000337\nTraining Epoch: 17 [17792/50000]\tLoss: 0.2544\tLR: 0.000337\nTraining Epoch: 17 [17920/50000]\tLoss: 0.2780\tLR: 0.000337\nTraining Epoch: 17 [18048/50000]\tLoss: 0.1705\tLR: 0.000337\nTraining Epoch: 17 [18176/50000]\tLoss: 0.2740\tLR: 0.000337\nTraining Epoch: 17 [18304/50000]\tLoss: 0.2534\tLR: 0.000337\nTraining Epoch: 17 [18432/50000]\tLoss: 0.1646\tLR: 0.000337\nTraining Epoch: 17 [18560/50000]\tLoss: 0.2153\tLR: 0.000337\nTraining Epoch: 17 [18688/50000]\tLoss: 0.2512\tLR: 0.000337\nTraining Epoch: 17 [18816/50000]\tLoss: 0.2763\tLR: 0.000337\nTraining Epoch: 17 [18944/50000]\tLoss: 0.3081\tLR: 0.000337\nTraining Epoch: 17 [19072/50000]\tLoss: 0.3136\tLR: 0.000337\nTraining Epoch: 17 [19200/50000]\tLoss: 0.2450\tLR: 0.000337\nTraining Epoch: 17 [19328/50000]\tLoss: 0.1686\tLR: 0.000337\nTraining Epoch: 17 [19456/50000]\tLoss: 0.3607\tLR: 0.000337\nTraining Epoch: 17 [19584/50000]\tLoss: 0.3586\tLR: 0.000337\nTraining Epoch: 17 [19712/50000]\tLoss: 0.2167\tLR: 0.000337\nTraining Epoch: 17 [19840/50000]\tLoss: 0.2427\tLR: 0.000337\nTraining Epoch: 17 [19968/50000]\tLoss: 0.1732\tLR: 0.000337\nTraining Epoch: 17 [20096/50000]\tLoss: 0.1761\tLR: 0.000337\nTraining Epoch: 17 [20224/50000]\tLoss: 0.2965\tLR: 0.000337\nTraining Epoch: 17 [20352/50000]\tLoss: 0.1954\tLR: 0.000337\nTraining Epoch: 17 [20480/50000]\tLoss: 0.2465\tLR: 0.000337\nTraining Epoch: 17 [20608/50000]\tLoss: 0.2294\tLR: 0.000337\nTraining Epoch: 17 [20736/50000]\tLoss: 0.2481\tLR: 0.000337\nTraining Epoch: 17 [20864/50000]\tLoss: 0.1926\tLR: 0.000337\nTraining Epoch: 17 [20992/50000]\tLoss: 0.3064\tLR: 0.000337\nTraining Epoch: 17 [21120/50000]\tLoss: 0.3238\tLR: 0.000337\nTraining Epoch: 17 [21248/50000]\tLoss: 0.1761\tLR: 0.000337\nTraining Epoch: 17 [21376/50000]\tLoss: 0.2039\tLR: 0.000337\nTraining Epoch: 17 [21504/50000]\tLoss: 0.2553\tLR: 0.000337\nTraining Epoch: 17 [21632/50000]\tLoss: 0.2126\tLR: 0.000337\nTraining Epoch: 17 [21760/50000]\tLoss: 0.2102\tLR: 0.000337\nTraining Epoch: 17 [21888/50000]\tLoss: 0.2307\tLR: 0.000337\nTraining Epoch: 17 [22016/50000]\tLoss: 0.1494\tLR: 0.000337\nTraining Epoch: 17 [22144/50000]\tLoss: 0.1862\tLR: 0.000337\nTraining Epoch: 17 [22272/50000]\tLoss: 0.2065\tLR: 0.000337\nTraining Epoch: 17 [22400/50000]\tLoss: 0.1691\tLR: 0.000337\nTraining Epoch: 17 [22528/50000]\tLoss: 0.2555\tLR: 0.000337\nTraining Epoch: 17 [22656/50000]\tLoss: 0.3457\tLR: 0.000337\nTraining Epoch: 17 [22784/50000]\tLoss: 0.2364\tLR: 0.000337\nTraining Epoch: 17 [22912/50000]\tLoss: 0.2850\tLR: 0.000337\nTraining Epoch: 17 [23040/50000]\tLoss: 0.2466\tLR: 0.000337\nTraining Epoch: 17 [23168/50000]\tLoss: 0.2703\tLR: 0.000337\nTraining Epoch: 17 [23296/50000]\tLoss: 0.2810\tLR: 0.000337\nTraining Epoch: 17 [23424/50000]\tLoss: 0.2906\tLR: 0.000337\nTraining Epoch: 17 [23552/50000]\tLoss: 0.2497\tLR: 0.000337\nTraining Epoch: 17 [23680/50000]\tLoss: 0.2796\tLR: 0.000337\nTraining Epoch: 17 [23808/50000]\tLoss: 0.1796\tLR: 0.000337\nTraining Epoch: 17 [23936/50000]\tLoss: 0.2671\tLR: 0.000337\nTraining Epoch: 17 [24064/50000]\tLoss: 0.2750\tLR: 0.000337\nTraining Epoch: 17 [24192/50000]\tLoss: 0.3249\tLR: 0.000337\nTraining Epoch: 17 [24320/50000]\tLoss: 0.2076\tLR: 0.000337\nTraining Epoch: 17 [24448/50000]\tLoss: 0.2034\tLR: 0.000337\nTraining Epoch: 17 [24576/50000]\tLoss: 0.4013\tLR: 0.000337\nTraining Epoch: 17 [24704/50000]\tLoss: 0.3052\tLR: 0.000337\nTraining Epoch: 17 [24832/50000]\tLoss: 0.2861\tLR: 0.000337\nTraining Epoch: 17 [24960/50000]\tLoss: 0.1841\tLR: 0.000337\nTraining Epoch: 17 [25088/50000]\tLoss: 0.2046\tLR: 0.000337\nTraining Epoch: 17 [25216/50000]\tLoss: 0.2361\tLR: 0.000337\nTraining Epoch: 17 [25344/50000]\tLoss: 0.3871\tLR: 0.000337\nTraining Epoch: 17 [25472/50000]\tLoss: 0.1952\tLR: 0.000337\nTraining Epoch: 17 [25600/50000]\tLoss: 0.3157\tLR: 0.000337\nTraining Epoch: 17 [25728/50000]\tLoss: 0.1978\tLR: 0.000337\nTraining Epoch: 17 [25856/50000]\tLoss: 0.2757\tLR: 0.000337\nTraining Epoch: 17 [25984/50000]\tLoss: 0.2805\tLR: 0.000337\nTraining Epoch: 17 [26112/50000]\tLoss: 0.3686\tLR: 0.000337\nTraining Epoch: 17 [26240/50000]\tLoss: 0.2155\tLR: 0.000337\nTraining Epoch: 17 [26368/50000]\tLoss: 0.2213\tLR: 0.000337\nTraining Epoch: 17 [26496/50000]\tLoss: 0.3000\tLR: 0.000337\nTraining Epoch: 17 [26624/50000]\tLoss: 0.2075\tLR: 0.000337\nTraining Epoch: 17 [26752/50000]\tLoss: 0.2971\tLR: 0.000337\nTraining Epoch: 17 [26880/50000]\tLoss: 0.3360\tLR: 0.000337\nTraining Epoch: 17 [27008/50000]\tLoss: 0.3914\tLR: 0.000337\nTraining Epoch: 17 [27136/50000]\tLoss: 0.1940\tLR: 0.000337\nTraining Epoch: 17 [27264/50000]\tLoss: 0.2595\tLR: 0.000337\nTraining Epoch: 17 [27392/50000]\tLoss: 0.1683\tLR: 0.000337\nTraining Epoch: 17 [27520/50000]\tLoss: 0.2495\tLR: 0.000337\nTraining Epoch: 17 [27648/50000]\tLoss: 0.2532\tLR: 0.000337\nTraining Epoch: 17 [27776/50000]\tLoss: 0.1498\tLR: 0.000337\nTraining Epoch: 17 [27904/50000]\tLoss: 0.1861\tLR: 0.000337\nTraining Epoch: 17 [28032/50000]\tLoss: 0.3659\tLR: 0.000337\nTraining Epoch: 17 [28160/50000]\tLoss: 0.1642\tLR: 0.000337\nTraining Epoch: 17 [28288/50000]\tLoss: 0.2303\tLR: 0.000337\nTraining Epoch: 17 [28416/50000]\tLoss: 0.2737\tLR: 0.000337\nTraining Epoch: 17 [28544/50000]\tLoss: 0.2324\tLR: 0.000337\nTraining Epoch: 17 [28672/50000]\tLoss: 0.3073\tLR: 0.000337\nTraining Epoch: 17 [28800/50000]\tLoss: 0.1890\tLR: 0.000337\nTraining Epoch: 17 [28928/50000]\tLoss: 0.2193\tLR: 0.000337\nTraining Epoch: 17 [29056/50000]\tLoss: 0.2782\tLR: 0.000337\nTraining Epoch: 17 [29184/50000]\tLoss: 0.2364\tLR: 0.000337\nTraining Epoch: 17 [29312/50000]\tLoss: 0.1858\tLR: 0.000337\nTraining Epoch: 17 [29440/50000]\tLoss: 0.2022\tLR: 0.000337\nTraining Epoch: 17 [29568/50000]\tLoss: 0.2122\tLR: 0.000337\nTraining Epoch: 17 [29696/50000]\tLoss: 0.3125\tLR: 0.000337\nTraining Epoch: 17 [29824/50000]\tLoss: 0.3581\tLR: 0.000337\nTraining Epoch: 17 [29952/50000]\tLoss: 0.2973\tLR: 0.000337\nTraining Epoch: 17 [30080/50000]\tLoss: 0.2541\tLR: 0.000337\nTraining Epoch: 17 [30208/50000]\tLoss: 0.3019\tLR: 0.000337\nTraining Epoch: 17 [30336/50000]\tLoss: 0.3131\tLR: 0.000337\nTraining Epoch: 17 [30464/50000]\tLoss: 0.2026\tLR: 0.000337\nTraining Epoch: 17 [30592/50000]\tLoss: 0.2319\tLR: 0.000337\nTraining Epoch: 17 [30720/50000]\tLoss: 0.2516\tLR: 0.000337\nTraining Epoch: 17 [30848/50000]\tLoss: 0.2182\tLR: 0.000337\nTraining Epoch: 17 [30976/50000]\tLoss: 0.2473\tLR: 0.000337\nTraining Epoch: 17 [31104/50000]\tLoss: 0.2539\tLR: 0.000337\nTraining Epoch: 17 [31232/50000]\tLoss: 0.2980\tLR: 0.000337\nTraining Epoch: 17 [31360/50000]\tLoss: 0.3164\tLR: 0.000337\nTraining Epoch: 17 [31488/50000]\tLoss: 0.3216\tLR: 0.000337\nTraining Epoch: 17 [31616/50000]\tLoss: 0.2678\tLR: 0.000337\nTraining Epoch: 17 [31744/50000]\tLoss: 0.2735\tLR: 0.000337\nTraining Epoch: 17 [31872/50000]\tLoss: 0.2427\tLR: 0.000337\nTraining Epoch: 17 [32000/50000]\tLoss: 0.3206\tLR: 0.000337\nTraining Epoch: 17 [32128/50000]\tLoss: 0.2384\tLR: 0.000337\nTraining Epoch: 17 [32256/50000]\tLoss: 0.2157\tLR: 0.000337\nTraining Epoch: 17 [32384/50000]\tLoss: 0.3010\tLR: 0.000337\nTraining Epoch: 17 [32512/50000]\tLoss: 0.2621\tLR: 0.000337\nTraining Epoch: 17 [32640/50000]\tLoss: 0.2158\tLR: 0.000337\nTraining Epoch: 17 [32768/50000]\tLoss: 0.2747\tLR: 0.000337\nTraining Epoch: 17 [32896/50000]\tLoss: 0.2020\tLR: 0.000337\nTraining Epoch: 17 [33024/50000]\tLoss: 0.2344\tLR: 0.000337\nTraining Epoch: 17 [33152/50000]\tLoss: 0.2438\tLR: 0.000337\nTraining Epoch: 17 [33280/50000]\tLoss: 0.2972\tLR: 0.000337\nTraining Epoch: 17 [33408/50000]\tLoss: 0.2447\tLR: 0.000337\nTraining Epoch: 17 [33536/50000]\tLoss: 0.3808\tLR: 0.000337\nTraining Epoch: 17 [33664/50000]\tLoss: 0.2099\tLR: 0.000337\nTraining Epoch: 17 [33792/50000]\tLoss: 0.3270\tLR: 0.000337\nTraining Epoch: 17 [33920/50000]\tLoss: 0.3043\tLR: 0.000337\nTraining Epoch: 17 [34048/50000]\tLoss: 0.1554\tLR: 0.000337\nTraining Epoch: 17 [34176/50000]\tLoss: 0.2370\tLR: 0.000337\nTraining Epoch: 17 [34304/50000]\tLoss: 0.2670\tLR: 0.000337\nTraining Epoch: 17 [34432/50000]\tLoss: 0.2643\tLR: 0.000337\nTraining Epoch: 17 [34560/50000]\tLoss: 0.4014\tLR: 0.000337\nTraining Epoch: 17 [34688/50000]\tLoss: 0.3145\tLR: 0.000337\nTraining Epoch: 17 [34816/50000]\tLoss: 0.2251\tLR: 0.000337\nTraining Epoch: 17 [34944/50000]\tLoss: 0.2524\tLR: 0.000337\nTraining Epoch: 17 [35072/50000]\tLoss: 0.2483\tLR: 0.000337\nTraining Epoch: 17 [35200/50000]\tLoss: 0.1605\tLR: 0.000337\nTraining Epoch: 17 [35328/50000]\tLoss: 0.2788\tLR: 0.000337\nTraining Epoch: 17 [35456/50000]\tLoss: 0.2079\tLR: 0.000337\nTraining Epoch: 17 [35584/50000]\tLoss: 0.2018\tLR: 0.000337\nTraining Epoch: 17 [35712/50000]\tLoss: 0.2269\tLR: 0.000337\nTraining Epoch: 17 [35840/50000]\tLoss: 0.3844\tLR: 0.000337\nTraining Epoch: 17 [35968/50000]\tLoss: 0.2712\tLR: 0.000337\nTraining Epoch: 17 [36096/50000]\tLoss: 0.2580\tLR: 0.000337\nTraining Epoch: 17 [36224/50000]\tLoss: 0.3789\tLR: 0.000337\nTraining Epoch: 17 [36352/50000]\tLoss: 0.2403\tLR: 0.000337\nTraining Epoch: 17 [36480/50000]\tLoss: 0.3750\tLR: 0.000337\nTraining Epoch: 17 [36608/50000]\tLoss: 0.2750\tLR: 0.000337\nTraining Epoch: 17 [36736/50000]\tLoss: 0.2202\tLR: 0.000337\nTraining Epoch: 17 [36864/50000]\tLoss: 0.2994\tLR: 0.000337\nTraining Epoch: 17 [36992/50000]\tLoss: 0.2628\tLR: 0.000337\nTraining Epoch: 17 [37120/50000]\tLoss: 0.3513\tLR: 0.000337\nTraining Epoch: 17 [37248/50000]\tLoss: 0.2083\tLR: 0.000337\nTraining Epoch: 17 [37376/50000]\tLoss: 0.2464\tLR: 0.000337\nTraining Epoch: 17 [37504/50000]\tLoss: 0.2873\tLR: 0.000337\nTraining Epoch: 17 [37632/50000]\tLoss: 0.3231\tLR: 0.000337\nTraining Epoch: 17 [37760/50000]\tLoss: 0.2623\tLR: 0.000337\nTraining Epoch: 17 [37888/50000]\tLoss: 0.1783\tLR: 0.000337\nTraining Epoch: 17 [38016/50000]\tLoss: 0.2152\tLR: 0.000337\nTraining Epoch: 17 [38144/50000]\tLoss: 0.2212\tLR: 0.000337\nTraining Epoch: 17 [38272/50000]\tLoss: 0.1669\tLR: 0.000337\nTraining Epoch: 17 [38400/50000]\tLoss: 0.2344\tLR: 0.000337\nTraining Epoch: 17 [38528/50000]\tLoss: 0.1970\tLR: 0.000337\nTraining Epoch: 17 [38656/50000]\tLoss: 0.2146\tLR: 0.000337\nTraining Epoch: 17 [38784/50000]\tLoss: 0.1883\tLR: 0.000337\nTraining Epoch: 17 [38912/50000]\tLoss: 0.3154\tLR: 0.000337\nTraining Epoch: 17 [39040/50000]\tLoss: 0.3067\tLR: 0.000337\nTraining Epoch: 17 [39168/50000]\tLoss: 0.2637\tLR: 0.000337\nTraining Epoch: 17 [39296/50000]\tLoss: 0.1973\tLR: 0.000337\nTraining Epoch: 17 [39424/50000]\tLoss: 0.2177\tLR: 0.000337\nTraining Epoch: 17 [39552/50000]\tLoss: 0.1678\tLR: 0.000337\nTraining Epoch: 17 [39680/50000]\tLoss: 0.1910\tLR: 0.000337\nTraining Epoch: 17 [39808/50000]\tLoss: 0.1950\tLR: 0.000337\nTraining Epoch: 17 [39936/50000]\tLoss: 0.2525\tLR: 0.000337\nTraining Epoch: 17 [40064/50000]\tLoss: 0.1749\tLR: 0.000337\nTraining Epoch: 17 [40192/50000]\tLoss: 0.3137\tLR: 0.000337\nTraining Epoch: 17 [40320/50000]\tLoss: 0.2325\tLR: 0.000337\nTraining Epoch: 17 [40448/50000]\tLoss: 0.3161\tLR: 0.000337\nTraining Epoch: 17 [40576/50000]\tLoss: 0.1992\tLR: 0.000337\nTraining Epoch: 17 [40704/50000]\tLoss: 0.2174\tLR: 0.000337\nTraining Epoch: 17 [40832/50000]\tLoss: 0.2034\tLR: 0.000337\nTraining Epoch: 17 [40960/50000]\tLoss: 0.2587\tLR: 0.000337\nTraining Epoch: 17 [41088/50000]\tLoss: 0.1887\tLR: 0.000337\nTraining Epoch: 17 [41216/50000]\tLoss: 0.3069\tLR: 0.000337\nTraining Epoch: 17 [41344/50000]\tLoss: 0.1809\tLR: 0.000337\nTraining Epoch: 17 [41472/50000]\tLoss: 0.2063\tLR: 0.000337\nTraining Epoch: 17 [41600/50000]\tLoss: 0.1659\tLR: 0.000337\nTraining Epoch: 17 [41728/50000]\tLoss: 0.2103\tLR: 0.000337\nTraining Epoch: 17 [41856/50000]\tLoss: 0.3053\tLR: 0.000337\nTraining Epoch: 17 [41984/50000]\tLoss: 0.2241\tLR: 0.000337\nTraining Epoch: 17 [42112/50000]\tLoss: 0.2583\tLR: 0.000337\nTraining Epoch: 17 [42240/50000]\tLoss: 0.2657\tLR: 0.000337\nTraining Epoch: 17 [42368/50000]\tLoss: 0.1893\tLR: 0.000337\nTraining Epoch: 17 [42496/50000]\tLoss: 0.2139\tLR: 0.000337\nTraining Epoch: 17 [42624/50000]\tLoss: 0.1772\tLR: 0.000337\nTraining Epoch: 17 [42752/50000]\tLoss: 0.2804\tLR: 0.000337\nTraining Epoch: 17 [42880/50000]\tLoss: 0.2346\tLR: 0.000337\nTraining Epoch: 17 [43008/50000]\tLoss: 0.2261\tLR: 0.000337\nTraining Epoch: 17 [43136/50000]\tLoss: 0.1976\tLR: 0.000337\nTraining Epoch: 17 [43264/50000]\tLoss: 0.2634\tLR: 0.000337\nTraining Epoch: 17 [43392/50000]\tLoss: 0.3235\tLR: 0.000337\nTraining Epoch: 17 [43520/50000]\tLoss: 0.3826\tLR: 0.000337\nTraining Epoch: 17 [43648/50000]\tLoss: 0.2754\tLR: 0.000337\nTraining Epoch: 17 [43776/50000]\tLoss: 0.2767\tLR: 0.000337\nTraining Epoch: 17 [43904/50000]\tLoss: 0.2918\tLR: 0.000337\nTraining Epoch: 17 [44032/50000]\tLoss: 0.1498\tLR: 0.000337\nTraining Epoch: 17 [44160/50000]\tLoss: 0.2491\tLR: 0.000337\nTraining Epoch: 17 [44288/50000]\tLoss: 0.2321\tLR: 0.000337\nTraining Epoch: 17 [44416/50000]\tLoss: 0.1930\tLR: 0.000337\nTraining Epoch: 17 [44544/50000]\tLoss: 0.4241\tLR: 0.000337\nTraining Epoch: 17 [44672/50000]\tLoss: 0.3045\tLR: 0.000337\nTraining Epoch: 17 [44800/50000]\tLoss: 0.2413\tLR: 0.000337\nTraining Epoch: 17 [44928/50000]\tLoss: 0.2939\tLR: 0.000337\nTraining Epoch: 17 [45056/50000]\tLoss: 0.2824\tLR: 0.000337\nTraining Epoch: 17 [45184/50000]\tLoss: 0.1959\tLR: 0.000337\nTraining Epoch: 17 [45312/50000]\tLoss: 0.2330\tLR: 0.000337\nTraining Epoch: 17 [45440/50000]\tLoss: 0.1862\tLR: 0.000337\nTraining Epoch: 17 [45568/50000]\tLoss: 0.2264\tLR: 0.000337\nTraining Epoch: 17 [45696/50000]\tLoss: 0.1909\tLR: 0.000337\nTraining Epoch: 17 [45824/50000]\tLoss: 0.2491\tLR: 0.000337\nTraining Epoch: 17 [45952/50000]\tLoss: 0.2306\tLR: 0.000337\nTraining Epoch: 17 [46080/50000]\tLoss: 0.2764\tLR: 0.000337\nTraining Epoch: 17 [46208/50000]\tLoss: 0.2575\tLR: 0.000337\nTraining Epoch: 17 [46336/50000]\tLoss: 0.2033\tLR: 0.000337\nTraining Epoch: 17 [46464/50000]\tLoss: 0.3492\tLR: 0.000337\nTraining Epoch: 17 [46592/50000]\tLoss: 0.3503\tLR: 0.000337\nTraining Epoch: 17 [46720/50000]\tLoss: 0.2548\tLR: 0.000337\nTraining Epoch: 17 [46848/50000]\tLoss: 0.2807\tLR: 0.000337\nTraining Epoch: 17 [46976/50000]\tLoss: 0.2188\tLR: 0.000337\nTraining Epoch: 17 [47104/50000]\tLoss: 0.2633\tLR: 0.000337\nTraining Epoch: 17 [47232/50000]\tLoss: 0.3013\tLR: 0.000337\nTraining Epoch: 17 [47360/50000]\tLoss: 0.3836\tLR: 0.000337\nTraining Epoch: 17 [47488/50000]\tLoss: 0.2997\tLR: 0.000337\nTraining Epoch: 17 [47616/50000]\tLoss: 0.2207\tLR: 0.000337\nTraining Epoch: 17 [47744/50000]\tLoss: 0.1929\tLR: 0.000337\nTraining Epoch: 17 [47872/50000]\tLoss: 0.2857\tLR: 0.000337\nTraining Epoch: 17 [48000/50000]\tLoss: 0.2337\tLR: 0.000337\nTraining Epoch: 17 [48128/50000]\tLoss: 0.2274\tLR: 0.000337\nTraining Epoch: 17 [48256/50000]\tLoss: 0.2704\tLR: 0.000337\nTraining Epoch: 17 [48384/50000]\tLoss: 0.2213\tLR: 0.000337\nTraining Epoch: 17 [48512/50000]\tLoss: 0.1915\tLR: 0.000337\nTraining Epoch: 17 [48640/50000]\tLoss: 0.1736\tLR: 0.000337\nTraining Epoch: 17 [48768/50000]\tLoss: 0.3933\tLR: 0.000337\nTraining Epoch: 17 [48896/50000]\tLoss: 0.2389\tLR: 0.000337\nTraining Epoch: 17 [49024/50000]\tLoss: 0.2127\tLR: 0.000337\nTraining Epoch: 17 [49152/50000]\tLoss: 0.1601\tLR: 0.000337\nTraining Epoch: 17 [49280/50000]\tLoss: 0.1870\tLR: 0.000337\nTraining Epoch: 17 [49408/50000]\tLoss: 0.3362\tLR: 0.000337\nTraining Epoch: 17 [49536/50000]\tLoss: 0.3024\tLR: 0.000337\nTraining Epoch: 17 [49664/50000]\tLoss: 0.2646\tLR: 0.000337\nTraining Epoch: 17 [49792/50000]\tLoss: 0.2896\tLR: 0.000337\nTraining Epoch: 17 [49920/50000]\tLoss: 0.3157\tLR: 0.000337\nTraining Epoch: 17 [50000/50000]\tLoss: 0.1600\tLR: 0.000337\nTest set: Average loss: 0.0024, Accuracy: 0.8986\n\nTraining Epoch: 18 [128/50000]\tLoss: 0.2296\tLR: 0.000337\nTraining Epoch: 18 [256/50000]\tLoss: 0.2445\tLR: 0.000337\nTraining Epoch: 18 [384/50000]\tLoss: 0.3136\tLR: 0.000337\nTraining Epoch: 18 [512/50000]\tLoss: 0.2610\tLR: 0.000337\nTraining Epoch: 18 [640/50000]\tLoss: 0.2859\tLR: 0.000337\nTraining Epoch: 18 [768/50000]\tLoss: 0.1993\tLR: 0.000337\nTraining Epoch: 18 [896/50000]\tLoss: 0.2651\tLR: 0.000337\nTraining Epoch: 18 [1024/50000]\tLoss: 0.2930\tLR: 0.000337\nTraining Epoch: 18 [1152/50000]\tLoss: 0.2640\tLR: 0.000337\nTraining Epoch: 18 [1280/50000]\tLoss: 0.2347\tLR: 0.000337\nTraining Epoch: 18 [1408/50000]\tLoss: 0.4079\tLR: 0.000337\nTraining Epoch: 18 [1536/50000]\tLoss: 0.1586\tLR: 0.000337\nTraining Epoch: 18 [1664/50000]\tLoss: 0.3051\tLR: 0.000337\nTraining Epoch: 18 [1792/50000]\tLoss: 0.2569\tLR: 0.000337\nTraining Epoch: 18 [1920/50000]\tLoss: 0.1997\tLR: 0.000337\nTraining Epoch: 18 [2048/50000]\tLoss: 0.1771\tLR: 0.000337\nTraining Epoch: 18 [2176/50000]\tLoss: 0.3304\tLR: 0.000337\nTraining Epoch: 18 [2304/50000]\tLoss: 0.3124\tLR: 0.000337\nTraining Epoch: 18 [2432/50000]\tLoss: 0.2179\tLR: 0.000337\nTraining Epoch: 18 [2560/50000]\tLoss: 0.3409\tLR: 0.000337\nTraining Epoch: 18 [2688/50000]\tLoss: 0.3398\tLR: 0.000337\nTraining Epoch: 18 [2816/50000]\tLoss: 0.2097\tLR: 0.000337\nTraining Epoch: 18 [2944/50000]\tLoss: 0.2727\tLR: 0.000337\nTraining Epoch: 18 [3072/50000]\tLoss: 0.2657\tLR: 0.000337\nTraining Epoch: 18 [3200/50000]\tLoss: 0.2213\tLR: 0.000337\nTraining Epoch: 18 [3328/50000]\tLoss: 0.2444\tLR: 0.000337\nTraining Epoch: 18 [3456/50000]\tLoss: 0.2316\tLR: 0.000337\nTraining Epoch: 18 [3584/50000]\tLoss: 0.3288\tLR: 0.000337\nTraining Epoch: 18 [3712/50000]\tLoss: 0.2251\tLR: 0.000337\nTraining Epoch: 18 [3840/50000]\tLoss: 0.1420\tLR: 0.000337\nTraining Epoch: 18 [3968/50000]\tLoss: 0.2940\tLR: 0.000337\nTraining Epoch: 18 [4096/50000]\tLoss: 0.1855\tLR: 0.000337\nTraining Epoch: 18 [4224/50000]\tLoss: 0.3889\tLR: 0.000337\nTraining Epoch: 18 [4352/50000]\tLoss: 0.2486\tLR: 0.000337\nTraining Epoch: 18 [4480/50000]\tLoss: 0.2896\tLR: 0.000337\nTraining Epoch: 18 [4608/50000]\tLoss: 0.2127\tLR: 0.000337\nTraining Epoch: 18 [4736/50000]\tLoss: 0.2187\tLR: 0.000337\nTraining Epoch: 18 [4864/50000]\tLoss: 0.1625\tLR: 0.000337\nTraining Epoch: 18 [4992/50000]\tLoss: 0.2188\tLR: 0.000337\nTraining Epoch: 18 [5120/50000]\tLoss: 0.1752\tLR: 0.000337\nTraining Epoch: 18 [5248/50000]\tLoss: 0.2433\tLR: 0.000337\nTraining Epoch: 18 [5376/50000]\tLoss: 0.2851\tLR: 0.000337\nTraining Epoch: 18 [5504/50000]\tLoss: 0.2016\tLR: 0.000337\nTraining Epoch: 18 [5632/50000]\tLoss: 0.3504\tLR: 0.000337\nTraining Epoch: 18 [5760/50000]\tLoss: 0.3712\tLR: 0.000337\nTraining Epoch: 18 [5888/50000]\tLoss: 0.3087\tLR: 0.000337\nTraining Epoch: 18 [6016/50000]\tLoss: 0.2429\tLR: 0.000337\nTraining Epoch: 18 [6144/50000]\tLoss: 0.2217\tLR: 0.000337\nTraining Epoch: 18 [6272/50000]\tLoss: 0.2294\tLR: 0.000337\nTraining Epoch: 18 [6400/50000]\tLoss: 0.2780\tLR: 0.000337\nTraining Epoch: 18 [6528/50000]\tLoss: 0.1931\tLR: 0.000337\nTraining Epoch: 18 [6656/50000]\tLoss: 0.2118\tLR: 0.000337\nTraining Epoch: 18 [6784/50000]\tLoss: 0.1699\tLR: 0.000337\nTraining Epoch: 18 [6912/50000]\tLoss: 0.2831\tLR: 0.000337\nTraining Epoch: 18 [7040/50000]\tLoss: 0.2210\tLR: 0.000337\nTraining Epoch: 18 [7168/50000]\tLoss: 0.4280\tLR: 0.000337\nTraining Epoch: 18 [7296/50000]\tLoss: 0.2799\tLR: 0.000337\nTraining Epoch: 18 [7424/50000]\tLoss: 0.3301\tLR: 0.000337\nTraining Epoch: 18 [7552/50000]\tLoss: 0.2036\tLR: 0.000337\nTraining Epoch: 18 [7680/50000]\tLoss: 0.2546\tLR: 0.000337\nTraining Epoch: 18 [7808/50000]\tLoss: 0.2478\tLR: 0.000337\nTraining Epoch: 18 [7936/50000]\tLoss: 0.1852\tLR: 0.000337\nTraining Epoch: 18 [8064/50000]\tLoss: 0.3056\tLR: 0.000337\nTraining Epoch: 18 [8192/50000]\tLoss: 0.1855\tLR: 0.000337\nTraining Epoch: 18 [8320/50000]\tLoss: 0.3218\tLR: 0.000337\nTraining Epoch: 18 [8448/50000]\tLoss: 0.2403\tLR: 0.000337\nTraining Epoch: 18 [8576/50000]\tLoss: 0.2847\tLR: 0.000337\nTraining Epoch: 18 [8704/50000]\tLoss: 0.3019\tLR: 0.000337\nTraining Epoch: 18 [8832/50000]\tLoss: 0.1277\tLR: 0.000337\nTraining Epoch: 18 [8960/50000]\tLoss: 0.3202\tLR: 0.000337\nTraining Epoch: 18 [9088/50000]\tLoss: 0.1702\tLR: 0.000337\nTraining Epoch: 18 [9216/50000]\tLoss: 0.2841\tLR: 0.000337\nTraining Epoch: 18 [9344/50000]\tLoss: 0.2113\tLR: 0.000337\nTraining Epoch: 18 [9472/50000]\tLoss: 0.3248\tLR: 0.000337\nTraining Epoch: 18 [9600/50000]\tLoss: 0.2464\tLR: 0.000337\nTraining Epoch: 18 [9728/50000]\tLoss: 0.2873\tLR: 0.000337\nTraining Epoch: 18 [9856/50000]\tLoss: 0.2162\tLR: 0.000337\nTraining Epoch: 18 [9984/50000]\tLoss: 0.2560\tLR: 0.000337\nTraining Epoch: 18 [10112/50000]\tLoss: 0.1240\tLR: 0.000337\nTraining Epoch: 18 [10240/50000]\tLoss: 0.2768\tLR: 0.000337\nTraining Epoch: 18 [10368/50000]\tLoss: 0.2543\tLR: 0.000337\nTraining Epoch: 18 [10496/50000]\tLoss: 0.2634\tLR: 0.000337\nTraining Epoch: 18 [10624/50000]\tLoss: 0.3512\tLR: 0.000337\nTraining Epoch: 18 [10752/50000]\tLoss: 0.2338\tLR: 0.000337\nTraining Epoch: 18 [10880/50000]\tLoss: 0.2518\tLR: 0.000337\nTraining Epoch: 18 [11008/50000]\tLoss: 0.2870\tLR: 0.000337\nTraining Epoch: 18 [11136/50000]\tLoss: 0.2179\tLR: 0.000337\nTraining Epoch: 18 [11264/50000]\tLoss: 0.3725\tLR: 0.000337\nTraining Epoch: 18 [11392/50000]\tLoss: 0.3548\tLR: 0.000337\nTraining Epoch: 18 [11520/50000]\tLoss: 0.2698\tLR: 0.000337\nTraining Epoch: 18 [11648/50000]\tLoss: 0.2632\tLR: 0.000337\nTraining Epoch: 18 [11776/50000]\tLoss: 0.1766\tLR: 0.000337\nTraining Epoch: 18 [11904/50000]\tLoss: 0.2795\tLR: 0.000337\nTraining Epoch: 18 [12032/50000]\tLoss: 0.2428\tLR: 0.000337\nTraining Epoch: 18 [12160/50000]\tLoss: 0.3033\tLR: 0.000337\nTraining Epoch: 18 [12288/50000]\tLoss: 0.2355\tLR: 0.000337\nTraining Epoch: 18 [12416/50000]\tLoss: 0.2185\tLR: 0.000337\nTraining Epoch: 18 [12544/50000]\tLoss: 0.3154\tLR: 0.000337\nTraining Epoch: 18 [12672/50000]\tLoss: 0.3062\tLR: 0.000337\nTraining Epoch: 18 [12800/50000]\tLoss: 0.2132\tLR: 0.000337\nTraining Epoch: 18 [12928/50000]\tLoss: 0.3312\tLR: 0.000337\nTraining Epoch: 18 [13056/50000]\tLoss: 0.3109\tLR: 0.000337\nTraining Epoch: 18 [13184/50000]\tLoss: 0.2897\tLR: 0.000337\nTraining Epoch: 18 [13312/50000]\tLoss: 0.2477\tLR: 0.000337\nTraining Epoch: 18 [13440/50000]\tLoss: 0.1990\tLR: 0.000337\nTraining Epoch: 18 [13568/50000]\tLoss: 0.2332\tLR: 0.000337\nTraining Epoch: 18 [13696/50000]\tLoss: 0.2909\tLR: 0.000337\nTraining Epoch: 18 [13824/50000]\tLoss: 0.3089\tLR: 0.000337\nTraining Epoch: 18 [13952/50000]\tLoss: 0.1796\tLR: 0.000337\nTraining Epoch: 18 [14080/50000]\tLoss: 0.3273\tLR: 0.000337\nTraining Epoch: 18 [14208/50000]\tLoss: 0.1775\tLR: 0.000337\nTraining Epoch: 18 [14336/50000]\tLoss: 0.3207\tLR: 0.000337\nTraining Epoch: 18 [14464/50000]\tLoss: 0.1710\tLR: 0.000337\nTraining Epoch: 18 [14592/50000]\tLoss: 0.3073\tLR: 0.000337\nTraining Epoch: 18 [14720/50000]\tLoss: 0.2613\tLR: 0.000337\nTraining Epoch: 18 [14848/50000]\tLoss: 0.2262\tLR: 0.000337\nTraining Epoch: 18 [14976/50000]\tLoss: 0.2673\tLR: 0.000337\nTraining Epoch: 18 [15104/50000]\tLoss: 0.2121\tLR: 0.000337\nTraining Epoch: 18 [15232/50000]\tLoss: 0.2455\tLR: 0.000337\nTraining Epoch: 18 [15360/50000]\tLoss: 0.2334\tLR: 0.000337\nTraining Epoch: 18 [15488/50000]\tLoss: 0.1860\tLR: 0.000337\nTraining Epoch: 18 [15616/50000]\tLoss: 0.2177\tLR: 0.000337\nTraining Epoch: 18 [15744/50000]\tLoss: 0.3145\tLR: 0.000337\nTraining Epoch: 18 [15872/50000]\tLoss: 0.2582\tLR: 0.000337\nTraining Epoch: 18 [16000/50000]\tLoss: 0.2764\tLR: 0.000337\nTraining Epoch: 18 [16128/50000]\tLoss: 0.3201\tLR: 0.000337\nTraining Epoch: 18 [16256/50000]\tLoss: 0.1741\tLR: 0.000337\nTraining Epoch: 18 [16384/50000]\tLoss: 0.2052\tLR: 0.000337\nTraining Epoch: 18 [16512/50000]\tLoss: 0.2964\tLR: 0.000337\nTraining Epoch: 18 [16640/50000]\tLoss: 0.3104\tLR: 0.000337\nTraining Epoch: 18 [16768/50000]\tLoss: 0.2568\tLR: 0.000337\nTraining Epoch: 18 [16896/50000]\tLoss: 0.2156\tLR: 0.000337\nTraining Epoch: 18 [17024/50000]\tLoss: 0.2252\tLR: 0.000337\nTraining Epoch: 18 [17152/50000]\tLoss: 0.2249\tLR: 0.000337\nTraining Epoch: 18 [17280/50000]\tLoss: 0.1797\tLR: 0.000337\nTraining Epoch: 18 [17408/50000]\tLoss: 0.3078\tLR: 0.000337\nTraining Epoch: 18 [17536/50000]\tLoss: 0.2096\tLR: 0.000337\nTraining Epoch: 18 [17664/50000]\tLoss: 0.2660\tLR: 0.000337\nTraining Epoch: 18 [17792/50000]\tLoss: 0.3509\tLR: 0.000337\nTraining Epoch: 18 [17920/50000]\tLoss: 0.2640\tLR: 0.000337\nTraining Epoch: 18 [18048/50000]\tLoss: 0.2909\tLR: 0.000337\nTraining Epoch: 18 [18176/50000]\tLoss: 0.3396\tLR: 0.000337\nTraining Epoch: 18 [18304/50000]\tLoss: 0.2131\tLR: 0.000337\nTraining Epoch: 18 [18432/50000]\tLoss: 0.2969\tLR: 0.000337\nTraining Epoch: 18 [18560/50000]\tLoss: 0.2110\tLR: 0.000337\nTraining Epoch: 18 [18688/50000]\tLoss: 0.2277\tLR: 0.000337\nTraining Epoch: 18 [18816/50000]\tLoss: 0.2625\tLR: 0.000337\nTraining Epoch: 18 [18944/50000]\tLoss: 0.2185\tLR: 0.000337\nTraining Epoch: 18 [19072/50000]\tLoss: 0.2192\tLR: 0.000337\nTraining Epoch: 18 [19200/50000]\tLoss: 0.2203\tLR: 0.000337\nTraining Epoch: 18 [19328/50000]\tLoss: 0.2493\tLR: 0.000337\nTraining Epoch: 18 [19456/50000]\tLoss: 0.2860\tLR: 0.000337\nTraining Epoch: 18 [19584/50000]\tLoss: 0.3021\tLR: 0.000337\nTraining Epoch: 18 [19712/50000]\tLoss: 0.2010\tLR: 0.000337\nTraining Epoch: 18 [19840/50000]\tLoss: 0.3319\tLR: 0.000337\nTraining Epoch: 18 [19968/50000]\tLoss: 0.3567\tLR: 0.000337\nTraining Epoch: 18 [20096/50000]\tLoss: 0.1944\tLR: 0.000337\nTraining Epoch: 18 [20224/50000]\tLoss: 0.2775\tLR: 0.000337\nTraining Epoch: 18 [20352/50000]\tLoss: 0.2709\tLR: 0.000337\nTraining Epoch: 18 [20480/50000]\tLoss: 0.2691\tLR: 0.000337\nTraining Epoch: 18 [20608/50000]\tLoss: 0.2661\tLR: 0.000337\nTraining Epoch: 18 [20736/50000]\tLoss: 0.1894\tLR: 0.000337\nTraining Epoch: 18 [20864/50000]\tLoss: 0.1843\tLR: 0.000337\nTraining Epoch: 18 [20992/50000]\tLoss: 0.2303\tLR: 0.000337\nTraining Epoch: 18 [21120/50000]\tLoss: 0.2407\tLR: 0.000337\nTraining Epoch: 18 [21248/50000]\tLoss: 0.3183\tLR: 0.000337\nTraining Epoch: 18 [21376/50000]\tLoss: 0.2390\tLR: 0.000337\nTraining Epoch: 18 [21504/50000]\tLoss: 0.2060\tLR: 0.000337\nTraining Epoch: 18 [21632/50000]\tLoss: 0.2015\tLR: 0.000337\nTraining Epoch: 18 [21760/50000]\tLoss: 0.1769\tLR: 0.000337\nTraining Epoch: 18 [21888/50000]\tLoss: 0.2581\tLR: 0.000337\nTraining Epoch: 18 [22016/50000]\tLoss: 0.3944\tLR: 0.000337\nTraining Epoch: 18 [22144/50000]\tLoss: 0.1954\tLR: 0.000337\nTraining Epoch: 18 [22272/50000]\tLoss: 0.2383\tLR: 0.000337\nTraining Epoch: 18 [22400/50000]\tLoss: 0.2562\tLR: 0.000337\nTraining Epoch: 18 [22528/50000]\tLoss: 0.1794\tLR: 0.000337\nTraining Epoch: 18 [22656/50000]\tLoss: 0.3784\tLR: 0.000337\nTraining Epoch: 18 [22784/50000]\tLoss: 0.1934\tLR: 0.000337\nTraining Epoch: 18 [22912/50000]\tLoss: 0.2402\tLR: 0.000337\nTraining Epoch: 18 [23040/50000]\tLoss: 0.2165\tLR: 0.000337\nTraining Epoch: 18 [23168/50000]\tLoss: 0.4289\tLR: 0.000337\nTraining Epoch: 18 [23296/50000]\tLoss: 0.2512\tLR: 0.000337\nTraining Epoch: 18 [23424/50000]\tLoss: 0.2137\tLR: 0.000337\nTraining Epoch: 18 [23552/50000]\tLoss: 0.1835\tLR: 0.000337\nTraining Epoch: 18 [23680/50000]\tLoss: 0.2657\tLR: 0.000337\nTraining Epoch: 18 [23808/50000]\tLoss: 0.2970\tLR: 0.000337\nTraining Epoch: 18 [23936/50000]\tLoss: 0.2141\tLR: 0.000337\nTraining Epoch: 18 [24064/50000]\tLoss: 0.2523\tLR: 0.000337\nTraining Epoch: 18 [24192/50000]\tLoss: 0.1886\tLR: 0.000337\nTraining Epoch: 18 [24320/50000]\tLoss: 0.2633\tLR: 0.000337\nTraining Epoch: 18 [24448/50000]\tLoss: 0.2428\tLR: 0.000337\nTraining Epoch: 18 [24576/50000]\tLoss: 0.2900\tLR: 0.000337\nTraining Epoch: 18 [24704/50000]\tLoss: 0.3318\tLR: 0.000337\nTraining Epoch: 18 [24832/50000]\tLoss: 0.1493\tLR: 0.000337\nTraining Epoch: 18 [24960/50000]\tLoss: 0.2125\tLR: 0.000337\nTraining Epoch: 18 [25088/50000]\tLoss: 0.2579\tLR: 0.000337\nTraining Epoch: 18 [25216/50000]\tLoss: 0.2176\tLR: 0.000337\nTraining Epoch: 18 [25344/50000]\tLoss: 0.1408\tLR: 0.000337\nTraining Epoch: 18 [25472/50000]\tLoss: 0.3242\tLR: 0.000337\nTraining Epoch: 18 [25600/50000]\tLoss: 0.2286\tLR: 0.000337\nTraining Epoch: 18 [25728/50000]\tLoss: 0.2652\tLR: 0.000337\nTraining Epoch: 18 [25856/50000]\tLoss: 0.2087\tLR: 0.000337\nTraining Epoch: 18 [25984/50000]\tLoss: 0.2156\tLR: 0.000337\nTraining Epoch: 18 [26112/50000]\tLoss: 0.2100\tLR: 0.000337\nTraining Epoch: 18 [26240/50000]\tLoss: 0.1615\tLR: 0.000337\nTraining Epoch: 18 [26368/50000]\tLoss: 0.3058\tLR: 0.000337\nTraining Epoch: 18 [26496/50000]\tLoss: 0.2956\tLR: 0.000337\nTraining Epoch: 18 [26624/50000]\tLoss: 0.1599\tLR: 0.000337\nTraining Epoch: 18 [26752/50000]\tLoss: 0.1626\tLR: 0.000337\nTraining Epoch: 18 [26880/50000]\tLoss: 0.3021\tLR: 0.000337\nTraining Epoch: 18 [27008/50000]\tLoss: 0.2660\tLR: 0.000337\nTraining Epoch: 18 [27136/50000]\tLoss: 0.3111\tLR: 0.000337\nTraining Epoch: 18 [27264/50000]\tLoss: 0.3628\tLR: 0.000337\nTraining Epoch: 18 [27392/50000]\tLoss: 0.2406\tLR: 0.000337\nTraining Epoch: 18 [27520/50000]\tLoss: 0.2844\tLR: 0.000337\nTraining Epoch: 18 [27648/50000]\tLoss: 0.1915\tLR: 0.000337\nTraining Epoch: 18 [27776/50000]\tLoss: 0.2635\tLR: 0.000337\nTraining Epoch: 18 [27904/50000]\tLoss: 0.2607\tLR: 0.000337\nTraining Epoch: 18 [28032/50000]\tLoss: 0.2476\tLR: 0.000337\nTraining Epoch: 18 [28160/50000]\tLoss: 0.2554\tLR: 0.000337\nTraining Epoch: 18 [28288/50000]\tLoss: 0.2999\tLR: 0.000337\nTraining Epoch: 18 [28416/50000]\tLoss: 0.1739\tLR: 0.000337\nTraining Epoch: 18 [28544/50000]\tLoss: 0.2792\tLR: 0.000337\nTraining Epoch: 18 [28672/50000]\tLoss: 0.2538\tLR: 0.000337\nTraining Epoch: 18 [28800/50000]\tLoss: 0.2979\tLR: 0.000337\nTraining Epoch: 18 [28928/50000]\tLoss: 0.2704\tLR: 0.000337\nTraining Epoch: 18 [29056/50000]\tLoss: 0.2628\tLR: 0.000337\nTraining Epoch: 18 [29184/50000]\tLoss: 0.2026\tLR: 0.000337\nTraining Epoch: 18 [29312/50000]\tLoss: 0.2100\tLR: 0.000337\nTraining Epoch: 18 [29440/50000]\tLoss: 0.2433\tLR: 0.000337\nTraining Epoch: 18 [29568/50000]\tLoss: 0.2774\tLR: 0.000337\nTraining Epoch: 18 [29696/50000]\tLoss: 0.2773\tLR: 0.000337\nTraining Epoch: 18 [29824/50000]\tLoss: 0.2036\tLR: 0.000337\nTraining Epoch: 18 [29952/50000]\tLoss: 0.2761\tLR: 0.000337\nTraining Epoch: 18 [30080/50000]\tLoss: 0.3732\tLR: 0.000337\nTraining Epoch: 18 [30208/50000]\tLoss: 0.2775\tLR: 0.000337\nTraining Epoch: 18 [30336/50000]\tLoss: 0.2740\tLR: 0.000337\nTraining Epoch: 18 [30464/50000]\tLoss: 0.2780\tLR: 0.000337\nTraining Epoch: 18 [30592/50000]\tLoss: 0.3105\tLR: 0.000337\nTraining Epoch: 18 [30720/50000]\tLoss: 0.3483\tLR: 0.000337\nTraining Epoch: 18 [30848/50000]\tLoss: 0.3516\tLR: 0.000337\nTraining Epoch: 18 [30976/50000]\tLoss: 0.2518\tLR: 0.000337\nTraining Epoch: 18 [31104/50000]\tLoss: 0.1986\tLR: 0.000337\nTraining Epoch: 18 [31232/50000]\tLoss: 0.1990\tLR: 0.000337\nTraining Epoch: 18 [31360/50000]\tLoss: 0.1982\tLR: 0.000337\nTraining Epoch: 18 [31488/50000]\tLoss: 0.2660\tLR: 0.000337\nTraining Epoch: 18 [31616/50000]\tLoss: 0.2833\tLR: 0.000337\nTraining Epoch: 18 [31744/50000]\tLoss: 0.3178\tLR: 0.000337\nTraining Epoch: 18 [31872/50000]\tLoss: 0.2804\tLR: 0.000337\nTraining Epoch: 18 [32000/50000]\tLoss: 0.2820\tLR: 0.000337\nTraining Epoch: 18 [32128/50000]\tLoss: 0.2572\tLR: 0.000337\nTraining Epoch: 18 [32256/50000]\tLoss: 0.2763\tLR: 0.000337\nTraining Epoch: 18 [32384/50000]\tLoss: 0.2245\tLR: 0.000337\nTraining Epoch: 18 [32512/50000]\tLoss: 0.1878\tLR: 0.000337\nTraining Epoch: 18 [32640/50000]\tLoss: 0.2342\tLR: 0.000337\nTraining Epoch: 18 [32768/50000]\tLoss: 0.2066\tLR: 0.000337\nTraining Epoch: 18 [32896/50000]\tLoss: 0.1829\tLR: 0.000337\nTraining Epoch: 18 [33024/50000]\tLoss: 0.2358\tLR: 0.000337\nTraining Epoch: 18 [33152/50000]\tLoss: 0.2853\tLR: 0.000337\nTraining Epoch: 18 [33280/50000]\tLoss: 0.2974\tLR: 0.000337\nTraining Epoch: 18 [33408/50000]\tLoss: 0.1981\tLR: 0.000337\nTraining Epoch: 18 [33536/50000]\tLoss: 0.1897\tLR: 0.000337\nTraining Epoch: 18 [33664/50000]\tLoss: 0.1866\tLR: 0.000337\nTraining Epoch: 18 [33792/50000]\tLoss: 0.2338\tLR: 0.000337\nTraining Epoch: 18 [33920/50000]\tLoss: 0.2907\tLR: 0.000337\nTraining Epoch: 18 [34048/50000]\tLoss: 0.2060\tLR: 0.000337\nTraining Epoch: 18 [34176/50000]\tLoss: 0.4217\tLR: 0.000337\nTraining Epoch: 18 [34304/50000]\tLoss: 0.2911\tLR: 0.000337\nTraining Epoch: 18 [34432/50000]\tLoss: 0.2801\tLR: 0.000337\nTraining Epoch: 18 [34560/50000]\tLoss: 0.3979\tLR: 0.000337\nTraining Epoch: 18 [34688/50000]\tLoss: 0.2292\tLR: 0.000337\nTraining Epoch: 18 [34816/50000]\tLoss: 0.3163\tLR: 0.000337\nTraining Epoch: 18 [34944/50000]\tLoss: 0.2121\tLR: 0.000337\nTraining Epoch: 18 [35072/50000]\tLoss: 0.2936\tLR: 0.000337\nTraining Epoch: 18 [35200/50000]\tLoss: 0.2824\tLR: 0.000337\nTraining Epoch: 18 [35328/50000]\tLoss: 0.2456\tLR: 0.000337\nTraining Epoch: 18 [35456/50000]\tLoss: 0.2187\tLR: 0.000337\nTraining Epoch: 18 [35584/50000]\tLoss: 0.2694\tLR: 0.000337\nTraining Epoch: 18 [35712/50000]\tLoss: 0.2145\tLR: 0.000337\nTraining Epoch: 18 [35840/50000]\tLoss: 0.1585\tLR: 0.000337\nTraining Epoch: 18 [35968/50000]\tLoss: 0.2751\tLR: 0.000337\nTraining Epoch: 18 [36096/50000]\tLoss: 0.2182\tLR: 0.000337\nTraining Epoch: 18 [36224/50000]\tLoss: 0.1938\tLR: 0.000337\nTraining Epoch: 18 [36352/50000]\tLoss: 0.1616\tLR: 0.000337\nTraining Epoch: 18 [36480/50000]\tLoss: 0.2114\tLR: 0.000337\nTraining Epoch: 18 [36608/50000]\tLoss: 0.2205\tLR: 0.000337\nTraining Epoch: 18 [36736/50000]\tLoss: 0.4492\tLR: 0.000337\nTraining Epoch: 18 [36864/50000]\tLoss: 0.2660\tLR: 0.000337\nTraining Epoch: 18 [36992/50000]\tLoss: 0.3020\tLR: 0.000337\nTraining Epoch: 18 [37120/50000]\tLoss: 0.2670\tLR: 0.000337\nTraining Epoch: 18 [37248/50000]\tLoss: 0.2774\tLR: 0.000337\nTraining Epoch: 18 [37376/50000]\tLoss: 0.1771\tLR: 0.000337\nTraining Epoch: 18 [37504/50000]\tLoss: 0.1938\tLR: 0.000337\nTraining Epoch: 18 [37632/50000]\tLoss: 0.1679\tLR: 0.000337\nTraining Epoch: 18 [37760/50000]\tLoss: 0.1421\tLR: 0.000337\nTraining Epoch: 18 [37888/50000]\tLoss: 0.1951\tLR: 0.000337\nTraining Epoch: 18 [38016/50000]\tLoss: 0.1721\tLR: 0.000337\nTraining Epoch: 18 [38144/50000]\tLoss: 0.3050\tLR: 0.000337\nTraining Epoch: 18 [38272/50000]\tLoss: 0.1265\tLR: 0.000337\nTraining Epoch: 18 [38400/50000]\tLoss: 0.2120\tLR: 0.000337\nTraining Epoch: 18 [38528/50000]\tLoss: 0.2518\tLR: 0.000337\nTraining Epoch: 18 [38656/50000]\tLoss: 0.2999\tLR: 0.000337\nTraining Epoch: 18 [38784/50000]\tLoss: 0.2171\tLR: 0.000337\nTraining Epoch: 18 [38912/50000]\tLoss: 0.2021\tLR: 0.000337\nTraining Epoch: 18 [39040/50000]\tLoss: 0.2914\tLR: 0.000337\nTraining Epoch: 18 [39168/50000]\tLoss: 0.2297\tLR: 0.000337\nTraining Epoch: 18 [39296/50000]\tLoss: 0.2894\tLR: 0.000337\nTraining Epoch: 18 [39424/50000]\tLoss: 0.2874\tLR: 0.000337\nTraining Epoch: 18 [39552/50000]\tLoss: 0.2805\tLR: 0.000337\nTraining Epoch: 18 [39680/50000]\tLoss: 0.2146\tLR: 0.000337\nTraining Epoch: 18 [39808/50000]\tLoss: 0.2446\tLR: 0.000337\nTraining Epoch: 18 [39936/50000]\tLoss: 0.2335\tLR: 0.000337\nTraining Epoch: 18 [40064/50000]\tLoss: 0.2196\tLR: 0.000337\nTraining Epoch: 18 [40192/50000]\tLoss: 0.2080\tLR: 0.000337\nTraining Epoch: 18 [40320/50000]\tLoss: 0.1532\tLR: 0.000337\nTraining Epoch: 18 [40448/50000]\tLoss: 0.2646\tLR: 0.000337\nTraining Epoch: 18 [40576/50000]\tLoss: 0.2298\tLR: 0.000337\nTraining Epoch: 18 [40704/50000]\tLoss: 0.2713\tLR: 0.000337\nTraining Epoch: 18 [40832/50000]\tLoss: 0.2511\tLR: 0.000337\nTraining Epoch: 18 [40960/50000]\tLoss: 0.2657\tLR: 0.000337\nTraining Epoch: 18 [41088/50000]\tLoss: 0.2108\tLR: 0.000337\nTraining Epoch: 18 [41216/50000]\tLoss: 0.1212\tLR: 0.000337\nTraining Epoch: 18 [41344/50000]\tLoss: 0.3209\tLR: 0.000337\nTraining Epoch: 18 [41472/50000]\tLoss: 0.2680\tLR: 0.000337\nTraining Epoch: 18 [41600/50000]\tLoss: 0.2174\tLR: 0.000337\nTraining Epoch: 18 [41728/50000]\tLoss: 0.2414\tLR: 0.000337\nTraining Epoch: 18 [41856/50000]\tLoss: 0.2460\tLR: 0.000337\nTraining Epoch: 18 [41984/50000]\tLoss: 0.3741\tLR: 0.000337\nTraining Epoch: 18 [42112/50000]\tLoss: 0.2655\tLR: 0.000337\nTraining Epoch: 18 [42240/50000]\tLoss: 0.2592\tLR: 0.000337\nTraining Epoch: 18 [42368/50000]\tLoss: 0.2624\tLR: 0.000337\nTraining Epoch: 18 [42496/50000]\tLoss: 0.2607\tLR: 0.000337\nTraining Epoch: 18 [42624/50000]\tLoss: 0.2077\tLR: 0.000337\nTraining Epoch: 18 [42752/50000]\tLoss: 0.1946\tLR: 0.000337\nTraining Epoch: 18 [42880/50000]\tLoss: 0.2788\tLR: 0.000337\nTraining Epoch: 18 [43008/50000]\tLoss: 0.1905\tLR: 0.000337\nTraining Epoch: 18 [43136/50000]\tLoss: 0.1879\tLR: 0.000337\nTraining Epoch: 18 [43264/50000]\tLoss: 0.2403\tLR: 0.000337\nTraining Epoch: 18 [43392/50000]\tLoss: 0.2057\tLR: 0.000337\nTraining Epoch: 18 [43520/50000]\tLoss: 0.1969\tLR: 0.000337\nTraining Epoch: 18 [43648/50000]\tLoss: 0.2132\tLR: 0.000337\nTraining Epoch: 18 [43776/50000]\tLoss: 0.3844\tLR: 0.000337\nTraining Epoch: 18 [43904/50000]\tLoss: 0.2415\tLR: 0.000337\nTraining Epoch: 18 [44032/50000]\tLoss: 0.3060\tLR: 0.000337\nTraining Epoch: 18 [44160/50000]\tLoss: 0.2572\tLR: 0.000337\nTraining Epoch: 18 [44288/50000]\tLoss: 0.2691\tLR: 0.000337\nTraining Epoch: 18 [44416/50000]\tLoss: 0.2227\tLR: 0.000337\nTraining Epoch: 18 [44544/50000]\tLoss: 0.1404\tLR: 0.000337\nTraining Epoch: 18 [44672/50000]\tLoss: 0.3038\tLR: 0.000337\nTraining Epoch: 18 [44800/50000]\tLoss: 0.1959\tLR: 0.000337\nTraining Epoch: 18 [44928/50000]\tLoss: 0.2141\tLR: 0.000337\nTraining Epoch: 18 [45056/50000]\tLoss: 0.2357\tLR: 0.000337\nTraining Epoch: 18 [45184/50000]\tLoss: 0.3115\tLR: 0.000337\nTraining Epoch: 18 [45312/50000]\tLoss: 0.2102\tLR: 0.000337\nTraining Epoch: 18 [45440/50000]\tLoss: 0.3261\tLR: 0.000337\nTraining Epoch: 18 [45568/50000]\tLoss: 0.2644\tLR: 0.000337\nTraining Epoch: 18 [45696/50000]\tLoss: 0.3303\tLR: 0.000337\nTraining Epoch: 18 [45824/50000]\tLoss: 0.3406\tLR: 0.000337\nTraining Epoch: 18 [45952/50000]\tLoss: 0.2555\tLR: 0.000337\nTraining Epoch: 18 [46080/50000]\tLoss: 0.2286\tLR: 0.000337\nTraining Epoch: 18 [46208/50000]\tLoss: 0.2856\tLR: 0.000337\nTraining Epoch: 18 [46336/50000]\tLoss: 0.1406\tLR: 0.000337\nTraining Epoch: 18 [46464/50000]\tLoss: 0.2216\tLR: 0.000337\nTraining Epoch: 18 [46592/50000]\tLoss: 0.1695\tLR: 0.000337\nTraining Epoch: 18 [46720/50000]\tLoss: 0.1908\tLR: 0.000337\nTraining Epoch: 18 [46848/50000]\tLoss: 0.3961\tLR: 0.000337\nTraining Epoch: 18 [46976/50000]\tLoss: 0.2110\tLR: 0.000337\nTraining Epoch: 18 [47104/50000]\tLoss: 0.3055\tLR: 0.000337\nTraining Epoch: 18 [47232/50000]\tLoss: 0.4637\tLR: 0.000337\nTraining Epoch: 18 [47360/50000]\tLoss: 0.2273\tLR: 0.000337\nTraining Epoch: 18 [47488/50000]\tLoss: 0.3073\tLR: 0.000337\nTraining Epoch: 18 [47616/50000]\tLoss: 0.1100\tLR: 0.000337\nTraining Epoch: 18 [47744/50000]\tLoss: 0.3118\tLR: 0.000337\nTraining Epoch: 18 [47872/50000]\tLoss: 0.2654\tLR: 0.000337\nTraining Epoch: 18 [48000/50000]\tLoss: 0.1956\tLR: 0.000337\nTraining Epoch: 18 [48128/50000]\tLoss: 0.3283\tLR: 0.000337\nTraining Epoch: 18 [48256/50000]\tLoss: 0.2587\tLR: 0.000337\nTraining Epoch: 18 [48384/50000]\tLoss: 0.2954\tLR: 0.000337\nTraining Epoch: 18 [48512/50000]\tLoss: 0.2390\tLR: 0.000337\nTraining Epoch: 18 [48640/50000]\tLoss: 0.3084\tLR: 0.000337\nTraining Epoch: 18 [48768/50000]\tLoss: 0.2282\tLR: 0.000337\nTraining Epoch: 18 [48896/50000]\tLoss: 0.2343\tLR: 0.000337\nTraining Epoch: 18 [49024/50000]\tLoss: 0.1653\tLR: 0.000337\nTraining Epoch: 18 [49152/50000]\tLoss: 0.2191\tLR: 0.000337\nTraining Epoch: 18 [49280/50000]\tLoss: 0.2629\tLR: 0.000337\nTraining Epoch: 18 [49408/50000]\tLoss: 0.2125\tLR: 0.000337\nTraining Epoch: 18 [49536/50000]\tLoss: 0.2337\tLR: 0.000337\nTraining Epoch: 18 [49664/50000]\tLoss: 0.2185\tLR: 0.000337\nTraining Epoch: 18 [49792/50000]\tLoss: 0.2623\tLR: 0.000337\nTraining Epoch: 18 [49920/50000]\tLoss: 0.2119\tLR: 0.000337\nTraining Epoch: 18 [50000/50000]\tLoss: 0.2710\tLR: 0.000337\nTest set: Average loss: 0.0024, Accuracy: 0.8990\n\nTraining Epoch: 19 [128/50000]\tLoss: 0.1662\tLR: 0.000337\nTraining Epoch: 19 [256/50000]\tLoss: 0.1489\tLR: 0.000337\nTraining Epoch: 19 [384/50000]\tLoss: 0.1736\tLR: 0.000337\nTraining Epoch: 19 [512/50000]\tLoss: 0.2688\tLR: 0.000337\nTraining Epoch: 19 [640/50000]\tLoss: 0.2252\tLR: 0.000337\nTraining Epoch: 19 [768/50000]\tLoss: 0.2907\tLR: 0.000337\nTraining Epoch: 19 [896/50000]\tLoss: 0.3154\tLR: 0.000337\nTraining Epoch: 19 [1024/50000]\tLoss: 0.2217\tLR: 0.000337\nTraining Epoch: 19 [1152/50000]\tLoss: 0.3393\tLR: 0.000337\nTraining Epoch: 19 [1280/50000]\tLoss: 0.2429\tLR: 0.000337\nTraining Epoch: 19 [1408/50000]\tLoss: 0.2722\tLR: 0.000337\nTraining Epoch: 19 [1536/50000]\tLoss: 0.1966\tLR: 0.000337\nTraining Epoch: 19 [1664/50000]\tLoss: 0.1291\tLR: 0.000337\nTraining Epoch: 19 [1792/50000]\tLoss: 0.2366\tLR: 0.000337\nTraining Epoch: 19 [1920/50000]\tLoss: 0.2529\tLR: 0.000337\nTraining Epoch: 19 [2048/50000]\tLoss: 0.3612\tLR: 0.000337\nTraining Epoch: 19 [2176/50000]\tLoss: 0.2526\tLR: 0.000337\nTraining Epoch: 19 [2304/50000]\tLoss: 0.2673\tLR: 0.000337\nTraining Epoch: 19 [2432/50000]\tLoss: 0.2264\tLR: 0.000337\nTraining Epoch: 19 [2560/50000]\tLoss: 0.2656\tLR: 0.000337\nTraining Epoch: 19 [2688/50000]\tLoss: 0.2326\tLR: 0.000337\nTraining Epoch: 19 [2816/50000]\tLoss: 0.2760\tLR: 0.000337\nTraining Epoch: 19 [2944/50000]\tLoss: 0.4289\tLR: 0.000337\nTraining Epoch: 19 [3072/50000]\tLoss: 0.3106\tLR: 0.000337\nTraining Epoch: 19 [3200/50000]\tLoss: 0.2416\tLR: 0.000337\nTraining Epoch: 19 [3328/50000]\tLoss: 0.2297\tLR: 0.000337\nTraining Epoch: 19 [3456/50000]\tLoss: 0.2804\tLR: 0.000337\nTraining Epoch: 19 [3584/50000]\tLoss: 0.3278\tLR: 0.000337\nTraining Epoch: 19 [3712/50000]\tLoss: 0.2286\tLR: 0.000337\nTraining Epoch: 19 [3840/50000]\tLoss: 0.2714\tLR: 0.000337\nTraining Epoch: 19 [3968/50000]\tLoss: 0.2706\tLR: 0.000337\nTraining Epoch: 19 [4096/50000]\tLoss: 0.2783\tLR: 0.000337\nTraining Epoch: 19 [4224/50000]\tLoss: 0.3440\tLR: 0.000337\nTraining Epoch: 19 [4352/50000]\tLoss: 0.2326\tLR: 0.000337\nTraining Epoch: 19 [4480/50000]\tLoss: 0.2526\tLR: 0.000337\nTraining Epoch: 19 [4608/50000]\tLoss: 0.1761\tLR: 0.000337\nTraining Epoch: 19 [4736/50000]\tLoss: 0.3280\tLR: 0.000337\nTraining Epoch: 19 [4864/50000]\tLoss: 0.3537\tLR: 0.000337\nTraining Epoch: 19 [4992/50000]\tLoss: 0.2159\tLR: 0.000337\nTraining Epoch: 19 [5120/50000]\tLoss: 0.2759\tLR: 0.000337\nTraining Epoch: 19 [5248/50000]\tLoss: 0.2804\tLR: 0.000337\nTraining Epoch: 19 [5376/50000]\tLoss: 0.3218\tLR: 0.000337\nTraining Epoch: 19 [5504/50000]\tLoss: 0.2465\tLR: 0.000337\nTraining Epoch: 19 [5632/50000]\tLoss: 0.2403\tLR: 0.000337\nTraining Epoch: 19 [5760/50000]\tLoss: 0.2324\tLR: 0.000337\nTraining Epoch: 19 [5888/50000]\tLoss: 0.3084\tLR: 0.000337\nTraining Epoch: 19 [6016/50000]\tLoss: 0.2882\tLR: 0.000337\nTraining Epoch: 19 [6144/50000]\tLoss: 0.2733\tLR: 0.000337\nTraining Epoch: 19 [6272/50000]\tLoss: 0.2075\tLR: 0.000337\nTraining Epoch: 19 [6400/50000]\tLoss: 0.1873\tLR: 0.000337\nTraining Epoch: 19 [6528/50000]\tLoss: 0.2496\tLR: 0.000337\nTraining Epoch: 19 [6656/50000]\tLoss: 0.3008\tLR: 0.000337\nTraining Epoch: 19 [6784/50000]\tLoss: 0.1954\tLR: 0.000337\nTraining Epoch: 19 [6912/50000]\tLoss: 0.2432\tLR: 0.000337\nTraining Epoch: 19 [7040/50000]\tLoss: 0.3185\tLR: 0.000337\nTraining Epoch: 19 [7168/50000]\tLoss: 0.2889\tLR: 0.000337\nTraining Epoch: 19 [7296/50000]\tLoss: 0.1817\tLR: 0.000337\nTraining Epoch: 19 [7424/50000]\tLoss: 0.3034\tLR: 0.000337\nTraining Epoch: 19 [7552/50000]\tLoss: 0.3345\tLR: 0.000337\nTraining Epoch: 19 [7680/50000]\tLoss: 0.1695\tLR: 0.000337\nTraining Epoch: 19 [7808/50000]\tLoss: 0.2182\tLR: 0.000337\nTraining Epoch: 19 [7936/50000]\tLoss: 0.3184\tLR: 0.000337\nTraining Epoch: 19 [8064/50000]\tLoss: 0.3597\tLR: 0.000337\nTraining Epoch: 19 [8192/50000]\tLoss: 0.2077\tLR: 0.000337\nTraining Epoch: 19 [8320/50000]\tLoss: 0.3479\tLR: 0.000337\nTraining Epoch: 19 [8448/50000]\tLoss: 0.1938\tLR: 0.000337\nTraining Epoch: 19 [8576/50000]\tLoss: 0.3213\tLR: 0.000337\nTraining Epoch: 19 [8704/50000]\tLoss: 0.2023\tLR: 0.000337\nTraining Epoch: 19 [8832/50000]\tLoss: 0.2955\tLR: 0.000337\nTraining Epoch: 19 [8960/50000]\tLoss: 0.2681\tLR: 0.000337\nTraining Epoch: 19 [9088/50000]\tLoss: 0.2803\tLR: 0.000337\nTraining Epoch: 19 [9216/50000]\tLoss: 0.2012\tLR: 0.000337\nTraining Epoch: 19 [9344/50000]\tLoss: 0.2076\tLR: 0.000337\nTraining Epoch: 19 [9472/50000]\tLoss: 0.1804\tLR: 0.000337\nTraining Epoch: 19 [9600/50000]\tLoss: 0.1833\tLR: 0.000337\nTraining Epoch: 19 [9728/50000]\tLoss: 0.2801\tLR: 0.000337\nTraining Epoch: 19 [9856/50000]\tLoss: 0.3429\tLR: 0.000337\nTraining Epoch: 19 [9984/50000]\tLoss: 0.2784\tLR: 0.000337\nTraining Epoch: 19 [10112/50000]\tLoss: 0.2981\tLR: 0.000337\nTraining Epoch: 19 [10240/50000]\tLoss: 0.2005\tLR: 0.000337\nTraining Epoch: 19 [10368/50000]\tLoss: 0.3016\tLR: 0.000337\nTraining Epoch: 19 [10496/50000]\tLoss: 0.2258\tLR: 0.000337\nTraining Epoch: 19 [10624/50000]\tLoss: 0.2168\tLR: 0.000337\nTraining Epoch: 19 [10752/50000]\tLoss: 0.3044\tLR: 0.000337\nTraining Epoch: 19 [10880/50000]\tLoss: 0.2400\tLR: 0.000337\nTraining Epoch: 19 [11008/50000]\tLoss: 0.2697\tLR: 0.000337\nTraining Epoch: 19 [11136/50000]\tLoss: 0.2191\tLR: 0.000337\nTraining Epoch: 19 [11264/50000]\tLoss: 0.2243\tLR: 0.000337\nTraining Epoch: 19 [11392/50000]\tLoss: 0.1911\tLR: 0.000337\nTraining Epoch: 19 [11520/50000]\tLoss: 0.1713\tLR: 0.000337\nTraining Epoch: 19 [11648/50000]\tLoss: 0.2249\tLR: 0.000337\nTraining Epoch: 19 [11776/50000]\tLoss: 0.3103\tLR: 0.000337\nTraining Epoch: 19 [11904/50000]\tLoss: 0.1923\tLR: 0.000337\nTraining Epoch: 19 [12032/50000]\tLoss: 0.3342\tLR: 0.000337\nTraining Epoch: 19 [12160/50000]\tLoss: 0.3157\tLR: 0.000337\nTraining Epoch: 19 [12288/50000]\tLoss: 0.4024\tLR: 0.000337\nTraining Epoch: 19 [12416/50000]\tLoss: 0.2391\tLR: 0.000337\nTraining Epoch: 19 [12544/50000]\tLoss: 0.2318\tLR: 0.000337\nTraining Epoch: 19 [12672/50000]\tLoss: 0.2599\tLR: 0.000337\nTraining Epoch: 19 [12800/50000]\tLoss: 0.2368\tLR: 0.000337\nTraining Epoch: 19 [12928/50000]\tLoss: 0.2687\tLR: 0.000337\nTraining Epoch: 19 [13056/50000]\tLoss: 0.2570\tLR: 0.000337\nTraining Epoch: 19 [13184/50000]\tLoss: 0.1659\tLR: 0.000337\nTraining Epoch: 19 [13312/50000]\tLoss: 0.2062\tLR: 0.000337\nTraining Epoch: 19 [13440/50000]\tLoss: 0.2621\tLR: 0.000337\nTraining Epoch: 19 [13568/50000]\tLoss: 0.3915\tLR: 0.000337\nTraining Epoch: 19 [13696/50000]\tLoss: 0.2300\tLR: 0.000337\nTraining Epoch: 19 [13824/50000]\tLoss: 0.2032\tLR: 0.000337\nTraining Epoch: 19 [13952/50000]\tLoss: 0.3005\tLR: 0.000337\nTraining Epoch: 19 [14080/50000]\tLoss: 0.2734\tLR: 0.000337\nTraining Epoch: 19 [14208/50000]\tLoss: 0.2579\tLR: 0.000337\nTraining Epoch: 19 [14336/50000]\tLoss: 0.3144\tLR: 0.000337\nTraining Epoch: 19 [14464/50000]\tLoss: 0.1724\tLR: 0.000337\nTraining Epoch: 19 [14592/50000]\tLoss: 0.1744\tLR: 0.000337\nTraining Epoch: 19 [14720/50000]\tLoss: 0.2830\tLR: 0.000337\nTraining Epoch: 19 [14848/50000]\tLoss: 0.3204\tLR: 0.000337\nTraining Epoch: 19 [14976/50000]\tLoss: 0.3695\tLR: 0.000337\nTraining Epoch: 19 [15104/50000]\tLoss: 0.3418\tLR: 0.000337\nTraining Epoch: 19 [15232/50000]\tLoss: 0.2560\tLR: 0.000337\nTraining Epoch: 19 [15360/50000]\tLoss: 0.2267\tLR: 0.000337\nTraining Epoch: 19 [15488/50000]\tLoss: 0.2921\tLR: 0.000337\nTraining Epoch: 19 [15616/50000]\tLoss: 0.2161\tLR: 0.000337\nTraining Epoch: 19 [15744/50000]\tLoss: 0.2141\tLR: 0.000337\nTraining Epoch: 19 [15872/50000]\tLoss: 0.2492\tLR: 0.000337\nTraining Epoch: 19 [16000/50000]\tLoss: 0.2296\tLR: 0.000337\nTraining Epoch: 19 [16128/50000]\tLoss: 0.2662\tLR: 0.000337\nTraining Epoch: 19 [16256/50000]\tLoss: 0.2303\tLR: 0.000337\nTraining Epoch: 19 [16384/50000]\tLoss: 0.1929\tLR: 0.000337\nTraining Epoch: 19 [16512/50000]\tLoss: 0.3254\tLR: 0.000337\nTraining Epoch: 19 [16640/50000]\tLoss: 0.1920\tLR: 0.000337\nTraining Epoch: 19 [16768/50000]\tLoss: 0.2354\tLR: 0.000337\nTraining Epoch: 19 [16896/50000]\tLoss: 0.2546\tLR: 0.000337\nTraining Epoch: 19 [17024/50000]\tLoss: 0.2197\tLR: 0.000337\nTraining Epoch: 19 [17152/50000]\tLoss: 0.2705\tLR: 0.000337\nTraining Epoch: 19 [17280/50000]\tLoss: 0.1988\tLR: 0.000337\nTraining Epoch: 19 [17408/50000]\tLoss: 0.2229\tLR: 0.000337\nTraining Epoch: 19 [17536/50000]\tLoss: 0.1829\tLR: 0.000337\nTraining Epoch: 19 [17664/50000]\tLoss: 0.1960\tLR: 0.000337\nTraining Epoch: 19 [17792/50000]\tLoss: 0.1724\tLR: 0.000337\nTraining Epoch: 19 [17920/50000]\tLoss: 0.2448\tLR: 0.000337\nTraining Epoch: 19 [18048/50000]\tLoss: 0.2365\tLR: 0.000337\nTraining Epoch: 19 [18176/50000]\tLoss: 0.2175\tLR: 0.000337\nTraining Epoch: 19 [18304/50000]\tLoss: 0.1613\tLR: 0.000337\nTraining Epoch: 19 [18432/50000]\tLoss: 0.3663\tLR: 0.000337\nTraining Epoch: 19 [18560/50000]\tLoss: 0.2313\tLR: 0.000337\nTraining Epoch: 19 [18688/50000]\tLoss: 0.1903\tLR: 0.000337\nTraining Epoch: 19 [18816/50000]\tLoss: 0.3054\tLR: 0.000337\nTraining Epoch: 19 [18944/50000]\tLoss: 0.3984\tLR: 0.000337\nTraining Epoch: 19 [19072/50000]\tLoss: 0.2592\tLR: 0.000337\nTraining Epoch: 19 [19200/50000]\tLoss: 0.3712\tLR: 0.000337\nTraining Epoch: 19 [19328/50000]\tLoss: 0.1816\tLR: 0.000337\nTraining Epoch: 19 [19456/50000]\tLoss: 0.2296\tLR: 0.000337\nTraining Epoch: 19 [19584/50000]\tLoss: 0.2299\tLR: 0.000337\nTraining Epoch: 19 [19712/50000]\tLoss: 0.2391\tLR: 0.000337\nTraining Epoch: 19 [19840/50000]\tLoss: 0.3016\tLR: 0.000337\nTraining Epoch: 19 [19968/50000]\tLoss: 0.2766\tLR: 0.000337\nTraining Epoch: 19 [20096/50000]\tLoss: 0.2127\tLR: 0.000337\nTraining Epoch: 19 [20224/50000]\tLoss: 0.2340\tLR: 0.000337\nTraining Epoch: 19 [20352/50000]\tLoss: 0.2030\tLR: 0.000337\nTraining Epoch: 19 [20480/50000]\tLoss: 0.2226\tLR: 0.000337\nTraining Epoch: 19 [20608/50000]\tLoss: 0.2410\tLR: 0.000337\nTraining Epoch: 19 [20736/50000]\tLoss: 0.2123\tLR: 0.000337\nTraining Epoch: 19 [20864/50000]\tLoss: 0.2337\tLR: 0.000337\nTraining Epoch: 19 [20992/50000]\tLoss: 0.1905\tLR: 0.000337\nTraining Epoch: 19 [21120/50000]\tLoss: 0.3478\tLR: 0.000337\nTraining Epoch: 19 [21248/50000]\tLoss: 0.2822\tLR: 0.000337\nTraining Epoch: 19 [21376/50000]\tLoss: 0.2121\tLR: 0.000337\nTraining Epoch: 19 [21504/50000]\tLoss: 0.2681\tLR: 0.000337\nTraining Epoch: 19 [21632/50000]\tLoss: 0.3364\tLR: 0.000337\nTraining Epoch: 19 [21760/50000]\tLoss: 0.1962\tLR: 0.000337\nTraining Epoch: 19 [21888/50000]\tLoss: 0.2927\tLR: 0.000337\nTraining Epoch: 19 [22016/50000]\tLoss: 0.1258\tLR: 0.000337\nTraining Epoch: 19 [22144/50000]\tLoss: 0.1915\tLR: 0.000337\nTraining Epoch: 19 [22272/50000]\tLoss: 0.1156\tLR: 0.000337\nTraining Epoch: 19 [22400/50000]\tLoss: 0.2528\tLR: 0.000337\nTraining Epoch: 19 [22528/50000]\tLoss: 0.2192\tLR: 0.000337\nTraining Epoch: 19 [22656/50000]\tLoss: 0.2917\tLR: 0.000337\nTraining Epoch: 19 [22784/50000]\tLoss: 0.3146\tLR: 0.000337\nTraining Epoch: 19 [22912/50000]\tLoss: 0.1841\tLR: 0.000337\nTraining Epoch: 19 [23040/50000]\tLoss: 0.2034\tLR: 0.000337\nTraining Epoch: 19 [23168/50000]\tLoss: 0.2143\tLR: 0.000337\nTraining Epoch: 19 [23296/50000]\tLoss: 0.2427\tLR: 0.000337\nTraining Epoch: 19 [23424/50000]\tLoss: 0.2617\tLR: 0.000337\nTraining Epoch: 19 [23552/50000]\tLoss: 0.2420\tLR: 0.000337\nTraining Epoch: 19 [23680/50000]\tLoss: 0.2414\tLR: 0.000337\nTraining Epoch: 19 [23808/50000]\tLoss: 0.2188\tLR: 0.000337\nTraining Epoch: 19 [23936/50000]\tLoss: 0.2567\tLR: 0.000337\nTraining Epoch: 19 [24064/50000]\tLoss: 0.2404\tLR: 0.000337\nTraining Epoch: 19 [24192/50000]\tLoss: 0.2241\tLR: 0.000337\nTraining Epoch: 19 [24320/50000]\tLoss: 0.2425\tLR: 0.000337\nTraining Epoch: 19 [24448/50000]\tLoss: 0.2563\tLR: 0.000337\nTraining Epoch: 19 [24576/50000]\tLoss: 0.1762\tLR: 0.000337\nTraining Epoch: 19 [24704/50000]\tLoss: 0.1851\tLR: 0.000337\nTraining Epoch: 19 [24832/50000]\tLoss: 0.2483\tLR: 0.000337\nTraining Epoch: 19 [24960/50000]\tLoss: 0.2732\tLR: 0.000337\nTraining Epoch: 19 [25088/50000]\tLoss: 0.3200\tLR: 0.000337\nTraining Epoch: 19 [25216/50000]\tLoss: 0.2618\tLR: 0.000337\nTraining Epoch: 19 [25344/50000]\tLoss: 0.2359\tLR: 0.000337\nTraining Epoch: 19 [25472/50000]\tLoss: 0.2269\tLR: 0.000337\nTraining Epoch: 19 [25600/50000]\tLoss: 0.2060\tLR: 0.000337\nTraining Epoch: 19 [25728/50000]\tLoss: 0.3046\tLR: 0.000337\nTraining Epoch: 19 [25856/50000]\tLoss: 0.2220\tLR: 0.000337\nTraining Epoch: 19 [25984/50000]\tLoss: 0.1991\tLR: 0.000337\nTraining Epoch: 19 [26112/50000]\tLoss: 0.2618\tLR: 0.000337\nTraining Epoch: 19 [26240/50000]\tLoss: 0.2255\tLR: 0.000337\nTraining Epoch: 19 [26368/50000]\tLoss: 0.2138\tLR: 0.000337\nTraining Epoch: 19 [26496/50000]\tLoss: 0.1613\tLR: 0.000337\nTraining Epoch: 19 [26624/50000]\tLoss: 0.2937\tLR: 0.000337\nTraining Epoch: 19 [26752/50000]\tLoss: 0.3482\tLR: 0.000337\nTraining Epoch: 19 [26880/50000]\tLoss: 0.1790\tLR: 0.000337\nTraining Epoch: 19 [27008/50000]\tLoss: 0.2273\tLR: 0.000337\nTraining Epoch: 19 [27136/50000]\tLoss: 0.1830\tLR: 0.000337\nTraining Epoch: 19 [27264/50000]\tLoss: 0.2110\tLR: 0.000337\nTraining Epoch: 19 [27392/50000]\tLoss: 0.2743\tLR: 0.000337\nTraining Epoch: 19 [27520/50000]\tLoss: 0.3181\tLR: 0.000337\nTraining Epoch: 19 [27648/50000]\tLoss: 0.1417\tLR: 0.000337\nTraining Epoch: 19 [27776/50000]\tLoss: 0.2455\tLR: 0.000337\nTraining Epoch: 19 [27904/50000]\tLoss: 0.3077\tLR: 0.000337\nTraining Epoch: 19 [28032/50000]\tLoss: 0.2258\tLR: 0.000337\nTraining Epoch: 19 [28160/50000]\tLoss: 0.2264\tLR: 0.000337\nTraining Epoch: 19 [28288/50000]\tLoss: 0.3398\tLR: 0.000337\nTraining Epoch: 19 [28416/50000]\tLoss: 0.1736\tLR: 0.000337\nTraining Epoch: 19 [28544/50000]\tLoss: 0.2215\tLR: 0.000337\nTraining Epoch: 19 [28672/50000]\tLoss: 0.2896\tLR: 0.000337\nTraining Epoch: 19 [28800/50000]\tLoss: 0.3063\tLR: 0.000337\nTraining Epoch: 19 [28928/50000]\tLoss: 0.4290\tLR: 0.000337\nTraining Epoch: 19 [29056/50000]\tLoss: 0.2051\tLR: 0.000337\nTraining Epoch: 19 [29184/50000]\tLoss: 0.2767\tLR: 0.000337\nTraining Epoch: 19 [29312/50000]\tLoss: 0.2812\tLR: 0.000337\nTraining Epoch: 19 [29440/50000]\tLoss: 0.2162\tLR: 0.000337\nTraining Epoch: 19 [29568/50000]\tLoss: 0.3668\tLR: 0.000337\nTraining Epoch: 19 [29696/50000]\tLoss: 0.2889\tLR: 0.000337\nTraining Epoch: 19 [29824/50000]\tLoss: 0.2023\tLR: 0.000337\nTraining Epoch: 19 [29952/50000]\tLoss: 0.1886\tLR: 0.000337\nTraining Epoch: 19 [30080/50000]\tLoss: 0.2641\tLR: 0.000337\nTraining Epoch: 19 [30208/50000]\tLoss: 0.1058\tLR: 0.000337\nTraining Epoch: 19 [30336/50000]\tLoss: 0.3252\tLR: 0.000337\nTraining Epoch: 19 [30464/50000]\tLoss: 0.2431\tLR: 0.000337\nTraining Epoch: 19 [30592/50000]\tLoss: 0.1576\tLR: 0.000337\nTraining Epoch: 19 [30720/50000]\tLoss: 0.2920\tLR: 0.000337\nTraining Epoch: 19 [30848/50000]\tLoss: 0.3495\tLR: 0.000337\nTraining Epoch: 19 [30976/50000]\tLoss: 0.2037\tLR: 0.000337\nTraining Epoch: 19 [31104/50000]\tLoss: 0.3377\tLR: 0.000337\nTraining Epoch: 19 [31232/50000]\tLoss: 0.2986\tLR: 0.000337\nTraining Epoch: 19 [31360/50000]\tLoss: 0.2162\tLR: 0.000337\nTraining Epoch: 19 [31488/50000]\tLoss: 0.2125\tLR: 0.000337\nTraining Epoch: 19 [31616/50000]\tLoss: 0.2667\tLR: 0.000337\nTraining Epoch: 19 [31744/50000]\tLoss: 0.2517\tLR: 0.000337\nTraining Epoch: 19 [31872/50000]\tLoss: 0.3102\tLR: 0.000337\nTraining Epoch: 19 [32000/50000]\tLoss: 0.1710\tLR: 0.000337\nTraining Epoch: 19 [32128/50000]\tLoss: 0.2301\tLR: 0.000337\nTraining Epoch: 19 [32256/50000]\tLoss: 0.2455\tLR: 0.000337\nTraining Epoch: 19 [32384/50000]\tLoss: 0.3035\tLR: 0.000337\nTraining Epoch: 19 [32512/50000]\tLoss: 0.2272\tLR: 0.000337\nTraining Epoch: 19 [32640/50000]\tLoss: 0.2473\tLR: 0.000337\nTraining Epoch: 19 [32768/50000]\tLoss: 0.3608\tLR: 0.000337\nTraining Epoch: 19 [32896/50000]\tLoss: 0.2392\tLR: 0.000337\nTraining Epoch: 19 [33024/50000]\tLoss: 0.3025\tLR: 0.000337\nTraining Epoch: 19 [33152/50000]\tLoss: 0.2389\tLR: 0.000337\nTraining Epoch: 19 [33280/50000]\tLoss: 0.2182\tLR: 0.000337\nTraining Epoch: 19 [33408/50000]\tLoss: 0.3118\tLR: 0.000337\nTraining Epoch: 19 [33536/50000]\tLoss: 0.1679\tLR: 0.000337\nTraining Epoch: 19 [33664/50000]\tLoss: 0.2447\tLR: 0.000337\nTraining Epoch: 19 [33792/50000]\tLoss: 0.2674\tLR: 0.000337\nTraining Epoch: 19 [33920/50000]\tLoss: 0.2050\tLR: 0.000337\nTraining Epoch: 19 [34048/50000]\tLoss: 0.2351\tLR: 0.000337\nTraining Epoch: 19 [34176/50000]\tLoss: 0.3069\tLR: 0.000337\nTraining Epoch: 19 [34304/50000]\tLoss: 0.2814\tLR: 0.000337\nTraining Epoch: 19 [34432/50000]\tLoss: 0.1542\tLR: 0.000337\nTraining Epoch: 19 [34560/50000]\tLoss: 0.2463\tLR: 0.000337\nTraining Epoch: 19 [34688/50000]\tLoss: 0.3044\tLR: 0.000337\nTraining Epoch: 19 [34816/50000]\tLoss: 0.3219\tLR: 0.000337\nTraining Epoch: 19 [34944/50000]\tLoss: 0.2365\tLR: 0.000337\nTraining Epoch: 19 [35072/50000]\tLoss: 0.2292\tLR: 0.000337\nTraining Epoch: 19 [35200/50000]\tLoss: 0.2778\tLR: 0.000337\nTraining Epoch: 19 [35328/50000]\tLoss: 0.2293\tLR: 0.000337\nTraining Epoch: 19 [35456/50000]\tLoss: 0.2400\tLR: 0.000337\nTraining Epoch: 19 [35584/50000]\tLoss: 0.2564\tLR: 0.000337\nTraining Epoch: 19 [35712/50000]\tLoss: 0.2199\tLR: 0.000337\nTraining Epoch: 19 [35840/50000]\tLoss: 0.2362\tLR: 0.000337\nTraining Epoch: 19 [35968/50000]\tLoss: 0.1553\tLR: 0.000337\nTraining Epoch: 19 [36096/50000]\tLoss: 0.2656\tLR: 0.000337\nTraining Epoch: 19 [36224/50000]\tLoss: 0.1521\tLR: 0.000337\nTraining Epoch: 19 [36352/50000]\tLoss: 0.2036\tLR: 0.000337\nTraining Epoch: 19 [36480/50000]\tLoss: 0.2802\tLR: 0.000337\nTraining Epoch: 19 [36608/50000]\tLoss: 0.2236\tLR: 0.000337\nTraining Epoch: 19 [36736/50000]\tLoss: 0.2142\tLR: 0.000337\nTraining Epoch: 19 [36864/50000]\tLoss: 0.2965\tLR: 0.000337\nTraining Epoch: 19 [36992/50000]\tLoss: 0.1762\tLR: 0.000337\nTraining Epoch: 19 [37120/50000]\tLoss: 0.2579\tLR: 0.000337\nTraining Epoch: 19 [37248/50000]\tLoss: 0.1331\tLR: 0.000337\nTraining Epoch: 19 [37376/50000]\tLoss: 0.3057\tLR: 0.000337\nTraining Epoch: 19 [37504/50000]\tLoss: 0.2798\tLR: 0.000337\nTraining Epoch: 19 [37632/50000]\tLoss: 0.2412\tLR: 0.000337\nTraining Epoch: 19 [37760/50000]\tLoss: 0.2199\tLR: 0.000337\nTraining Epoch: 19 [37888/50000]\tLoss: 0.3103\tLR: 0.000337\nTraining Epoch: 19 [38016/50000]\tLoss: 0.3294\tLR: 0.000337\nTraining Epoch: 19 [38144/50000]\tLoss: 0.3312\tLR: 0.000337\nTraining Epoch: 19 [38272/50000]\tLoss: 0.3005\tLR: 0.000337\nTraining Epoch: 19 [38400/50000]\tLoss: 0.2377\tLR: 0.000337\nTraining Epoch: 19 [38528/50000]\tLoss: 0.1870\tLR: 0.000337\nTraining Epoch: 19 [38656/50000]\tLoss: 0.1579\tLR: 0.000337\nTraining Epoch: 19 [38784/50000]\tLoss: 0.3409\tLR: 0.000337\nTraining Epoch: 19 [38912/50000]\tLoss: 0.2212\tLR: 0.000337\nTraining Epoch: 19 [39040/50000]\tLoss: 0.2238\tLR: 0.000337\nTraining Epoch: 19 [39168/50000]\tLoss: 0.2778\tLR: 0.000337\nTraining Epoch: 19 [39296/50000]\tLoss: 0.3297\tLR: 0.000337\nTraining Epoch: 19 [39424/50000]\tLoss: 0.2522\tLR: 0.000337\nTraining Epoch: 19 [39552/50000]\tLoss: 0.1685\tLR: 0.000337\nTraining Epoch: 19 [39680/50000]\tLoss: 0.2313\tLR: 0.000337\nTraining Epoch: 19 [39808/50000]\tLoss: 0.1812\tLR: 0.000337\nTraining Epoch: 19 [39936/50000]\tLoss: 0.1901\tLR: 0.000337\nTraining Epoch: 19 [40064/50000]\tLoss: 0.2473\tLR: 0.000337\nTraining Epoch: 19 [40192/50000]\tLoss: 0.1333\tLR: 0.000337\nTraining Epoch: 19 [40320/50000]\tLoss: 0.2729\tLR: 0.000337\nTraining Epoch: 19 [40448/50000]\tLoss: 0.3194\tLR: 0.000337\nTraining Epoch: 19 [40576/50000]\tLoss: 0.2969\tLR: 0.000337\nTraining Epoch: 19 [40704/50000]\tLoss: 0.1998\tLR: 0.000337\nTraining Epoch: 19 [40832/50000]\tLoss: 0.2277\tLR: 0.000337\nTraining Epoch: 19 [40960/50000]\tLoss: 0.2755\tLR: 0.000337\nTraining Epoch: 19 [41088/50000]\tLoss: 0.1711\tLR: 0.000337\nTraining Epoch: 19 [41216/50000]\tLoss: 0.1938\tLR: 0.000337\nTraining Epoch: 19 [41344/50000]\tLoss: 0.1793\tLR: 0.000337\nTraining Epoch: 19 [41472/50000]\tLoss: 0.3863\tLR: 0.000337\nTraining Epoch: 19 [41600/50000]\tLoss: 0.2436\tLR: 0.000337\nTraining Epoch: 19 [41728/50000]\tLoss: 0.3039\tLR: 0.000337\nTraining Epoch: 19 [41856/50000]\tLoss: 0.2280\tLR: 0.000337\nTraining Epoch: 19 [41984/50000]\tLoss: 0.3694\tLR: 0.000337\nTraining Epoch: 19 [42112/50000]\tLoss: 0.2337\tLR: 0.000337\nTraining Epoch: 19 [42240/50000]\tLoss: 0.2852\tLR: 0.000337\nTraining Epoch: 19 [42368/50000]\tLoss: 0.2373\tLR: 0.000337\nTraining Epoch: 19 [42496/50000]\tLoss: 0.2124\tLR: 0.000337\nTraining Epoch: 19 [42624/50000]\tLoss: 0.1590\tLR: 0.000337\nTraining Epoch: 19 [42752/50000]\tLoss: 0.2269\tLR: 0.000337\nTraining Epoch: 19 [42880/50000]\tLoss: 0.2899\tLR: 0.000337\nTraining Epoch: 19 [43008/50000]\tLoss: 0.2216\tLR: 0.000337\nTraining Epoch: 19 [43136/50000]\tLoss: 0.2033\tLR: 0.000337\nTraining Epoch: 19 [43264/50000]\tLoss: 0.2740\tLR: 0.000337\nTraining Epoch: 19 [43392/50000]\tLoss: 0.2408\tLR: 0.000337\nTraining Epoch: 19 [43520/50000]\tLoss: 0.2709\tLR: 0.000337\nTraining Epoch: 19 [43648/50000]\tLoss: 0.2795\tLR: 0.000337\nTraining Epoch: 19 [43776/50000]\tLoss: 0.3122\tLR: 0.000337\nTraining Epoch: 19 [43904/50000]\tLoss: 0.2296\tLR: 0.000337\nTraining Epoch: 19 [44032/50000]\tLoss: 0.1387\tLR: 0.000337\nTraining Epoch: 19 [44160/50000]\tLoss: 0.2984\tLR: 0.000337\nTraining Epoch: 19 [44288/50000]\tLoss: 0.2479\tLR: 0.000337\nTraining Epoch: 19 [44416/50000]\tLoss: 0.2413\tLR: 0.000337\nTraining Epoch: 19 [44544/50000]\tLoss: 0.3208\tLR: 0.000337\nTraining Epoch: 19 [44672/50000]\tLoss: 0.1870\tLR: 0.000337\nTraining Epoch: 19 [44800/50000]\tLoss: 0.1723\tLR: 0.000337\nTraining Epoch: 19 [44928/50000]\tLoss: 0.2637\tLR: 0.000337\nTraining Epoch: 19 [45056/50000]\tLoss: 0.2965\tLR: 0.000337\nTraining Epoch: 19 [45184/50000]\tLoss: 0.3154\tLR: 0.000337\nTraining Epoch: 19 [45312/50000]\tLoss: 0.2258\tLR: 0.000337\nTraining Epoch: 19 [45440/50000]\tLoss: 0.2687\tLR: 0.000337\nTraining Epoch: 19 [45568/50000]\tLoss: 0.2336\tLR: 0.000337\nTraining Epoch: 19 [45696/50000]\tLoss: 0.2586\tLR: 0.000337\nTraining Epoch: 19 [45824/50000]\tLoss: 0.2550\tLR: 0.000337\nTraining Epoch: 19 [45952/50000]\tLoss: 0.2166\tLR: 0.000337\nTraining Epoch: 19 [46080/50000]\tLoss: 0.2573\tLR: 0.000337\nTraining Epoch: 19 [46208/50000]\tLoss: 0.2298\tLR: 0.000337\nTraining Epoch: 19 [46336/50000]\tLoss: 0.3832\tLR: 0.000337\nTraining Epoch: 19 [46464/50000]\tLoss: 0.2548\tLR: 0.000337\nTraining Epoch: 19 [46592/50000]\tLoss: 0.2473\tLR: 0.000337\nTraining Epoch: 19 [46720/50000]\tLoss: 0.2053\tLR: 0.000337\nTraining Epoch: 19 [46848/50000]\tLoss: 0.2364\tLR: 0.000337\nTraining Epoch: 19 [46976/50000]\tLoss: 0.3212\tLR: 0.000337\nTraining Epoch: 19 [47104/50000]\tLoss: 0.3697\tLR: 0.000337\nTraining Epoch: 19 [47232/50000]\tLoss: 0.3257\tLR: 0.000337\nTraining Epoch: 19 [47360/50000]\tLoss: 0.2262\tLR: 0.000337\nTraining Epoch: 19 [47488/50000]\tLoss: 0.3487\tLR: 0.000337\nTraining Epoch: 19 [47616/50000]\tLoss: 0.2982\tLR: 0.000337\nTraining Epoch: 19 [47744/50000]\tLoss: 0.2411\tLR: 0.000337\nTraining Epoch: 19 [47872/50000]\tLoss: 0.1847\tLR: 0.000337\nTraining Epoch: 19 [48000/50000]\tLoss: 0.2389\tLR: 0.000337\nTraining Epoch: 19 [48128/50000]\tLoss: 0.1987\tLR: 0.000337\nTraining Epoch: 19 [48256/50000]\tLoss: 0.3304\tLR: 0.000337\nTraining Epoch: 19 [48384/50000]\tLoss: 0.1237\tLR: 0.000337\nTraining Epoch: 19 [48512/50000]\tLoss: 0.2806\tLR: 0.000337\nTraining Epoch: 19 [48640/50000]\tLoss: 0.2083\tLR: 0.000337\nTraining Epoch: 19 [48768/50000]\tLoss: 0.1850\tLR: 0.000337\nTraining Epoch: 19 [48896/50000]\tLoss: 0.2455\tLR: 0.000337\nTraining Epoch: 19 [49024/50000]\tLoss: 0.2171\tLR: 0.000337\nTraining Epoch: 19 [49152/50000]\tLoss: 0.2493\tLR: 0.000337\nTraining Epoch: 19 [49280/50000]\tLoss: 0.2931\tLR: 0.000337\nTraining Epoch: 19 [49408/50000]\tLoss: 0.2113\tLR: 0.000337\nTraining Epoch: 19 [49536/50000]\tLoss: 0.2007\tLR: 0.000337\nTraining Epoch: 19 [49664/50000]\tLoss: 0.1874\tLR: 0.000337\nTraining Epoch: 19 [49792/50000]\tLoss: 0.2632\tLR: 0.000337\nTraining Epoch: 19 [49920/50000]\tLoss: 0.1930\tLR: 0.000337\nTraining Epoch: 19 [50000/50000]\tLoss: 0.2730\tLR: 0.000337\nTest set: Average loss: 0.0024, Accuracy: 0.8980\n\nTraining Epoch: 20 [128/50000]\tLoss: 0.2500\tLR: 0.000337\nTraining Epoch: 20 [256/50000]\tLoss: 0.1805\tLR: 0.000337\nTraining Epoch: 20 [384/50000]\tLoss: 0.1849\tLR: 0.000337\nTraining Epoch: 20 [512/50000]\tLoss: 0.3124\tLR: 0.000337\nTraining Epoch: 20 [640/50000]\tLoss: 0.2012\tLR: 0.000337\nTraining Epoch: 20 [768/50000]\tLoss: 0.1662\tLR: 0.000337\nTraining Epoch: 20 [896/50000]\tLoss: 0.4141\tLR: 0.000337\nTraining Epoch: 20 [1024/50000]\tLoss: 0.2843\tLR: 0.000337\nTraining Epoch: 20 [1152/50000]\tLoss: 0.2715\tLR: 0.000337\nTraining Epoch: 20 [1280/50000]\tLoss: 0.2602\tLR: 0.000337\nTraining Epoch: 20 [1408/50000]\tLoss: 0.1758\tLR: 0.000337\nTraining Epoch: 20 [1536/50000]\tLoss: 0.2253\tLR: 0.000337\nTraining Epoch: 20 [1664/50000]\tLoss: 0.2815\tLR: 0.000337\nTraining Epoch: 20 [1792/50000]\tLoss: 0.2988\tLR: 0.000337\nTraining Epoch: 20 [1920/50000]\tLoss: 0.2777\tLR: 0.000337\nTraining Epoch: 20 [2048/50000]\tLoss: 0.1883\tLR: 0.000337\nTraining Epoch: 20 [2176/50000]\tLoss: 0.2049\tLR: 0.000337\nTraining Epoch: 20 [2304/50000]\tLoss: 0.2020\tLR: 0.000337\nTraining Epoch: 20 [2432/50000]\tLoss: 0.2682\tLR: 0.000337\nTraining Epoch: 20 [2560/50000]\tLoss: 0.3452\tLR: 0.000337\nTraining Epoch: 20 [2688/50000]\tLoss: 0.2531\tLR: 0.000337\nTraining Epoch: 20 [2816/50000]\tLoss: 0.1977\tLR: 0.000337\nTraining Epoch: 20 [2944/50000]\tLoss: 0.2059\tLR: 0.000337\nTraining Epoch: 20 [3072/50000]\tLoss: 0.3325\tLR: 0.000337\nTraining Epoch: 20 [3200/50000]\tLoss: 0.1951\tLR: 0.000337\nTraining Epoch: 20 [3328/50000]\tLoss: 0.2656\tLR: 0.000337\nTraining Epoch: 20 [3456/50000]\tLoss: 0.1840\tLR: 0.000337\nTraining Epoch: 20 [3584/50000]\tLoss: 0.2227\tLR: 0.000337\nTraining Epoch: 20 [3712/50000]\tLoss: 0.1959\tLR: 0.000337\nTraining Epoch: 20 [3840/50000]\tLoss: 0.2361\tLR: 0.000337\nTraining Epoch: 20 [3968/50000]\tLoss: 0.3426\tLR: 0.000337\nTraining Epoch: 20 [4096/50000]\tLoss: 0.1975\tLR: 0.000337\nTraining Epoch: 20 [4224/50000]\tLoss: 0.3021\tLR: 0.000337\nTraining Epoch: 20 [4352/50000]\tLoss: 0.1755\tLR: 0.000337\nTraining Epoch: 20 [4480/50000]\tLoss: 0.3319\tLR: 0.000337\nTraining Epoch: 20 [4608/50000]\tLoss: 0.2292\tLR: 0.000337\nTraining Epoch: 20 [4736/50000]\tLoss: 0.1994\tLR: 0.000337\nTraining Epoch: 20 [4864/50000]\tLoss: 0.2037\tLR: 0.000337\nTraining Epoch: 20 [4992/50000]\tLoss: 0.2108\tLR: 0.000337\nTraining Epoch: 20 [5120/50000]\tLoss: 0.2259\tLR: 0.000337\nTraining Epoch: 20 [5248/50000]\tLoss: 0.3472\tLR: 0.000337\nTraining Epoch: 20 [5376/50000]\tLoss: 0.1849\tLR: 0.000337\nTraining Epoch: 20 [5504/50000]\tLoss: 0.2427\tLR: 0.000337\nTraining Epoch: 20 [5632/50000]\tLoss: 0.2499\tLR: 0.000337\nTraining Epoch: 20 [5760/50000]\tLoss: 0.2139\tLR: 0.000337\nTraining Epoch: 20 [5888/50000]\tLoss: 0.2221\tLR: 0.000337\nTraining Epoch: 20 [6016/50000]\tLoss: 0.2403\tLR: 0.000337\nTraining Epoch: 20 [6144/50000]\tLoss: 0.2960\tLR: 0.000337\nTraining Epoch: 20 [6272/50000]\tLoss: 0.2622\tLR: 0.000337\nTraining Epoch: 20 [6400/50000]\tLoss: 0.2476\tLR: 0.000337\nTraining Epoch: 20 [6528/50000]\tLoss: 0.2724\tLR: 0.000337\nTraining Epoch: 20 [6656/50000]\tLoss: 0.1701\tLR: 0.000337\nTraining Epoch: 20 [6784/50000]\tLoss: 0.1565\tLR: 0.000337\nTraining Epoch: 20 [6912/50000]\tLoss: 0.2110\tLR: 0.000337\nTraining Epoch: 20 [7040/50000]\tLoss: 0.2376\tLR: 0.000337\nTraining Epoch: 20 [7168/50000]\tLoss: 0.2681\tLR: 0.000337\nTraining Epoch: 20 [7296/50000]\tLoss: 0.2543\tLR: 0.000337\nTraining Epoch: 20 [7424/50000]\tLoss: 0.2092\tLR: 0.000337\nTraining Epoch: 20 [7552/50000]\tLoss: 0.1905\tLR: 0.000337\nTraining Epoch: 20 [7680/50000]\tLoss: 0.2647\tLR: 0.000337\nTraining Epoch: 20 [7808/50000]\tLoss: 0.2408\tLR: 0.000337\nTraining Epoch: 20 [7936/50000]\tLoss: 0.3029\tLR: 0.000337\nTraining Epoch: 20 [8064/50000]\tLoss: 0.1972\tLR: 0.000337\nTraining Epoch: 20 [8192/50000]\tLoss: 0.3579\tLR: 0.000337\nTraining Epoch: 20 [8320/50000]\tLoss: 0.2402\tLR: 0.000337\nTraining Epoch: 20 [8448/50000]\tLoss: 0.2489\tLR: 0.000337\nTraining Epoch: 20 [8576/50000]\tLoss: 0.1964\tLR: 0.000337\nTraining Epoch: 20 [8704/50000]\tLoss: 0.1609\tLR: 0.000337\nTraining Epoch: 20 [8832/50000]\tLoss: 0.2664\tLR: 0.000337\nTraining Epoch: 20 [8960/50000]\tLoss: 0.2790\tLR: 0.000337\nTraining Epoch: 20 [9088/50000]\tLoss: 0.2258\tLR: 0.000337\nTraining Epoch: 20 [9216/50000]\tLoss: 0.2521\tLR: 0.000337\nTraining Epoch: 20 [9344/50000]\tLoss: 0.2982\tLR: 0.000337\nTraining Epoch: 20 [9472/50000]\tLoss: 0.2806\tLR: 0.000337\nTraining Epoch: 20 [9600/50000]\tLoss: 0.2211\tLR: 0.000337\nTraining Epoch: 20 [9728/50000]\tLoss: 0.2553\tLR: 0.000337\nTraining Epoch: 20 [9856/50000]\tLoss: 0.3054\tLR: 0.000337\nTraining Epoch: 20 [9984/50000]\tLoss: 0.1646\tLR: 0.000337\nTraining Epoch: 20 [10112/50000]\tLoss: 0.2454\tLR: 0.000337\nTraining Epoch: 20 [10240/50000]\tLoss: 0.2669\tLR: 0.000337\nTraining Epoch: 20 [10368/50000]\tLoss: 0.3092\tLR: 0.000337\nTraining Epoch: 20 [10496/50000]\tLoss: 0.3452\tLR: 0.000337\nTraining Epoch: 20 [10624/50000]\tLoss: 0.2145\tLR: 0.000337\nTraining Epoch: 20 [10752/50000]\tLoss: 0.2724\tLR: 0.000337\nTraining Epoch: 20 [10880/50000]\tLoss: 0.2336\tLR: 0.000337\nTraining Epoch: 20 [11008/50000]\tLoss: 0.3198\tLR: 0.000337\nTraining Epoch: 20 [11136/50000]\tLoss: 0.2642\tLR: 0.000337\nTraining Epoch: 20 [11264/50000]\tLoss: 0.2183\tLR: 0.000337\nTraining Epoch: 20 [11392/50000]\tLoss: 0.2494\tLR: 0.000337\nTraining Epoch: 20 [11520/50000]\tLoss: 0.2261\tLR: 0.000337\nTraining Epoch: 20 [11648/50000]\tLoss: 0.2121\tLR: 0.000337\nTraining Epoch: 20 [11776/50000]\tLoss: 0.3469\tLR: 0.000337\nTraining Epoch: 20 [11904/50000]\tLoss: 0.2100\tLR: 0.000337\nTraining Epoch: 20 [12032/50000]\tLoss: 0.2119\tLR: 0.000337\nTraining Epoch: 20 [12160/50000]\tLoss: 0.2417\tLR: 0.000337\nTraining Epoch: 20 [12288/50000]\tLoss: 0.2110\tLR: 0.000337\nTraining Epoch: 20 [12416/50000]\tLoss: 0.2699\tLR: 0.000337\nTraining Epoch: 20 [12544/50000]\tLoss: 0.2656\tLR: 0.000337\nTraining Epoch: 20 [12672/50000]\tLoss: 0.3573\tLR: 0.000337\nTraining Epoch: 20 [12800/50000]\tLoss: 0.3412\tLR: 0.000337\nTraining Epoch: 20 [12928/50000]\tLoss: 0.1922\tLR: 0.000337\nTraining Epoch: 20 [13056/50000]\tLoss: 0.2684\tLR: 0.000337\nTraining Epoch: 20 [13184/50000]\tLoss: 0.2137\tLR: 0.000337\nTraining Epoch: 20 [13312/50000]\tLoss: 0.3096\tLR: 0.000337\nTraining Epoch: 20 [13440/50000]\tLoss: 0.2277\tLR: 0.000337\nTraining Epoch: 20 [13568/50000]\tLoss: 0.1267\tLR: 0.000337\nTraining Epoch: 20 [13696/50000]\tLoss: 0.1699\tLR: 0.000337\nTraining Epoch: 20 [13824/50000]\tLoss: 0.2717\tLR: 0.000337\nTraining Epoch: 20 [13952/50000]\tLoss: 0.3060\tLR: 0.000337\nTraining Epoch: 20 [14080/50000]\tLoss: 0.3823\tLR: 0.000337\nTraining Epoch: 20 [14208/50000]\tLoss: 0.3013\tLR: 0.000337\nTraining Epoch: 20 [14336/50000]\tLoss: 0.2055\tLR: 0.000337\nTraining Epoch: 20 [14464/50000]\tLoss: 0.2895\tLR: 0.000337\nTraining Epoch: 20 [14592/50000]\tLoss: 0.2205\tLR: 0.000337\nTraining Epoch: 20 [14720/50000]\tLoss: 0.2403\tLR: 0.000337\nTraining Epoch: 20 [14848/50000]\tLoss: 0.2304\tLR: 0.000337\nTraining Epoch: 20 [14976/50000]\tLoss: 0.2403\tLR: 0.000337\nTraining Epoch: 20 [15104/50000]\tLoss: 0.2324\tLR: 0.000337\nTraining Epoch: 20 [15232/50000]\tLoss: 0.1950\tLR: 0.000337\nTraining Epoch: 20 [15360/50000]\tLoss: 0.3706\tLR: 0.000337\nTraining Epoch: 20 [15488/50000]\tLoss: 0.2339\tLR: 0.000337\nTraining Epoch: 20 [15616/50000]\tLoss: 0.1573\tLR: 0.000337\nTraining Epoch: 20 [15744/50000]\tLoss: 0.3220\tLR: 0.000337\nTraining Epoch: 20 [15872/50000]\tLoss: 0.1706\tLR: 0.000337\nTraining Epoch: 20 [16000/50000]\tLoss: 0.2524\tLR: 0.000337\nTraining Epoch: 20 [16128/50000]\tLoss: 0.1991\tLR: 0.000337\nTraining Epoch: 20 [16256/50000]\tLoss: 0.2009\tLR: 0.000337\nTraining Epoch: 20 [16384/50000]\tLoss: 0.2428\tLR: 0.000337\nTraining Epoch: 20 [16512/50000]\tLoss: 0.2195\tLR: 0.000337\nTraining Epoch: 20 [16640/50000]\tLoss: 0.2448\tLR: 0.000337\nTraining Epoch: 20 [16768/50000]\tLoss: 0.2705\tLR: 0.000337\nTraining Epoch: 20 [16896/50000]\tLoss: 0.2390\tLR: 0.000337\nTraining Epoch: 20 [17024/50000]\tLoss: 0.2384\tLR: 0.000337\nTraining Epoch: 20 [17152/50000]\tLoss: 0.2519\tLR: 0.000337\nTraining Epoch: 20 [17280/50000]\tLoss: 0.1907\tLR: 0.000337\nTraining Epoch: 20 [17408/50000]\tLoss: 0.2595\tLR: 0.000337\nTraining Epoch: 20 [17536/50000]\tLoss: 0.2235\tLR: 0.000337\nTraining Epoch: 20 [17664/50000]\tLoss: 0.2644\tLR: 0.000337\nTraining Epoch: 20 [17792/50000]\tLoss: 0.2316\tLR: 0.000337\nTraining Epoch: 20 [17920/50000]\tLoss: 0.2529\tLR: 0.000337\nTraining Epoch: 20 [18048/50000]\tLoss: 0.1958\tLR: 0.000337\nTraining Epoch: 20 [18176/50000]\tLoss: 0.2411\tLR: 0.000337\nTraining Epoch: 20 [18304/50000]\tLoss: 0.3087\tLR: 0.000337\nTraining Epoch: 20 [18432/50000]\tLoss: 0.4011\tLR: 0.000337\nTraining Epoch: 20 [18560/50000]\tLoss: 0.2450\tLR: 0.000337\nTraining Epoch: 20 [18688/50000]\tLoss: 0.2805\tLR: 0.000337\nTraining Epoch: 20 [18816/50000]\tLoss: 0.2203\tLR: 0.000337\nTraining Epoch: 20 [18944/50000]\tLoss: 0.2160\tLR: 0.000337\nTraining Epoch: 20 [19072/50000]\tLoss: 0.2050\tLR: 0.000337\nTraining Epoch: 20 [19200/50000]\tLoss: 0.2212\tLR: 0.000337\nTraining Epoch: 20 [19328/50000]\tLoss: 0.2669\tLR: 0.000337\nTraining Epoch: 20 [19456/50000]\tLoss: 0.1541\tLR: 0.000337\nTraining Epoch: 20 [19584/50000]\tLoss: 0.4014\tLR: 0.000337\nTraining Epoch: 20 [19712/50000]\tLoss: 0.2208\tLR: 0.000337\nTraining Epoch: 20 [19840/50000]\tLoss: 0.2592\tLR: 0.000337\nTraining Epoch: 20 [19968/50000]\tLoss: 0.2732\tLR: 0.000337\nTraining Epoch: 20 [20096/50000]\tLoss: 0.2797\tLR: 0.000337\nTraining Epoch: 20 [20224/50000]\tLoss: 0.2604\tLR: 0.000337\nTraining Epoch: 20 [20352/50000]\tLoss: 0.2808\tLR: 0.000337\nTraining Epoch: 20 [20480/50000]\tLoss: 0.2305\tLR: 0.000337\nTraining Epoch: 20 [20608/50000]\tLoss: 0.2749\tLR: 0.000337\nTraining Epoch: 20 [20736/50000]\tLoss: 0.3500\tLR: 0.000337\nTraining Epoch: 20 [20864/50000]\tLoss: 0.3593\tLR: 0.000337\nTraining Epoch: 20 [20992/50000]\tLoss: 0.2186\tLR: 0.000337\nTraining Epoch: 20 [21120/50000]\tLoss: 0.2930\tLR: 0.000337\nTraining Epoch: 20 [21248/50000]\tLoss: 0.2483\tLR: 0.000337\nTraining Epoch: 20 [21376/50000]\tLoss: 0.2267\tLR: 0.000337\nTraining Epoch: 20 [21504/50000]\tLoss: 0.3075\tLR: 0.000337\nTraining Epoch: 20 [21632/50000]\tLoss: 0.2624\tLR: 0.000337\nTraining Epoch: 20 [21760/50000]\tLoss: 0.1550\tLR: 0.000337\nTraining Epoch: 20 [21888/50000]\tLoss: 0.2116\tLR: 0.000337\nTraining Epoch: 20 [22016/50000]\tLoss: 0.2894\tLR: 0.000337\nTraining Epoch: 20 [22144/50000]\tLoss: 0.2257\tLR: 0.000337\nTraining Epoch: 20 [22272/50000]\tLoss: 0.2892\tLR: 0.000337\nTraining Epoch: 20 [22400/50000]\tLoss: 0.2693\tLR: 0.000337\nTraining Epoch: 20 [22528/50000]\tLoss: 0.3084\tLR: 0.000337\nTraining Epoch: 20 [22656/50000]\tLoss: 0.1888\tLR: 0.000337\nTraining Epoch: 20 [22784/50000]\tLoss: 0.2006\tLR: 0.000337\nTraining Epoch: 20 [22912/50000]\tLoss: 0.1795\tLR: 0.000337\nTraining Epoch: 20 [23040/50000]\tLoss: 0.2178\tLR: 0.000337\nTraining Epoch: 20 [23168/50000]\tLoss: 0.2388\tLR: 0.000337\nTraining Epoch: 20 [23296/50000]\tLoss: 0.2813\tLR: 0.000337\nTraining Epoch: 20 [23424/50000]\tLoss: 0.2514\tLR: 0.000337\nTraining Epoch: 20 [23552/50000]\tLoss: 0.3674\tLR: 0.000337\nTraining Epoch: 20 [23680/50000]\tLoss: 0.2202\tLR: 0.000337\nTraining Epoch: 20 [23808/50000]\tLoss: 0.3041\tLR: 0.000337\nTraining Epoch: 20 [23936/50000]\tLoss: 0.3198\tLR: 0.000337\nTraining Epoch: 20 [24064/50000]\tLoss: 0.1752\tLR: 0.000337\nTraining Epoch: 20 [24192/50000]\tLoss: 0.1340\tLR: 0.000337\nTraining Epoch: 20 [24320/50000]\tLoss: 0.1479\tLR: 0.000337\nTraining Epoch: 20 [24448/50000]\tLoss: 0.2829\tLR: 0.000337\nTraining Epoch: 20 [24576/50000]\tLoss: 0.2349\tLR: 0.000337\nTraining Epoch: 20 [24704/50000]\tLoss: 0.2603\tLR: 0.000337\nTraining Epoch: 20 [24832/50000]\tLoss: 0.2731\tLR: 0.000337\nTraining Epoch: 20 [24960/50000]\tLoss: 0.1904\tLR: 0.000337\nTraining Epoch: 20 [25088/50000]\tLoss: 0.3011\tLR: 0.000337\nTraining Epoch: 20 [25216/50000]\tLoss: 0.2901\tLR: 0.000337\nTraining Epoch: 20 [25344/50000]\tLoss: 0.1939\tLR: 0.000337\nTraining Epoch: 20 [25472/50000]\tLoss: 0.2156\tLR: 0.000337\nTraining Epoch: 20 [25600/50000]\tLoss: 0.1946\tLR: 0.000337\nTraining Epoch: 20 [25728/50000]\tLoss: 0.2526\tLR: 0.000337\nTraining Epoch: 20 [25856/50000]\tLoss: 0.2727\tLR: 0.000337\nTraining Epoch: 20 [25984/50000]\tLoss: 0.3151\tLR: 0.000337\nTraining Epoch: 20 [26112/50000]\tLoss: 0.2441\tLR: 0.000337\nTraining Epoch: 20 [26240/50000]\tLoss: 0.1777\tLR: 0.000337\nTraining Epoch: 20 [26368/50000]\tLoss: 0.2591\tLR: 0.000337\nTraining Epoch: 20 [26496/50000]\tLoss: 0.2125\tLR: 0.000337\nTraining Epoch: 20 [26624/50000]\tLoss: 0.2571\tLR: 0.000337\nTraining Epoch: 20 [26752/50000]\tLoss: 0.3097\tLR: 0.000337\nTraining Epoch: 20 [26880/50000]\tLoss: 0.2041\tLR: 0.000337\nTraining Epoch: 20 [27008/50000]\tLoss: 0.3783\tLR: 0.000337\nTraining Epoch: 20 [27136/50000]\tLoss: 0.2816\tLR: 0.000337\nTraining Epoch: 20 [27264/50000]\tLoss: 0.2061\tLR: 0.000337\nTraining Epoch: 20 [27392/50000]\tLoss: 0.1371\tLR: 0.000337\nTraining Epoch: 20 [27520/50000]\tLoss: 0.3146\tLR: 0.000337\nTraining Epoch: 20 [27648/50000]\tLoss: 0.2851\tLR: 0.000337\nTraining Epoch: 20 [27776/50000]\tLoss: 0.2958\tLR: 0.000337\nTraining Epoch: 20 [27904/50000]\tLoss: 0.2291\tLR: 0.000337\nTraining Epoch: 20 [28032/50000]\tLoss: 0.2295\tLR: 0.000337\nTraining Epoch: 20 [28160/50000]\tLoss: 0.3289\tLR: 0.000337\nTraining Epoch: 20 [28288/50000]\tLoss: 0.4292\tLR: 0.000337\nTraining Epoch: 20 [28416/50000]\tLoss: 0.2592\tLR: 0.000337\nTraining Epoch: 20 [28544/50000]\tLoss: 0.2729\tLR: 0.000337\nTraining Epoch: 20 [28672/50000]\tLoss: 0.2680\tLR: 0.000337\nTraining Epoch: 20 [28800/50000]\tLoss: 0.2375\tLR: 0.000337\nTraining Epoch: 20 [28928/50000]\tLoss: 0.1968\tLR: 0.000337\nTraining Epoch: 20 [29056/50000]\tLoss: 0.2238\tLR: 0.000337\nTraining Epoch: 20 [29184/50000]\tLoss: 0.3061\tLR: 0.000337\nTraining Epoch: 20 [29312/50000]\tLoss: 0.2934\tLR: 0.000337\nTraining Epoch: 20 [29440/50000]\tLoss: 0.2056\tLR: 0.000337\nTraining Epoch: 20 [29568/50000]\tLoss: 0.2030\tLR: 0.000337\nTraining Epoch: 20 [29696/50000]\tLoss: 0.3058\tLR: 0.000337\nTraining Epoch: 20 [29824/50000]\tLoss: 0.2587\tLR: 0.000337\nTraining Epoch: 20 [29952/50000]\tLoss: 0.3572\tLR: 0.000337\nTraining Epoch: 20 [30080/50000]\tLoss: 0.2003\tLR: 0.000337\nTraining Epoch: 20 [30208/50000]\tLoss: 0.2439\tLR: 0.000337\nTraining Epoch: 20 [30336/50000]\tLoss: 0.2485\tLR: 0.000337\nTraining Epoch: 20 [30464/50000]\tLoss: 0.2143\tLR: 0.000337\nTraining Epoch: 20 [30592/50000]\tLoss: 0.3321\tLR: 0.000337\nTraining Epoch: 20 [30720/50000]\tLoss: 0.4211\tLR: 0.000337\nTraining Epoch: 20 [30848/50000]\tLoss: 0.3431\tLR: 0.000337\nTraining Epoch: 20 [30976/50000]\tLoss: 0.1651\tLR: 0.000337\nTraining Epoch: 20 [31104/50000]\tLoss: 0.1992\tLR: 0.000337\nTraining Epoch: 20 [31232/50000]\tLoss: 0.2769\tLR: 0.000337\nTraining Epoch: 20 [31360/50000]\tLoss: 0.1445\tLR: 0.000337\nTraining Epoch: 20 [31488/50000]\tLoss: 0.3044\tLR: 0.000337\nTraining Epoch: 20 [31616/50000]\tLoss: 0.1559\tLR: 0.000337\nTraining Epoch: 20 [31744/50000]\tLoss: 0.2076\tLR: 0.000337\nTraining Epoch: 20 [31872/50000]\tLoss: 0.2004\tLR: 0.000337\nTraining Epoch: 20 [32000/50000]\tLoss: 0.2180\tLR: 0.000337\nTraining Epoch: 20 [32128/50000]\tLoss: 0.2478\tLR: 0.000337\nTraining Epoch: 20 [32256/50000]\tLoss: 0.2435\tLR: 0.000337\nTraining Epoch: 20 [32384/50000]\tLoss: 0.1962\tLR: 0.000337\nTraining Epoch: 20 [32512/50000]\tLoss: 0.2476\tLR: 0.000337\nTraining Epoch: 20 [32640/50000]\tLoss: 0.1949\tLR: 0.000337\nTraining Epoch: 20 [32768/50000]\tLoss: 0.2579\tLR: 0.000337\nTraining Epoch: 20 [32896/50000]\tLoss: 0.2278\tLR: 0.000337\nTraining Epoch: 20 [33024/50000]\tLoss: 0.3237\tLR: 0.000337\nTraining Epoch: 20 [33152/50000]\tLoss: 0.2270\tLR: 0.000337\nTraining Epoch: 20 [33280/50000]\tLoss: 0.1936\tLR: 0.000337\nTraining Epoch: 20 [33408/50000]\tLoss: 0.1963\tLR: 0.000337\nTraining Epoch: 20 [33536/50000]\tLoss: 0.2439\tLR: 0.000337\nTraining Epoch: 20 [33664/50000]\tLoss: 0.2363\tLR: 0.000337\nTraining Epoch: 20 [33792/50000]\tLoss: 0.1926\tLR: 0.000337\nTraining Epoch: 20 [33920/50000]\tLoss: 0.2277\tLR: 0.000337\nTraining Epoch: 20 [34048/50000]\tLoss: 0.2809\tLR: 0.000337\nTraining Epoch: 20 [34176/50000]\tLoss: 0.1900\tLR: 0.000337\nTraining Epoch: 20 [34304/50000]\tLoss: 0.3129\tLR: 0.000337\nTraining Epoch: 20 [34432/50000]\tLoss: 0.3763\tLR: 0.000337\nTraining Epoch: 20 [34560/50000]\tLoss: 0.2619\tLR: 0.000337\nTraining Epoch: 20 [34688/50000]\tLoss: 0.1757\tLR: 0.000337\nTraining Epoch: 20 [34816/50000]\tLoss: 0.2227\tLR: 0.000337\nTraining Epoch: 20 [34944/50000]\tLoss: 0.2571\tLR: 0.000337\nTraining Epoch: 20 [35072/50000]\tLoss: 0.2081\tLR: 0.000337\nTraining Epoch: 20 [35200/50000]\tLoss: 0.2783\tLR: 0.000337\nTraining Epoch: 20 [35328/50000]\tLoss: 0.2829\tLR: 0.000337\nTraining Epoch: 20 [35456/50000]\tLoss: 0.3461\tLR: 0.000337\nTraining Epoch: 20 [35584/50000]\tLoss: 0.2587\tLR: 0.000337\nTraining Epoch: 20 [35712/50000]\tLoss: 0.2287\tLR: 0.000337\nTraining Epoch: 20 [35840/50000]\tLoss: 0.2877\tLR: 0.000337\nTraining Epoch: 20 [35968/50000]\tLoss: 0.1826\tLR: 0.000337\nTraining Epoch: 20 [36096/50000]\tLoss: 0.2365\tLR: 0.000337\nTraining Epoch: 20 [36224/50000]\tLoss: 0.2903\tLR: 0.000337\nTraining Epoch: 20 [36352/50000]\tLoss: 0.1475\tLR: 0.000337\nTraining Epoch: 20 [36480/50000]\tLoss: 0.2831\tLR: 0.000337\nTraining Epoch: 20 [36608/50000]\tLoss: 0.1443\tLR: 0.000337\nTraining Epoch: 20 [36736/50000]\tLoss: 0.2807\tLR: 0.000337\nTraining Epoch: 20 [36864/50000]\tLoss: 0.3672\tLR: 0.000337\nTraining Epoch: 20 [36992/50000]\tLoss: 0.2875\tLR: 0.000337\nTraining Epoch: 20 [37120/50000]\tLoss: 0.3100\tLR: 0.000337\nTraining Epoch: 20 [37248/50000]\tLoss: 0.2235\tLR: 0.000337\nTraining Epoch: 20 [37376/50000]\tLoss: 0.1879\tLR: 0.000337\nTraining Epoch: 20 [37504/50000]\tLoss: 0.2566\tLR: 0.000337\nTraining Epoch: 20 [37632/50000]\tLoss: 0.2513\tLR: 0.000337\nTraining Epoch: 20 [37760/50000]\tLoss: 0.2457\tLR: 0.000337\nTraining Epoch: 20 [37888/50000]\tLoss: 0.2163\tLR: 0.000337\nTraining Epoch: 20 [38016/50000]\tLoss: 0.2573\tLR: 0.000337\nTraining Epoch: 20 [38144/50000]\tLoss: 0.1977\tLR: 0.000337\nTraining Epoch: 20 [38272/50000]\tLoss: 0.2428\tLR: 0.000337\nTraining Epoch: 20 [38400/50000]\tLoss: 0.2505\tLR: 0.000337\nTraining Epoch: 20 [38528/50000]\tLoss: 0.3199\tLR: 0.000337\nTraining Epoch: 20 [38656/50000]\tLoss: 0.2289\tLR: 0.000337\nTraining Epoch: 20 [38784/50000]\tLoss: 0.1369\tLR: 0.000337\nTraining Epoch: 20 [38912/50000]\tLoss: 0.2097\tLR: 0.000337\nTraining Epoch: 20 [39040/50000]\tLoss: 0.2390\tLR: 0.000337\nTraining Epoch: 20 [39168/50000]\tLoss: 0.2074\tLR: 0.000337\nTraining Epoch: 20 [39296/50000]\tLoss: 0.2612\tLR: 0.000337\nTraining Epoch: 20 [39424/50000]\tLoss: 0.1910\tLR: 0.000337\nTraining Epoch: 20 [39552/50000]\tLoss: 0.1789\tLR: 0.000337\nTraining Epoch: 20 [39680/50000]\tLoss: 0.2900\tLR: 0.000337\nTraining Epoch: 20 [39808/50000]\tLoss: 0.1509\tLR: 0.000337\nTraining Epoch: 20 [39936/50000]\tLoss: 0.1945\tLR: 0.000337\nTraining Epoch: 20 [40064/50000]\tLoss: 0.2359\tLR: 0.000337\nTraining Epoch: 20 [40192/50000]\tLoss: 0.1926\tLR: 0.000337\nTraining Epoch: 20 [40320/50000]\tLoss: 0.2972\tLR: 0.000337\nTraining Epoch: 20 [40448/50000]\tLoss: 0.2183\tLR: 0.000337\nTraining Epoch: 20 [40576/50000]\tLoss: 0.2658\tLR: 0.000337\nTraining Epoch: 20 [40704/50000]\tLoss: 0.2665\tLR: 0.000337\nTraining Epoch: 20 [40832/50000]\tLoss: 0.2434\tLR: 0.000337\nTraining Epoch: 20 [40960/50000]\tLoss: 0.2382\tLR: 0.000337\nTraining Epoch: 20 [41088/50000]\tLoss: 0.2589\tLR: 0.000337\nTraining Epoch: 20 [41216/50000]\tLoss: 0.2821\tLR: 0.000337\nTraining Epoch: 20 [41344/50000]\tLoss: 0.2032\tLR: 0.000337\nTraining Epoch: 20 [41472/50000]\tLoss: 0.2688\tLR: 0.000337\nTraining Epoch: 20 [41600/50000]\tLoss: 0.2483\tLR: 0.000337\nTraining Epoch: 20 [41728/50000]\tLoss: 0.2762\tLR: 0.000337\nTraining Epoch: 20 [41856/50000]\tLoss: 0.3375\tLR: 0.000337\nTraining Epoch: 20 [41984/50000]\tLoss: 0.2114\tLR: 0.000337\nTraining Epoch: 20 [42112/50000]\tLoss: 0.2504\tLR: 0.000337\nTraining Epoch: 20 [42240/50000]\tLoss: 0.2143\tLR: 0.000337\nTraining Epoch: 20 [42368/50000]\tLoss: 0.2400\tLR: 0.000337\nTraining Epoch: 20 [42496/50000]\tLoss: 0.2461\tLR: 0.000337\nTraining Epoch: 20 [42624/50000]\tLoss: 0.2406\tLR: 0.000337\nTraining Epoch: 20 [42752/50000]\tLoss: 0.2164\tLR: 0.000337\nTraining Epoch: 20 [42880/50000]\tLoss: 0.2530\tLR: 0.000337\nTraining Epoch: 20 [43008/50000]\tLoss: 0.2523\tLR: 0.000337\nTraining Epoch: 20 [43136/50000]\tLoss: 0.1556\tLR: 0.000337\nTraining Epoch: 20 [43264/50000]\tLoss: 0.3116\tLR: 0.000337\nTraining Epoch: 20 [43392/50000]\tLoss: 0.2802\tLR: 0.000337\nTraining Epoch: 20 [43520/50000]\tLoss: 0.2250\tLR: 0.000337\nTraining Epoch: 20 [43648/50000]\tLoss: 0.2699\tLR: 0.000337\nTraining Epoch: 20 [43776/50000]\tLoss: 0.2349\tLR: 0.000337\nTraining Epoch: 20 [43904/50000]\tLoss: 0.2307\tLR: 0.000337\nTraining Epoch: 20 [44032/50000]\tLoss: 0.3931\tLR: 0.000337\nTraining Epoch: 20 [44160/50000]\tLoss: 0.1823\tLR: 0.000337\nTraining Epoch: 20 [44288/50000]\tLoss: 0.1782\tLR: 0.000337\nTraining Epoch: 20 [44416/50000]\tLoss: 0.1698\tLR: 0.000337\nTraining Epoch: 20 [44544/50000]\tLoss: 0.2602\tLR: 0.000337\nTraining Epoch: 20 [44672/50000]\tLoss: 0.2062\tLR: 0.000337\nTraining Epoch: 20 [44800/50000]\tLoss: 0.2932\tLR: 0.000337\nTraining Epoch: 20 [44928/50000]\tLoss: 0.2682\tLR: 0.000337\nTraining Epoch: 20 [45056/50000]\tLoss: 0.2890\tLR: 0.000337\nTraining Epoch: 20 [45184/50000]\tLoss: 0.2364\tLR: 0.000337\nTraining Epoch: 20 [45312/50000]\tLoss: 0.1555\tLR: 0.000337\nTraining Epoch: 20 [45440/50000]\tLoss: 0.2891\tLR: 0.000337\nTraining Epoch: 20 [45568/50000]\tLoss: 0.2575\tLR: 0.000337\nTraining Epoch: 20 [45696/50000]\tLoss: 0.3367\tLR: 0.000337\nTraining Epoch: 20 [45824/50000]\tLoss: 0.3791\tLR: 0.000337\nTraining Epoch: 20 [45952/50000]\tLoss: 0.3072\tLR: 0.000337\nTraining Epoch: 20 [46080/50000]\tLoss: 0.1716\tLR: 0.000337\nTraining Epoch: 20 [46208/50000]\tLoss: 0.2269\tLR: 0.000337\nTraining Epoch: 20 [46336/50000]\tLoss: 0.3065\tLR: 0.000337\nTraining Epoch: 20 [46464/50000]\tLoss: 0.2895\tLR: 0.000337\nTraining Epoch: 20 [46592/50000]\tLoss: 0.2294\tLR: 0.000337\nTraining Epoch: 20 [46720/50000]\tLoss: 0.2376\tLR: 0.000337\nTraining Epoch: 20 [46848/50000]\tLoss: 0.2790\tLR: 0.000337\nTraining Epoch: 20 [46976/50000]\tLoss: 0.3076\tLR: 0.000337\nTraining Epoch: 20 [47104/50000]\tLoss: 0.2691\tLR: 0.000337\nTraining Epoch: 20 [47232/50000]\tLoss: 0.2656\tLR: 0.000337\nTraining Epoch: 20 [47360/50000]\tLoss: 0.2901\tLR: 0.000337\nTraining Epoch: 20 [47488/50000]\tLoss: 0.3289\tLR: 0.000337\nTraining Epoch: 20 [47616/50000]\tLoss: 0.2677\tLR: 0.000337\nTraining Epoch: 20 [47744/50000]\tLoss: 0.2385\tLR: 0.000337\nTraining Epoch: 20 [47872/50000]\tLoss: 0.2891\tLR: 0.000337\nTraining Epoch: 20 [48000/50000]\tLoss: 0.1961\tLR: 0.000337\nTraining Epoch: 20 [48128/50000]\tLoss: 0.3098\tLR: 0.000337\nTraining Epoch: 20 [48256/50000]\tLoss: 0.2421\tLR: 0.000337\nTraining Epoch: 20 [48384/50000]\tLoss: 0.1978\tLR: 0.000337\nTraining Epoch: 20 [48512/50000]\tLoss: 0.2205\tLR: 0.000337\nTraining Epoch: 20 [48640/50000]\tLoss: 0.2517\tLR: 0.000337\nTraining Epoch: 20 [48768/50000]\tLoss: 0.2077\tLR: 0.000337\nTraining Epoch: 20 [48896/50000]\tLoss: 0.1989\tLR: 0.000337\nTraining Epoch: 20 [49024/50000]\tLoss: 0.2173\tLR: 0.000337\nTraining Epoch: 20 [49152/50000]\tLoss: 0.2788\tLR: 0.000337\nTraining Epoch: 20 [49280/50000]\tLoss: 0.3330\tLR: 0.000337\nTraining Epoch: 20 [49408/50000]\tLoss: 0.2063\tLR: 0.000337\nTraining Epoch: 20 [49536/50000]\tLoss: 0.3767\tLR: 0.000337\nTraining Epoch: 20 [49664/50000]\tLoss: 0.2465\tLR: 0.000337\nTraining Epoch: 20 [49792/50000]\tLoss: 0.3298\tLR: 0.000337\nTraining Epoch: 20 [49920/50000]\tLoss: 0.2424\tLR: 0.000337\nTraining Epoch: 20 [50000/50000]\tLoss: 0.2811\tLR: 0.000337\nTest set: Average loss: 0.0024, Accuracy: 0.8985\n\nTraining Epoch: 21 [128/50000]\tLoss: 0.1580\tLR: 0.000337\nTraining Epoch: 21 [256/50000]\tLoss: 0.2993\tLR: 0.000337\nTraining Epoch: 21 [384/50000]\tLoss: 0.2701\tLR: 0.000337\nTraining Epoch: 21 [512/50000]\tLoss: 0.2761\tLR: 0.000337\nTraining Epoch: 21 [640/50000]\tLoss: 0.2457\tLR: 0.000337\nTraining Epoch: 21 [768/50000]\tLoss: 0.2338\tLR: 0.000337\nTraining Epoch: 21 [896/50000]\tLoss: 0.1635\tLR: 0.000337\nTraining Epoch: 21 [1024/50000]\tLoss: 0.2783\tLR: 0.000337\nTraining Epoch: 21 [1152/50000]\tLoss: 0.2964\tLR: 0.000337\nTraining Epoch: 21 [1280/50000]\tLoss: 0.3626\tLR: 0.000337\nTraining Epoch: 21 [1408/50000]\tLoss: 0.2439\tLR: 0.000337\nTraining Epoch: 21 [1536/50000]\tLoss: 0.2199\tLR: 0.000337\nTraining Epoch: 21 [1664/50000]\tLoss: 0.4529\tLR: 0.000337\nTraining Epoch: 21 [1792/50000]\tLoss: 0.2246\tLR: 0.000337\nTraining Epoch: 21 [1920/50000]\tLoss: 0.2731\tLR: 0.000337\nTraining Epoch: 21 [2048/50000]\tLoss: 0.3014\tLR: 0.000337\nTraining Epoch: 21 [2176/50000]\tLoss: 0.2930\tLR: 0.000337\nTraining Epoch: 21 [2304/50000]\tLoss: 0.2642\tLR: 0.000337\nTraining Epoch: 21 [2432/50000]\tLoss: 0.3199\tLR: 0.000337\nTraining Epoch: 21 [2560/50000]\tLoss: 0.3639\tLR: 0.000337\nTraining Epoch: 21 [2688/50000]\tLoss: 0.1724\tLR: 0.000337\nTraining Epoch: 21 [2816/50000]\tLoss: 0.2422\tLR: 0.000337\nTraining Epoch: 21 [2944/50000]\tLoss: 0.2546\tLR: 0.000337\nTraining Epoch: 21 [3072/50000]\tLoss: 0.2277\tLR: 0.000337\nTraining Epoch: 21 [3200/50000]\tLoss: 0.3040\tLR: 0.000337\nTraining Epoch: 21 [3328/50000]\tLoss: 0.2585\tLR: 0.000337\nTraining Epoch: 21 [3456/50000]\tLoss: 0.2141\tLR: 0.000337\nTraining Epoch: 21 [3584/50000]\tLoss: 0.2045\tLR: 0.000337\nTraining Epoch: 21 [3712/50000]\tLoss: 0.2020\tLR: 0.000337\nTraining Epoch: 21 [3840/50000]\tLoss: 0.3084\tLR: 0.000337\nTraining Epoch: 21 [3968/50000]\tLoss: 0.1898\tLR: 0.000337\nTraining Epoch: 21 [4096/50000]\tLoss: 0.2335\tLR: 0.000337\nTraining Epoch: 21 [4224/50000]\tLoss: 0.2913\tLR: 0.000337\nTraining Epoch: 21 [4352/50000]\tLoss: 0.2341\tLR: 0.000337\nTraining Epoch: 21 [4480/50000]\tLoss: 0.1998\tLR: 0.000337\nTraining Epoch: 21 [4608/50000]\tLoss: 0.3089\tLR: 0.000337\nTraining Epoch: 21 [4736/50000]\tLoss: 0.2896\tLR: 0.000337\nTraining Epoch: 21 [4864/50000]\tLoss: 0.2545\tLR: 0.000337\nTraining Epoch: 21 [4992/50000]\tLoss: 0.1637\tLR: 0.000337\nTraining Epoch: 21 [5120/50000]\tLoss: 0.2049\tLR: 0.000337\nTraining Epoch: 21 [5248/50000]\tLoss: 0.1938\tLR: 0.000337\nTraining Epoch: 21 [5376/50000]\tLoss: 0.2391\tLR: 0.000337\nTraining Epoch: 21 [5504/50000]\tLoss: 0.2997\tLR: 0.000337\nTraining Epoch: 21 [5632/50000]\tLoss: 0.2546\tLR: 0.000337\nTraining Epoch: 21 [5760/50000]\tLoss: 0.2207\tLR: 0.000337\nTraining Epoch: 21 [5888/50000]\tLoss: 0.2782\tLR: 0.000337\nTraining Epoch: 21 [6016/50000]\tLoss: 0.1523\tLR: 0.000337\nTraining Epoch: 21 [6144/50000]\tLoss: 0.2203\tLR: 0.000337\nTraining Epoch: 21 [6272/50000]\tLoss: 0.2040\tLR: 0.000337\nTraining Epoch: 21 [6400/50000]\tLoss: 0.2884\tLR: 0.000337\nTraining Epoch: 21 [6528/50000]\tLoss: 0.1973\tLR: 0.000337\nTraining Epoch: 21 [6656/50000]\tLoss: 0.2320\tLR: 0.000337\nTraining Epoch: 21 [6784/50000]\tLoss: 0.2422\tLR: 0.000337\nTraining Epoch: 21 [6912/50000]\tLoss: 0.1975\tLR: 0.000337\nTraining Epoch: 21 [7040/50000]\tLoss: 0.2553\tLR: 0.000337\nTraining Epoch: 21 [7168/50000]\tLoss: 0.3362\tLR: 0.000337\nTraining Epoch: 21 [7296/50000]\tLoss: 0.1954\tLR: 0.000337\nTraining Epoch: 21 [7424/50000]\tLoss: 0.2071\tLR: 0.000337\nTraining Epoch: 21 [7552/50000]\tLoss: 0.2814\tLR: 0.000337\nTraining Epoch: 21 [7680/50000]\tLoss: 0.1990\tLR: 0.000337\nTraining Epoch: 21 [7808/50000]\tLoss: 0.2268\tLR: 0.000337\nTraining Epoch: 21 [7936/50000]\tLoss: 0.3665\tLR: 0.000337\nTraining Epoch: 21 [8064/50000]\tLoss: 0.3482\tLR: 0.000337\nTraining Epoch: 21 [8192/50000]\tLoss: 0.3099\tLR: 0.000337\nTraining Epoch: 21 [8320/50000]\tLoss: 0.2709\tLR: 0.000337\nTraining Epoch: 21 [8448/50000]\tLoss: 0.2282\tLR: 0.000337\nTraining Epoch: 21 [8576/50000]\tLoss: 0.3037\tLR: 0.000337\nTraining Epoch: 21 [8704/50000]\tLoss: 0.3569\tLR: 0.000337\nTraining Epoch: 21 [8832/50000]\tLoss: 0.2310\tLR: 0.000337\nTraining Epoch: 21 [8960/50000]\tLoss: 0.2989\tLR: 0.000337\nTraining Epoch: 21 [9088/50000]\tLoss: 0.2155\tLR: 0.000337\nTraining Epoch: 21 [9216/50000]\tLoss: 0.3316\tLR: 0.000337\nTraining Epoch: 21 [9344/50000]\tLoss: 0.2169\tLR: 0.000337\nTraining Epoch: 21 [9472/50000]\tLoss: 0.2393\tLR: 0.000337\nTraining Epoch: 21 [9600/50000]\tLoss: 0.3365\tLR: 0.000337\nTraining Epoch: 21 [9728/50000]\tLoss: 0.2629\tLR: 0.000337\nTraining Epoch: 21 [9856/50000]\tLoss: 0.1681\tLR: 0.000337\nTraining Epoch: 21 [9984/50000]\tLoss: 0.3334\tLR: 0.000337\nTraining Epoch: 21 [10112/50000]\tLoss: 0.2729\tLR: 0.000337\nTraining Epoch: 21 [10240/50000]\tLoss: 0.2129\tLR: 0.000337\nTraining Epoch: 21 [10368/50000]\tLoss: 0.2772\tLR: 0.000337\nTraining Epoch: 21 [10496/50000]\tLoss: 0.3202\tLR: 0.000337\nTraining Epoch: 21 [10624/50000]\tLoss: 0.2424\tLR: 0.000337\nTraining Epoch: 21 [10752/50000]\tLoss: 0.1606\tLR: 0.000337\nTraining Epoch: 21 [10880/50000]\tLoss: 0.2618\tLR: 0.000337\nTraining Epoch: 21 [11008/50000]\tLoss: 0.2521\tLR: 0.000337\nTraining Epoch: 21 [11136/50000]\tLoss: 0.2265\tLR: 0.000337\nTraining Epoch: 21 [11264/50000]\tLoss: 0.2254\tLR: 0.000337\nTraining Epoch: 21 [11392/50000]\tLoss: 0.2506\tLR: 0.000337\nTraining Epoch: 21 [11520/50000]\tLoss: 0.2524\tLR: 0.000337\nTraining Epoch: 21 [11648/50000]\tLoss: 0.3031\tLR: 0.000337\nTraining Epoch: 21 [11776/50000]\tLoss: 0.2812\tLR: 0.000337\nTraining Epoch: 21 [11904/50000]\tLoss: 0.2179\tLR: 0.000337\nTraining Epoch: 21 [12032/50000]\tLoss: 0.2128\tLR: 0.000337\nTraining Epoch: 21 [12160/50000]\tLoss: 0.3876\tLR: 0.000337\nTraining Epoch: 21 [12288/50000]\tLoss: 0.1508\tLR: 0.000337\nTraining Epoch: 21 [12416/50000]\tLoss: 0.2413\tLR: 0.000337\nTraining Epoch: 21 [12544/50000]\tLoss: 0.2469\tLR: 0.000337\nTraining Epoch: 21 [12672/50000]\tLoss: 0.2013\tLR: 0.000337\nTraining Epoch: 21 [12800/50000]\tLoss: 0.2194\tLR: 0.000337\nTraining Epoch: 21 [12928/50000]\tLoss: 0.1831\tLR: 0.000337\nTraining Epoch: 21 [13056/50000]\tLoss: 0.2935\tLR: 0.000337\nTraining Epoch: 21 [13184/50000]\tLoss: 0.2432\tLR: 0.000337\nTraining Epoch: 21 [13312/50000]\tLoss: 0.2970\tLR: 0.000337\nTraining Epoch: 21 [13440/50000]\tLoss: 0.1447\tLR: 0.000337\nTraining Epoch: 21 [13568/50000]\tLoss: 0.2153\tLR: 0.000337\nTraining Epoch: 21 [13696/50000]\tLoss: 0.2060\tLR: 0.000337\nTraining Epoch: 21 [13824/50000]\tLoss: 0.2110\tLR: 0.000337\nTraining Epoch: 21 [13952/50000]\tLoss: 0.2500\tLR: 0.000337\nTraining Epoch: 21 [14080/50000]\tLoss: 0.2379\tLR: 0.000337\nTraining Epoch: 21 [14208/50000]\tLoss: 0.3226\tLR: 0.000337\nTraining Epoch: 21 [14336/50000]\tLoss: 0.3063\tLR: 0.000337\nTraining Epoch: 21 [14464/50000]\tLoss: 0.2971\tLR: 0.000337\nTraining Epoch: 21 [14592/50000]\tLoss: 0.2090\tLR: 0.000337\nTraining Epoch: 21 [14720/50000]\tLoss: 0.1365\tLR: 0.000337\nTraining Epoch: 21 [14848/50000]\tLoss: 0.2361\tLR: 0.000337\nTraining Epoch: 21 [14976/50000]\tLoss: 0.3319\tLR: 0.000337\nTraining Epoch: 21 [15104/50000]\tLoss: 0.2508\tLR: 0.000337\nTraining Epoch: 21 [15232/50000]\tLoss: 0.2943\tLR: 0.000337\nTraining Epoch: 21 [15360/50000]\tLoss: 0.1677\tLR: 0.000337\nTraining Epoch: 21 [15488/50000]\tLoss: 0.1907\tLR: 0.000337\nTraining Epoch: 21 [15616/50000]\tLoss: 0.3177\tLR: 0.000337\nTraining Epoch: 21 [15744/50000]\tLoss: 0.2128\tLR: 0.000337\nTraining Epoch: 21 [15872/50000]\tLoss: 0.2321\tLR: 0.000337\nTraining Epoch: 21 [16000/50000]\tLoss: 0.2724\tLR: 0.000337\nTraining Epoch: 21 [16128/50000]\tLoss: 0.1647\tLR: 0.000337\nTraining Epoch: 21 [16256/50000]\tLoss: 0.2073\tLR: 0.000337\nTraining Epoch: 21 [16384/50000]\tLoss: 0.1764\tLR: 0.000337\nTraining Epoch: 21 [16512/50000]\tLoss: 0.1719\tLR: 0.000337\nTraining Epoch: 21 [16640/50000]\tLoss: 0.2852\tLR: 0.000337\nTraining Epoch: 21 [16768/50000]\tLoss: 0.2543\tLR: 0.000337\nTraining Epoch: 21 [16896/50000]\tLoss: 0.1989\tLR: 0.000337\nTraining Epoch: 21 [17024/50000]\tLoss: 0.2454\tLR: 0.000337\nTraining Epoch: 21 [17152/50000]\tLoss: 0.2781\tLR: 0.000337\nTraining Epoch: 21 [17280/50000]\tLoss: 0.1865\tLR: 0.000337\nTraining Epoch: 21 [17408/50000]\tLoss: 0.3314\tLR: 0.000337\nTraining Epoch: 21 [17536/50000]\tLoss: 0.1650\tLR: 0.000337\nTraining Epoch: 21 [17664/50000]\tLoss: 0.2233\tLR: 0.000337\nTraining Epoch: 21 [17792/50000]\tLoss: 0.2588\tLR: 0.000337\nTraining Epoch: 21 [17920/50000]\tLoss: 0.2661\tLR: 0.000337\nTraining Epoch: 21 [18048/50000]\tLoss: 0.2733\tLR: 0.000337\nTraining Epoch: 21 [18176/50000]\tLoss: 0.1881\tLR: 0.000337\nTraining Epoch: 21 [18304/50000]\tLoss: 0.1904\tLR: 0.000337\nTraining Epoch: 21 [18432/50000]\tLoss: 0.2003\tLR: 0.000337\nTraining Epoch: 21 [18560/50000]\tLoss: 0.2404\tLR: 0.000337\nTraining Epoch: 21 [18688/50000]\tLoss: 0.2272\tLR: 0.000337\nTraining Epoch: 21 [18816/50000]\tLoss: 0.1500\tLR: 0.000337\nTraining Epoch: 21 [18944/50000]\tLoss: 0.1829\tLR: 0.000337\nTraining Epoch: 21 [19072/50000]\tLoss: 0.2714\tLR: 0.000337\nTraining Epoch: 21 [19200/50000]\tLoss: 0.2375\tLR: 0.000337\nTraining Epoch: 21 [19328/50000]\tLoss: 0.2741\tLR: 0.000337\nTraining Epoch: 21 [19456/50000]\tLoss: 0.2632\tLR: 0.000337\nTraining Epoch: 21 [19584/50000]\tLoss: 0.2745\tLR: 0.000337\nTraining Epoch: 21 [19712/50000]\tLoss: 0.2502\tLR: 0.000337\nTraining Epoch: 21 [19840/50000]\tLoss: 0.1761\tLR: 0.000337\nTraining Epoch: 21 [19968/50000]\tLoss: 0.2300\tLR: 0.000337\nTraining Epoch: 21 [20096/50000]\tLoss: 0.3200\tLR: 0.000337\nTraining Epoch: 21 [20224/50000]\tLoss: 0.2291\tLR: 0.000337\nTraining Epoch: 21 [20352/50000]\tLoss: 0.1904\tLR: 0.000337\nTraining Epoch: 21 [20480/50000]\tLoss: 0.2376\tLR: 0.000337\nTraining Epoch: 21 [20608/50000]\tLoss: 0.2303\tLR: 0.000337\nTraining Epoch: 21 [20736/50000]\tLoss: 0.3031\tLR: 0.000337\nTraining Epoch: 21 [20864/50000]\tLoss: 0.3207\tLR: 0.000337\nTraining Epoch: 21 [20992/50000]\tLoss: 0.2731\tLR: 0.000337\nTraining Epoch: 21 [21120/50000]\tLoss: 0.3068\tLR: 0.000337\nTraining Epoch: 21 [21248/50000]\tLoss: 0.3052\tLR: 0.000337\nTraining Epoch: 21 [21376/50000]\tLoss: 0.3555\tLR: 0.000337\nTraining Epoch: 21 [21504/50000]\tLoss: 0.2649\tLR: 0.000337\nTraining Epoch: 21 [21632/50000]\tLoss: 0.3175\tLR: 0.000337\nTraining Epoch: 21 [21760/50000]\tLoss: 0.2696\tLR: 0.000337\nTraining Epoch: 21 [21888/50000]\tLoss: 0.2720\tLR: 0.000337\nTraining Epoch: 21 [22016/50000]\tLoss: 0.2963\tLR: 0.000337\nTraining Epoch: 21 [22144/50000]\tLoss: 0.2777\tLR: 0.000337\nTraining Epoch: 21 [22272/50000]\tLoss: 0.2275\tLR: 0.000337\nTraining Epoch: 21 [22400/50000]\tLoss: 0.1897\tLR: 0.000337\nTraining Epoch: 21 [22528/50000]\tLoss: 0.2674\tLR: 0.000337\nTraining Epoch: 21 [22656/50000]\tLoss: 0.2789\tLR: 0.000337\nTraining Epoch: 21 [22784/50000]\tLoss: 0.3128\tLR: 0.000337\nTraining Epoch: 21 [22912/50000]\tLoss: 0.2067\tLR: 0.000337\nTraining Epoch: 21 [23040/50000]\tLoss: 0.2326\tLR: 0.000337\nTraining Epoch: 21 [23168/50000]\tLoss: 0.3539\tLR: 0.000337\nTraining Epoch: 21 [23296/50000]\tLoss: 0.2842\tLR: 0.000337\nTraining Epoch: 21 [23424/50000]\tLoss: 0.2542\tLR: 0.000337\nTraining Epoch: 21 [23552/50000]\tLoss: 0.3164\tLR: 0.000337\nTraining Epoch: 21 [23680/50000]\tLoss: 0.2230\tLR: 0.000337\nTraining Epoch: 21 [23808/50000]\tLoss: 0.2111\tLR: 0.000337\nTraining Epoch: 21 [23936/50000]\tLoss: 0.2405\tLR: 0.000337\nTraining Epoch: 21 [24064/50000]\tLoss: 0.2224\tLR: 0.000337\nTraining Epoch: 21 [24192/50000]\tLoss: 0.2008\tLR: 0.000337\nTraining Epoch: 21 [24320/50000]\tLoss: 0.1733\tLR: 0.000337\nTraining Epoch: 21 [24448/50000]\tLoss: 0.2072\tLR: 0.000337\nTraining Epoch: 21 [24576/50000]\tLoss: 0.1752\tLR: 0.000337\nTraining Epoch: 21 [24704/50000]\tLoss: 0.2871\tLR: 0.000337\nTraining Epoch: 21 [24832/50000]\tLoss: 0.2898\tLR: 0.000337\nTraining Epoch: 21 [24960/50000]\tLoss: 0.2570\tLR: 0.000337\nTraining Epoch: 21 [25088/50000]\tLoss: 0.2307\tLR: 0.000337\nTraining Epoch: 21 [25216/50000]\tLoss: 0.2124\tLR: 0.000337\nTraining Epoch: 21 [25344/50000]\tLoss: 0.2329\tLR: 0.000337\nTraining Epoch: 21 [25472/50000]\tLoss: 0.1875\tLR: 0.000337\nTraining Epoch: 21 [25600/50000]\tLoss: 0.3809\tLR: 0.000337\nTraining Epoch: 21 [25728/50000]\tLoss: 0.2287\tLR: 0.000337\nTraining Epoch: 21 [25856/50000]\tLoss: 0.2389\tLR: 0.000337\nTraining Epoch: 21 [25984/50000]\tLoss: 0.1716\tLR: 0.000337\nTraining Epoch: 21 [26112/50000]\tLoss: 0.2383\tLR: 0.000337\nTraining Epoch: 21 [26240/50000]\tLoss: 0.3670\tLR: 0.000337\nTraining Epoch: 21 [26368/50000]\tLoss: 0.2427\tLR: 0.000337\nTraining Epoch: 21 [26496/50000]\tLoss: 0.2574\tLR: 0.000337\nTraining Epoch: 21 [26624/50000]\tLoss: 0.2390\tLR: 0.000337\nTraining Epoch: 21 [26752/50000]\tLoss: 0.1812\tLR: 0.000337\nTraining Epoch: 21 [26880/50000]\tLoss: 0.3165\tLR: 0.000337\nTraining Epoch: 21 [27008/50000]\tLoss: 0.1809\tLR: 0.000337\nTraining Epoch: 21 [27136/50000]\tLoss: 0.2122\tLR: 0.000337\nTraining Epoch: 21 [27264/50000]\tLoss: 0.2078\tLR: 0.000337\nTraining Epoch: 21 [27392/50000]\tLoss: 0.2397\tLR: 0.000337\nTraining Epoch: 21 [27520/50000]\tLoss: 0.2035\tLR: 0.000337\nTraining Epoch: 21 [27648/50000]\tLoss: 0.2745\tLR: 0.000337\nTraining Epoch: 21 [27776/50000]\tLoss: 0.2495\tLR: 0.000337\nTraining Epoch: 21 [27904/50000]\tLoss: 0.3253\tLR: 0.000337\nTraining Epoch: 21 [28032/50000]\tLoss: 0.2116\tLR: 0.000337\nTraining Epoch: 21 [28160/50000]\tLoss: 0.2217\tLR: 0.000337\nTraining Epoch: 21 [28288/50000]\tLoss: 0.2835\tLR: 0.000337\nTraining Epoch: 21 [28416/50000]\tLoss: 0.2192\tLR: 0.000337\nTraining Epoch: 21 [28544/50000]\tLoss: 0.1480\tLR: 0.000337\nTraining Epoch: 21 [28672/50000]\tLoss: 0.2813\tLR: 0.000337\nTraining Epoch: 21 [28800/50000]\tLoss: 0.1459\tLR: 0.000337\nTraining Epoch: 21 [28928/50000]\tLoss: 0.2320\tLR: 0.000337\nTraining Epoch: 21 [29056/50000]\tLoss: 0.2962\tLR: 0.000337\nTraining Epoch: 21 [29184/50000]\tLoss: 0.2513\tLR: 0.000337\nTraining Epoch: 21 [29312/50000]\tLoss: 0.1949\tLR: 0.000337\nTraining Epoch: 21 [29440/50000]\tLoss: 0.2707\tLR: 0.000337\nTraining Epoch: 21 [29568/50000]\tLoss: 0.2071\tLR: 0.000337\nTraining Epoch: 21 [29696/50000]\tLoss: 0.2324\tLR: 0.000337\nTraining Epoch: 21 [29824/50000]\tLoss: 0.2217\tLR: 0.000337\nTraining Epoch: 21 [29952/50000]\tLoss: 0.3252\tLR: 0.000337\nTraining Epoch: 21 [30080/50000]\tLoss: 0.2862\tLR: 0.000337\nTraining Epoch: 21 [30208/50000]\tLoss: 0.3014\tLR: 0.000337\nTraining Epoch: 21 [30336/50000]\tLoss: 0.2303\tLR: 0.000337\nTraining Epoch: 21 [30464/50000]\tLoss: 0.4002\tLR: 0.000337\nTraining Epoch: 21 [30592/50000]\tLoss: 0.2088\tLR: 0.000337\nTraining Epoch: 21 [30720/50000]\tLoss: 0.2581\tLR: 0.000337\nTraining Epoch: 21 [30848/50000]\tLoss: 0.3041\tLR: 0.000337\nTraining Epoch: 21 [30976/50000]\tLoss: 0.1818\tLR: 0.000337\nTraining Epoch: 21 [31104/50000]\tLoss: 0.1935\tLR: 0.000337\nTraining Epoch: 21 [31232/50000]\tLoss: 0.2151\tLR: 0.000337\nTraining Epoch: 21 [31360/50000]\tLoss: 0.1978\tLR: 0.000337\nTraining Epoch: 21 [31488/50000]\tLoss: 0.2891\tLR: 0.000337\nTraining Epoch: 21 [31616/50000]\tLoss: 0.2154\tLR: 0.000337\nTraining Epoch: 21 [31744/50000]\tLoss: 0.2607\tLR: 0.000337\nTraining Epoch: 21 [31872/50000]\tLoss: 0.2930\tLR: 0.000337\nTraining Epoch: 21 [32000/50000]\tLoss: 0.2148\tLR: 0.000337\nTraining Epoch: 21 [32128/50000]\tLoss: 0.2439\tLR: 0.000337\nTraining Epoch: 21 [32256/50000]\tLoss: 0.2987\tLR: 0.000337\nTraining Epoch: 21 [32384/50000]\tLoss: 0.1541\tLR: 0.000337\nTraining Epoch: 21 [32512/50000]\tLoss: 0.2627\tLR: 0.000337\nTraining Epoch: 21 [32640/50000]\tLoss: 0.3052\tLR: 0.000337\nTraining Epoch: 21 [32768/50000]\tLoss: 0.3545\tLR: 0.000337\nTraining Epoch: 21 [32896/50000]\tLoss: 0.2938\tLR: 0.000337\nTraining Epoch: 21 [33024/50000]\tLoss: 0.3442\tLR: 0.000337\nTraining Epoch: 21 [33152/50000]\tLoss: 0.2850\tLR: 0.000337\nTraining Epoch: 21 [33280/50000]\tLoss: 0.3096\tLR: 0.000337\nTraining Epoch: 21 [33408/50000]\tLoss: 0.2515\tLR: 0.000337\nTraining Epoch: 21 [33536/50000]\tLoss: 0.1821\tLR: 0.000337\nTraining Epoch: 21 [33664/50000]\tLoss: 0.1892\tLR: 0.000337\nTraining Epoch: 21 [33792/50000]\tLoss: 0.1577\tLR: 0.000337\nTraining Epoch: 21 [33920/50000]\tLoss: 0.2541\tLR: 0.000337\nTraining Epoch: 21 [34048/50000]\tLoss: 0.2626\tLR: 0.000337\nTraining Epoch: 21 [34176/50000]\tLoss: 0.2822\tLR: 0.000337\nTraining Epoch: 21 [34304/50000]\tLoss: 0.2724\tLR: 0.000337\nTraining Epoch: 21 [34432/50000]\tLoss: 0.2346\tLR: 0.000337\nTraining Epoch: 21 [34560/50000]\tLoss: 0.1840\tLR: 0.000337\nTraining Epoch: 21 [34688/50000]\tLoss: 0.2409\tLR: 0.000337\nTraining Epoch: 21 [34816/50000]\tLoss: 0.2043\tLR: 0.000337\nTraining Epoch: 21 [34944/50000]\tLoss: 0.2030\tLR: 0.000337\nTraining Epoch: 21 [35072/50000]\tLoss: 0.2953\tLR: 0.000337\nTraining Epoch: 21 [35200/50000]\tLoss: 0.2911\tLR: 0.000337\nTraining Epoch: 21 [35328/50000]\tLoss: 0.2377\tLR: 0.000337\nTraining Epoch: 21 [35456/50000]\tLoss: 0.2962\tLR: 0.000337\nTraining Epoch: 21 [35584/50000]\tLoss: 0.3572\tLR: 0.000337\nTraining Epoch: 21 [35712/50000]\tLoss: 0.2149\tLR: 0.000337\nTraining Epoch: 21 [35840/50000]\tLoss: 0.2829\tLR: 0.000337\nTraining Epoch: 21 [35968/50000]\tLoss: 0.2240\tLR: 0.000337\nTraining Epoch: 21 [36096/50000]\tLoss: 0.1592\tLR: 0.000337\nTraining Epoch: 21 [36224/50000]\tLoss: 0.2578\tLR: 0.000337\nTraining Epoch: 21 [36352/50000]\tLoss: 0.2741\tLR: 0.000337\nTraining Epoch: 21 [36480/50000]\tLoss: 0.3503\tLR: 0.000337\nTraining Epoch: 21 [36608/50000]\tLoss: 0.3429\tLR: 0.000337\nTraining Epoch: 21 [36736/50000]\tLoss: 0.3476\tLR: 0.000337\nTraining Epoch: 21 [36864/50000]\tLoss: 0.2418\tLR: 0.000337\nTraining Epoch: 21 [36992/50000]\tLoss: 0.2770\tLR: 0.000337\nTraining Epoch: 21 [37120/50000]\tLoss: 0.3265\tLR: 0.000337\nTraining Epoch: 21 [37248/50000]\tLoss: 0.1718\tLR: 0.000337\nTraining Epoch: 21 [37376/50000]\tLoss: 0.1672\tLR: 0.000337\nTraining Epoch: 21 [37504/50000]\tLoss: 0.3281\tLR: 0.000337\nTraining Epoch: 21 [37632/50000]\tLoss: 0.4271\tLR: 0.000337\nTraining Epoch: 21 [37760/50000]\tLoss: 0.1570\tLR: 0.000337\nTraining Epoch: 21 [37888/50000]\tLoss: 0.1750\tLR: 0.000337\nTraining Epoch: 21 [38016/50000]\tLoss: 0.3455\tLR: 0.000337\nTraining Epoch: 21 [38144/50000]\tLoss: 0.3346\tLR: 0.000337\nTraining Epoch: 21 [38272/50000]\tLoss: 0.2401\tLR: 0.000337\nTraining Epoch: 21 [38400/50000]\tLoss: 0.2101\tLR: 0.000337\nTraining Epoch: 21 [38528/50000]\tLoss: 0.2643\tLR: 0.000337\nTraining Epoch: 21 [38656/50000]\tLoss: 0.3225\tLR: 0.000337\nTraining Epoch: 21 [38784/50000]\tLoss: 0.1398\tLR: 0.000337\nTraining Epoch: 21 [38912/50000]\tLoss: 0.2700\tLR: 0.000337\nTraining Epoch: 21 [39040/50000]\tLoss: 0.1656\tLR: 0.000337\nTraining Epoch: 21 [39168/50000]\tLoss: 0.1871\tLR: 0.000337\nTraining Epoch: 21 [39296/50000]\tLoss: 0.2995\tLR: 0.000337\nTraining Epoch: 21 [39424/50000]\tLoss: 0.3933\tLR: 0.000337\nTraining Epoch: 21 [39552/50000]\tLoss: 0.1935\tLR: 0.000337\nTraining Epoch: 21 [39680/50000]\tLoss: 0.2291\tLR: 0.000337\nTraining Epoch: 21 [39808/50000]\tLoss: 0.2286\tLR: 0.000337\nTraining Epoch: 21 [39936/50000]\tLoss: 0.1805\tLR: 0.000337\nTraining Epoch: 21 [40064/50000]\tLoss: 0.2533\tLR: 0.000337\nTraining Epoch: 21 [40192/50000]\tLoss: 0.3506\tLR: 0.000337\nTraining Epoch: 21 [40320/50000]\tLoss: 0.2830\tLR: 0.000337\nTraining Epoch: 21 [40448/50000]\tLoss: 0.2134\tLR: 0.000337\nTraining Epoch: 21 [40576/50000]\tLoss: 0.3084\tLR: 0.000337\nTraining Epoch: 21 [40704/50000]\tLoss: 0.2336\tLR: 0.000337\nTraining Epoch: 21 [40832/50000]\tLoss: 0.1735\tLR: 0.000337\nTraining Epoch: 21 [40960/50000]\tLoss: 0.3236\tLR: 0.000337\nTraining Epoch: 21 [41088/50000]\tLoss: 0.1944\tLR: 0.000337\nTraining Epoch: 21 [41216/50000]\tLoss: 0.2607\tLR: 0.000337\nTraining Epoch: 21 [41344/50000]\tLoss: 0.2767\tLR: 0.000337\nTraining Epoch: 21 [41472/50000]\tLoss: 0.3107\tLR: 0.000337\nTraining Epoch: 21 [41600/50000]\tLoss: 0.2946\tLR: 0.000337\nTraining Epoch: 21 [41728/50000]\tLoss: 0.2237\tLR: 0.000337\nTraining Epoch: 21 [41856/50000]\tLoss: 0.3554\tLR: 0.000337\nTraining Epoch: 21 [41984/50000]\tLoss: 0.2094\tLR: 0.000337\nTraining Epoch: 21 [42112/50000]\tLoss: 0.2661\tLR: 0.000337\nTraining Epoch: 21 [42240/50000]\tLoss: 0.1493\tLR: 0.000337\nTraining Epoch: 21 [42368/50000]\tLoss: 0.2468\tLR: 0.000337\nTraining Epoch: 21 [42496/50000]\tLoss: 0.2721\tLR: 0.000337\nTraining Epoch: 21 [42624/50000]\tLoss: 0.2452\tLR: 0.000337\nTraining Epoch: 21 [42752/50000]\tLoss: 0.2449\tLR: 0.000337\nTraining Epoch: 21 [42880/50000]\tLoss: 0.1756\tLR: 0.000337\nTraining Epoch: 21 [43008/50000]\tLoss: 0.2265\tLR: 0.000337\nTraining Epoch: 21 [43136/50000]\tLoss: 0.2032\tLR: 0.000337\nTraining Epoch: 21 [43264/50000]\tLoss: 0.3024\tLR: 0.000337\nTraining Epoch: 21 [43392/50000]\tLoss: 0.2551\tLR: 0.000337\nTraining Epoch: 21 [43520/50000]\tLoss: 0.2435\tLR: 0.000337\nTraining Epoch: 21 [43648/50000]\tLoss: 0.3245\tLR: 0.000337\nTraining Epoch: 21 [43776/50000]\tLoss: 0.2802\tLR: 0.000337\nTraining Epoch: 21 [43904/50000]\tLoss: 0.1829\tLR: 0.000337\nTraining Epoch: 21 [44032/50000]\tLoss: 0.2707\tLR: 0.000337\nTraining Epoch: 21 [44160/50000]\tLoss: 0.3110\tLR: 0.000337\nTraining Epoch: 21 [44288/50000]\tLoss: 0.3042\tLR: 0.000337\nTraining Epoch: 21 [44416/50000]\tLoss: 0.2231\tLR: 0.000337\nTraining Epoch: 21 [44544/50000]\tLoss: 0.1255\tLR: 0.000337\nTraining Epoch: 21 [44672/50000]\tLoss: 0.2405\tLR: 0.000337\nTraining Epoch: 21 [44800/50000]\tLoss: 0.2566\tLR: 0.000337\nTraining Epoch: 21 [44928/50000]\tLoss: 0.2803\tLR: 0.000337\nTraining Epoch: 21 [45056/50000]\tLoss: 0.2283\tLR: 0.000337\nTraining Epoch: 21 [45184/50000]\tLoss: 0.2207\tLR: 0.000337\nTraining Epoch: 21 [45312/50000]\tLoss: 0.1784\tLR: 0.000337\nTraining Epoch: 21 [45440/50000]\tLoss: 0.2382\tLR: 0.000337\nTraining Epoch: 21 [45568/50000]\tLoss: 0.2801\tLR: 0.000337\nTraining Epoch: 21 [45696/50000]\tLoss: 0.2292\tLR: 0.000337\nTraining Epoch: 21 [45824/50000]\tLoss: 0.2671\tLR: 0.000337\nTraining Epoch: 21 [45952/50000]\tLoss: 0.1953\tLR: 0.000337\nTraining Epoch: 21 [46080/50000]\tLoss: 0.2442\tLR: 0.000337\nTraining Epoch: 21 [46208/50000]\tLoss: 0.2223\tLR: 0.000337\nTraining Epoch: 21 [46336/50000]\tLoss: 0.2232\tLR: 0.000337\nTraining Epoch: 21 [46464/50000]\tLoss: 0.2487\tLR: 0.000337\nTraining Epoch: 21 [46592/50000]\tLoss: 0.2245\tLR: 0.000337\nTraining Epoch: 21 [46720/50000]\tLoss: 0.2919\tLR: 0.000337\nTraining Epoch: 21 [46848/50000]\tLoss: 0.1875\tLR: 0.000337\nTraining Epoch: 21 [46976/50000]\tLoss: 0.2683\tLR: 0.000337\nTraining Epoch: 21 [47104/50000]\tLoss: 0.2567\tLR: 0.000337\nTraining Epoch: 21 [47232/50000]\tLoss: 0.2743\tLR: 0.000337\nTraining Epoch: 21 [47360/50000]\tLoss: 0.2890\tLR: 0.000337\nTraining Epoch: 21 [47488/50000]\tLoss: 0.1743\tLR: 0.000337\nTraining Epoch: 21 [47616/50000]\tLoss: 0.3004\tLR: 0.000337\nTraining Epoch: 21 [47744/50000]\tLoss: 0.2613\tLR: 0.000337\nTraining Epoch: 21 [47872/50000]\tLoss: 0.3330\tLR: 0.000337\nTraining Epoch: 21 [48000/50000]\tLoss: 0.1671\tLR: 0.000337\nTraining Epoch: 21 [48128/50000]\tLoss: 0.2528\tLR: 0.000337\nTraining Epoch: 21 [48256/50000]\tLoss: 0.2618\tLR: 0.000337\nTraining Epoch: 21 [48384/50000]\tLoss: 0.2178\tLR: 0.000337\nTraining Epoch: 21 [48512/50000]\tLoss: 0.1853\tLR: 0.000337\nTraining Epoch: 21 [48640/50000]\tLoss: 0.1842\tLR: 0.000337\nTraining Epoch: 21 [48768/50000]\tLoss: 0.1814\tLR: 0.000337\nTraining Epoch: 21 [48896/50000]\tLoss: 0.2445\tLR: 0.000337\nTraining Epoch: 21 [49024/50000]\tLoss: 0.2401\tLR: 0.000337\nTraining Epoch: 21 [49152/50000]\tLoss: 0.3605\tLR: 0.000337\nTraining Epoch: 21 [49280/50000]\tLoss: 0.2089\tLR: 0.000337\nTraining Epoch: 21 [49408/50000]\tLoss: 0.2101\tLR: 0.000337\nTraining Epoch: 21 [49536/50000]\tLoss: 0.2501\tLR: 0.000337\nTraining Epoch: 21 [49664/50000]\tLoss: 0.2319\tLR: 0.000337\nTraining Epoch: 21 [49792/50000]\tLoss: 0.1784\tLR: 0.000337\nTraining Epoch: 21 [49920/50000]\tLoss: 0.2636\tLR: 0.000337\nTraining Epoch: 21 [50000/50000]\tLoss: 0.2860\tLR: 0.000337\nTest set: Average loss: 0.0024, Accuracy: 0.8974\n\nTraining Epoch: 22 [128/50000]\tLoss: 0.2722\tLR: 0.000337\nTraining Epoch: 22 [256/50000]\tLoss: 0.2125\tLR: 0.000337\nTraining Epoch: 22 [384/50000]\tLoss: 0.2435\tLR: 0.000337\nTraining Epoch: 22 [512/50000]\tLoss: 0.1213\tLR: 0.000337\nTraining Epoch: 22 [640/50000]\tLoss: 0.2028\tLR: 0.000337\nTraining Epoch: 22 [768/50000]\tLoss: 0.2641\tLR: 0.000337\nTraining Epoch: 22 [896/50000]\tLoss: 0.2407\tLR: 0.000337\nTraining Epoch: 22 [1024/50000]\tLoss: 0.1955\tLR: 0.000337\nTraining Epoch: 22 [1152/50000]\tLoss: 0.1621\tLR: 0.000337\nTraining Epoch: 22 [1280/50000]\tLoss: 0.2930\tLR: 0.000337\nTraining Epoch: 22 [1408/50000]\tLoss: 0.2867\tLR: 0.000337\nTraining Epoch: 22 [1536/50000]\tLoss: 0.3147\tLR: 0.000337\nTraining Epoch: 22 [1664/50000]\tLoss: 0.3257\tLR: 0.000337\nTraining Epoch: 22 [1792/50000]\tLoss: 0.2767\tLR: 0.000337\nTraining Epoch: 22 [1920/50000]\tLoss: 0.3151\tLR: 0.000337\nTraining Epoch: 22 [2048/50000]\tLoss: 0.1632\tLR: 0.000337\nTraining Epoch: 22 [2176/50000]\tLoss: 0.2922\tLR: 0.000337\nTraining Epoch: 22 [2304/50000]\tLoss: 0.2820\tLR: 0.000337\nTraining Epoch: 22 [2432/50000]\tLoss: 0.2080\tLR: 0.000337\nTraining Epoch: 22 [2560/50000]\tLoss: 0.2113\tLR: 0.000337\nTraining Epoch: 22 [2688/50000]\tLoss: 0.2066\tLR: 0.000337\nTraining Epoch: 22 [2816/50000]\tLoss: 0.1978\tLR: 0.000337\nTraining Epoch: 22 [2944/50000]\tLoss: 0.2696\tLR: 0.000337\nTraining Epoch: 22 [3072/50000]\tLoss: 0.2053\tLR: 0.000337\nTraining Epoch: 22 [3200/50000]\tLoss: 0.2276\tLR: 0.000337\nTraining Epoch: 22 [3328/50000]\tLoss: 0.1521\tLR: 0.000337\nTraining Epoch: 22 [3456/50000]\tLoss: 0.2126\tLR: 0.000337\nTraining Epoch: 22 [3584/50000]\tLoss: 0.2534\tLR: 0.000337\nTraining Epoch: 22 [3712/50000]\tLoss: 0.3232\tLR: 0.000337\nTraining Epoch: 22 [3840/50000]\tLoss: 0.2791\tLR: 0.000337\nTraining Epoch: 22 [3968/50000]\tLoss: 0.2344\tLR: 0.000337\nTraining Epoch: 22 [4096/50000]\tLoss: 0.2486\tLR: 0.000337\nTraining Epoch: 22 [4224/50000]\tLoss: 0.2184\tLR: 0.000337\nTraining Epoch: 22 [4352/50000]\tLoss: 0.3156\tLR: 0.000337\nTraining Epoch: 22 [4480/50000]\tLoss: 0.2977\tLR: 0.000337\nTraining Epoch: 22 [4608/50000]\tLoss: 0.2273\tLR: 0.000337\nTraining Epoch: 22 [4736/50000]\tLoss: 0.2619\tLR: 0.000337\nTraining Epoch: 22 [4864/50000]\tLoss: 0.3539\tLR: 0.000337\nTraining Epoch: 22 [4992/50000]\tLoss: 0.4069\tLR: 0.000337\nTraining Epoch: 22 [5120/50000]\tLoss: 0.2120\tLR: 0.000337\nTraining Epoch: 22 [5248/50000]\tLoss: 0.3541\tLR: 0.000337\nTraining Epoch: 22 [5376/50000]\tLoss: 0.2243\tLR: 0.000337\nTraining Epoch: 22 [5504/50000]\tLoss: 0.2988\tLR: 0.000337\nTraining Epoch: 22 [5632/50000]\tLoss: 0.1729\tLR: 0.000337\nTraining Epoch: 22 [5760/50000]\tLoss: 0.2116\tLR: 0.000337\nTraining Epoch: 22 [5888/50000]\tLoss: 0.2637\tLR: 0.000337\nTraining Epoch: 22 [6016/50000]\tLoss: 0.1464\tLR: 0.000337\nTraining Epoch: 22 [6144/50000]\tLoss: 0.2594\tLR: 0.000337\nTraining Epoch: 22 [6272/50000]\tLoss: 0.2208\tLR: 0.000337\nTraining Epoch: 22 [6400/50000]\tLoss: 0.3649\tLR: 0.000337\nTraining Epoch: 22 [6528/50000]\tLoss: 0.2603\tLR: 0.000337\nTraining Epoch: 22 [6656/50000]\tLoss: 0.2562\tLR: 0.000337\nTraining Epoch: 22 [6784/50000]\tLoss: 0.2111\tLR: 0.000337\nTraining Epoch: 22 [6912/50000]\tLoss: 0.3014\tLR: 0.000337\nTraining Epoch: 22 [7040/50000]\tLoss: 0.1820\tLR: 0.000337\nTraining Epoch: 22 [7168/50000]\tLoss: 0.1752\tLR: 0.000337\nTraining Epoch: 22 [7296/50000]\tLoss: 0.2493\tLR: 0.000337\nTraining Epoch: 22 [7424/50000]\tLoss: 0.2895\tLR: 0.000337\nTraining Epoch: 22 [7552/50000]\tLoss: 0.2828\tLR: 0.000337\nTraining Epoch: 22 [7680/50000]\tLoss: 0.3215\tLR: 0.000337\nTraining Epoch: 22 [7808/50000]\tLoss: 0.3268\tLR: 0.000337\nTraining Epoch: 22 [7936/50000]\tLoss: 0.2238\tLR: 0.000337\nTraining Epoch: 22 [8064/50000]\tLoss: 0.2111\tLR: 0.000337\nTraining Epoch: 22 [8192/50000]\tLoss: 0.2067\tLR: 0.000337\nTraining Epoch: 22 [8320/50000]\tLoss: 0.3051\tLR: 0.000337\nTraining Epoch: 22 [8448/50000]\tLoss: 0.2108\tLR: 0.000337\nTraining Epoch: 22 [8576/50000]\tLoss: 0.4740\tLR: 0.000337\nTraining Epoch: 22 [8704/50000]\tLoss: 0.2125\tLR: 0.000337\nTraining Epoch: 22 [8832/50000]\tLoss: 0.3318\tLR: 0.000337\nTraining Epoch: 22 [8960/50000]\tLoss: 0.2741\tLR: 0.000337\nTraining Epoch: 22 [9088/50000]\tLoss: 0.3039\tLR: 0.000337\nTraining Epoch: 22 [9216/50000]\tLoss: 0.2228\tLR: 0.000337\nTraining Epoch: 22 [9344/50000]\tLoss: 0.1916\tLR: 0.000337\nTraining Epoch: 22 [9472/50000]\tLoss: 0.3075\tLR: 0.000337\nTraining Epoch: 22 [9600/50000]\tLoss: 0.2723\tLR: 0.000337\nTraining Epoch: 22 [9728/50000]\tLoss: 0.1933\tLR: 0.000337\nTraining Epoch: 22 [9856/50000]\tLoss: 0.2236\tLR: 0.000337\nTraining Epoch: 22 [9984/50000]\tLoss: 0.1917\tLR: 0.000337\nTraining Epoch: 22 [10112/50000]\tLoss: 0.2196\tLR: 0.000337\nTraining Epoch: 22 [10240/50000]\tLoss: 0.1952\tLR: 0.000337\nTraining Epoch: 22 [10368/50000]\tLoss: 0.1738\tLR: 0.000337\nTraining Epoch: 22 [10496/50000]\tLoss: 0.2657\tLR: 0.000337\nTraining Epoch: 22 [10624/50000]\tLoss: 0.2112\tLR: 0.000337\nTraining Epoch: 22 [10752/50000]\tLoss: 0.2601\tLR: 0.000337\nTraining Epoch: 22 [10880/50000]\tLoss: 0.2007\tLR: 0.000337\nTraining Epoch: 22 [11008/50000]\tLoss: 0.1472\tLR: 0.000337\nTraining Epoch: 22 [11136/50000]\tLoss: 0.2845\tLR: 0.000337\nTraining Epoch: 22 [11264/50000]\tLoss: 0.3070\tLR: 0.000337\nTraining Epoch: 22 [11392/50000]\tLoss: 0.3941\tLR: 0.000337\nTraining Epoch: 22 [11520/50000]\tLoss: 0.2209\tLR: 0.000337\nTraining Epoch: 22 [11648/50000]\tLoss: 0.3153\tLR: 0.000337\nTraining Epoch: 22 [11776/50000]\tLoss: 0.2880\tLR: 0.000337\nTraining Epoch: 22 [11904/50000]\tLoss: 0.3298\tLR: 0.000337\nTraining Epoch: 22 [12032/50000]\tLoss: 0.2054\tLR: 0.000337\nTraining Epoch: 22 [12160/50000]\tLoss: 0.3677\tLR: 0.000337\nTraining Epoch: 22 [12288/50000]\tLoss: 0.2505\tLR: 0.000337\nTraining Epoch: 22 [12416/50000]\tLoss: 0.2965\tLR: 0.000337\nTraining Epoch: 22 [12544/50000]\tLoss: 0.2985\tLR: 0.000337\nTraining Epoch: 22 [12672/50000]\tLoss: 0.2089\tLR: 0.000337\nTraining Epoch: 22 [12800/50000]\tLoss: 0.2537\tLR: 0.000337\nTraining Epoch: 22 [12928/50000]\tLoss: 0.2963\tLR: 0.000337\nTraining Epoch: 22 [13056/50000]\tLoss: 0.1735\tLR: 0.000337\nTraining Epoch: 22 [13184/50000]\tLoss: 0.2533\tLR: 0.000337\nTraining Epoch: 22 [13312/50000]\tLoss: 0.2149\tLR: 0.000337\nTraining Epoch: 22 [13440/50000]\tLoss: 0.2403\tLR: 0.000337\nTraining Epoch: 22 [13568/50000]\tLoss: 0.1975\tLR: 0.000337\nTraining Epoch: 22 [13696/50000]\tLoss: 0.2489\tLR: 0.000337\nTraining Epoch: 22 [13824/50000]\tLoss: 0.2824\tLR: 0.000337\nTraining Epoch: 22 [13952/50000]\tLoss: 0.2509\tLR: 0.000337\nTraining Epoch: 22 [14080/50000]\tLoss: 0.1871\tLR: 0.000337\nTraining Epoch: 22 [14208/50000]\tLoss: 0.2097\tLR: 0.000337\nTraining Epoch: 22 [14336/50000]\tLoss: 0.1864\tLR: 0.000337\nTraining Epoch: 22 [14464/50000]\tLoss: 0.3090\tLR: 0.000337\nTraining Epoch: 22 [14592/50000]\tLoss: 0.2510\tLR: 0.000337\nTraining Epoch: 22 [14720/50000]\tLoss: 0.1748\tLR: 0.000337\nTraining Epoch: 22 [14848/50000]\tLoss: 0.2770\tLR: 0.000337\nTraining Epoch: 22 [14976/50000]\tLoss: 0.1707\tLR: 0.000337\nTraining Epoch: 22 [15104/50000]\tLoss: 0.1860\tLR: 0.000337\nTraining Epoch: 22 [15232/50000]\tLoss: 0.2508\tLR: 0.000337\nTraining Epoch: 22 [15360/50000]\tLoss: 0.2416\tLR: 0.000337\nTraining Epoch: 22 [15488/50000]\tLoss: 0.2581\tLR: 0.000337\nTraining Epoch: 22 [15616/50000]\tLoss: 0.2424\tLR: 0.000337\nTraining Epoch: 22 [15744/50000]\tLoss: 0.3334\tLR: 0.000337\nTraining Epoch: 22 [15872/50000]\tLoss: 0.2867\tLR: 0.000337\nTraining Epoch: 22 [16000/50000]\tLoss: 0.2312\tLR: 0.000337\nTraining Epoch: 22 [16128/50000]\tLoss: 0.1752\tLR: 0.000337\nTraining Epoch: 22 [16256/50000]\tLoss: 0.1672\tLR: 0.000337\nTraining Epoch: 22 [16384/50000]\tLoss: 0.2912\tLR: 0.000337\nTraining Epoch: 22 [16512/50000]\tLoss: 0.3679\tLR: 0.000337\nTraining Epoch: 22 [16640/50000]\tLoss: 0.2207\tLR: 0.000337\nTraining Epoch: 22 [16768/50000]\tLoss: 0.1977\tLR: 0.000337\nTraining Epoch: 22 [16896/50000]\tLoss: 0.2462\tLR: 0.000337\nTraining Epoch: 22 [17024/50000]\tLoss: 0.3978\tLR: 0.000337\nTraining Epoch: 22 [17152/50000]\tLoss: 0.1963\tLR: 0.000337\nTraining Epoch: 22 [17280/50000]\tLoss: 0.2353\tLR: 0.000337\nTraining Epoch: 22 [17408/50000]\tLoss: 0.2641\tLR: 0.000337\nTraining Epoch: 22 [17536/50000]\tLoss: 0.1728\tLR: 0.000337\nTraining Epoch: 22 [17664/50000]\tLoss: 0.3065\tLR: 0.000337\nTraining Epoch: 22 [17792/50000]\tLoss: 0.1835\tLR: 0.000337\nTraining Epoch: 22 [17920/50000]\tLoss: 0.2527\tLR: 0.000337\nTraining Epoch: 22 [18048/50000]\tLoss: 0.2052\tLR: 0.000337\nTraining Epoch: 22 [18176/50000]\tLoss: 0.2049\tLR: 0.000337\nTraining Epoch: 22 [18304/50000]\tLoss: 0.1288\tLR: 0.000337\nTraining Epoch: 22 [18432/50000]\tLoss: 0.2057\tLR: 0.000337\nTraining Epoch: 22 [18560/50000]\tLoss: 0.2156\tLR: 0.000337\nTraining Epoch: 22 [18688/50000]\tLoss: 0.3034\tLR: 0.000337\nTraining Epoch: 22 [18816/50000]\tLoss: 0.2245\tLR: 0.000337\nTraining Epoch: 22 [18944/50000]\tLoss: 0.1399\tLR: 0.000337\nTraining Epoch: 22 [19072/50000]\tLoss: 0.3659\tLR: 0.000337\nTraining Epoch: 22 [19200/50000]\tLoss: 0.1666\tLR: 0.000337\nTraining Epoch: 22 [19328/50000]\tLoss: 0.2108\tLR: 0.000337\nTraining Epoch: 22 [19456/50000]\tLoss: 0.1898\tLR: 0.000337\nTraining Epoch: 22 [19584/50000]\tLoss: 0.1856\tLR: 0.000337\nTraining Epoch: 22 [19712/50000]\tLoss: 0.2718\tLR: 0.000337\nTraining Epoch: 22 [19840/50000]\tLoss: 0.2818\tLR: 0.000337\nTraining Epoch: 22 [19968/50000]\tLoss: 0.2822\tLR: 0.000337\nTraining Epoch: 22 [20096/50000]\tLoss: 0.2214\tLR: 0.000337\nTraining Epoch: 22 [20224/50000]\tLoss: 0.2199\tLR: 0.000337\nTraining Epoch: 22 [20352/50000]\tLoss: 0.2224\tLR: 0.000337\nTraining Epoch: 22 [20480/50000]\tLoss: 0.1760\tLR: 0.000337\nTraining Epoch: 22 [20608/50000]\tLoss: 0.2522\tLR: 0.000337\nTraining Epoch: 22 [20736/50000]\tLoss: 0.1640\tLR: 0.000337\nTraining Epoch: 22 [20864/50000]\tLoss: 0.2433\tLR: 0.000337\nTraining Epoch: 22 [20992/50000]\tLoss: 0.1991\tLR: 0.000337\nTraining Epoch: 22 [21120/50000]\tLoss: 0.2570\tLR: 0.000337\nTraining Epoch: 22 [21248/50000]\tLoss: 0.3545\tLR: 0.000337\nTraining Epoch: 22 [21376/50000]\tLoss: 0.2229\tLR: 0.000337\nTraining Epoch: 22 [21504/50000]\tLoss: 0.1934\tLR: 0.000337\nTraining Epoch: 22 [21632/50000]\tLoss: 0.2226\tLR: 0.000337\nTraining Epoch: 22 [21760/50000]\tLoss: 0.2759\tLR: 0.000337\nTraining Epoch: 22 [21888/50000]\tLoss: 0.2020\tLR: 0.000337\nTraining Epoch: 22 [22016/50000]\tLoss: 0.2603\tLR: 0.000337\nTraining Epoch: 22 [22144/50000]\tLoss: 0.1753\tLR: 0.000337\nTraining Epoch: 22 [22272/50000]\tLoss: 0.1813\tLR: 0.000337\nTraining Epoch: 22 [22400/50000]\tLoss: 0.3691\tLR: 0.000337\nTraining Epoch: 22 [22528/50000]\tLoss: 0.2807\tLR: 0.000337\nTraining Epoch: 22 [22656/50000]\tLoss: 0.2054\tLR: 0.000337\nTraining Epoch: 22 [22784/50000]\tLoss: 0.3001\tLR: 0.000337\nTraining Epoch: 22 [22912/50000]\tLoss: 0.2284\tLR: 0.000337\nTraining Epoch: 22 [23040/50000]\tLoss: 0.2004\tLR: 0.000337\nTraining Epoch: 22 [23168/50000]\tLoss: 0.2353\tLR: 0.000337\nTraining Epoch: 22 [23296/50000]\tLoss: 0.1772\tLR: 0.000337\nTraining Epoch: 22 [23424/50000]\tLoss: 0.2862\tLR: 0.000337\nTraining Epoch: 22 [23552/50000]\tLoss: 0.1698\tLR: 0.000337\nTraining Epoch: 22 [23680/50000]\tLoss: 0.3353\tLR: 0.000337\nTraining Epoch: 22 [23808/50000]\tLoss: 0.3606\tLR: 0.000337\nTraining Epoch: 22 [23936/50000]\tLoss: 0.3652\tLR: 0.000337\nTraining Epoch: 22 [24064/50000]\tLoss: 0.2371\tLR: 0.000337\nTraining Epoch: 22 [24192/50000]\tLoss: 0.2690\tLR: 0.000337\nTraining Epoch: 22 [24320/50000]\tLoss: 0.3459\tLR: 0.000337\nTraining Epoch: 22 [24448/50000]\tLoss: 0.2488\tLR: 0.000337\nTraining Epoch: 22 [24576/50000]\tLoss: 0.2210\tLR: 0.000337\nTraining Epoch: 22 [24704/50000]\tLoss: 0.2448\tLR: 0.000337\nTraining Epoch: 22 [24832/50000]\tLoss: 0.2004\tLR: 0.000337\nTraining Epoch: 22 [24960/50000]\tLoss: 0.2498\tLR: 0.000337\nTraining Epoch: 22 [25088/50000]\tLoss: 0.1700\tLR: 0.000337\nTraining Epoch: 22 [25216/50000]\tLoss: 0.2460\tLR: 0.000337\nTraining Epoch: 22 [25344/50000]\tLoss: 0.2307\tLR: 0.000337\nTraining Epoch: 22 [25472/50000]\tLoss: 0.2400\tLR: 0.000337\nTraining Epoch: 22 [25600/50000]\tLoss: 0.3264\tLR: 0.000337\nTraining Epoch: 22 [25728/50000]\tLoss: 0.2197\tLR: 0.000337\nTraining Epoch: 22 [25856/50000]\tLoss: 0.2547\tLR: 0.000337\nTraining Epoch: 22 [25984/50000]\tLoss: 0.2370\tLR: 0.000337\nTraining Epoch: 22 [26112/50000]\tLoss: 0.2122\tLR: 0.000337\nTraining Epoch: 22 [26240/50000]\tLoss: 0.3228\tLR: 0.000337\nTraining Epoch: 22 [26368/50000]\tLoss: 0.2108\tLR: 0.000337\nTraining Epoch: 22 [26496/50000]\tLoss: 0.2473\tLR: 0.000337\nTraining Epoch: 22 [26624/50000]\tLoss: 0.3243\tLR: 0.000337\nTraining Epoch: 22 [26752/50000]\tLoss: 0.2987\tLR: 0.000337\nTraining Epoch: 22 [26880/50000]\tLoss: 0.2248\tLR: 0.000337\nTraining Epoch: 22 [27008/50000]\tLoss: 0.2549\tLR: 0.000337\nTraining Epoch: 22 [27136/50000]\tLoss: 0.2972\tLR: 0.000337\nTraining Epoch: 22 [27264/50000]\tLoss: 0.2608\tLR: 0.000337\nTraining Epoch: 22 [27392/50000]\tLoss: 0.2200\tLR: 0.000337\nTraining Epoch: 22 [27520/50000]\tLoss: 0.3340\tLR: 0.000337\nTraining Epoch: 22 [27648/50000]\tLoss: 0.2063\tLR: 0.000337\nTraining Epoch: 22 [27776/50000]\tLoss: 0.1981\tLR: 0.000337\nTraining Epoch: 22 [27904/50000]\tLoss: 0.3171\tLR: 0.000337\nTraining Epoch: 22 [28032/50000]\tLoss: 0.2320\tLR: 0.000337\nTraining Epoch: 22 [28160/50000]\tLoss: 0.1757\tLR: 0.000337\nTraining Epoch: 22 [28288/50000]\tLoss: 0.2225\tLR: 0.000337\nTraining Epoch: 22 [28416/50000]\tLoss: 0.2897\tLR: 0.000337\nTraining Epoch: 22 [28544/50000]\tLoss: 0.2366\tLR: 0.000337\nTraining Epoch: 22 [28672/50000]\tLoss: 0.2809\tLR: 0.000337\nTraining Epoch: 22 [28800/50000]\tLoss: 0.2504\tLR: 0.000337\nTraining Epoch: 22 [28928/50000]\tLoss: 0.3262\tLR: 0.000337\nTraining Epoch: 22 [29056/50000]\tLoss: 0.2799\tLR: 0.000337\nTraining Epoch: 22 [29184/50000]\tLoss: 0.2398\tLR: 0.000337\nTraining Epoch: 22 [29312/50000]\tLoss: 0.3252\tLR: 0.000337\nTraining Epoch: 22 [29440/50000]\tLoss: 0.1926\tLR: 0.000337\nTraining Epoch: 22 [29568/50000]\tLoss: 0.2790\tLR: 0.000337\nTraining Epoch: 22 [29696/50000]\tLoss: 0.2826\tLR: 0.000337\nTraining Epoch: 22 [29824/50000]\tLoss: 0.2019\tLR: 0.000337\nTraining Epoch: 22 [29952/50000]\tLoss: 0.3086\tLR: 0.000337\nTraining Epoch: 22 [30080/50000]\tLoss: 0.2292\tLR: 0.000337\nTraining Epoch: 22 [30208/50000]\tLoss: 0.1629\tLR: 0.000337\nTraining Epoch: 22 [30336/50000]\tLoss: 0.2574\tLR: 0.000337\nTraining Epoch: 22 [30464/50000]\tLoss: 0.3632\tLR: 0.000337\nTraining Epoch: 22 [30592/50000]\tLoss: 0.3480\tLR: 0.000337\nTraining Epoch: 22 [30720/50000]\tLoss: 0.1655\tLR: 0.000337\nTraining Epoch: 22 [30848/50000]\tLoss: 0.2819\tLR: 0.000337\nTraining Epoch: 22 [30976/50000]\tLoss: 0.2843\tLR: 0.000337\nTraining Epoch: 22 [31104/50000]\tLoss: 0.1602\tLR: 0.000337\nTraining Epoch: 22 [31232/50000]\tLoss: 0.2282\tLR: 0.000337\nTraining Epoch: 22 [31360/50000]\tLoss: 0.2568\tLR: 0.000337\nTraining Epoch: 22 [31488/50000]\tLoss: 0.2582\tLR: 0.000337\nTraining Epoch: 22 [31616/50000]\tLoss: 0.3044\tLR: 0.000337\nTraining Epoch: 22 [31744/50000]\tLoss: 0.2675\tLR: 0.000337\nTraining Epoch: 22 [31872/50000]\tLoss: 0.2204\tLR: 0.000337\nTraining Epoch: 22 [32000/50000]\tLoss: 0.1891\tLR: 0.000337\nTraining Epoch: 22 [32128/50000]\tLoss: 0.1497\tLR: 0.000337\nTraining Epoch: 22 [32256/50000]\tLoss: 0.2344\tLR: 0.000337\nTraining Epoch: 22 [32384/50000]\tLoss: 0.2708\tLR: 0.000337\nTraining Epoch: 22 [32512/50000]\tLoss: 0.2133\tLR: 0.000337\nTraining Epoch: 22 [32640/50000]\tLoss: 0.2833\tLR: 0.000337\nTraining Epoch: 22 [32768/50000]\tLoss: 0.2016\tLR: 0.000337\nTraining Epoch: 22 [32896/50000]\tLoss: 0.2171\tLR: 0.000337\nTraining Epoch: 22 [33024/50000]\tLoss: 0.2613\tLR: 0.000337\nTraining Epoch: 22 [33152/50000]\tLoss: 0.1574\tLR: 0.000337\nTraining Epoch: 22 [33280/50000]\tLoss: 0.2202\tLR: 0.000337\nTraining Epoch: 22 [33408/50000]\tLoss: 0.2643\tLR: 0.000337\nTraining Epoch: 22 [33536/50000]\tLoss: 0.1940\tLR: 0.000337\nTraining Epoch: 22 [33664/50000]\tLoss: 0.3284\tLR: 0.000337\nTraining Epoch: 22 [33792/50000]\tLoss: 0.2928\tLR: 0.000337\nTraining Epoch: 22 [33920/50000]\tLoss: 0.2037\tLR: 0.000337\nTraining Epoch: 22 [34048/50000]\tLoss: 0.2342\tLR: 0.000337\nTraining Epoch: 22 [34176/50000]\tLoss: 0.3195\tLR: 0.000337\nTraining Epoch: 22 [34304/50000]\tLoss: 0.1748\tLR: 0.000337\nTraining Epoch: 22 [34432/50000]\tLoss: 0.2898\tLR: 0.000337\nTraining Epoch: 22 [34560/50000]\tLoss: 0.2088\tLR: 0.000337\nTraining Epoch: 22 [34688/50000]\tLoss: 0.2339\tLR: 0.000337\nTraining Epoch: 22 [34816/50000]\tLoss: 0.2328\tLR: 0.000337\nTraining Epoch: 22 [34944/50000]\tLoss: 0.2222\tLR: 0.000337\nTraining Epoch: 22 [35072/50000]\tLoss: 0.1505\tLR: 0.000337\nTraining Epoch: 22 [35200/50000]\tLoss: 0.1728\tLR: 0.000337\nTraining Epoch: 22 [35328/50000]\tLoss: 0.3322\tLR: 0.000337\nTraining Epoch: 22 [35456/50000]\tLoss: 0.1977\tLR: 0.000337\nTraining Epoch: 22 [35584/50000]\tLoss: 0.3620\tLR: 0.000337\nTraining Epoch: 22 [35712/50000]\tLoss: 0.1411\tLR: 0.000337\nTraining Epoch: 22 [35840/50000]\tLoss: 0.1855\tLR: 0.000337\nTraining Epoch: 22 [35968/50000]\tLoss: 0.2157\tLR: 0.000337\nTraining Epoch: 22 [36096/50000]\tLoss: 0.3172\tLR: 0.000337\nTraining Epoch: 22 [36224/50000]\tLoss: 0.2928\tLR: 0.000337\nTraining Epoch: 22 [36352/50000]\tLoss: 0.2005\tLR: 0.000337\nTraining Epoch: 22 [36480/50000]\tLoss: 0.1780\tLR: 0.000337\nTraining Epoch: 22 [36608/50000]\tLoss: 0.1974\tLR: 0.000337\nTraining Epoch: 22 [36736/50000]\tLoss: 0.2814\tLR: 0.000337\nTraining Epoch: 22 [36864/50000]\tLoss: 0.4742\tLR: 0.000337\nTraining Epoch: 22 [36992/50000]\tLoss: 0.2142\tLR: 0.000337\nTraining Epoch: 22 [37120/50000]\tLoss: 0.3172\tLR: 0.000337\nTraining Epoch: 22 [37248/50000]\tLoss: 0.2915\tLR: 0.000337\nTraining Epoch: 22 [37376/50000]\tLoss: 0.2851\tLR: 0.000337\nTraining Epoch: 22 [37504/50000]\tLoss: 0.2167\tLR: 0.000337\nTraining Epoch: 22 [37632/50000]\tLoss: 0.2927\tLR: 0.000337\nTraining Epoch: 22 [37760/50000]\tLoss: 0.3051\tLR: 0.000337\nTraining Epoch: 22 [37888/50000]\tLoss: 0.2909\tLR: 0.000337\nTraining Epoch: 22 [38016/50000]\tLoss: 0.2908\tLR: 0.000337\nTraining Epoch: 22 [38144/50000]\tLoss: 0.1524\tLR: 0.000337\nTraining Epoch: 22 [38272/50000]\tLoss: 0.2154\tLR: 0.000337\nTraining Epoch: 22 [38400/50000]\tLoss: 0.3625\tLR: 0.000337\nTraining Epoch: 22 [38528/50000]\tLoss: 0.2923\tLR: 0.000337\nTraining Epoch: 22 [38656/50000]\tLoss: 0.3548\tLR: 0.000337\nTraining Epoch: 22 [38784/50000]\tLoss: 0.2478\tLR: 0.000337\nTraining Epoch: 22 [38912/50000]\tLoss: 0.1294\tLR: 0.000337\nTraining Epoch: 22 [39040/50000]\tLoss: 0.2179\tLR: 0.000337\nTraining Epoch: 22 [39168/50000]\tLoss: 0.1842\tLR: 0.000337\nTraining Epoch: 22 [39296/50000]\tLoss: 0.2446\tLR: 0.000337\nTraining Epoch: 22 [39424/50000]\tLoss: 0.2035\tLR: 0.000337\nTraining Epoch: 22 [39552/50000]\tLoss: 0.2201\tLR: 0.000337\nTraining Epoch: 22 [39680/50000]\tLoss: 0.2524\tLR: 0.000337\nTraining Epoch: 22 [39808/50000]\tLoss: 0.2818\tLR: 0.000337\nTraining Epoch: 22 [39936/50000]\tLoss: 0.2980\tLR: 0.000337\nTraining Epoch: 22 [40064/50000]\tLoss: 0.2119\tLR: 0.000337\nTraining Epoch: 22 [40192/50000]\tLoss: 0.2671\tLR: 0.000337\nTraining Epoch: 22 [40320/50000]\tLoss: 0.2308\tLR: 0.000337\nTraining Epoch: 22 [40448/50000]\tLoss: 0.2081\tLR: 0.000337\nTraining Epoch: 22 [40576/50000]\tLoss: 0.2428\tLR: 0.000337\nTraining Epoch: 22 [40704/50000]\tLoss: 0.2701\tLR: 0.000337\nTraining Epoch: 22 [40832/50000]\tLoss: 0.4202\tLR: 0.000337\nTraining Epoch: 22 [40960/50000]\tLoss: 0.2489\tLR: 0.000337\nTraining Epoch: 22 [41088/50000]\tLoss: 0.2306\tLR: 0.000337\nTraining Epoch: 22 [41216/50000]\tLoss: 0.2844\tLR: 0.000337\nTraining Epoch: 22 [41344/50000]\tLoss: 0.2152\tLR: 0.000337\nTraining Epoch: 22 [41472/50000]\tLoss: 0.3382\tLR: 0.000337\nTraining Epoch: 22 [41600/50000]\tLoss: 0.2474\tLR: 0.000337\nTraining Epoch: 22 [41728/50000]\tLoss: 0.1895\tLR: 0.000337\nTraining Epoch: 22 [41856/50000]\tLoss: 0.1881\tLR: 0.000337\nTraining Epoch: 22 [41984/50000]\tLoss: 0.2240\tLR: 0.000337\nTraining Epoch: 22 [42112/50000]\tLoss: 0.1688\tLR: 0.000337\nTraining Epoch: 22 [42240/50000]\tLoss: 0.1901\tLR: 0.000337\nTraining Epoch: 22 [42368/50000]\tLoss: 0.2715\tLR: 0.000337\nTraining Epoch: 22 [42496/50000]\tLoss: 0.2207\tLR: 0.000337\nTraining Epoch: 22 [42624/50000]\tLoss: 0.1999\tLR: 0.000337\nTraining Epoch: 22 [42752/50000]\tLoss: 0.2200\tLR: 0.000337\nTraining Epoch: 22 [42880/50000]\tLoss: 0.2240\tLR: 0.000337\nTraining Epoch: 22 [43008/50000]\tLoss: 0.1634\tLR: 0.000337\nTraining Epoch: 22 [43136/50000]\tLoss: 0.3078\tLR: 0.000337\nTraining Epoch: 22 [43264/50000]\tLoss: 0.2289\tLR: 0.000337\nTraining Epoch: 22 [43392/50000]\tLoss: 0.2452\tLR: 0.000337\nTraining Epoch: 22 [43520/50000]\tLoss: 0.2280\tLR: 0.000337\nTraining Epoch: 22 [43648/50000]\tLoss: 0.1821\tLR: 0.000337\nTraining Epoch: 22 [43776/50000]\tLoss: 0.2746\tLR: 0.000337\nTraining Epoch: 22 [43904/50000]\tLoss: 0.2140\tLR: 0.000337\nTraining Epoch: 22 [44032/50000]\tLoss: 0.2126\tLR: 0.000337\nTraining Epoch: 22 [44160/50000]\tLoss: 0.2816\tLR: 0.000337\nTraining Epoch: 22 [44288/50000]\tLoss: 0.1516\tLR: 0.000337\nTraining Epoch: 22 [44416/50000]\tLoss: 0.1940\tLR: 0.000337\nTraining Epoch: 22 [44544/50000]\tLoss: 0.3529\tLR: 0.000337\nTraining Epoch: 22 [44672/50000]\tLoss: 0.2096\tLR: 0.000337\nTraining Epoch: 22 [44800/50000]\tLoss: 0.1557\tLR: 0.000337\nTraining Epoch: 22 [44928/50000]\tLoss: 0.2357\tLR: 0.000337\nTraining Epoch: 22 [45056/50000]\tLoss: 0.2647\tLR: 0.000337\nTraining Epoch: 22 [45184/50000]\tLoss: 0.2637\tLR: 0.000337\nTraining Epoch: 22 [45312/50000]\tLoss: 0.2480\tLR: 0.000337\nTraining Epoch: 22 [45440/50000]\tLoss: 0.3381\tLR: 0.000337\nTraining Epoch: 22 [45568/50000]\tLoss: 0.2572\tLR: 0.000337\nTraining Epoch: 22 [45696/50000]\tLoss: 0.2740\tLR: 0.000337\nTraining Epoch: 22 [45824/50000]\tLoss: 0.1830\tLR: 0.000337\nTraining Epoch: 22 [45952/50000]\tLoss: 0.2174\tLR: 0.000337\nTraining Epoch: 22 [46080/50000]\tLoss: 0.1943\tLR: 0.000337\nTraining Epoch: 22 [46208/50000]\tLoss: 0.2265\tLR: 0.000337\nTraining Epoch: 22 [46336/50000]\tLoss: 0.2422\tLR: 0.000337\nTraining Epoch: 22 [46464/50000]\tLoss: 0.2268\tLR: 0.000337\nTraining Epoch: 22 [46592/50000]\tLoss: 0.2363\tLR: 0.000337\nTraining Epoch: 22 [46720/50000]\tLoss: 0.2421\tLR: 0.000337\nTraining Epoch: 22 [46848/50000]\tLoss: 0.2359\tLR: 0.000337\nTraining Epoch: 22 [46976/50000]\tLoss: 0.1945\tLR: 0.000337\nTraining Epoch: 22 [47104/50000]\tLoss: 0.3035\tLR: 0.000337\nTraining Epoch: 22 [47232/50000]\tLoss: 0.3412\tLR: 0.000337\nTraining Epoch: 22 [47360/50000]\tLoss: 0.2111\tLR: 0.000337\nTraining Epoch: 22 [47488/50000]\tLoss: 0.2342\tLR: 0.000337\nTraining Epoch: 22 [47616/50000]\tLoss: 0.1916\tLR: 0.000337\nTraining Epoch: 22 [47744/50000]\tLoss: 0.3465\tLR: 0.000337\nTraining Epoch: 22 [47872/50000]\tLoss: 0.2139\tLR: 0.000337\nTraining Epoch: 22 [48000/50000]\tLoss: 0.1969\tLR: 0.000337\nTraining Epoch: 22 [48128/50000]\tLoss: 0.1797\tLR: 0.000337\nTraining Epoch: 22 [48256/50000]\tLoss: 0.2750\tLR: 0.000337\nTraining Epoch: 22 [48384/50000]\tLoss: 0.3055\tLR: 0.000337\nTraining Epoch: 22 [48512/50000]\tLoss: 0.3242\tLR: 0.000337\nTraining Epoch: 22 [48640/50000]\tLoss: 0.3307\tLR: 0.000337\nTraining Epoch: 22 [48768/50000]\tLoss: 0.2641\tLR: 0.000337\nTraining Epoch: 22 [48896/50000]\tLoss: 0.2202\tLR: 0.000337\nTraining Epoch: 22 [49024/50000]\tLoss: 0.1628\tLR: 0.000337\nTraining Epoch: 22 [49152/50000]\tLoss: 0.2601\tLR: 0.000337\nTraining Epoch: 22 [49280/50000]\tLoss: 0.3105\tLR: 0.000337\nTraining Epoch: 22 [49408/50000]\tLoss: 0.3321\tLR: 0.000337\nTraining Epoch: 22 [49536/50000]\tLoss: 0.3454\tLR: 0.000337\nTraining Epoch: 22 [49664/50000]\tLoss: 0.1942\tLR: 0.000337\nTraining Epoch: 22 [49792/50000]\tLoss: 0.1723\tLR: 0.000337\nTraining Epoch: 22 [49920/50000]\tLoss: 0.2787\tLR: 0.000337\nTraining Epoch: 22 [50000/50000]\tLoss: 0.2960\tLR: 0.000337\nTest set: Average loss: 0.0024, Accuracy: 0.8982\n\nTraining Epoch: 23 [128/50000]\tLoss: 0.2871\tLR: 0.000337\nTraining Epoch: 23 [256/50000]\tLoss: 0.3079\tLR: 0.000337\nTraining Epoch: 23 [384/50000]\tLoss: 0.1865\tLR: 0.000337\nTraining Epoch: 23 [512/50000]\tLoss: 0.1693\tLR: 0.000337\nTraining Epoch: 23 [640/50000]\tLoss: 0.2469\tLR: 0.000337\nTraining Epoch: 23 [768/50000]\tLoss: 0.2107\tLR: 0.000337\nTraining Epoch: 23 [896/50000]\tLoss: 0.1374\tLR: 0.000337\nTraining Epoch: 23 [1024/50000]\tLoss: 0.2304\tLR: 0.000337\nTraining Epoch: 23 [1152/50000]\tLoss: 0.2654\tLR: 0.000337\nTraining Epoch: 23 [1280/50000]\tLoss: 0.2195\tLR: 0.000337\nTraining Epoch: 23 [1408/50000]\tLoss: 0.2132\tLR: 0.000337\nTraining Epoch: 23 [1536/50000]\tLoss: 0.3003\tLR: 0.000337\nTraining Epoch: 23 [1664/50000]\tLoss: 0.3159\tLR: 0.000337\nTraining Epoch: 23 [1792/50000]\tLoss: 0.2600\tLR: 0.000337\nTraining Epoch: 23 [1920/50000]\tLoss: 0.2094\tLR: 0.000337\nTraining Epoch: 23 [2048/50000]\tLoss: 0.2230\tLR: 0.000337\nTraining Epoch: 23 [2176/50000]\tLoss: 0.3037\tLR: 0.000337\nTraining Epoch: 23 [2304/50000]\tLoss: 0.3295\tLR: 0.000337\nTraining Epoch: 23 [2432/50000]\tLoss: 0.2214\tLR: 0.000337\nTraining Epoch: 23 [2560/50000]\tLoss: 0.2204\tLR: 0.000337\nTraining Epoch: 23 [2688/50000]\tLoss: 0.2241\tLR: 0.000337\nTraining Epoch: 23 [2816/50000]\tLoss: 0.3426\tLR: 0.000337\nTraining Epoch: 23 [2944/50000]\tLoss: 0.2995\tLR: 0.000337\nTraining Epoch: 23 [3072/50000]\tLoss: 0.2289\tLR: 0.000337\nTraining Epoch: 23 [3200/50000]\tLoss: 0.2965\tLR: 0.000337\nTraining Epoch: 23 [3328/50000]\tLoss: 0.2191\tLR: 0.000337\nTraining Epoch: 23 [3456/50000]\tLoss: 0.2137\tLR: 0.000337\nTraining Epoch: 23 [3584/50000]\tLoss: 0.3677\tLR: 0.000337\nTraining Epoch: 23 [3712/50000]\tLoss: 0.2554\tLR: 0.000337\nTraining Epoch: 23 [3840/50000]\tLoss: 0.2990\tLR: 0.000337\nTraining Epoch: 23 [3968/50000]\tLoss: 0.1278\tLR: 0.000337\nTraining Epoch: 23 [4096/50000]\tLoss: 0.2298\tLR: 0.000337\nTraining Epoch: 23 [4224/50000]\tLoss: 0.2723\tLR: 0.000337\nTraining Epoch: 23 [4352/50000]\tLoss: 0.2374\tLR: 0.000337\nTraining Epoch: 23 [4480/50000]\tLoss: 0.2083\tLR: 0.000337\nTraining Epoch: 23 [4608/50000]\tLoss: 0.4274\tLR: 0.000337\nTraining Epoch: 23 [4736/50000]\tLoss: 0.2208\tLR: 0.000337\nTraining Epoch: 23 [4864/50000]\tLoss: 0.2337\tLR: 0.000337\nTraining Epoch: 23 [4992/50000]\tLoss: 0.1667\tLR: 0.000337\nTraining Epoch: 23 [5120/50000]\tLoss: 0.2150\tLR: 0.000337\nTraining Epoch: 23 [5248/50000]\tLoss: 0.2023\tLR: 0.000337\nTraining Epoch: 23 [5376/50000]\tLoss: 0.3047\tLR: 0.000337\nTraining Epoch: 23 [5504/50000]\tLoss: 0.2773\tLR: 0.000337\nTraining Epoch: 23 [5632/50000]\tLoss: 0.3128\tLR: 0.000337\nTraining Epoch: 23 [5760/50000]\tLoss: 0.3741\tLR: 0.000337\nTraining Epoch: 23 [5888/50000]\tLoss: 0.3073\tLR: 0.000337\nTraining Epoch: 23 [6016/50000]\tLoss: 0.1861\tLR: 0.000337\nTraining Epoch: 23 [6144/50000]\tLoss: 0.2330\tLR: 0.000337\nTraining Epoch: 23 [6272/50000]\tLoss: 0.2525\tLR: 0.000337\nTraining Epoch: 23 [6400/50000]\tLoss: 0.2189\tLR: 0.000337\nTraining Epoch: 23 [6528/50000]\tLoss: 0.2238\tLR: 0.000337\nTraining Epoch: 23 [6656/50000]\tLoss: 0.2662\tLR: 0.000337\nTraining Epoch: 23 [6784/50000]\tLoss: 0.2646\tLR: 0.000337\nTraining Epoch: 23 [6912/50000]\tLoss: 0.2326\tLR: 0.000337\nTraining Epoch: 23 [7040/50000]\tLoss: 0.1981\tLR: 0.000337\nTraining Epoch: 23 [7168/50000]\tLoss: 0.1419\tLR: 0.000337\nTraining Epoch: 23 [7296/50000]\tLoss: 0.2989\tLR: 0.000337\nTraining Epoch: 23 [7424/50000]\tLoss: 0.2093\tLR: 0.000337\nTraining Epoch: 23 [7552/50000]\tLoss: 0.2494\tLR: 0.000337\nTraining Epoch: 23 [7680/50000]\tLoss: 0.2585\tLR: 0.000337\nTraining Epoch: 23 [7808/50000]\tLoss: 0.2602\tLR: 0.000337\nTraining Epoch: 23 [7936/50000]\tLoss: 0.3551\tLR: 0.000337\nTraining Epoch: 23 [8064/50000]\tLoss: 0.2706\tLR: 0.000337\nTraining Epoch: 23 [8192/50000]\tLoss: 0.3239\tLR: 0.000337\nTraining Epoch: 23 [8320/50000]\tLoss: 0.2543\tLR: 0.000337\nTraining Epoch: 23 [8448/50000]\tLoss: 0.2355\tLR: 0.000337\nTraining Epoch: 23 [8576/50000]\tLoss: 0.3371\tLR: 0.000337\nTraining Epoch: 23 [8704/50000]\tLoss: 0.2317\tLR: 0.000337\nTraining Epoch: 23 [8832/50000]\tLoss: 0.1735\tLR: 0.000337\nTraining Epoch: 23 [8960/50000]\tLoss: 0.2081\tLR: 0.000337\nTraining Epoch: 23 [9088/50000]\tLoss: 0.3897\tLR: 0.000337\nTraining Epoch: 23 [9216/50000]\tLoss: 0.2249\tLR: 0.000337\nTraining Epoch: 23 [9344/50000]\tLoss: 0.2321\tLR: 0.000337\nTraining Epoch: 23 [9472/50000]\tLoss: 0.3258\tLR: 0.000337\nTraining Epoch: 23 [9600/50000]\tLoss: 0.2555\tLR: 0.000337\nTraining Epoch: 23 [9728/50000]\tLoss: 0.2465\tLR: 0.000337\nTraining Epoch: 23 [9856/50000]\tLoss: 0.2332\tLR: 0.000337\nTraining Epoch: 23 [9984/50000]\tLoss: 0.2282\tLR: 0.000337\nTraining Epoch: 23 [10112/50000]\tLoss: 0.2521\tLR: 0.000337\nTraining Epoch: 23 [10240/50000]\tLoss: 0.3014\tLR: 0.000337\nTraining Epoch: 23 [10368/50000]\tLoss: 0.2754\tLR: 0.000337\nTraining Epoch: 23 [10496/50000]\tLoss: 0.2169\tLR: 0.000337\nTraining Epoch: 23 [10624/50000]\tLoss: 0.1772\tLR: 0.000337\nTraining Epoch: 23 [10752/50000]\tLoss: 0.1883\tLR: 0.000337\nTraining Epoch: 23 [10880/50000]\tLoss: 0.1967\tLR: 0.000337\nTraining Epoch: 23 [11008/50000]\tLoss: 0.2029\tLR: 0.000337\nTraining Epoch: 23 [11136/50000]\tLoss: 0.1645\tLR: 0.000337\nTraining Epoch: 23 [11264/50000]\tLoss: 0.2302\tLR: 0.000337\nTraining Epoch: 23 [11392/50000]\tLoss: 0.2214\tLR: 0.000337\nTraining Epoch: 23 [11520/50000]\tLoss: 0.1998\tLR: 0.000337\nTraining Epoch: 23 [11648/50000]\tLoss: 0.1585\tLR: 0.000337\nTraining Epoch: 23 [11776/50000]\tLoss: 0.2779\tLR: 0.000337\nTraining Epoch: 23 [11904/50000]\tLoss: 0.3223\tLR: 0.000337\nTraining Epoch: 23 [12032/50000]\tLoss: 0.2317\tLR: 0.000337\nTraining Epoch: 23 [12160/50000]\tLoss: 0.1800\tLR: 0.000337\nTraining Epoch: 23 [12288/50000]\tLoss: 0.1848\tLR: 0.000337\nTraining Epoch: 23 [12416/50000]\tLoss: 0.1962\tLR: 0.000337\nTraining Epoch: 23 [12544/50000]\tLoss: 0.1923\tLR: 0.000337\nTraining Epoch: 23 [12672/50000]\tLoss: 0.1889\tLR: 0.000337\nTraining Epoch: 23 [12800/50000]\tLoss: 0.3703\tLR: 0.000337\nTraining Epoch: 23 [12928/50000]\tLoss: 0.2195\tLR: 0.000337\nTraining Epoch: 23 [13056/50000]\tLoss: 0.3419\tLR: 0.000337\nTraining Epoch: 23 [13184/50000]\tLoss: 0.2373\tLR: 0.000337\nTraining Epoch: 23 [13312/50000]\tLoss: 0.2067\tLR: 0.000337\nTraining Epoch: 23 [13440/50000]\tLoss: 0.2250\tLR: 0.000337\nTraining Epoch: 23 [13568/50000]\tLoss: 0.3321\tLR: 0.000337\nTraining Epoch: 23 [13696/50000]\tLoss: 0.2696\tLR: 0.000337\nTraining Epoch: 23 [13824/50000]\tLoss: 0.3205\tLR: 0.000337\nTraining Epoch: 23 [13952/50000]\tLoss: 0.2963\tLR: 0.000337\nTraining Epoch: 23 [14080/50000]\tLoss: 0.2517\tLR: 0.000337\nTraining Epoch: 23 [14208/50000]\tLoss: 0.3096\tLR: 0.000337\nTraining Epoch: 23 [14336/50000]\tLoss: 0.3443\tLR: 0.000337\nTraining Epoch: 23 [14464/50000]\tLoss: 0.2465\tLR: 0.000337\nTraining Epoch: 23 [14592/50000]\tLoss: 0.1708\tLR: 0.000337\nTraining Epoch: 23 [14720/50000]\tLoss: 0.1990\tLR: 0.000337\nTraining Epoch: 23 [14848/50000]\tLoss: 0.2508\tLR: 0.000337\nTraining Epoch: 23 [14976/50000]\tLoss: 0.1158\tLR: 0.000337\nTraining Epoch: 23 [15104/50000]\tLoss: 0.3098\tLR: 0.000337\nTraining Epoch: 23 [15232/50000]\tLoss: 0.1436\tLR: 0.000337\nTraining Epoch: 23 [15360/50000]\tLoss: 0.2967\tLR: 0.000337\nTraining Epoch: 23 [15488/50000]\tLoss: 0.2574\tLR: 0.000337\nTraining Epoch: 23 [15616/50000]\tLoss: 0.2098\tLR: 0.000337\nTraining Epoch: 23 [15744/50000]\tLoss: 0.3376\tLR: 0.000337\nTraining Epoch: 23 [15872/50000]\tLoss: 0.3641\tLR: 0.000337\nTraining Epoch: 23 [16000/50000]\tLoss: 0.2328\tLR: 0.000337\nTraining Epoch: 23 [16128/50000]\tLoss: 0.2514\tLR: 0.000337\nTraining Epoch: 23 [16256/50000]\tLoss: 0.1851\tLR: 0.000337\nTraining Epoch: 23 [16384/50000]\tLoss: 0.3011\tLR: 0.000337\nTraining Epoch: 23 [16512/50000]\tLoss: 0.2590\tLR: 0.000337\nTraining Epoch: 23 [16640/50000]\tLoss: 0.2128\tLR: 0.000337\nTraining Epoch: 23 [16768/50000]\tLoss: 0.3194\tLR: 0.000337\nTraining Epoch: 23 [16896/50000]\tLoss: 0.2968\tLR: 0.000337\nTraining Epoch: 23 [17024/50000]\tLoss: 0.2979\tLR: 0.000337\nTraining Epoch: 23 [17152/50000]\tLoss: 0.2131\tLR: 0.000337\nTraining Epoch: 23 [17280/50000]\tLoss: 0.2574\tLR: 0.000337\nTraining Epoch: 23 [17408/50000]\tLoss: 0.2743\tLR: 0.000337\nTraining Epoch: 23 [17536/50000]\tLoss: 0.3153\tLR: 0.000337\nTraining Epoch: 23 [17664/50000]\tLoss: 0.4941\tLR: 0.000337\nTraining Epoch: 23 [17792/50000]\tLoss: 0.1951\tLR: 0.000337\nTraining Epoch: 23 [17920/50000]\tLoss: 0.3084\tLR: 0.000337\nTraining Epoch: 23 [18048/50000]\tLoss: 0.2859\tLR: 0.000337\nTraining Epoch: 23 [18176/50000]\tLoss: 0.1668\tLR: 0.000337\nTraining Epoch: 23 [18304/50000]\tLoss: 0.2272\tLR: 0.000337\nTraining Epoch: 23 [18432/50000]\tLoss: 0.2903\tLR: 0.000337\nTraining Epoch: 23 [18560/50000]\tLoss: 0.3373\tLR: 0.000337\nTraining Epoch: 23 [18688/50000]\tLoss: 0.2778\tLR: 0.000337\nTraining Epoch: 23 [18816/50000]\tLoss: 0.1392\tLR: 0.000337\nTraining Epoch: 23 [18944/50000]\tLoss: 0.2605\tLR: 0.000337\nTraining Epoch: 23 [19072/50000]\tLoss: 0.2472\tLR: 0.000337\nTraining Epoch: 23 [19200/50000]\tLoss: 0.1796\tLR: 0.000337\nTraining Epoch: 23 [19328/50000]\tLoss: 0.1762\tLR: 0.000337\nTraining Epoch: 23 [19456/50000]\tLoss: 0.2417\tLR: 0.000337\nTraining Epoch: 23 [19584/50000]\tLoss: 0.3116\tLR: 0.000337\nTraining Epoch: 23 [19712/50000]\tLoss: 0.2568\tLR: 0.000337\nTraining Epoch: 23 [19840/50000]\tLoss: 0.1536\tLR: 0.000337\nTraining Epoch: 23 [19968/50000]\tLoss: 0.2222\tLR: 0.000337\nTraining Epoch: 23 [20096/50000]\tLoss: 0.2195\tLR: 0.000337\nTraining Epoch: 23 [20224/50000]\tLoss: 0.2926\tLR: 0.000337\nTraining Epoch: 23 [20352/50000]\tLoss: 0.2542\tLR: 0.000337\nTraining Epoch: 23 [20480/50000]\tLoss: 0.3142\tLR: 0.000337\nTraining Epoch: 23 [20608/50000]\tLoss: 0.2959\tLR: 0.000337\nTraining Epoch: 23 [20736/50000]\tLoss: 0.1599\tLR: 0.000337\nTraining Epoch: 23 [20864/50000]\tLoss: 0.2563\tLR: 0.000337\nTraining Epoch: 23 [20992/50000]\tLoss: 0.2336\tLR: 0.000337\nTraining Epoch: 23 [21120/50000]\tLoss: 0.2874\tLR: 0.000337\nTraining Epoch: 23 [21248/50000]\tLoss: 0.2456\tLR: 0.000337\nTraining Epoch: 23 [21376/50000]\tLoss: 0.3146\tLR: 0.000337\nTraining Epoch: 23 [21504/50000]\tLoss: 0.2639\tLR: 0.000337\nTraining Epoch: 23 [21632/50000]\tLoss: 0.2841\tLR: 0.000337\nTraining Epoch: 23 [21760/50000]\tLoss: 0.2713\tLR: 0.000337\nTraining Epoch: 23 [21888/50000]\tLoss: 0.2904\tLR: 0.000337\nTraining Epoch: 23 [22016/50000]\tLoss: 0.1498\tLR: 0.000337\nTraining Epoch: 23 [22144/50000]\tLoss: 0.2211\tLR: 0.000337\nTraining Epoch: 23 [22272/50000]\tLoss: 0.2375\tLR: 0.000337\nTraining Epoch: 23 [22400/50000]\tLoss: 0.2204\tLR: 0.000337\nTraining Epoch: 23 [22528/50000]\tLoss: 0.3944\tLR: 0.000337\nTraining Epoch: 23 [22656/50000]\tLoss: 0.1789\tLR: 0.000337\nTraining Epoch: 23 [22784/50000]\tLoss: 0.1556\tLR: 0.000337\nTraining Epoch: 23 [22912/50000]\tLoss: 0.2712\tLR: 0.000337\nTraining Epoch: 23 [23040/50000]\tLoss: 0.1745\tLR: 0.000337\nTraining Epoch: 23 [23168/50000]\tLoss: 0.2248\tLR: 0.000337\nTraining Epoch: 23 [23296/50000]\tLoss: 0.3092\tLR: 0.000337\nTraining Epoch: 23 [23424/50000]\tLoss: 0.3174\tLR: 0.000337\nTraining Epoch: 23 [23552/50000]\tLoss: 0.2636\tLR: 0.000337\nTraining Epoch: 23 [23680/50000]\tLoss: 0.2201\tLR: 0.000337\nTraining Epoch: 23 [23808/50000]\tLoss: 0.2131\tLR: 0.000337\nTraining Epoch: 23 [23936/50000]\tLoss: 0.2707\tLR: 0.000337\nTraining Epoch: 23 [24064/50000]\tLoss: 0.1588\tLR: 0.000337\nTraining Epoch: 23 [24192/50000]\tLoss: 0.3551\tLR: 0.000337\nTraining Epoch: 23 [24320/50000]\tLoss: 0.2778\tLR: 0.000337\nTraining Epoch: 23 [24448/50000]\tLoss: 0.3045\tLR: 0.000337\nTraining Epoch: 23 [24576/50000]\tLoss: 0.2309\tLR: 0.000337\nTraining Epoch: 23 [24704/50000]\tLoss: 0.1852\tLR: 0.000337\nTraining Epoch: 23 [24832/50000]\tLoss: 0.2501\tLR: 0.000337\nTraining Epoch: 23 [24960/50000]\tLoss: 0.2651\tLR: 0.000337\nTraining Epoch: 23 [25088/50000]\tLoss: 0.2490\tLR: 0.000337\nTraining Epoch: 23 [25216/50000]\tLoss: 0.2922\tLR: 0.000337\nTraining Epoch: 23 [25344/50000]\tLoss: 0.1706\tLR: 0.000337\nTraining Epoch: 23 [25472/50000]\tLoss: 0.2829\tLR: 0.000337\nTraining Epoch: 23 [25600/50000]\tLoss: 0.2357\tLR: 0.000337\nTraining Epoch: 23 [25728/50000]\tLoss: 0.2654\tLR: 0.000337\nTraining Epoch: 23 [25856/50000]\tLoss: 0.3056\tLR: 0.000337\nTraining Epoch: 23 [25984/50000]\tLoss: 0.1834\tLR: 0.000337\nTraining Epoch: 23 [26112/50000]\tLoss: 0.1728\tLR: 0.000337\nTraining Epoch: 23 [26240/50000]\tLoss: 0.2103\tLR: 0.000337\nTraining Epoch: 23 [26368/50000]\tLoss: 0.1605\tLR: 0.000337\nTraining Epoch: 23 [26496/50000]\tLoss: 0.2216\tLR: 0.000337\nTraining Epoch: 23 [26624/50000]\tLoss: 0.2197\tLR: 0.000337\nTraining Epoch: 23 [26752/50000]\tLoss: 0.2288\tLR: 0.000337\nTraining Epoch: 23 [26880/50000]\tLoss: 0.2880\tLR: 0.000337\nTraining Epoch: 23 [27008/50000]\tLoss: 0.3224\tLR: 0.000337\nTraining Epoch: 23 [27136/50000]\tLoss: 0.2343\tLR: 0.000337\nTraining Epoch: 23 [27264/50000]\tLoss: 0.2596\tLR: 0.000337\nTraining Epoch: 23 [27392/50000]\tLoss: 0.2553\tLR: 0.000337\nTraining Epoch: 23 [27520/50000]\tLoss: 0.2067\tLR: 0.000337\nTraining Epoch: 23 [27648/50000]\tLoss: 0.1932\tLR: 0.000337\nTraining Epoch: 23 [27776/50000]\tLoss: 0.2989\tLR: 0.000337\nTraining Epoch: 23 [27904/50000]\tLoss: 0.3258\tLR: 0.000337\nTraining Epoch: 23 [28032/50000]\tLoss: 0.3668\tLR: 0.000337\nTraining Epoch: 23 [28160/50000]\tLoss: 0.2093\tLR: 0.000337\nTraining Epoch: 23 [28288/50000]\tLoss: 0.2574\tLR: 0.000337\nTraining Epoch: 23 [28416/50000]\tLoss: 0.1740\tLR: 0.000337\nTraining Epoch: 23 [28544/50000]\tLoss: 0.1992\tLR: 0.000337\nTraining Epoch: 23 [28672/50000]\tLoss: 0.2227\tLR: 0.000337\nTraining Epoch: 23 [28800/50000]\tLoss: 0.2337\tLR: 0.000337\nTraining Epoch: 23 [28928/50000]\tLoss: 0.3682\tLR: 0.000337\nTraining Epoch: 23 [29056/50000]\tLoss: 0.2671\tLR: 0.000337\nTraining Epoch: 23 [29184/50000]\tLoss: 0.2755\tLR: 0.000337\nTraining Epoch: 23 [29312/50000]\tLoss: 0.2792\tLR: 0.000337\nTraining Epoch: 23 [29440/50000]\tLoss: 0.1787\tLR: 0.000337\nTraining Epoch: 23 [29568/50000]\tLoss: 0.2512\tLR: 0.000337\nTraining Epoch: 23 [29696/50000]\tLoss: 0.2242\tLR: 0.000337\nTraining Epoch: 23 [29824/50000]\tLoss: 0.1960\tLR: 0.000337\nTraining Epoch: 23 [29952/50000]\tLoss: 0.2397\tLR: 0.000337\nTraining Epoch: 23 [30080/50000]\tLoss: 0.2281\tLR: 0.000337\nTraining Epoch: 23 [30208/50000]\tLoss: 0.1779\tLR: 0.000337\nTraining Epoch: 23 [30336/50000]\tLoss: 0.3816\tLR: 0.000337\nTraining Epoch: 23 [30464/50000]\tLoss: 0.2250\tLR: 0.000337\nTraining Epoch: 23 [30592/50000]\tLoss: 0.2429\tLR: 0.000337\nTraining Epoch: 23 [30720/50000]\tLoss: 0.2816\tLR: 0.000337\nTraining Epoch: 23 [30848/50000]\tLoss: 0.2570\tLR: 0.000337\nTraining Epoch: 23 [30976/50000]\tLoss: 0.2456\tLR: 0.000337\nTraining Epoch: 23 [31104/50000]\tLoss: 0.3293\tLR: 0.000337\nTraining Epoch: 23 [31232/50000]\tLoss: 0.2480\tLR: 0.000337\nTraining Epoch: 23 [31360/50000]\tLoss: 0.3728\tLR: 0.000337\nTraining Epoch: 23 [31488/50000]\tLoss: 0.1864\tLR: 0.000337\nTraining Epoch: 23 [31616/50000]\tLoss: 0.2218\tLR: 0.000337\nTraining Epoch: 23 [31744/50000]\tLoss: 0.2901\tLR: 0.000337\nTraining Epoch: 23 [31872/50000]\tLoss: 0.2387\tLR: 0.000337\nTraining Epoch: 23 [32000/50000]\tLoss: 0.2038\tLR: 0.000337\nTraining Epoch: 23 [32128/50000]\tLoss: 0.2244\tLR: 0.000337\nTraining Epoch: 23 [32256/50000]\tLoss: 0.2225\tLR: 0.000337\nTraining Epoch: 23 [32384/50000]\tLoss: 0.3161\tLR: 0.000337\nTraining Epoch: 23 [32512/50000]\tLoss: 0.2102\tLR: 0.000337\nTraining Epoch: 23 [32640/50000]\tLoss: 0.2289\tLR: 0.000337\nTraining Epoch: 23 [32768/50000]\tLoss: 0.3704\tLR: 0.000337\nTraining Epoch: 23 [32896/50000]\tLoss: 0.2515\tLR: 0.000337\nTraining Epoch: 23 [33024/50000]\tLoss: 0.2461\tLR: 0.000337\nTraining Epoch: 23 [33152/50000]\tLoss: 0.2249\tLR: 0.000337\nTraining Epoch: 23 [33280/50000]\tLoss: 0.1046\tLR: 0.000337\nTraining Epoch: 23 [33408/50000]\tLoss: 0.2140\tLR: 0.000337\nTraining Epoch: 23 [33536/50000]\tLoss: 0.2204\tLR: 0.000337\nTraining Epoch: 23 [33664/50000]\tLoss: 0.2152\tLR: 0.000337\nTraining Epoch: 23 [33792/50000]\tLoss: 0.2416\tLR: 0.000337\nTraining Epoch: 23 [33920/50000]\tLoss: 0.2859\tLR: 0.000337\nTraining Epoch: 23 [34048/50000]\tLoss: 0.1479\tLR: 0.000337\nTraining Epoch: 23 [34176/50000]\tLoss: 0.2927\tLR: 0.000337\nTraining Epoch: 23 [34304/50000]\tLoss: 0.3543\tLR: 0.000337\nTraining Epoch: 23 [34432/50000]\tLoss: 0.2411\tLR: 0.000337\nTraining Epoch: 23 [34560/50000]\tLoss: 0.2220\tLR: 0.000337\nTraining Epoch: 23 [34688/50000]\tLoss: 0.2512\tLR: 0.000337\nTraining Epoch: 23 [34816/50000]\tLoss: 0.2551\tLR: 0.000337\nTraining Epoch: 23 [34944/50000]\tLoss: 0.2970\tLR: 0.000337\nTraining Epoch: 23 [35072/50000]\tLoss: 0.1566\tLR: 0.000337\nTraining Epoch: 23 [35200/50000]\tLoss: 0.2499\tLR: 0.000337\nTraining Epoch: 23 [35328/50000]\tLoss: 0.1679\tLR: 0.000337\nTraining Epoch: 23 [35456/50000]\tLoss: 0.2467\tLR: 0.000337\nTraining Epoch: 23 [35584/50000]\tLoss: 0.2447\tLR: 0.000337\nTraining Epoch: 23 [35712/50000]\tLoss: 0.2255\tLR: 0.000337\nTraining Epoch: 23 [35840/50000]\tLoss: 0.2451\tLR: 0.000337\nTraining Epoch: 23 [35968/50000]\tLoss: 0.2111\tLR: 0.000337\nTraining Epoch: 23 [36096/50000]\tLoss: 0.2412\tLR: 0.000337\nTraining Epoch: 23 [36224/50000]\tLoss: 0.2634\tLR: 0.000337\nTraining Epoch: 23 [36352/50000]\tLoss: 0.3440\tLR: 0.000337\nTraining Epoch: 23 [36480/50000]\tLoss: 0.2411\tLR: 0.000337\nTraining Epoch: 23 [36608/50000]\tLoss: 0.1114\tLR: 0.000337\nTraining Epoch: 23 [36736/50000]\tLoss: 0.1850\tLR: 0.000337\nTraining Epoch: 23 [36864/50000]\tLoss: 0.2575\tLR: 0.000337\nTraining Epoch: 23 [36992/50000]\tLoss: 0.1862\tLR: 0.000337\nTraining Epoch: 23 [37120/50000]\tLoss: 0.3236\tLR: 0.000337\nTraining Epoch: 23 [37248/50000]\tLoss: 0.3805\tLR: 0.000337\nTraining Epoch: 23 [37376/50000]\tLoss: 0.2503\tLR: 0.000337\nTraining Epoch: 23 [37504/50000]\tLoss: 0.2344\tLR: 0.000337\nTraining Epoch: 23 [37632/50000]\tLoss: 0.2311\tLR: 0.000337\nTraining Epoch: 23 [37760/50000]\tLoss: 0.2775\tLR: 0.000337\nTraining Epoch: 23 [37888/50000]\tLoss: 0.2568\tLR: 0.000337\nTraining Epoch: 23 [38016/50000]\tLoss: 0.2100\tLR: 0.000337\nTraining Epoch: 23 [38144/50000]\tLoss: 0.2704\tLR: 0.000337\nTraining Epoch: 23 [38272/50000]\tLoss: 0.3116\tLR: 0.000337\nTraining Epoch: 23 [38400/50000]\tLoss: 0.2136\tLR: 0.000337\nTraining Epoch: 23 [38528/50000]\tLoss: 0.2203\tLR: 0.000337\nTraining Epoch: 23 [38656/50000]\tLoss: 0.2899\tLR: 0.000337\nTraining Epoch: 23 [38784/50000]\tLoss: 0.2332\tLR: 0.000337\nTraining Epoch: 23 [38912/50000]\tLoss: 0.2689\tLR: 0.000337\nTraining Epoch: 23 [39040/50000]\tLoss: 0.1886\tLR: 0.000337\nTraining Epoch: 23 [39168/50000]\tLoss: 0.1599\tLR: 0.000337\nTraining Epoch: 23 [39296/50000]\tLoss: 0.3206\tLR: 0.000337\nTraining Epoch: 23 [39424/50000]\tLoss: 0.1364\tLR: 0.000337\nTraining Epoch: 23 [39552/50000]\tLoss: 0.2640\tLR: 0.000337\nTraining Epoch: 23 [39680/50000]\tLoss: 0.2618\tLR: 0.000337\nTraining Epoch: 23 [39808/50000]\tLoss: 0.2293\tLR: 0.000337\nTraining Epoch: 23 [39936/50000]\tLoss: 0.2028\tLR: 0.000337\nTraining Epoch: 23 [40064/50000]\tLoss: 0.1989\tLR: 0.000337\nTraining Epoch: 23 [40192/50000]\tLoss: 0.2300\tLR: 0.000337\nTraining Epoch: 23 [40320/50000]\tLoss: 0.1270\tLR: 0.000337\nTraining Epoch: 23 [40448/50000]\tLoss: 0.2194\tLR: 0.000337\nTraining Epoch: 23 [40576/50000]\tLoss: 0.3538\tLR: 0.000337\nTraining Epoch: 23 [40704/50000]\tLoss: 0.1833\tLR: 0.000337\nTraining Epoch: 23 [40832/50000]\tLoss: 0.2170\tLR: 0.000337\nTraining Epoch: 23 [40960/50000]\tLoss: 0.2964\tLR: 0.000337\nTraining Epoch: 23 [41088/50000]\tLoss: 0.1987\tLR: 0.000337\nTraining Epoch: 23 [41216/50000]\tLoss: 0.2414\tLR: 0.000337\nTraining Epoch: 23 [41344/50000]\tLoss: 0.3070\tLR: 0.000337\nTraining Epoch: 23 [41472/50000]\tLoss: 0.2215\tLR: 0.000337\nTraining Epoch: 23 [41600/50000]\tLoss: 0.2235\tLR: 0.000337\nTraining Epoch: 23 [41728/50000]\tLoss: 0.3792\tLR: 0.000337\nTraining Epoch: 23 [41856/50000]\tLoss: 0.1638\tLR: 0.000337\nTraining Epoch: 23 [41984/50000]\tLoss: 0.2118\tLR: 0.000337\nTraining Epoch: 23 [42112/50000]\tLoss: 0.2627\tLR: 0.000337\nTraining Epoch: 23 [42240/50000]\tLoss: 0.2470\tLR: 0.000337\nTraining Epoch: 23 [42368/50000]\tLoss: 0.1898\tLR: 0.000337\nTraining Epoch: 23 [42496/50000]\tLoss: 0.2429\tLR: 0.000337\nTraining Epoch: 23 [42624/50000]\tLoss: 0.3188\tLR: 0.000337\nTraining Epoch: 23 [42752/50000]\tLoss: 0.2740\tLR: 0.000337\nTraining Epoch: 23 [42880/50000]\tLoss: 0.2220\tLR: 0.000337\nTraining Epoch: 23 [43008/50000]\tLoss: 0.2804\tLR: 0.000337\nTraining Epoch: 23 [43136/50000]\tLoss: 0.2764\tLR: 0.000337\nTraining Epoch: 23 [43264/50000]\tLoss: 0.1680\tLR: 0.000337\nTraining Epoch: 23 [43392/50000]\tLoss: 0.2595\tLR: 0.000337\nTraining Epoch: 23 [43520/50000]\tLoss: 0.2596\tLR: 0.000337\nTraining Epoch: 23 [43648/50000]\tLoss: 0.2406\tLR: 0.000337\nTraining Epoch: 23 [43776/50000]\tLoss: 0.2499\tLR: 0.000337\nTraining Epoch: 23 [43904/50000]\tLoss: 0.1375\tLR: 0.000337\nTraining Epoch: 23 [44032/50000]\tLoss: 0.2646\tLR: 0.000337\nTraining Epoch: 23 [44160/50000]\tLoss: 0.3217\tLR: 0.000337\nTraining Epoch: 23 [44288/50000]\tLoss: 0.2856\tLR: 0.000337\nTraining Epoch: 23 [44416/50000]\tLoss: 0.2435\tLR: 0.000337\nTraining Epoch: 23 [44544/50000]\tLoss: 0.2557\tLR: 0.000337\nTraining Epoch: 23 [44672/50000]\tLoss: 0.3279\tLR: 0.000337\nTraining Epoch: 23 [44800/50000]\tLoss: 0.2447\tLR: 0.000337\nTraining Epoch: 23 [44928/50000]\tLoss: 0.4710\tLR: 0.000337\nTraining Epoch: 23 [45056/50000]\tLoss: 0.1714\tLR: 0.000337\nTraining Epoch: 23 [45184/50000]\tLoss: 0.2973\tLR: 0.000337\nTraining Epoch: 23 [45312/50000]\tLoss: 0.2189\tLR: 0.000337\nTraining Epoch: 23 [45440/50000]\tLoss: 0.1836\tLR: 0.000337\nTraining Epoch: 23 [45568/50000]\tLoss: 0.2196\tLR: 0.000337\nTraining Epoch: 23 [45696/50000]\tLoss: 0.3190\tLR: 0.000337\nTraining Epoch: 23 [45824/50000]\tLoss: 0.3455\tLR: 0.000337\nTraining Epoch: 23 [45952/50000]\tLoss: 0.1631\tLR: 0.000337\nTraining Epoch: 23 [46080/50000]\tLoss: 0.2748\tLR: 0.000337\nTraining Epoch: 23 [46208/50000]\tLoss: 0.2098\tLR: 0.000337\nTraining Epoch: 23 [46336/50000]\tLoss: 0.2726\tLR: 0.000337\nTraining Epoch: 23 [46464/50000]\tLoss: 0.2655\tLR: 0.000337\nTraining Epoch: 23 [46592/50000]\tLoss: 0.2701\tLR: 0.000337\nTraining Epoch: 23 [46720/50000]\tLoss: 0.2657\tLR: 0.000337\nTraining Epoch: 23 [46848/50000]\tLoss: 0.2621\tLR: 0.000337\nTraining Epoch: 23 [46976/50000]\tLoss: 0.2582\tLR: 0.000337\nTraining Epoch: 23 [47104/50000]\tLoss: 0.2904\tLR: 0.000337\nTraining Epoch: 23 [47232/50000]\tLoss: 0.2700\tLR: 0.000337\nTraining Epoch: 23 [47360/50000]\tLoss: 0.2290\tLR: 0.000337\nTraining Epoch: 23 [47488/50000]\tLoss: 0.3797\tLR: 0.000337\nTraining Epoch: 23 [47616/50000]\tLoss: 0.2494\tLR: 0.000337\nTraining Epoch: 23 [47744/50000]\tLoss: 0.1514\tLR: 0.000337\nTraining Epoch: 23 [47872/50000]\tLoss: 0.1995\tLR: 0.000337\nTraining Epoch: 23 [48000/50000]\tLoss: 0.2611\tLR: 0.000337\nTraining Epoch: 23 [48128/50000]\tLoss: 0.2151\tLR: 0.000337\nTraining Epoch: 23 [48256/50000]\tLoss: 0.2758\tLR: 0.000337\nTraining Epoch: 23 [48384/50000]\tLoss: 0.2812\tLR: 0.000337\nTraining Epoch: 23 [48512/50000]\tLoss: 0.2298\tLR: 0.000337\nTraining Epoch: 23 [48640/50000]\tLoss: 0.1705\tLR: 0.000337\nTraining Epoch: 23 [48768/50000]\tLoss: 0.2934\tLR: 0.000337\nTraining Epoch: 23 [48896/50000]\tLoss: 0.2188\tLR: 0.000337\nTraining Epoch: 23 [49024/50000]\tLoss: 0.3789\tLR: 0.000337\nTraining Epoch: 23 [49152/50000]\tLoss: 0.1747\tLR: 0.000337\nTraining Epoch: 23 [49280/50000]\tLoss: 0.1768\tLR: 0.000337\nTraining Epoch: 23 [49408/50000]\tLoss: 0.2218\tLR: 0.000337\nTraining Epoch: 23 [49536/50000]\tLoss: 0.1945\tLR: 0.000337\nTraining Epoch: 23 [49664/50000]\tLoss: 0.1991\tLR: 0.000337\nTraining Epoch: 23 [49792/50000]\tLoss: 0.2630\tLR: 0.000337\nTraining Epoch: 23 [49920/50000]\tLoss: 0.2164\tLR: 0.000337\nTraining Epoch: 23 [50000/50000]\tLoss: 0.4192\tLR: 0.000337\nTest set: Average loss: 0.0024, Accuracy: 0.8995\n\nTraining Epoch: 24 [128/50000]\tLoss: 0.2491\tLR: 0.000337\nTraining Epoch: 24 [256/50000]\tLoss: 0.3512\tLR: 0.000337\nTraining Epoch: 24 [384/50000]\tLoss: 0.1713\tLR: 0.000337\nTraining Epoch: 24 [512/50000]\tLoss: 0.2307\tLR: 0.000337\nTraining Epoch: 24 [640/50000]\tLoss: 0.3416\tLR: 0.000337\nTraining Epoch: 24 [768/50000]\tLoss: 0.3275\tLR: 0.000337\nTraining Epoch: 24 [896/50000]\tLoss: 0.2606\tLR: 0.000337\nTraining Epoch: 24 [1024/50000]\tLoss: 0.3272\tLR: 0.000337\nTraining Epoch: 24 [1152/50000]\tLoss: 0.1809\tLR: 0.000337\nTraining Epoch: 24 [1280/50000]\tLoss: 0.2414\tLR: 0.000337\nTraining Epoch: 24 [1408/50000]\tLoss: 0.2212\tLR: 0.000337\nTraining Epoch: 24 [1536/50000]\tLoss: 0.2798\tLR: 0.000337\nTraining Epoch: 24 [1664/50000]\tLoss: 0.2495\tLR: 0.000337\nTraining Epoch: 24 [1792/50000]\tLoss: 0.2029\tLR: 0.000337\nTraining Epoch: 24 [1920/50000]\tLoss: 0.2122\tLR: 0.000337\nTraining Epoch: 24 [2048/50000]\tLoss: 0.2162\tLR: 0.000337\nTraining Epoch: 24 [2176/50000]\tLoss: 0.3006\tLR: 0.000337\nTraining Epoch: 24 [2304/50000]\tLoss: 0.3090\tLR: 0.000337\nTraining Epoch: 24 [2432/50000]\tLoss: 0.3093\tLR: 0.000337\nTraining Epoch: 24 [2560/50000]\tLoss: 0.2386\tLR: 0.000337\nTraining Epoch: 24 [2688/50000]\tLoss: 0.2541\tLR: 0.000337\nTraining Epoch: 24 [2816/50000]\tLoss: 0.3302\tLR: 0.000337\nTraining Epoch: 24 [2944/50000]\tLoss: 0.2312\tLR: 0.000337\nTraining Epoch: 24 [3072/50000]\tLoss: 0.2298\tLR: 0.000337\nTraining Epoch: 24 [3200/50000]\tLoss: 0.2392\tLR: 0.000337\nTraining Epoch: 24 [3328/50000]\tLoss: 0.3003\tLR: 0.000337\nTraining Epoch: 24 [3456/50000]\tLoss: 0.2380\tLR: 0.000337\nTraining Epoch: 24 [3584/50000]\tLoss: 0.2305\tLR: 0.000337\nTraining Epoch: 24 [3712/50000]\tLoss: 0.2704\tLR: 0.000337\nTraining Epoch: 24 [3840/50000]\tLoss: 0.1727\tLR: 0.000337\nTraining Epoch: 24 [3968/50000]\tLoss: 0.2664\tLR: 0.000337\nTraining Epoch: 24 [4096/50000]\tLoss: 0.3718\tLR: 0.000337\nTraining Epoch: 24 [4224/50000]\tLoss: 0.2100\tLR: 0.000337\nTraining Epoch: 24 [4352/50000]\tLoss: 0.2204\tLR: 0.000337\nTraining Epoch: 24 [4480/50000]\tLoss: 0.2147\tLR: 0.000337\nTraining Epoch: 24 [4608/50000]\tLoss: 0.2797\tLR: 0.000337\nTraining Epoch: 24 [4736/50000]\tLoss: 0.2230\tLR: 0.000337\nTraining Epoch: 24 [4864/50000]\tLoss: 0.2778\tLR: 0.000337\nTraining Epoch: 24 [4992/50000]\tLoss: 0.2558\tLR: 0.000337\nTraining Epoch: 24 [5120/50000]\tLoss: 0.2461\tLR: 0.000337\nTraining Epoch: 24 [5248/50000]\tLoss: 0.2229\tLR: 0.000337\nTraining Epoch: 24 [5376/50000]\tLoss: 0.3473\tLR: 0.000337\nTraining Epoch: 24 [5504/50000]\tLoss: 0.2863\tLR: 0.000337\nTraining Epoch: 24 [5632/50000]\tLoss: 0.2322\tLR: 0.000337\nTraining Epoch: 24 [5760/50000]\tLoss: 0.1831\tLR: 0.000337\nTraining Epoch: 24 [5888/50000]\tLoss: 0.3226\tLR: 0.000337\nTraining Epoch: 24 [6016/50000]\tLoss: 0.1680\tLR: 0.000337\nTraining Epoch: 24 [6144/50000]\tLoss: 0.3240\tLR: 0.000337\nTraining Epoch: 24 [6272/50000]\tLoss: 0.2458\tLR: 0.000337\nTraining Epoch: 24 [6400/50000]\tLoss: 0.2478\tLR: 0.000337\nTraining Epoch: 24 [6528/50000]\tLoss: 0.2867\tLR: 0.000337\nTraining Epoch: 24 [6656/50000]\tLoss: 0.2894\tLR: 0.000337\nTraining Epoch: 24 [6784/50000]\tLoss: 0.1788\tLR: 0.000337\nTraining Epoch: 24 [6912/50000]\tLoss: 0.2735\tLR: 0.000337\nTraining Epoch: 24 [7040/50000]\tLoss: 0.2715\tLR: 0.000337\nTraining Epoch: 24 [7168/50000]\tLoss: 0.2279\tLR: 0.000337\nTraining Epoch: 24 [7296/50000]\tLoss: 0.4720\tLR: 0.000337\nTraining Epoch: 24 [7424/50000]\tLoss: 0.2588\tLR: 0.000337\nTraining Epoch: 24 [7552/50000]\tLoss: 0.1880\tLR: 0.000337\nTraining Epoch: 24 [7680/50000]\tLoss: 0.1739\tLR: 0.000337\nTraining Epoch: 24 [7808/50000]\tLoss: 0.1936\tLR: 0.000337\nTraining Epoch: 24 [7936/50000]\tLoss: 0.1762\tLR: 0.000337\nTraining Epoch: 24 [8064/50000]\tLoss: 0.2616\tLR: 0.000337\nTraining Epoch: 24 [8192/50000]\tLoss: 0.2670\tLR: 0.000337\nTraining Epoch: 24 [8320/50000]\tLoss: 0.2171\tLR: 0.000337\nTraining Epoch: 24 [8448/50000]\tLoss: 0.2358\tLR: 0.000337\nTraining Epoch: 24 [8576/50000]\tLoss: 0.2530\tLR: 0.000337\nTraining Epoch: 24 [8704/50000]\tLoss: 0.2317\tLR: 0.000337\nTraining Epoch: 24 [8832/50000]\tLoss: 0.2999\tLR: 0.000337\nTraining Epoch: 24 [8960/50000]\tLoss: 0.1417\tLR: 0.000337\nTraining Epoch: 24 [9088/50000]\tLoss: 0.2065\tLR: 0.000337\nTraining Epoch: 24 [9216/50000]\tLoss: 0.3008\tLR: 0.000337\nTraining Epoch: 24 [9344/50000]\tLoss: 0.2543\tLR: 0.000337\nTraining Epoch: 24 [9472/50000]\tLoss: 0.2585\tLR: 0.000337\nTraining Epoch: 24 [9600/50000]\tLoss: 0.2549\tLR: 0.000337\nTraining Epoch: 24 [9728/50000]\tLoss: 0.1497\tLR: 0.000337\nTraining Epoch: 24 [9856/50000]\tLoss: 0.2338\tLR: 0.000337\nTraining Epoch: 24 [9984/50000]\tLoss: 0.2861\tLR: 0.000337\nTraining Epoch: 24 [10112/50000]\tLoss: 0.2152\tLR: 0.000337\nTraining Epoch: 24 [10240/50000]\tLoss: 0.3375\tLR: 0.000337\nTraining Epoch: 24 [10368/50000]\tLoss: 0.2142\tLR: 0.000337\nTraining Epoch: 24 [10496/50000]\tLoss: 0.2076\tLR: 0.000337\nTraining Epoch: 24 [10624/50000]\tLoss: 0.3138\tLR: 0.000337\nTraining Epoch: 24 [10752/50000]\tLoss: 0.3157\tLR: 0.000337\nTraining Epoch: 24 [10880/50000]\tLoss: 0.2182\tLR: 0.000337\nTraining Epoch: 24 [11008/50000]\tLoss: 0.2197\tLR: 0.000337\nTraining Epoch: 24 [11136/50000]\tLoss: 0.2137\tLR: 0.000337\nTraining Epoch: 24 [11264/50000]\tLoss: 0.2635\tLR: 0.000337\nTraining Epoch: 24 [11392/50000]\tLoss: 0.2292\tLR: 0.000337\nTraining Epoch: 24 [11520/50000]\tLoss: 0.2492\tLR: 0.000337\nTraining Epoch: 24 [11648/50000]\tLoss: 0.2598\tLR: 0.000337\nTraining Epoch: 24 [11776/50000]\tLoss: 0.2613\tLR: 0.000337\nTraining Epoch: 24 [11904/50000]\tLoss: 0.2033\tLR: 0.000337\nTraining Epoch: 24 [12032/50000]\tLoss: 0.1986\tLR: 0.000337\nTraining Epoch: 24 [12160/50000]\tLoss: 0.2637\tLR: 0.000337\nTraining Epoch: 24 [12288/50000]\tLoss: 0.2511\tLR: 0.000337\nTraining Epoch: 24 [12416/50000]\tLoss: 0.2256\tLR: 0.000337\nTraining Epoch: 24 [12544/50000]\tLoss: 0.2375\tLR: 0.000337\nTraining Epoch: 24 [12672/50000]\tLoss: 0.2962\tLR: 0.000337\nTraining Epoch: 24 [12800/50000]\tLoss: 0.1519\tLR: 0.000337\nTraining Epoch: 24 [12928/50000]\tLoss: 0.2264\tLR: 0.000337\nTraining Epoch: 24 [13056/50000]\tLoss: 0.3335\tLR: 0.000337\nTraining Epoch: 24 [13184/50000]\tLoss: 0.2604\tLR: 0.000337\nTraining Epoch: 24 [13312/50000]\tLoss: 0.2147\tLR: 0.000337\nTraining Epoch: 24 [13440/50000]\tLoss: 0.1784\tLR: 0.000337\nTraining Epoch: 24 [13568/50000]\tLoss: 0.2479\tLR: 0.000337\nTraining Epoch: 24 [13696/50000]\tLoss: 0.2107\tLR: 0.000337\nTraining Epoch: 24 [13824/50000]\tLoss: 0.2781\tLR: 0.000337\nTraining Epoch: 24 [13952/50000]\tLoss: 0.2626\tLR: 0.000337\nTraining Epoch: 24 [14080/50000]\tLoss: 0.2034\tLR: 0.000337\nTraining Epoch: 24 [14208/50000]\tLoss: 0.2358\tLR: 0.000337\nTraining Epoch: 24 [14336/50000]\tLoss: 0.2068\tLR: 0.000337\nTraining Epoch: 24 [14464/50000]\tLoss: 0.3259\tLR: 0.000337\nTraining Epoch: 24 [14592/50000]\tLoss: 0.2727\tLR: 0.000337\nTraining Epoch: 24 [14720/50000]\tLoss: 0.1946\tLR: 0.000337\nTraining Epoch: 24 [14848/50000]\tLoss: 0.1702\tLR: 0.000337\nTraining Epoch: 24 [14976/50000]\tLoss: 0.2242\tLR: 0.000337\nTraining Epoch: 24 [15104/50000]\tLoss: 0.3089\tLR: 0.000337\nTraining Epoch: 24 [15232/50000]\tLoss: 0.3031\tLR: 0.000337\nTraining Epoch: 24 [15360/50000]\tLoss: 0.2012\tLR: 0.000337\nTraining Epoch: 24 [15488/50000]\tLoss: 0.3210\tLR: 0.000337\nTraining Epoch: 24 [15616/50000]\tLoss: 0.2609\tLR: 0.000337\nTraining Epoch: 24 [15744/50000]\tLoss: 0.2224\tLR: 0.000337\nTraining Epoch: 24 [15872/50000]\tLoss: 0.1605\tLR: 0.000337\nTraining Epoch: 24 [16000/50000]\tLoss: 0.1805\tLR: 0.000337\nTraining Epoch: 24 [16128/50000]\tLoss: 0.1959\tLR: 0.000337\nTraining Epoch: 24 [16256/50000]\tLoss: 0.1848\tLR: 0.000337\nTraining Epoch: 24 [16384/50000]\tLoss: 0.1801\tLR: 0.000337\nTraining Epoch: 24 [16512/50000]\tLoss: 0.2669\tLR: 0.000337\nTraining Epoch: 24 [16640/50000]\tLoss: 0.1624\tLR: 0.000337\nTraining Epoch: 24 [16768/50000]\tLoss: 0.1812\tLR: 0.000337\nTraining Epoch: 24 [16896/50000]\tLoss: 0.1650\tLR: 0.000337\nTraining Epoch: 24 [17024/50000]\tLoss: 0.2399\tLR: 0.000337\nTraining Epoch: 24 [17152/50000]\tLoss: 0.1836\tLR: 0.000337\nTraining Epoch: 24 [17280/50000]\tLoss: 0.2364\tLR: 0.000337\nTraining Epoch: 24 [17408/50000]\tLoss: 0.2449\tLR: 0.000337\nTraining Epoch: 24 [17536/50000]\tLoss: 0.2254\tLR: 0.000337\nTraining Epoch: 24 [17664/50000]\tLoss: 0.1447\tLR: 0.000337\nTraining Epoch: 24 [17792/50000]\tLoss: 0.2614\tLR: 0.000337\nTraining Epoch: 24 [17920/50000]\tLoss: 0.1830\tLR: 0.000337\nTraining Epoch: 24 [18048/50000]\tLoss: 0.2538\tLR: 0.000337\nTraining Epoch: 24 [18176/50000]\tLoss: 0.2214\tLR: 0.000337\nTraining Epoch: 24 [18304/50000]\tLoss: 0.1902\tLR: 0.000337\nTraining Epoch: 24 [18432/50000]\tLoss: 0.2954\tLR: 0.000337\nTraining Epoch: 24 [18560/50000]\tLoss: 0.3979\tLR: 0.000337\nTraining Epoch: 24 [18688/50000]\tLoss: 0.3224\tLR: 0.000337\nTraining Epoch: 24 [18816/50000]\tLoss: 0.3380\tLR: 0.000337\nTraining Epoch: 24 [18944/50000]\tLoss: 0.1817\tLR: 0.000337\nTraining Epoch: 24 [19072/50000]\tLoss: 0.2292\tLR: 0.000337\nTraining Epoch: 24 [19200/50000]\tLoss: 0.3838\tLR: 0.000337\nTraining Epoch: 24 [19328/50000]\tLoss: 0.3023\tLR: 0.000337\nTraining Epoch: 24 [19456/50000]\tLoss: 0.2823\tLR: 0.000337\nTraining Epoch: 24 [19584/50000]\tLoss: 0.2182\tLR: 0.000337\nTraining Epoch: 24 [19712/50000]\tLoss: 0.2374\tLR: 0.000337\nTraining Epoch: 24 [19840/50000]\tLoss: 0.3029\tLR: 0.000337\nTraining Epoch: 24 [19968/50000]\tLoss: 0.2762\tLR: 0.000337\nTraining Epoch: 24 [20096/50000]\tLoss: 0.2145\tLR: 0.000337\nTraining Epoch: 24 [20224/50000]\tLoss: 0.2529\tLR: 0.000337\nTraining Epoch: 24 [20352/50000]\tLoss: 0.1649\tLR: 0.000337\nTraining Epoch: 24 [20480/50000]\tLoss: 0.2875\tLR: 0.000337\nTraining Epoch: 24 [20608/50000]\tLoss: 0.1885\tLR: 0.000337\nTraining Epoch: 24 [20736/50000]\tLoss: 0.3400\tLR: 0.000337\nTraining Epoch: 24 [20864/50000]\tLoss: 0.2140\tLR: 0.000337\nTraining Epoch: 24 [20992/50000]\tLoss: 0.2267\tLR: 0.000337\nTraining Epoch: 24 [21120/50000]\tLoss: 0.2265\tLR: 0.000337\nTraining Epoch: 24 [21248/50000]\tLoss: 0.2316\tLR: 0.000337\nTraining Epoch: 24 [21376/50000]\tLoss: 0.2769\tLR: 0.000337\nTraining Epoch: 24 [21504/50000]\tLoss: 0.3218\tLR: 0.000337\nTraining Epoch: 24 [21632/50000]\tLoss: 0.1776\tLR: 0.000337\nTraining Epoch: 24 [21760/50000]\tLoss: 0.2048\tLR: 0.000337\nTraining Epoch: 24 [21888/50000]\tLoss: 0.2772\tLR: 0.000337\nTraining Epoch: 24 [22016/50000]\tLoss: 0.1629\tLR: 0.000337\nTraining Epoch: 24 [22144/50000]\tLoss: 0.2684\tLR: 0.000337\nTraining Epoch: 24 [22272/50000]\tLoss: 0.2035\tLR: 0.000337\nTraining Epoch: 24 [22400/50000]\tLoss: 0.2307\tLR: 0.000337\nTraining Epoch: 24 [22528/50000]\tLoss: 0.2237\tLR: 0.000337\nTraining Epoch: 24 [22656/50000]\tLoss: 0.2608\tLR: 0.000337\nTraining Epoch: 24 [22784/50000]\tLoss: 0.1905\tLR: 0.000337\nTraining Epoch: 24 [22912/50000]\tLoss: 0.1724\tLR: 0.000337\nTraining Epoch: 24 [23040/50000]\tLoss: 0.2879\tLR: 0.000337\nTraining Epoch: 24 [23168/50000]\tLoss: 0.2164\tLR: 0.000337\nTraining Epoch: 24 [23296/50000]\tLoss: 0.2022\tLR: 0.000337\nTraining Epoch: 24 [23424/50000]\tLoss: 0.2056\tLR: 0.000337\nTraining Epoch: 24 [23552/50000]\tLoss: 0.2775\tLR: 0.000337\nTraining Epoch: 24 [23680/50000]\tLoss: 0.3058\tLR: 0.000337\nTraining Epoch: 24 [23808/50000]\tLoss: 0.2229\tLR: 0.000337\nTraining Epoch: 24 [23936/50000]\tLoss: 0.2261\tLR: 0.000337\nTraining Epoch: 24 [24064/50000]\tLoss: 0.3215\tLR: 0.000337\nTraining Epoch: 24 [24192/50000]\tLoss: 0.2961\tLR: 0.000337\nTraining Epoch: 24 [24320/50000]\tLoss: 0.1302\tLR: 0.000337\nTraining Epoch: 24 [24448/50000]\tLoss: 0.2015\tLR: 0.000337\nTraining Epoch: 24 [24576/50000]\tLoss: 0.1701\tLR: 0.000337\nTraining Epoch: 24 [24704/50000]\tLoss: 0.2427\tLR: 0.000337\nTraining Epoch: 24 [24832/50000]\tLoss: 0.2995\tLR: 0.000337\nTraining Epoch: 24 [24960/50000]\tLoss: 0.3554\tLR: 0.000337\nTraining Epoch: 24 [25088/50000]\tLoss: 0.2112\tLR: 0.000337\nTraining Epoch: 24 [25216/50000]\tLoss: 0.2747\tLR: 0.000337\nTraining Epoch: 24 [25344/50000]\tLoss: 0.1495\tLR: 0.000337\nTraining Epoch: 24 [25472/50000]\tLoss: 0.1591\tLR: 0.000337\nTraining Epoch: 24 [25600/50000]\tLoss: 0.1523\tLR: 0.000337\nTraining Epoch: 24 [25728/50000]\tLoss: 0.1734\tLR: 0.000337\nTraining Epoch: 24 [25856/50000]\tLoss: 0.3306\tLR: 0.000337\nTraining Epoch: 24 [25984/50000]\tLoss: 0.1835\tLR: 0.000337\nTraining Epoch: 24 [26112/50000]\tLoss: 0.3022\tLR: 0.000337\nTraining Epoch: 24 [26240/50000]\tLoss: 0.2292\tLR: 0.000337\nTraining Epoch: 24 [26368/50000]\tLoss: 0.2953\tLR: 0.000337\nTraining Epoch: 24 [26496/50000]\tLoss: 0.3327\tLR: 0.000337\nTraining Epoch: 24 [26624/50000]\tLoss: 0.2560\tLR: 0.000337\nTraining Epoch: 24 [26752/50000]\tLoss: 0.1802\tLR: 0.000337\nTraining Epoch: 24 [26880/50000]\tLoss: 0.2701\tLR: 0.000337\nTraining Epoch: 24 [27008/50000]\tLoss: 0.1183\tLR: 0.000337\nTraining Epoch: 24 [27136/50000]\tLoss: 0.2969\tLR: 0.000337\nTraining Epoch: 24 [27264/50000]\tLoss: 0.3327\tLR: 0.000337\nTraining Epoch: 24 [27392/50000]\tLoss: 0.1922\tLR: 0.000337\nTraining Epoch: 24 [27520/50000]\tLoss: 0.1457\tLR: 0.000337\nTraining Epoch: 24 [27648/50000]\tLoss: 0.3304\tLR: 0.000337\nTraining Epoch: 24 [27776/50000]\tLoss: 0.2630\tLR: 0.000337\nTraining Epoch: 24 [27904/50000]\tLoss: 0.2450\tLR: 0.000337\nTraining Epoch: 24 [28032/50000]\tLoss: 0.3208\tLR: 0.000337\nTraining Epoch: 24 [28160/50000]\tLoss: 0.1291\tLR: 0.000337\nTraining Epoch: 24 [28288/50000]\tLoss: 0.3984\tLR: 0.000337\nTraining Epoch: 24 [28416/50000]\tLoss: 0.2210\tLR: 0.000337\nTraining Epoch: 24 [28544/50000]\tLoss: 0.1897\tLR: 0.000337\nTraining Epoch: 24 [28672/50000]\tLoss: 0.2375\tLR: 0.000337\nTraining Epoch: 24 [28800/50000]\tLoss: 0.2765\tLR: 0.000337\nTraining Epoch: 24 [28928/50000]\tLoss: 0.2641\tLR: 0.000337\nTraining Epoch: 24 [29056/50000]\tLoss: 0.3005\tLR: 0.000337\nTraining Epoch: 24 [29184/50000]\tLoss: 0.3579\tLR: 0.000337\nTraining Epoch: 24 [29312/50000]\tLoss: 0.2013\tLR: 0.000337\nTraining Epoch: 24 [29440/50000]\tLoss: 0.1587\tLR: 0.000337\nTraining Epoch: 24 [29568/50000]\tLoss: 0.2291\tLR: 0.000337\nTraining Epoch: 24 [29696/50000]\tLoss: 0.2531\tLR: 0.000337\nTraining Epoch: 24 [29824/50000]\tLoss: 0.1909\tLR: 0.000337\nTraining Epoch: 24 [29952/50000]\tLoss: 0.2994\tLR: 0.000337\nTraining Epoch: 24 [30080/50000]\tLoss: 0.2472\tLR: 0.000337\nTraining Epoch: 24 [30208/50000]\tLoss: 0.1974\tLR: 0.000337\nTraining Epoch: 24 [30336/50000]\tLoss: 0.2195\tLR: 0.000337\nTraining Epoch: 24 [30464/50000]\tLoss: 0.1411\tLR: 0.000337\nTraining Epoch: 24 [30592/50000]\tLoss: 0.1859\tLR: 0.000337\nTraining Epoch: 24 [30720/50000]\tLoss: 0.2517\tLR: 0.000337\nTraining Epoch: 24 [30848/50000]\tLoss: 0.2222\tLR: 0.000337\nTraining Epoch: 24 [30976/50000]\tLoss: 0.2276\tLR: 0.000337\nTraining Epoch: 24 [31104/50000]\tLoss: 0.2625\tLR: 0.000337\nTraining Epoch: 24 [31232/50000]\tLoss: 0.2472\tLR: 0.000337\nTraining Epoch: 24 [31360/50000]\tLoss: 0.2283\tLR: 0.000337\nTraining Epoch: 24 [31488/50000]\tLoss: 0.2731\tLR: 0.000337\nTraining Epoch: 24 [31616/50000]\tLoss: 0.3161\tLR: 0.000337\nTraining Epoch: 24 [31744/50000]\tLoss: 0.2727\tLR: 0.000337\nTraining Epoch: 24 [31872/50000]\tLoss: 0.2277\tLR: 0.000337\nTraining Epoch: 24 [32000/50000]\tLoss: 0.2978\tLR: 0.000337\nTraining Epoch: 24 [32128/50000]\tLoss: 0.1600\tLR: 0.000337\nTraining Epoch: 24 [32256/50000]\tLoss: 0.2269\tLR: 0.000337\nTraining Epoch: 24 [32384/50000]\tLoss: 0.2169\tLR: 0.000337\nTraining Epoch: 24 [32512/50000]\tLoss: 0.1743\tLR: 0.000337\nTraining Epoch: 24 [32640/50000]\tLoss: 0.2370\tLR: 0.000337\nTraining Epoch: 24 [32768/50000]\tLoss: 0.3557\tLR: 0.000337\nTraining Epoch: 24 [32896/50000]\tLoss: 0.2776\tLR: 0.000337\nTraining Epoch: 24 [33024/50000]\tLoss: 0.3143\tLR: 0.000337\nTraining Epoch: 24 [33152/50000]\tLoss: 0.2541\tLR: 0.000337\nTraining Epoch: 24 [33280/50000]\tLoss: 0.1412\tLR: 0.000337\nTraining Epoch: 24 [33408/50000]\tLoss: 0.2214\tLR: 0.000337\nTraining Epoch: 24 [33536/50000]\tLoss: 0.2954\tLR: 0.000337\nTraining Epoch: 24 [33664/50000]\tLoss: 0.2218\tLR: 0.000337\nTraining Epoch: 24 [33792/50000]\tLoss: 0.3352\tLR: 0.000337\nTraining Epoch: 24 [33920/50000]\tLoss: 0.3046\tLR: 0.000337\nTraining Epoch: 24 [34048/50000]\tLoss: 0.3489\tLR: 0.000337\nTraining Epoch: 24 [34176/50000]\tLoss: 0.3322\tLR: 0.000337\nTraining Epoch: 24 [34304/50000]\tLoss: 0.2205\tLR: 0.000337\nTraining Epoch: 24 [34432/50000]\tLoss: 0.2007\tLR: 0.000337\nTraining Epoch: 24 [34560/50000]\tLoss: 0.3298\tLR: 0.000337\nTraining Epoch: 24 [34688/50000]\tLoss: 0.3497\tLR: 0.000337\nTraining Epoch: 24 [34816/50000]\tLoss: 0.1635\tLR: 0.000337\nTraining Epoch: 24 [34944/50000]\tLoss: 0.3641\tLR: 0.000337\nTraining Epoch: 24 [35072/50000]\tLoss: 0.3859\tLR: 0.000337\nTraining Epoch: 24 [35200/50000]\tLoss: 0.1617\tLR: 0.000337\nTraining Epoch: 24 [35328/50000]\tLoss: 0.2883\tLR: 0.000337\nTraining Epoch: 24 [35456/50000]\tLoss: 0.2223\tLR: 0.000337\nTraining Epoch: 24 [35584/50000]\tLoss: 0.2087\tLR: 0.000337\nTraining Epoch: 24 [35712/50000]\tLoss: 0.2571\tLR: 0.000337\nTraining Epoch: 24 [35840/50000]\tLoss: 0.1605\tLR: 0.000337\nTraining Epoch: 24 [35968/50000]\tLoss: 0.3167\tLR: 0.000337\nTraining Epoch: 24 [36096/50000]\tLoss: 0.1951\tLR: 0.000337\nTraining Epoch: 24 [36224/50000]\tLoss: 0.3223\tLR: 0.000337\nTraining Epoch: 24 [36352/50000]\tLoss: 0.2847\tLR: 0.000337\nTraining Epoch: 24 [36480/50000]\tLoss: 0.1981\tLR: 0.000337\nTraining Epoch: 24 [36608/50000]\tLoss: 0.3211\tLR: 0.000337\nTraining Epoch: 24 [36736/50000]\tLoss: 0.1818\tLR: 0.000337\nTraining Epoch: 24 [36864/50000]\tLoss: 0.2446\tLR: 0.000337\nTraining Epoch: 24 [36992/50000]\tLoss: 0.1962\tLR: 0.000337\nTraining Epoch: 24 [37120/50000]\tLoss: 0.2237\tLR: 0.000337\nTraining Epoch: 24 [37248/50000]\tLoss: 0.2613\tLR: 0.000337\nTraining Epoch: 24 [37376/50000]\tLoss: 0.2744\tLR: 0.000337\nTraining Epoch: 24 [37504/50000]\tLoss: 0.1977\tLR: 0.000337\nTraining Epoch: 24 [37632/50000]\tLoss: 0.2121\tLR: 0.000337\nTraining Epoch: 24 [37760/50000]\tLoss: 0.2903\tLR: 0.000337\nTraining Epoch: 24 [37888/50000]\tLoss: 0.2456\tLR: 0.000337\nTraining Epoch: 24 [38016/50000]\tLoss: 0.2210\tLR: 0.000337\nTraining Epoch: 24 [38144/50000]\tLoss: 0.2948\tLR: 0.000337\nTraining Epoch: 24 [38272/50000]\tLoss: 0.3236\tLR: 0.000337\nTraining Epoch: 24 [38400/50000]\tLoss: 0.2498\tLR: 0.000337\nTraining Epoch: 24 [38528/50000]\tLoss: 0.3170\tLR: 0.000337\nTraining Epoch: 24 [38656/50000]\tLoss: 0.1947\tLR: 0.000337\nTraining Epoch: 24 [38784/50000]\tLoss: 0.1541\tLR: 0.000337\nTraining Epoch: 24 [38912/50000]\tLoss: 0.3289\tLR: 0.000337\nTraining Epoch: 24 [39040/50000]\tLoss: 0.2401\tLR: 0.000337\nTraining Epoch: 24 [39168/50000]\tLoss: 0.2390\tLR: 0.000337\nTraining Epoch: 24 [39296/50000]\tLoss: 0.1821\tLR: 0.000337\nTraining Epoch: 24 [39424/50000]\tLoss: 0.2000\tLR: 0.000337\nTraining Epoch: 24 [39552/50000]\tLoss: 0.1889\tLR: 0.000337\nTraining Epoch: 24 [39680/50000]\tLoss: 0.1845\tLR: 0.000337\nTraining Epoch: 24 [39808/50000]\tLoss: 0.2433\tLR: 0.000337\nTraining Epoch: 24 [39936/50000]\tLoss: 0.2291\tLR: 0.000337\nTraining Epoch: 24 [40064/50000]\tLoss: 0.2759\tLR: 0.000337\nTraining Epoch: 24 [40192/50000]\tLoss: 0.1721\tLR: 0.000337\nTraining Epoch: 24 [40320/50000]\tLoss: 0.2435\tLR: 0.000337\nTraining Epoch: 24 [40448/50000]\tLoss: 0.2301\tLR: 0.000337\nTraining Epoch: 24 [40576/50000]\tLoss: 0.2040\tLR: 0.000337\nTraining Epoch: 24 [40704/50000]\tLoss: 0.2884\tLR: 0.000337\nTraining Epoch: 24 [40832/50000]\tLoss: 0.2785\tLR: 0.000337\nTraining Epoch: 24 [40960/50000]\tLoss: 0.2110\tLR: 0.000337\nTraining Epoch: 24 [41088/50000]\tLoss: 0.2086\tLR: 0.000337\nTraining Epoch: 24 [41216/50000]\tLoss: 0.1992\tLR: 0.000337\nTraining Epoch: 24 [41344/50000]\tLoss: 0.2239\tLR: 0.000337\nTraining Epoch: 24 [41472/50000]\tLoss: 0.2498\tLR: 0.000337\nTraining Epoch: 24 [41600/50000]\tLoss: 0.3282\tLR: 0.000337\nTraining Epoch: 24 [41728/50000]\tLoss: 0.3190\tLR: 0.000337\nTraining Epoch: 24 [41856/50000]\tLoss: 0.2519\tLR: 0.000337\nTraining Epoch: 24 [41984/50000]\tLoss: 0.1961\tLR: 0.000337\nTraining Epoch: 24 [42112/50000]\tLoss: 0.2558\tLR: 0.000337\nTraining Epoch: 24 [42240/50000]\tLoss: 0.1994\tLR: 0.000337\nTraining Epoch: 24 [42368/50000]\tLoss: 0.4735\tLR: 0.000337\nTraining Epoch: 24 [42496/50000]\tLoss: 0.1709\tLR: 0.000337\nTraining Epoch: 24 [42624/50000]\tLoss: 0.2514\tLR: 0.000337\nTraining Epoch: 24 [42752/50000]\tLoss: 0.2974\tLR: 0.000337\nTraining Epoch: 24 [42880/50000]\tLoss: 0.2838\tLR: 0.000337\nTraining Epoch: 24 [43008/50000]\tLoss: 0.2095\tLR: 0.000337\nTraining Epoch: 24 [43136/50000]\tLoss: 0.2132\tLR: 0.000337\nTraining Epoch: 24 [43264/50000]\tLoss: 0.2282\tLR: 0.000337\nTraining Epoch: 24 [43392/50000]\tLoss: 0.1995\tLR: 0.000337\nTraining Epoch: 24 [43520/50000]\tLoss: 0.1934\tLR: 0.000337\nTraining Epoch: 24 [43648/50000]\tLoss: 0.2132\tLR: 0.000337\nTraining Epoch: 24 [43776/50000]\tLoss: 0.1529\tLR: 0.000337\nTraining Epoch: 24 [43904/50000]\tLoss: 0.1611\tLR: 0.000337\nTraining Epoch: 24 [44032/50000]\tLoss: 0.2179\tLR: 0.000337\nTraining Epoch: 24 [44160/50000]\tLoss: 0.2311\tLR: 0.000337\nTraining Epoch: 24 [44288/50000]\tLoss: 0.2691\tLR: 0.000337\nTraining Epoch: 24 [44416/50000]\tLoss: 0.2098\tLR: 0.000337\nTraining Epoch: 24 [44544/50000]\tLoss: 0.2286\tLR: 0.000337\nTraining Epoch: 24 [44672/50000]\tLoss: 0.2544\tLR: 0.000337\nTraining Epoch: 24 [44800/50000]\tLoss: 0.2157\tLR: 0.000337\nTraining Epoch: 24 [44928/50000]\tLoss: 0.2228\tLR: 0.000337\nTraining Epoch: 24 [45056/50000]\tLoss: 0.3673\tLR: 0.000337\nTraining Epoch: 24 [45184/50000]\tLoss: 0.3521\tLR: 0.000337\nTraining Epoch: 24 [45312/50000]\tLoss: 0.1974\tLR: 0.000337\nTraining Epoch: 24 [45440/50000]\tLoss: 0.2671\tLR: 0.000337\nTraining Epoch: 24 [45568/50000]\tLoss: 0.2222\tLR: 0.000337\nTraining Epoch: 24 [45696/50000]\tLoss: 0.2187\tLR: 0.000337\nTraining Epoch: 24 [45824/50000]\tLoss: 0.2356\tLR: 0.000337\nTraining Epoch: 24 [45952/50000]\tLoss: 0.3016\tLR: 0.000337\nTraining Epoch: 24 [46080/50000]\tLoss: 0.2186\tLR: 0.000337\nTraining Epoch: 24 [46208/50000]\tLoss: 0.1988\tLR: 0.000337\nTraining Epoch: 24 [46336/50000]\tLoss: 0.2314\tLR: 0.000337\nTraining Epoch: 24 [46464/50000]\tLoss: 0.3133\tLR: 0.000337\nTraining Epoch: 24 [46592/50000]\tLoss: 0.2505\tLR: 0.000337\nTraining Epoch: 24 [46720/50000]\tLoss: 0.3169\tLR: 0.000337\nTraining Epoch: 24 [46848/50000]\tLoss: 0.2124\tLR: 0.000337\nTraining Epoch: 24 [46976/50000]\tLoss: 0.3941\tLR: 0.000337\nTraining Epoch: 24 [47104/50000]\tLoss: 0.2183\tLR: 0.000337\nTraining Epoch: 24 [47232/50000]\tLoss: 0.3068\tLR: 0.000337\nTraining Epoch: 24 [47360/50000]\tLoss: 0.2296\tLR: 0.000337\nTraining Epoch: 24 [47488/50000]\tLoss: 0.1903\tLR: 0.000337\nTraining Epoch: 24 [47616/50000]\tLoss: 0.1424\tLR: 0.000337\nTraining Epoch: 24 [47744/50000]\tLoss: 0.2550\tLR: 0.000337\nTraining Epoch: 24 [47872/50000]\tLoss: 0.2611\tLR: 0.000337\nTraining Epoch: 24 [48000/50000]\tLoss: 0.2987\tLR: 0.000337\nTraining Epoch: 24 [48128/50000]\tLoss: 0.2127\tLR: 0.000337\nTraining Epoch: 24 [48256/50000]\tLoss: 0.2673\tLR: 0.000337\nTraining Epoch: 24 [48384/50000]\tLoss: 0.2072\tLR: 0.000337\nTraining Epoch: 24 [48512/50000]\tLoss: 0.2982\tLR: 0.000337\nTraining Epoch: 24 [48640/50000]\tLoss: 0.2596\tLR: 0.000337\nTraining Epoch: 24 [48768/50000]\tLoss: 0.3124\tLR: 0.000337\nTraining Epoch: 24 [48896/50000]\tLoss: 0.1368\tLR: 0.000337\nTraining Epoch: 24 [49024/50000]\tLoss: 0.2243\tLR: 0.000337\nTraining Epoch: 24 [49152/50000]\tLoss: 0.1465\tLR: 0.000337\nTraining Epoch: 24 [49280/50000]\tLoss: 0.3224\tLR: 0.000337\nTraining Epoch: 24 [49408/50000]\tLoss: 0.3676\tLR: 0.000337\nTraining Epoch: 24 [49536/50000]\tLoss: 0.2084\tLR: 0.000337\nTraining Epoch: 24 [49664/50000]\tLoss: 0.2891\tLR: 0.000337\nTraining Epoch: 24 [49792/50000]\tLoss: 0.2518\tLR: 0.000337\nTraining Epoch: 24 [49920/50000]\tLoss: 0.2462\tLR: 0.000337\nTraining Epoch: 24 [50000/50000]\tLoss: 0.4450\tLR: 0.000337\nTest set: Average loss: 0.0024, Accuracy: 0.9000\n\n\nbest_acc:  tensor(0.9000, device='cuda:0')\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Testing the Model\n","metadata":{}},{"cell_type":"code","source":"weights_file=\"./resnet18.pth\"\ntorch.save(net.state_dict(), weights_file)","metadata":{"execution":{"iopub.status.busy":"2024-03-29T00:04:28.748484Z","iopub.execute_input":"2024-03-29T00:04:28.748855Z","iopub.status.idle":"2024-03-29T00:04:28.800979Z","shell.execute_reply.started":"2024-03-29T00:04:28.748809Z","shell.execute_reply":"2024-03-29T00:04:28.800195Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"if __name__ == '__main__':\n    net = get_network()\n    CIFAR10_test_loader = get_test_dataloader(\n        CIFAR10_TRAIN_MEAN,\n        CIFAR10_TRAIN_STD,\n        #CIFAR10_PATH,\n        num_workers=2,\n        batch_size=128,\n        shuffle=True\n    )\n\n    net.load_state_dict(torch.load(weights_file), True)\n    print(net)\n    net.eval()\n\n    correct_1 = 0.0\n    correct_5 = 0.0\n    total = 0\n\n    for n_iter, (image, label) in enumerate(CIFAR10_test_loader):\n        print(\"iteration: {}\\ttotal {} iterations\".format(n_iter + 1, len(CIFAR10_test_loader)))\n        image = Variable(image).cuda()\n        label = Variable(label).cuda()\n        output = net(image)\n        _, pred = output.topk(5, 1, largest=True, sorted=True)\n\n        label = label.view(label.size(0), -1).expand_as(pred)\n        correct = pred.eq(label).float()\n\n        #compute top 5\n        correct_5 += correct[:, :5].sum()\n\n        #compute top1 \n        correct_1 += correct[:, :1].sum()\n\n\n    print()\n    print(\"Top 1 err: \", 1 - correct_1 / len(CIFAR10_test_loader.dataset))\n    print(\"Top 5 err: \", 1 - correct_5 / len(CIFAR10_test_loader.dataset))\n    print(\"Parameter numbers: {}\".format(sum(p.numel() for p in net.parameters())))","metadata":{"execution":{"iopub.status.busy":"2024-03-29T00:04:28.802057Z","iopub.execute_input":"2024-03-29T00:04:28.802343Z","iopub.status.idle":"2024-03-29T00:04:32.028955Z","shell.execute_reply.started":"2024-03-29T00:04:28.802318Z","shell.execute_reply":"2024-03-29T00:04:32.027812Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"Files already downloaded and verified\nMobileNet(\n  (model): Sequential(\n    (0): Sequential(\n      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU(inplace=True)\n    )\n    (1): Sequential(\n      (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU(inplace=True)\n      (3): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (5): ReLU(inplace=True)\n    )\n    (2): Sequential(\n      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU(inplace=True)\n      (3): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (5): ReLU(inplace=True)\n    )\n    (3): Sequential(\n      (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU(inplace=True)\n      (3): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (5): ReLU(inplace=True)\n    )\n    (4): Sequential(\n      (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=128, bias=False)\n      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU(inplace=True)\n      (3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (5): ReLU(inplace=True)\n    )\n    (5): Sequential(\n      (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU(inplace=True)\n      (3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (5): ReLU(inplace=True)\n    )\n    (6): Sequential(\n      (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=256, bias=False)\n      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU(inplace=True)\n      (3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (5): ReLU(inplace=True)\n    )\n    (7): Sequential(\n      (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)\n      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU(inplace=True)\n      (3): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (5): ReLU(inplace=True)\n    )\n    (8): Sequential(\n      (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)\n      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU(inplace=True)\n      (3): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (5): ReLU(inplace=True)\n    )\n    (9): Sequential(\n      (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)\n      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU(inplace=True)\n      (3): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (5): ReLU(inplace=True)\n    )\n    (10): Sequential(\n      (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)\n      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU(inplace=True)\n      (3): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (5): ReLU(inplace=True)\n    )\n    (11): Sequential(\n      (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)\n      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU(inplace=True)\n      (3): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (5): ReLU(inplace=True)\n    )\n    (12): Sequential(\n      (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=512, bias=False)\n      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU(inplace=True)\n      (3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (4): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (5): ReLU(inplace=True)\n    )\n    (13): Sequential(\n      (0): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024, bias=False)\n      (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU(inplace=True)\n      (3): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (4): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (5): ReLU(inplace=True)\n    )\n    (14): AvgPool2d(kernel_size=4, stride=4, padding=0)\n  )\n  (fc): Linear(in_features=1024, out_features=10, bias=True)\n)\niteration: 1\ttotal 79 iterations\niteration: 2\ttotal 79 iterations\niteration: 3\ttotal 79 iterations\niteration: 4\ttotal 79 iterations\niteration: 5\ttotal 79 iterations\niteration: 6\ttotal 79 iterations\niteration: 7\ttotal 79 iterations\niteration: 8\ttotal 79 iterations\niteration: 9\ttotal 79 iterations\niteration: 10\ttotal 79 iterations\niteration: 11\ttotal 79 iterations\niteration: 12\ttotal 79 iterations\niteration: 13\ttotal 79 iterations\niteration: 14\ttotal 79 iterations\niteration: 15\ttotal 79 iterations\niteration: 16\ttotal 79 iterations\niteration: 17\ttotal 79 iterations\niteration: 18\ttotal 79 iterations\niteration: 19\ttotal 79 iterations\niteration: 20\ttotal 79 iterations\niteration: 21\ttotal 79 iterations\niteration: 22\ttotal 79 iterations\niteration: 23\ttotal 79 iterations\niteration: 24\ttotal 79 iterations\niteration: 25\ttotal 79 iterations\niteration: 26\ttotal 79 iterations\niteration: 27\ttotal 79 iterations\niteration: 28\ttotal 79 iterations\niteration: 29\ttotal 79 iterations\niteration: 30\ttotal 79 iterations\niteration: 31\ttotal 79 iterations\niteration: 32\ttotal 79 iterations\niteration: 33\ttotal 79 iterations\niteration: 34\ttotal 79 iterations\niteration: 35\ttotal 79 iterations\niteration: 36\ttotal 79 iterations\niteration: 37\ttotal 79 iterations\niteration: 38\ttotal 79 iterations\niteration: 39\ttotal 79 iterations\niteration: 40\ttotal 79 iterations\niteration: 41\ttotal 79 iterations\niteration: 42\ttotal 79 iterations\niteration: 43\ttotal 79 iterations\niteration: 44\ttotal 79 iterations\niteration: 45\ttotal 79 iterations\niteration: 46\ttotal 79 iterations\niteration: 47\ttotal 79 iterations\niteration: 48\ttotal 79 iterations\niteration: 49\ttotal 79 iterations\niteration: 50\ttotal 79 iterations\niteration: 51\ttotal 79 iterations\niteration: 52\ttotal 79 iterations\niteration: 53\ttotal 79 iterations\niteration: 54\ttotal 79 iterations\niteration: 55\ttotal 79 iterations\niteration: 56\ttotal 79 iterations\niteration: 57\ttotal 79 iterations\niteration: 58\ttotal 79 iterations\niteration: 59\ttotal 79 iterations\niteration: 60\ttotal 79 iterations\niteration: 61\ttotal 79 iterations\niteration: 62\ttotal 79 iterations\niteration: 63\ttotal 79 iterations\niteration: 64\ttotal 79 iterations\niteration: 65\ttotal 79 iterations\niteration: 66\ttotal 79 iterations\niteration: 67\ttotal 79 iterations\niteration: 68\ttotal 79 iterations\niteration: 69\ttotal 79 iterations\niteration: 70\ttotal 79 iterations\niteration: 71\ttotal 79 iterations\niteration: 72\ttotal 79 iterations\niteration: 73\ttotal 79 iterations\niteration: 74\ttotal 79 iterations\niteration: 75\ttotal 79 iterations\niteration: 76\ttotal 79 iterations\niteration: 77\ttotal 79 iterations\niteration: 78\ttotal 79 iterations\niteration: 79\ttotal 79 iterations\n\nTop 1 err:  tensor(0.1000, device='cuda:0')\nTop 5 err:  tensor(0.0035, device='cuda:0')\nParameter numbers: 3217226\n","output_type":"stream"}]}]}