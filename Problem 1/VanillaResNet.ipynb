{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30674,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport sys\nimport pickle\nfrom skimage import io\nimport matplotlib.pyplot as plt\nimport numpy \nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.optim.lr_scheduler import _LRScheduler\nfrom torch.autograd import Variable\nimport torchvision\nimport torchvision.transforms as transforms\nimport argparse\nimport glob\nimport cv2\nimport torch.optim as optim\nimport matplotlib\nmatplotlib.use('Agg')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-03-28T23:25:25.673202Z","iopub.execute_input":"2024-03-28T23:25:25.674107Z","iopub.status.idle":"2024-03-28T23:25:38.624732Z","shell.execute_reply.started":"2024-03-28T23:25:25.674073Z","shell.execute_reply":"2024-03-28T23:25:38.623721Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"## Loading Data (CIFAR10)","metadata":{}},{"cell_type":"code","source":"class CIFAR10Train(Dataset):\n    \"\"\"CIFAR10 test dataset, derived from\n    torch.utils.data.DataSet\n    \"\"\"\n\n    def __init__(self, path, transform=None):\n        #if transform is given, we transoform data using\n        with open(os.path.join(path, 'train'), 'rb') as CIFAR10:\n            self.data = pickle.load(CIFAR10, encoding='bytes')\n        self.transform = transform\n        \n    def __len__(self):\n        return len(self.data['fine_labels'.encode()])\n\n    def __getitem__(self, index):\n        label = self.data['fine_labels'.encode()][index]\n        r = self.data['data'.encode()][index, :1024].reshape(32, 32)\n        g = self.data['data'.encode()][index, 1024:2048].reshape(32, 32)\n        b = self.data['data'.encode()][index, 2048:].reshape(32, 32)\n        image = numpy.dstack((r, g, b))\n\n        if self.transform:\n            image = self.transform(image)\n        return label, image\n\nclass CIFAR10Test(Dataset):\n    \"\"\"CIFAR10 test dataset, derived from\n    torch.utils.data.DataSet\n    \"\"\"\n\n    def __init__(self, path, transform=None):\n        with open(os.path.join(path, 'test'), 'rb') as CIFAR10:\n            self.data = pickle.load(CIFAR10, encoding='bytes')\n        self.transform = transform \n\n    def __len__(self):\n        return len(self.data['data'.encode()])\n    \n    def __getitem__(self, index):\n        label = self.data['fine_labels'.encode()][index]\n        r = self.data['data'.encode()][index, :1024].reshape(32, 32)\n        g = self.data['data'.encode()][index, 1024:2048].reshape(32, 32)\n        b = self.data['data'.encode()][index, 2048:].reshape(32, 32)\n        image = numpy.dstack((r, g, b))\n\n        if self.transform:\n            image = self.transform(image)\n        return label, image","metadata":{"execution":{"iopub.status.busy":"2024-03-28T23:25:38.626302Z","iopub.execute_input":"2024-03-28T23:25:38.626702Z","iopub.status.idle":"2024-03-28T23:25:38.639667Z","shell.execute_reply.started":"2024-03-28T23:25:38.626677Z","shell.execute_reply":"2024-03-28T23:25:38.638782Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"## Models (ResNet,MobileNet)","metadata":{}},{"cell_type":"code","source":"class BasicBlock(nn.Module):\n    expansion = 1\n\n    def __init__(self, in_planes, planes, stride=1):\n        super(BasicBlock, self).__init__()\n        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(planes)\n        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(planes)\n        self.shortcut = nn.Sequential()\n        if stride != 1 or in_planes != self.expansion*planes:\n            self.shortcut = nn.Sequential(\n                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False),\n                nn.BatchNorm2d(self.expansion*planes)\n            )\n\n    def forward(self, x):\n        residual = x\n        out = F.relu(self.bn1(self.conv1(x)))\n        out = self.bn2(self.conv2(out))\n        out += self.shortcut(residual)\n        out = F.relu(out)\n        return out\n\n\nclass Bottleneck(nn.Module):\n    expansion = 4\n\n    def __init__(self, in_planes, planes, stride=1):\n        super(Bottleneck, self).__init__()\n        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(planes)\n        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(planes)\n        self.conv3 = nn.Conv2d(planes, self.expansion*planes, kernel_size=1, bias=False)\n        self.bn3 = nn.BatchNorm2d(self.expansion*planes)\n        self.shortcut = nn.Sequential()\n        if stride != 1 or in_planes != self.expansion*planes:\n            self.shortcut = nn.Sequential(\n                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False),\n                nn.BatchNorm2d(self.expansion*planes)\n            )\n        \n    def forward(self, x):\n        residual = x\n        out = F.relu(self.bn1(self.conv1(x)))\n        out = F.relu(self.bn2(self.conv2(out)))\n        out = self.bn3(self.conv3(out))\n        out += self.shortcut(residual)\n        out = F.relu(out)\n        return out\n\n\nclass ResNet(nn.Module):\n    def __init__(self, block, num_blocks, num_classes=10):\n        super(ResNet, self).__init__()\n        self.in_planes = 64\n\n        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(64)\n        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n        self.linear = nn.Linear(512*block.expansion, num_classes)\n\n    def _make_layer(self, block, planes, num_blocks, stride):\n        strides = [stride] + [1]*(num_blocks-1)\n        layers = []\n        for stride in strides:\n            layers.append(block(self.in_planes, planes, stride))\n            self.in_planes = planes * block.expansion\n        return nn.Sequential(*layers)\n\n    def forward(self, x):\n        out = F.relu(self.bn1(self.conv1(x)))\n        out = self.layer1(out)\n        out = self.layer2(out)\n        out = self.layer3(out)\n        out = self.layer4(out)\n        out = F.avg_pool2d(out, 4)\n        out = out.view(out.size(0), -1)\n        out = self.linear(out)\n        return out\n\n\ndef ResNet18():\n    return ResNet(BasicBlock, [2,2,2,2])\n\nclass MobileNet(nn.Module):\n    def __init__(self, classes = 100):\n        super(MobileNet, self).__init__()\n\n        def conv_bn(inp, oup, stride):\n            return nn.Sequential(\n                nn.Conv2d(inp, oup, 3, stride, 1, bias=False),\n                nn.BatchNorm2d(oup),\n                nn.ReLU(inplace=True)\n            )\n\n        def conv_dw(inp, oup, stride):\n            return nn.Sequential(\n                nn.Conv2d(inp, inp, 3, stride, 1, groups=inp, bias=False),\n                nn.BatchNorm2d(inp),\n                nn.ReLU(inplace=True),\n                nn.Conv2d(inp, oup, 1, 1, 0, bias=False),\n                nn.BatchNorm2d(oup),\n                nn.ReLU(inplace=True),\n            )\n\n        self.model = nn.Sequential(\n            conv_bn(  3,  32, 1), \n            conv_dw( 32,  64, 1),\n            conv_dw( 64, 128, 1),\n            conv_dw(128, 128, 1),\n            conv_dw(128, 256, 2),\n            conv_dw(256, 256, 1),\n            conv_dw(256, 512, 2),\n            conv_dw(512, 512, 1),\n            conv_dw(512, 512, 1),\n            conv_dw(512, 512, 1),\n            conv_dw(512, 512, 1),\n            conv_dw(512, 512, 1),\n            conv_dw(512, 1024, 2),\n            conv_dw(1024, 1024, 1),\n            nn.AvgPool2d(4),\n        )\n        self.fc = nn.Linear(1024, classes)\n\n    def forward(self, x):\n        x = self.model(x)\n        x = x.view(-1, 1024)\n        x = self.fc(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2024-03-28T23:25:38.640928Z","iopub.execute_input":"2024-03-28T23:25:38.641194Z","iopub.status.idle":"2024-03-28T23:25:38.671930Z","shell.execute_reply.started":"2024-03-28T23:25:38.641172Z","shell.execute_reply":"2024-03-28T23:25:38.671110Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"## Utils","metadata":{}},{"cell_type":"code","source":"def get_network():\n    net=ResNet18().cuda()\n    #net=MobileNet().cuda()\n    \"\"\" return given network\n    \"\"\"\n    return net\n\n\ndef get_training_dataloader(mean, std, batch_size=16, num_workers=2, shuffle=True):\n    \"\"\" return training dataloader\n    Args:\n        mean: mean of CIFAR10 training dataset\n        std: std of CIFAR10 training dataset\n        path: path to CIFAR10 training python dataset\n        batch_size: dataloader batchsize\n        num_workers: dataloader num_works\n        shuffle: whether to shuffle \n    Returns: train_data_loader:torch dataloader object\n    \"\"\"\n\n    transform_train = transforms.Compose([\n        #transforms.ToPILImage(),\n        transforms.RandomCrop(32, padding=4),\n        transforms.RandomHorizontalFlip(),\n        transforms.RandomRotation(15),\n        transforms.ToTensor(),\n        transforms.Normalize(mean, std)\n    ])\n    #CIFAR10_training = CIFAR10Train(path, transform=transform_train)\n    CIFAR10_training = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n    CIFAR10_training_loader = DataLoader(\n        CIFAR10_training, shuffle=shuffle, num_workers=num_workers, batch_size=batch_size)\n\n    return CIFAR10_training_loader\n\ndef get_test_dataloader(mean, std, batch_size=16, num_workers=2, shuffle=True):\n    \"\"\" return training dataloader\n    Args:\n        mean: mean of CIFAR10 test dataset\n        std: std of CIFAR10 test dataset\n        path: path to CIFAR10 test python dataset\n        batch_size: dataloader batchsize\n        num_workers: dataloader num_works\n        shuffle: whether to shuffle \n    Returns: CIFAR10_test_loader:torch dataloader object\n    \"\"\"\n\n    transform_test = transforms.Compose([\n        transforms.ToTensor(),\n        transforms.Normalize(mean, std)\n    ])\n    #CIFAR10_test = CIFAR10Test(path, transform=transform_test)\n    CIFAR10_test = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n    CIFAR10_test_loader = DataLoader(\n        CIFAR10_test, shuffle=shuffle, num_workers=num_workers, batch_size=batch_size)\n\n    return CIFAR10_test_loader\n\ndef compute_mean_std(CIFAR10_dataset):\n    \"\"\"compute the mean and std of CIFAR10 dataset\n    Args:\n        CIFAR10_training_dataset or CIFAR10_test_dataset\n        witch derived from class torch.utils.data\n    \n    Returns:\n        a tuple contains mean, std value of entire dataset\n    \"\"\"\n\n    data_r = numpy.dstack([CIFAR10_dataset[i][1][:, :, 0] for i in range(len(CIFAR10_dataset))])\n    data_g = numpy.dstack([CIFAR10_dataset[i][1][:, :, 1] for i in range(len(CIFAR10_dataset))])\n    data_b = numpy.dstack([CIFAR10_dataset[i][1][:, :, 2] for i in range(len(CIFAR10_dataset))])\n    mean = numpy.mean(data_r), numpy.mean(data_g), numpy.mean(data_b)\n    std = numpy.std(data_r), numpy.std(data_g), numpy.std(data_b)\n\n    return mean, std\n\nclass WarmUpLR(_LRScheduler):\n    \"\"\"warmup_training learning rate scheduler\n    Args:\n        optimizer: optimzier(e.g. SGD)\n        total_iters: totoal_iters of warmup phase\n    \"\"\"\n    def __init__(self, optimizer, total_iters, last_epoch=-1):\n        \n        self.total_iters = total_iters\n        super().__init__(optimizer, last_epoch)\n\n    def get_lr(self):\n        \"\"\"we will use the first m batches, and set the learning\n        rate to base_lr * m / total_iters\n        \"\"\"\n        return [base_lr * self.last_epoch / (self.total_iters + 1e-8) for base_lr in self.base_lrs]","metadata":{"execution":{"iopub.status.busy":"2024-03-28T23:25:38.674140Z","iopub.execute_input":"2024-03-28T23:25:38.674407Z","iopub.status.idle":"2024-03-28T23:25:38.694663Z","shell.execute_reply.started":"2024-03-28T23:25:38.674385Z","shell.execute_reply":"2024-03-28T23:25:38.693979Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"from datetime import datetime\nCIFAR10_TRAIN_MEAN = (0.49139968, 0.48215827 ,0.44653124)\nCIFAR10_TRAIN_STD = (0.24703233, 0.24348505, 0.26158768)\n\n#CIFAR100_TEST_MEAN = (0.5088964127604166, 0.48739301317401956, 0.44194221124387256)\n#CIFAR100_TEST_STD = (0.2682515741720801, 0.2573637364478126, 0.2770957707973042)\n\n#directory to save weights file\nCHECKPOINT_PATH = 'checkpoint'\n\n#total training epoches\nEPOCH = 25\nMILESTONES = [6, 12, 16]\n\n#initial learning rate\n#INIT_LR = 0.1\n\n#time of we run the script\nTIME_NOW = datetime.now().isoformat()\n\n#tensorboard log dir\nLOG_DIR = 'runs'\n\n#save weights file per SAVE_EPOCH epoch\nSAVE_EPOCH = 10","metadata":{"execution":{"iopub.status.busy":"2024-03-28T23:25:38.695680Z","iopub.execute_input":"2024-03-28T23:25:38.695963Z","iopub.status.idle":"2024-03-28T23:25:38.712904Z","shell.execute_reply.started":"2024-03-28T23:25:38.695940Z","shell.execute_reply":"2024-03-28T23:25:38.712086Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"## Training the model","metadata":{}},{"cell_type":"code","source":"def train(epoch):\n\n    net.train()\n    for batch_index, (images, labels) in enumerate(CIFAR10_training_loader):\n        if epoch <= 1:\n            warmup_scheduler.step()\n\n        images = Variable(images)\n        labels = Variable(labels)\n\n        labels = labels.cuda()\n        images = images.cuda()\n\n        optimizer.zero_grad()\n        outputs = net(images)\n        loss = loss_function(outputs, labels)\n        loss.backward()\n        optimizer.step()\n\n        print('Training Epoch: {epoch} [{trained_samples}/{total_samples}]\\tLoss: {:0.4f}\\tLR: {:0.6f}'.format(\n            loss.item(),\n            optimizer.param_groups[0]['lr'],\n            epoch=epoch,\n            trained_samples=batch_index * 128 + len(images),\n            total_samples=len(CIFAR10_training_loader.dataset)\n        ))\n\n\n    for name, param in net.named_parameters():\n        layer, attr = os.path.splitext(name)\n        attr = attr[1:]\n\ndef eval_training(epoch):\n    net.eval()\n\n    test_loss = 0.0 # cost function error\n    correct = 0.0\n\n    for (images, labels) in CIFAR10_test_loader:\n        images = Variable(images)\n        labels = Variable(labels)\n\n        images = images.cuda()\n        labels = labels.cuda()\n\n        outputs = net(images)\n        loss = loss_function(outputs, labels)\n        test_loss += loss.item()\n        _, preds = outputs.max(1)\n        correct += preds.eq(labels).sum()\n\n    print('Test set: Average loss: {:.4f}, Accuracy: {:.4f}'.format(\n        test_loss / len(CIFAR10_test_loader.dataset),\n        correct.float() / len(CIFAR10_test_loader.dataset)\n    ))\n    print()\n\n\n    return correct.float() / len(CIFAR10_test_loader.dataset)\n\nif __name__ == '__main__':\n    \n#     parser = argparse.ArgumentParser()\n#     parser.add_argument('-net', type=str, required=True, help='net type')\n#     parser.add_argument('-gpu', type=bool, default=True, help='use gpu or not')\n#     parser.add_argument('-w', type=int, default=2, help='number of workers for dataloader')\n#     parser.add_argument('-b', type=int, default=128, help='batch size for dataloader')\n#     parser.add_argument('-s', type=bool, default=True, help='whether shuffle the dataset')\n#     parser.add_argument('-warm', type=int, default=1, help='warm up training phase')\n#     parser.add_argument('-lr', type=float, default=0.1, help='initial learning rate')\n#     args = parser.parse_args()\n\n    net= get_network()\n    \n        \n    #data preprocessing:\n    CIFAR10_training_loader = get_training_dataloader(\n        CIFAR10_TRAIN_MEAN,\n        CIFAR10_TRAIN_STD,\n        num_workers=2,\n        batch_size=128,\n        shuffle=True\n    )\n    \n    CIFAR10_test_loader = get_test_dataloader(\n        CIFAR10_TRAIN_MEAN,\n        CIFAR10_TRAIN_STD,\n        num_workers=2,\n        batch_size=128,\n        shuffle=True\n    )\n    \n    loss_function = nn.CrossEntropyLoss()\n    optimizer = optim.SGD(net.parameters(), lr=0.1, momentum=0.9, weight_decay=5e-4)\n    train_scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=MILESTONES, gamma=0.15) #learning rate decay\n    iter_per_epoch = len(CIFAR10_training_loader)\n    warmup_scheduler = WarmUpLR(optimizer, iter_per_epoch * 1)\n    checkpoint_path = os.path.join(CHECKPOINT_PATH, \"resnet18\")\n\n    #create checkpoint folder to save model\n    if not os.path.exists(checkpoint_path):\n        os.makedirs(checkpoint_path)\n    checkpoint_path = os.path.join(checkpoint_path, '{net}-{epoch}-{type}.pth')\n\n    best_acc = 0.0\n    for epoch in range(1, EPOCH):\n        if epoch > 1:\n            train_scheduler.step(epoch)\n\n        train(epoch)\n        acc = eval_training(epoch)\n\n        #start to save best performance model after learning rate decay to 0.01 \n        if epoch > MILESTONES[1] and best_acc < acc:\n            torch.save(net.state_dict(), checkpoint_path.format(net=\"resnet18\", epoch=epoch, type='best'))\n            best_acc = acc\n            continue\n\n        if not epoch % SAVE_EPOCH:\n            torch.save(net.state_dict(), checkpoint_path.format(net=\"resnet18\", epoch=epoch, type='regular'))\n    print()\n    print(\"best_acc: \", best_acc)\n    ","metadata":{"execution":{"iopub.status.busy":"2024-03-28T23:25:38.713948Z","iopub.execute_input":"2024-03-28T23:25:38.714189Z","iopub.status.idle":"2024-03-28T23:43:27.731654Z","shell.execute_reply.started":"2024-03-28T23:25:38.714167Z","shell.execute_reply":"2024-03-28T23:43:27.730461Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 170498071/170498071 [00:02<00:00, 77963567.09it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracting ./data/cifar-10-python.tar.gz to ./data\nFiles already downloaded and verified\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:136: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n","output_type":"stream"},{"name":"stdout","text":"Training Epoch: 1 [128/50000]\tLoss: 2.3169\tLR: 0.000256\nTraining Epoch: 1 [256/50000]\tLoss: 2.2806\tLR: 0.000512\nTraining Epoch: 1 [384/50000]\tLoss: 2.3210\tLR: 0.000767\nTraining Epoch: 1 [512/50000]\tLoss: 2.3193\tLR: 0.001023\nTraining Epoch: 1 [640/50000]\tLoss: 2.2938\tLR: 0.001279\nTraining Epoch: 1 [768/50000]\tLoss: 2.2713\tLR: 0.001535\nTraining Epoch: 1 [896/50000]\tLoss: 2.2865\tLR: 0.001790\nTraining Epoch: 1 [1024/50000]\tLoss: 2.2267\tLR: 0.002046\nTraining Epoch: 1 [1152/50000]\tLoss: 2.2596\tLR: 0.002302\nTraining Epoch: 1 [1280/50000]\tLoss: 2.2200\tLR: 0.002558\nTraining Epoch: 1 [1408/50000]\tLoss: 2.2298\tLR: 0.002813\nTraining Epoch: 1 [1536/50000]\tLoss: 2.1597\tLR: 0.003069\nTraining Epoch: 1 [1664/50000]\tLoss: 2.2252\tLR: 0.003325\nTraining Epoch: 1 [1792/50000]\tLoss: 2.2125\tLR: 0.003581\nTraining Epoch: 1 [1920/50000]\tLoss: 2.2091\tLR: 0.003836\nTraining Epoch: 1 [2048/50000]\tLoss: 2.0378\tLR: 0.004092\nTraining Epoch: 1 [2176/50000]\tLoss: 2.0733\tLR: 0.004348\nTraining Epoch: 1 [2304/50000]\tLoss: 2.2246\tLR: 0.004604\nTraining Epoch: 1 [2432/50000]\tLoss: 2.0100\tLR: 0.004859\nTraining Epoch: 1 [2560/50000]\tLoss: 1.9738\tLR: 0.005115\nTraining Epoch: 1 [2688/50000]\tLoss: 2.1088\tLR: 0.005371\nTraining Epoch: 1 [2816/50000]\tLoss: 1.9942\tLR: 0.005627\nTraining Epoch: 1 [2944/50000]\tLoss: 2.0711\tLR: 0.005882\nTraining Epoch: 1 [3072/50000]\tLoss: 1.9579\tLR: 0.006138\nTraining Epoch: 1 [3200/50000]\tLoss: 2.0029\tLR: 0.006394\nTraining Epoch: 1 [3328/50000]\tLoss: 1.9014\tLR: 0.006650\nTraining Epoch: 1 [3456/50000]\tLoss: 1.9035\tLR: 0.006905\nTraining Epoch: 1 [3584/50000]\tLoss: 1.8386\tLR: 0.007161\nTraining Epoch: 1 [3712/50000]\tLoss: 1.9984\tLR: 0.007417\nTraining Epoch: 1 [3840/50000]\tLoss: 1.8352\tLR: 0.007673\nTraining Epoch: 1 [3968/50000]\tLoss: 1.8893\tLR: 0.007928\nTraining Epoch: 1 [4096/50000]\tLoss: 1.8350\tLR: 0.008184\nTraining Epoch: 1 [4224/50000]\tLoss: 1.9240\tLR: 0.008440\nTraining Epoch: 1 [4352/50000]\tLoss: 1.9819\tLR: 0.008696\nTraining Epoch: 1 [4480/50000]\tLoss: 1.8321\tLR: 0.008951\nTraining Epoch: 1 [4608/50000]\tLoss: 1.9682\tLR: 0.009207\nTraining Epoch: 1 [4736/50000]\tLoss: 1.8454\tLR: 0.009463\nTraining Epoch: 1 [4864/50000]\tLoss: 1.9842\tLR: 0.009719\nTraining Epoch: 1 [4992/50000]\tLoss: 1.9172\tLR: 0.009974\nTraining Epoch: 1 [5120/50000]\tLoss: 1.8798\tLR: 0.010230\nTraining Epoch: 1 [5248/50000]\tLoss: 1.9397\tLR: 0.010486\nTraining Epoch: 1 [5376/50000]\tLoss: 1.8211\tLR: 0.010742\nTraining Epoch: 1 [5504/50000]\tLoss: 1.8360\tLR: 0.010997\nTraining Epoch: 1 [5632/50000]\tLoss: 1.9956\tLR: 0.011253\nTraining Epoch: 1 [5760/50000]\tLoss: 1.6955\tLR: 0.011509\nTraining Epoch: 1 [5888/50000]\tLoss: 1.7507\tLR: 0.011765\nTraining Epoch: 1 [6016/50000]\tLoss: 2.0676\tLR: 0.012020\nTraining Epoch: 1 [6144/50000]\tLoss: 1.9131\tLR: 0.012276\nTraining Epoch: 1 [6272/50000]\tLoss: 2.2843\tLR: 0.012532\nTraining Epoch: 1 [6400/50000]\tLoss: 1.8162\tLR: 0.012788\nTraining Epoch: 1 [6528/50000]\tLoss: 2.0734\tLR: 0.013043\nTraining Epoch: 1 [6656/50000]\tLoss: 2.2906\tLR: 0.013299\nTraining Epoch: 1 [6784/50000]\tLoss: 1.8672\tLR: 0.013555\nTraining Epoch: 1 [6912/50000]\tLoss: 2.0968\tLR: 0.013811\nTraining Epoch: 1 [7040/50000]\tLoss: 1.7819\tLR: 0.014066\nTraining Epoch: 1 [7168/50000]\tLoss: 1.8361\tLR: 0.014322\nTraining Epoch: 1 [7296/50000]\tLoss: 1.9025\tLR: 0.014578\nTraining Epoch: 1 [7424/50000]\tLoss: 1.9059\tLR: 0.014834\nTraining Epoch: 1 [7552/50000]\tLoss: 1.9524\tLR: 0.015090\nTraining Epoch: 1 [7680/50000]\tLoss: 2.1051\tLR: 0.015345\nTraining Epoch: 1 [7808/50000]\tLoss: 1.9213\tLR: 0.015601\nTraining Epoch: 1 [7936/50000]\tLoss: 1.7318\tLR: 0.015857\nTraining Epoch: 1 [8064/50000]\tLoss: 1.9377\tLR: 0.016113\nTraining Epoch: 1 [8192/50000]\tLoss: 1.6507\tLR: 0.016368\nTraining Epoch: 1 [8320/50000]\tLoss: 1.7340\tLR: 0.016624\nTraining Epoch: 1 [8448/50000]\tLoss: 1.8434\tLR: 0.016880\nTraining Epoch: 1 [8576/50000]\tLoss: 2.0524\tLR: 0.017136\nTraining Epoch: 1 [8704/50000]\tLoss: 1.7137\tLR: 0.017391\nTraining Epoch: 1 [8832/50000]\tLoss: 1.8219\tLR: 0.017647\nTraining Epoch: 1 [8960/50000]\tLoss: 1.8138\tLR: 0.017903\nTraining Epoch: 1 [9088/50000]\tLoss: 1.8980\tLR: 0.018159\nTraining Epoch: 1 [9216/50000]\tLoss: 1.8145\tLR: 0.018414\nTraining Epoch: 1 [9344/50000]\tLoss: 1.8906\tLR: 0.018670\nTraining Epoch: 1 [9472/50000]\tLoss: 1.6907\tLR: 0.018926\nTraining Epoch: 1 [9600/50000]\tLoss: 2.0302\tLR: 0.019182\nTraining Epoch: 1 [9728/50000]\tLoss: 1.7605\tLR: 0.019437\nTraining Epoch: 1 [9856/50000]\tLoss: 1.9365\tLR: 0.019693\nTraining Epoch: 1 [9984/50000]\tLoss: 1.8012\tLR: 0.019949\nTraining Epoch: 1 [10112/50000]\tLoss: 1.8075\tLR: 0.020205\nTraining Epoch: 1 [10240/50000]\tLoss: 1.8060\tLR: 0.020460\nTraining Epoch: 1 [10368/50000]\tLoss: 1.8173\tLR: 0.020716\nTraining Epoch: 1 [10496/50000]\tLoss: 1.8392\tLR: 0.020972\nTraining Epoch: 1 [10624/50000]\tLoss: 1.7237\tLR: 0.021228\nTraining Epoch: 1 [10752/50000]\tLoss: 1.7702\tLR: 0.021483\nTraining Epoch: 1 [10880/50000]\tLoss: 1.7826\tLR: 0.021739\nTraining Epoch: 1 [11008/50000]\tLoss: 1.7427\tLR: 0.021995\nTraining Epoch: 1 [11136/50000]\tLoss: 1.9201\tLR: 0.022251\nTraining Epoch: 1 [11264/50000]\tLoss: 1.7667\tLR: 0.022506\nTraining Epoch: 1 [11392/50000]\tLoss: 1.8313\tLR: 0.022762\nTraining Epoch: 1 [11520/50000]\tLoss: 1.8985\tLR: 0.023018\nTraining Epoch: 1 [11648/50000]\tLoss: 1.6794\tLR: 0.023274\nTraining Epoch: 1 [11776/50000]\tLoss: 1.7549\tLR: 0.023529\nTraining Epoch: 1 [11904/50000]\tLoss: 1.8560\tLR: 0.023785\nTraining Epoch: 1 [12032/50000]\tLoss: 1.7332\tLR: 0.024041\nTraining Epoch: 1 [12160/50000]\tLoss: 1.7882\tLR: 0.024297\nTraining Epoch: 1 [12288/50000]\tLoss: 1.8251\tLR: 0.024552\nTraining Epoch: 1 [12416/50000]\tLoss: 1.7410\tLR: 0.024808\nTraining Epoch: 1 [12544/50000]\tLoss: 1.5649\tLR: 0.025064\nTraining Epoch: 1 [12672/50000]\tLoss: 1.6738\tLR: 0.025320\nTraining Epoch: 1 [12800/50000]\tLoss: 1.7475\tLR: 0.025575\nTraining Epoch: 1 [12928/50000]\tLoss: 1.7397\tLR: 0.025831\nTraining Epoch: 1 [13056/50000]\tLoss: 1.8986\tLR: 0.026087\nTraining Epoch: 1 [13184/50000]\tLoss: 1.7487\tLR: 0.026343\nTraining Epoch: 1 [13312/50000]\tLoss: 1.7116\tLR: 0.026598\nTraining Epoch: 1 [13440/50000]\tLoss: 1.8876\tLR: 0.026854\nTraining Epoch: 1 [13568/50000]\tLoss: 1.7367\tLR: 0.027110\nTraining Epoch: 1 [13696/50000]\tLoss: 1.5302\tLR: 0.027366\nTraining Epoch: 1 [13824/50000]\tLoss: 1.7831\tLR: 0.027621\nTraining Epoch: 1 [13952/50000]\tLoss: 1.6328\tLR: 0.027877\nTraining Epoch: 1 [14080/50000]\tLoss: 1.6514\tLR: 0.028133\nTraining Epoch: 1 [14208/50000]\tLoss: 1.7883\tLR: 0.028389\nTraining Epoch: 1 [14336/50000]\tLoss: 1.7444\tLR: 0.028645\nTraining Epoch: 1 [14464/50000]\tLoss: 1.8380\tLR: 0.028900\nTraining Epoch: 1 [14592/50000]\tLoss: 1.9175\tLR: 0.029156\nTraining Epoch: 1 [14720/50000]\tLoss: 1.8197\tLR: 0.029412\nTraining Epoch: 1 [14848/50000]\tLoss: 1.8046\tLR: 0.029668\nTraining Epoch: 1 [14976/50000]\tLoss: 1.6739\tLR: 0.029923\nTraining Epoch: 1 [15104/50000]\tLoss: 1.7663\tLR: 0.030179\nTraining Epoch: 1 [15232/50000]\tLoss: 1.8053\tLR: 0.030435\nTraining Epoch: 1 [15360/50000]\tLoss: 1.9124\tLR: 0.030691\nTraining Epoch: 1 [15488/50000]\tLoss: 1.6911\tLR: 0.030946\nTraining Epoch: 1 [15616/50000]\tLoss: 1.6357\tLR: 0.031202\nTraining Epoch: 1 [15744/50000]\tLoss: 1.8928\tLR: 0.031458\nTraining Epoch: 1 [15872/50000]\tLoss: 1.5922\tLR: 0.031714\nTraining Epoch: 1 [16000/50000]\tLoss: 1.9809\tLR: 0.031969\nTraining Epoch: 1 [16128/50000]\tLoss: 1.5138\tLR: 0.032225\nTraining Epoch: 1 [16256/50000]\tLoss: 1.6112\tLR: 0.032481\nTraining Epoch: 1 [16384/50000]\tLoss: 1.7878\tLR: 0.032737\nTraining Epoch: 1 [16512/50000]\tLoss: 1.9027\tLR: 0.032992\nTraining Epoch: 1 [16640/50000]\tLoss: 1.6592\tLR: 0.033248\nTraining Epoch: 1 [16768/50000]\tLoss: 1.9753\tLR: 0.033504\nTraining Epoch: 1 [16896/50000]\tLoss: 1.6690\tLR: 0.033760\nTraining Epoch: 1 [17024/50000]\tLoss: 1.8767\tLR: 0.034015\nTraining Epoch: 1 [17152/50000]\tLoss: 2.0573\tLR: 0.034271\nTraining Epoch: 1 [17280/50000]\tLoss: 1.7860\tLR: 0.034527\nTraining Epoch: 1 [17408/50000]\tLoss: 1.9375\tLR: 0.034783\nTraining Epoch: 1 [17536/50000]\tLoss: 2.0283\tLR: 0.035038\nTraining Epoch: 1 [17664/50000]\tLoss: 1.9499\tLR: 0.035294\nTraining Epoch: 1 [17792/50000]\tLoss: 1.7248\tLR: 0.035550\nTraining Epoch: 1 [17920/50000]\tLoss: 1.7273\tLR: 0.035806\nTraining Epoch: 1 [18048/50000]\tLoss: 1.7534\tLR: 0.036061\nTraining Epoch: 1 [18176/50000]\tLoss: 1.7465\tLR: 0.036317\nTraining Epoch: 1 [18304/50000]\tLoss: 1.6500\tLR: 0.036573\nTraining Epoch: 1 [18432/50000]\tLoss: 2.0206\tLR: 0.036829\nTraining Epoch: 1 [18560/50000]\tLoss: 1.7641\tLR: 0.037084\nTraining Epoch: 1 [18688/50000]\tLoss: 1.7656\tLR: 0.037340\nTraining Epoch: 1 [18816/50000]\tLoss: 1.7963\tLR: 0.037596\nTraining Epoch: 1 [18944/50000]\tLoss: 1.8549\tLR: 0.037852\nTraining Epoch: 1 [19072/50000]\tLoss: 1.8554\tLR: 0.038107\nTraining Epoch: 1 [19200/50000]\tLoss: 1.7288\tLR: 0.038363\nTraining Epoch: 1 [19328/50000]\tLoss: 1.6984\tLR: 0.038619\nTraining Epoch: 1 [19456/50000]\tLoss: 1.5980\tLR: 0.038875\nTraining Epoch: 1 [19584/50000]\tLoss: 2.2139\tLR: 0.039130\nTraining Epoch: 1 [19712/50000]\tLoss: 1.6850\tLR: 0.039386\nTraining Epoch: 1 [19840/50000]\tLoss: 1.7774\tLR: 0.039642\nTraining Epoch: 1 [19968/50000]\tLoss: 1.7404\tLR: 0.039898\nTraining Epoch: 1 [20096/50000]\tLoss: 1.8377\tLR: 0.040153\nTraining Epoch: 1 [20224/50000]\tLoss: 1.6675\tLR: 0.040409\nTraining Epoch: 1 [20352/50000]\tLoss: 1.8796\tLR: 0.040665\nTraining Epoch: 1 [20480/50000]\tLoss: 1.8310\tLR: 0.040921\nTraining Epoch: 1 [20608/50000]\tLoss: 1.6240\tLR: 0.041176\nTraining Epoch: 1 [20736/50000]\tLoss: 1.6894\tLR: 0.041432\nTraining Epoch: 1 [20864/50000]\tLoss: 1.8752\tLR: 0.041688\nTraining Epoch: 1 [20992/50000]\tLoss: 1.7692\tLR: 0.041944\nTraining Epoch: 1 [21120/50000]\tLoss: 1.7442\tLR: 0.042199\nTraining Epoch: 1 [21248/50000]\tLoss: 1.7559\tLR: 0.042455\nTraining Epoch: 1 [21376/50000]\tLoss: 1.7000\tLR: 0.042711\nTraining Epoch: 1 [21504/50000]\tLoss: 1.5865\tLR: 0.042967\nTraining Epoch: 1 [21632/50000]\tLoss: 1.6347\tLR: 0.043223\nTraining Epoch: 1 [21760/50000]\tLoss: 1.6876\tLR: 0.043478\nTraining Epoch: 1 [21888/50000]\tLoss: 1.7799\tLR: 0.043734\nTraining Epoch: 1 [22016/50000]\tLoss: 1.5598\tLR: 0.043990\nTraining Epoch: 1 [22144/50000]\tLoss: 1.5885\tLR: 0.044246\nTraining Epoch: 1 [22272/50000]\tLoss: 1.6691\tLR: 0.044501\nTraining Epoch: 1 [22400/50000]\tLoss: 2.0153\tLR: 0.044757\nTraining Epoch: 1 [22528/50000]\tLoss: 1.6125\tLR: 0.045013\nTraining Epoch: 1 [22656/50000]\tLoss: 1.5305\tLR: 0.045269\nTraining Epoch: 1 [22784/50000]\tLoss: 1.4996\tLR: 0.045524\nTraining Epoch: 1 [22912/50000]\tLoss: 1.5817\tLR: 0.045780\nTraining Epoch: 1 [23040/50000]\tLoss: 1.4947\tLR: 0.046036\nTraining Epoch: 1 [23168/50000]\tLoss: 1.7201\tLR: 0.046292\nTraining Epoch: 1 [23296/50000]\tLoss: 1.5447\tLR: 0.046547\nTraining Epoch: 1 [23424/50000]\tLoss: 1.7689\tLR: 0.046803\nTraining Epoch: 1 [23552/50000]\tLoss: 1.4919\tLR: 0.047059\nTraining Epoch: 1 [23680/50000]\tLoss: 1.6614\tLR: 0.047315\nTraining Epoch: 1 [23808/50000]\tLoss: 1.6626\tLR: 0.047570\nTraining Epoch: 1 [23936/50000]\tLoss: 1.6475\tLR: 0.047826\nTraining Epoch: 1 [24064/50000]\tLoss: 1.5417\tLR: 0.048082\nTraining Epoch: 1 [24192/50000]\tLoss: 1.5803\tLR: 0.048338\nTraining Epoch: 1 [24320/50000]\tLoss: 1.6896\tLR: 0.048593\nTraining Epoch: 1 [24448/50000]\tLoss: 1.6420\tLR: 0.048849\nTraining Epoch: 1 [24576/50000]\tLoss: 1.7364\tLR: 0.049105\nTraining Epoch: 1 [24704/50000]\tLoss: 1.5844\tLR: 0.049361\nTraining Epoch: 1 [24832/50000]\tLoss: 1.5349\tLR: 0.049616\nTraining Epoch: 1 [24960/50000]\tLoss: 1.5306\tLR: 0.049872\nTraining Epoch: 1 [25088/50000]\tLoss: 1.8991\tLR: 0.050128\nTraining Epoch: 1 [25216/50000]\tLoss: 1.5794\tLR: 0.050384\nTraining Epoch: 1 [25344/50000]\tLoss: 1.6247\tLR: 0.050639\nTraining Epoch: 1 [25472/50000]\tLoss: 1.5321\tLR: 0.050895\nTraining Epoch: 1 [25600/50000]\tLoss: 1.6493\tLR: 0.051151\nTraining Epoch: 1 [25728/50000]\tLoss: 1.5813\tLR: 0.051407\nTraining Epoch: 1 [25856/50000]\tLoss: 1.6773\tLR: 0.051662\nTraining Epoch: 1 [25984/50000]\tLoss: 1.4426\tLR: 0.051918\nTraining Epoch: 1 [26112/50000]\tLoss: 1.6658\tLR: 0.052174\nTraining Epoch: 1 [26240/50000]\tLoss: 1.5553\tLR: 0.052430\nTraining Epoch: 1 [26368/50000]\tLoss: 1.5888\tLR: 0.052685\nTraining Epoch: 1 [26496/50000]\tLoss: 1.4895\tLR: 0.052941\nTraining Epoch: 1 [26624/50000]\tLoss: 1.6625\tLR: 0.053197\nTraining Epoch: 1 [26752/50000]\tLoss: 1.6359\tLR: 0.053453\nTraining Epoch: 1 [26880/50000]\tLoss: 1.4929\tLR: 0.053708\nTraining Epoch: 1 [27008/50000]\tLoss: 1.4986\tLR: 0.053964\nTraining Epoch: 1 [27136/50000]\tLoss: 1.5060\tLR: 0.054220\nTraining Epoch: 1 [27264/50000]\tLoss: 1.5566\tLR: 0.054476\nTraining Epoch: 1 [27392/50000]\tLoss: 1.6630\tLR: 0.054731\nTraining Epoch: 1 [27520/50000]\tLoss: 1.5477\tLR: 0.054987\nTraining Epoch: 1 [27648/50000]\tLoss: 1.5184\tLR: 0.055243\nTraining Epoch: 1 [27776/50000]\tLoss: 1.7052\tLR: 0.055499\nTraining Epoch: 1 [27904/50000]\tLoss: 1.7031\tLR: 0.055754\nTraining Epoch: 1 [28032/50000]\tLoss: 1.6726\tLR: 0.056010\nTraining Epoch: 1 [28160/50000]\tLoss: 1.8327\tLR: 0.056266\nTraining Epoch: 1 [28288/50000]\tLoss: 1.6495\tLR: 0.056522\nTraining Epoch: 1 [28416/50000]\tLoss: 1.5390\tLR: 0.056777\nTraining Epoch: 1 [28544/50000]\tLoss: 1.6584\tLR: 0.057033\nTraining Epoch: 1 [28672/50000]\tLoss: 1.3582\tLR: 0.057289\nTraining Epoch: 1 [28800/50000]\tLoss: 1.5937\tLR: 0.057545\nTraining Epoch: 1 [28928/50000]\tLoss: 1.6118\tLR: 0.057801\nTraining Epoch: 1 [29056/50000]\tLoss: 1.7426\tLR: 0.058056\nTraining Epoch: 1 [29184/50000]\tLoss: 1.7102\tLR: 0.058312\nTraining Epoch: 1 [29312/50000]\tLoss: 1.6203\tLR: 0.058568\nTraining Epoch: 1 [29440/50000]\tLoss: 1.5031\tLR: 0.058824\nTraining Epoch: 1 [29568/50000]\tLoss: 1.5932\tLR: 0.059079\nTraining Epoch: 1 [29696/50000]\tLoss: 1.8074\tLR: 0.059335\nTraining Epoch: 1 [29824/50000]\tLoss: 1.7501\tLR: 0.059591\nTraining Epoch: 1 [29952/50000]\tLoss: 1.6141\tLR: 0.059847\nTraining Epoch: 1 [30080/50000]\tLoss: 1.4788\tLR: 0.060102\nTraining Epoch: 1 [30208/50000]\tLoss: 1.4713\tLR: 0.060358\nTraining Epoch: 1 [30336/50000]\tLoss: 1.7526\tLR: 0.060614\nTraining Epoch: 1 [30464/50000]\tLoss: 1.4616\tLR: 0.060870\nTraining Epoch: 1 [30592/50000]\tLoss: 1.5228\tLR: 0.061125\nTraining Epoch: 1 [30720/50000]\tLoss: 1.6211\tLR: 0.061381\nTraining Epoch: 1 [30848/50000]\tLoss: 1.4277\tLR: 0.061637\nTraining Epoch: 1 [30976/50000]\tLoss: 1.6139\tLR: 0.061893\nTraining Epoch: 1 [31104/50000]\tLoss: 1.3946\tLR: 0.062148\nTraining Epoch: 1 [31232/50000]\tLoss: 1.2904\tLR: 0.062404\nTraining Epoch: 1 [31360/50000]\tLoss: 1.6348\tLR: 0.062660\nTraining Epoch: 1 [31488/50000]\tLoss: 1.5769\tLR: 0.062916\nTraining Epoch: 1 [31616/50000]\tLoss: 1.5562\tLR: 0.063171\nTraining Epoch: 1 [31744/50000]\tLoss: 1.4772\tLR: 0.063427\nTraining Epoch: 1 [31872/50000]\tLoss: 1.4782\tLR: 0.063683\nTraining Epoch: 1 [32000/50000]\tLoss: 1.6806\tLR: 0.063939\nTraining Epoch: 1 [32128/50000]\tLoss: 1.5325\tLR: 0.064194\nTraining Epoch: 1 [32256/50000]\tLoss: 1.4357\tLR: 0.064450\nTraining Epoch: 1 [32384/50000]\tLoss: 1.6384\tLR: 0.064706\nTraining Epoch: 1 [32512/50000]\tLoss: 1.6408\tLR: 0.064962\nTraining Epoch: 1 [32640/50000]\tLoss: 1.7891\tLR: 0.065217\nTraining Epoch: 1 [32768/50000]\tLoss: 1.6823\tLR: 0.065473\nTraining Epoch: 1 [32896/50000]\tLoss: 1.8108\tLR: 0.065729\nTraining Epoch: 1 [33024/50000]\tLoss: 1.8415\tLR: 0.065985\nTraining Epoch: 1 [33152/50000]\tLoss: 1.7230\tLR: 0.066240\nTraining Epoch: 1 [33280/50000]\tLoss: 1.5521\tLR: 0.066496\nTraining Epoch: 1 [33408/50000]\tLoss: 1.5853\tLR: 0.066752\nTraining Epoch: 1 [33536/50000]\tLoss: 1.9626\tLR: 0.067008\nTraining Epoch: 1 [33664/50000]\tLoss: 1.7575\tLR: 0.067263\nTraining Epoch: 1 [33792/50000]\tLoss: 1.8274\tLR: 0.067519\nTraining Epoch: 1 [33920/50000]\tLoss: 1.4973\tLR: 0.067775\nTraining Epoch: 1 [34048/50000]\tLoss: 1.8079\tLR: 0.068031\nTraining Epoch: 1 [34176/50000]\tLoss: 1.4760\tLR: 0.068286\nTraining Epoch: 1 [34304/50000]\tLoss: 1.6428\tLR: 0.068542\nTraining Epoch: 1 [34432/50000]\tLoss: 1.5637\tLR: 0.068798\nTraining Epoch: 1 [34560/50000]\tLoss: 1.6137\tLR: 0.069054\nTraining Epoch: 1 [34688/50000]\tLoss: 1.5418\tLR: 0.069309\nTraining Epoch: 1 [34816/50000]\tLoss: 1.4663\tLR: 0.069565\nTraining Epoch: 1 [34944/50000]\tLoss: 1.6291\tLR: 0.069821\nTraining Epoch: 1 [35072/50000]\tLoss: 1.5420\tLR: 0.070077\nTraining Epoch: 1 [35200/50000]\tLoss: 1.8254\tLR: 0.070332\nTraining Epoch: 1 [35328/50000]\tLoss: 1.6815\tLR: 0.070588\nTraining Epoch: 1 [35456/50000]\tLoss: 1.3445\tLR: 0.070844\nTraining Epoch: 1 [35584/50000]\tLoss: 1.6433\tLR: 0.071100\nTraining Epoch: 1 [35712/50000]\tLoss: 1.4662\tLR: 0.071355\nTraining Epoch: 1 [35840/50000]\tLoss: 1.5483\tLR: 0.071611\nTraining Epoch: 1 [35968/50000]\tLoss: 1.7673\tLR: 0.071867\nTraining Epoch: 1 [36096/50000]\tLoss: 1.4062\tLR: 0.072123\nTraining Epoch: 1 [36224/50000]\tLoss: 1.7066\tLR: 0.072379\nTraining Epoch: 1 [36352/50000]\tLoss: 1.5064\tLR: 0.072634\nTraining Epoch: 1 [36480/50000]\tLoss: 1.4144\tLR: 0.072890\nTraining Epoch: 1 [36608/50000]\tLoss: 1.6036\tLR: 0.073146\nTraining Epoch: 1 [36736/50000]\tLoss: 1.4387\tLR: 0.073402\nTraining Epoch: 1 [36864/50000]\tLoss: 1.4679\tLR: 0.073657\nTraining Epoch: 1 [36992/50000]\tLoss: 1.7237\tLR: 0.073913\nTraining Epoch: 1 [37120/50000]\tLoss: 1.5367\tLR: 0.074169\nTraining Epoch: 1 [37248/50000]\tLoss: 1.4719\tLR: 0.074425\nTraining Epoch: 1 [37376/50000]\tLoss: 1.6210\tLR: 0.074680\nTraining Epoch: 1 [37504/50000]\tLoss: 1.4807\tLR: 0.074936\nTraining Epoch: 1 [37632/50000]\tLoss: 1.6083\tLR: 0.075192\nTraining Epoch: 1 [37760/50000]\tLoss: 1.7381\tLR: 0.075448\nTraining Epoch: 1 [37888/50000]\tLoss: 1.6073\tLR: 0.075703\nTraining Epoch: 1 [38016/50000]\tLoss: 1.3666\tLR: 0.075959\nTraining Epoch: 1 [38144/50000]\tLoss: 1.6051\tLR: 0.076215\nTraining Epoch: 1 [38272/50000]\tLoss: 1.5382\tLR: 0.076471\nTraining Epoch: 1 [38400/50000]\tLoss: 1.3586\tLR: 0.076726\nTraining Epoch: 1 [38528/50000]\tLoss: 1.4575\tLR: 0.076982\nTraining Epoch: 1 [38656/50000]\tLoss: 1.4771\tLR: 0.077238\nTraining Epoch: 1 [38784/50000]\tLoss: 1.5194\tLR: 0.077494\nTraining Epoch: 1 [38912/50000]\tLoss: 1.7002\tLR: 0.077749\nTraining Epoch: 1 [39040/50000]\tLoss: 1.4485\tLR: 0.078005\nTraining Epoch: 1 [39168/50000]\tLoss: 1.6523\tLR: 0.078261\nTraining Epoch: 1 [39296/50000]\tLoss: 1.6679\tLR: 0.078517\nTraining Epoch: 1 [39424/50000]\tLoss: 1.3711\tLR: 0.078772\nTraining Epoch: 1 [39552/50000]\tLoss: 1.6484\tLR: 0.079028\nTraining Epoch: 1 [39680/50000]\tLoss: 1.4738\tLR: 0.079284\nTraining Epoch: 1 [39808/50000]\tLoss: 1.4539\tLR: 0.079540\nTraining Epoch: 1 [39936/50000]\tLoss: 1.3941\tLR: 0.079795\nTraining Epoch: 1 [40064/50000]\tLoss: 1.4000\tLR: 0.080051\nTraining Epoch: 1 [40192/50000]\tLoss: 1.6353\tLR: 0.080307\nTraining Epoch: 1 [40320/50000]\tLoss: 1.5703\tLR: 0.080563\nTraining Epoch: 1 [40448/50000]\tLoss: 1.4807\tLR: 0.080818\nTraining Epoch: 1 [40576/50000]\tLoss: 1.3056\tLR: 0.081074\nTraining Epoch: 1 [40704/50000]\tLoss: 1.4005\tLR: 0.081330\nTraining Epoch: 1 [40832/50000]\tLoss: 1.4587\tLR: 0.081586\nTraining Epoch: 1 [40960/50000]\tLoss: 1.5565\tLR: 0.081841\nTraining Epoch: 1 [41088/50000]\tLoss: 1.4321\tLR: 0.082097\nTraining Epoch: 1 [41216/50000]\tLoss: 1.5251\tLR: 0.082353\nTraining Epoch: 1 [41344/50000]\tLoss: 1.3012\tLR: 0.082609\nTraining Epoch: 1 [41472/50000]\tLoss: 1.5518\tLR: 0.082864\nTraining Epoch: 1 [41600/50000]\tLoss: 1.4658\tLR: 0.083120\nTraining Epoch: 1 [41728/50000]\tLoss: 1.3829\tLR: 0.083376\nTraining Epoch: 1 [41856/50000]\tLoss: 1.6461\tLR: 0.083632\nTraining Epoch: 1 [41984/50000]\tLoss: 1.3541\tLR: 0.083887\nTraining Epoch: 1 [42112/50000]\tLoss: 1.3461\tLR: 0.084143\nTraining Epoch: 1 [42240/50000]\tLoss: 1.4352\tLR: 0.084399\nTraining Epoch: 1 [42368/50000]\tLoss: 1.5030\tLR: 0.084655\nTraining Epoch: 1 [42496/50000]\tLoss: 1.7065\tLR: 0.084910\nTraining Epoch: 1 [42624/50000]\tLoss: 1.5311\tLR: 0.085166\nTraining Epoch: 1 [42752/50000]\tLoss: 1.5247\tLR: 0.085422\nTraining Epoch: 1 [42880/50000]\tLoss: 1.4648\tLR: 0.085678\nTraining Epoch: 1 [43008/50000]\tLoss: 1.4396\tLR: 0.085934\nTraining Epoch: 1 [43136/50000]\tLoss: 1.4771\tLR: 0.086189\nTraining Epoch: 1 [43264/50000]\tLoss: 1.6321\tLR: 0.086445\nTraining Epoch: 1 [43392/50000]\tLoss: 1.4719\tLR: 0.086701\nTraining Epoch: 1 [43520/50000]\tLoss: 1.4958\tLR: 0.086957\nTraining Epoch: 1 [43648/50000]\tLoss: 1.4615\tLR: 0.087212\nTraining Epoch: 1 [43776/50000]\tLoss: 1.3615\tLR: 0.087468\nTraining Epoch: 1 [43904/50000]\tLoss: 1.5709\tLR: 0.087724\nTraining Epoch: 1 [44032/50000]\tLoss: 1.2778\tLR: 0.087980\nTraining Epoch: 1 [44160/50000]\tLoss: 1.5219\tLR: 0.088235\nTraining Epoch: 1 [44288/50000]\tLoss: 1.5220\tLR: 0.088491\nTraining Epoch: 1 [44416/50000]\tLoss: 1.4838\tLR: 0.088747\nTraining Epoch: 1 [44544/50000]\tLoss: 1.3352\tLR: 0.089003\nTraining Epoch: 1 [44672/50000]\tLoss: 1.4041\tLR: 0.089258\nTraining Epoch: 1 [44800/50000]\tLoss: 1.3646\tLR: 0.089514\nTraining Epoch: 1 [44928/50000]\tLoss: 1.5556\tLR: 0.089770\nTraining Epoch: 1 [45056/50000]\tLoss: 1.3452\tLR: 0.090026\nTraining Epoch: 1 [45184/50000]\tLoss: 1.4215\tLR: 0.090281\nTraining Epoch: 1 [45312/50000]\tLoss: 1.3187\tLR: 0.090537\nTraining Epoch: 1 [45440/50000]\tLoss: 1.5721\tLR: 0.090793\nTraining Epoch: 1 [45568/50000]\tLoss: 1.5591\tLR: 0.091049\nTraining Epoch: 1 [45696/50000]\tLoss: 1.3189\tLR: 0.091304\nTraining Epoch: 1 [45824/50000]\tLoss: 1.4657\tLR: 0.091560\nTraining Epoch: 1 [45952/50000]\tLoss: 1.5207\tLR: 0.091816\nTraining Epoch: 1 [46080/50000]\tLoss: 1.4226\tLR: 0.092072\nTraining Epoch: 1 [46208/50000]\tLoss: 1.5634\tLR: 0.092327\nTraining Epoch: 1 [46336/50000]\tLoss: 1.4622\tLR: 0.092583\nTraining Epoch: 1 [46464/50000]\tLoss: 1.4240\tLR: 0.092839\nTraining Epoch: 1 [46592/50000]\tLoss: 1.4295\tLR: 0.093095\nTraining Epoch: 1 [46720/50000]\tLoss: 1.4848\tLR: 0.093350\nTraining Epoch: 1 [46848/50000]\tLoss: 1.4312\tLR: 0.093606\nTraining Epoch: 1 [46976/50000]\tLoss: 1.3881\tLR: 0.093862\nTraining Epoch: 1 [47104/50000]\tLoss: 1.3694\tLR: 0.094118\nTraining Epoch: 1 [47232/50000]\tLoss: 1.5526\tLR: 0.094373\nTraining Epoch: 1 [47360/50000]\tLoss: 1.4971\tLR: 0.094629\nTraining Epoch: 1 [47488/50000]\tLoss: 1.3390\tLR: 0.094885\nTraining Epoch: 1 [47616/50000]\tLoss: 1.4598\tLR: 0.095141\nTraining Epoch: 1 [47744/50000]\tLoss: 1.5411\tLR: 0.095396\nTraining Epoch: 1 [47872/50000]\tLoss: 1.2310\tLR: 0.095652\nTraining Epoch: 1 [48000/50000]\tLoss: 1.4480\tLR: 0.095908\nTraining Epoch: 1 [48128/50000]\tLoss: 1.6235\tLR: 0.096164\nTraining Epoch: 1 [48256/50000]\tLoss: 1.1816\tLR: 0.096419\nTraining Epoch: 1 [48384/50000]\tLoss: 1.3276\tLR: 0.096675\nTraining Epoch: 1 [48512/50000]\tLoss: 1.2837\tLR: 0.096931\nTraining Epoch: 1 [48640/50000]\tLoss: 1.4108\tLR: 0.097187\nTraining Epoch: 1 [48768/50000]\tLoss: 1.2344\tLR: 0.097442\nTraining Epoch: 1 [48896/50000]\tLoss: 1.4065\tLR: 0.097698\nTraining Epoch: 1 [49024/50000]\tLoss: 1.4655\tLR: 0.097954\nTraining Epoch: 1 [49152/50000]\tLoss: 1.5703\tLR: 0.098210\nTraining Epoch: 1 [49280/50000]\tLoss: 1.6139\tLR: 0.098465\nTraining Epoch: 1 [49408/50000]\tLoss: 1.6764\tLR: 0.098721\nTraining Epoch: 1 [49536/50000]\tLoss: 1.3388\tLR: 0.098977\nTraining Epoch: 1 [49664/50000]\tLoss: 1.6056\tLR: 0.099233\nTraining Epoch: 1 [49792/50000]\tLoss: 1.3783\tLR: 0.099488\nTraining Epoch: 1 [49920/50000]\tLoss: 1.1541\tLR: 0.099744\nTraining Epoch: 1 [50000/50000]\tLoss: 1.3632\tLR: 0.100000\nTest set: Average loss: 0.0151, Accuracy: 0.3880\n\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:149: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","output_type":"stream"},{"name":"stdout","text":"Training Epoch: 2 [128/50000]\tLoss: 1.6367\tLR: 0.100000\nTraining Epoch: 2 [256/50000]\tLoss: 1.4351\tLR: 0.100000\nTraining Epoch: 2 [384/50000]\tLoss: 1.4422\tLR: 0.100000\nTraining Epoch: 2 [512/50000]\tLoss: 1.4248\tLR: 0.100000\nTraining Epoch: 2 [640/50000]\tLoss: 1.4554\tLR: 0.100000\nTraining Epoch: 2 [768/50000]\tLoss: 1.5007\tLR: 0.100000\nTraining Epoch: 2 [896/50000]\tLoss: 1.6712\tLR: 0.100000\nTraining Epoch: 2 [1024/50000]\tLoss: 1.3870\tLR: 0.100000\nTraining Epoch: 2 [1152/50000]\tLoss: 1.6635\tLR: 0.100000\nTraining Epoch: 2 [1280/50000]\tLoss: 1.4878\tLR: 0.100000\nTraining Epoch: 2 [1408/50000]\tLoss: 1.6492\tLR: 0.100000\nTraining Epoch: 2 [1536/50000]\tLoss: 1.4627\tLR: 0.100000\nTraining Epoch: 2 [1664/50000]\tLoss: 1.5006\tLR: 0.100000\nTraining Epoch: 2 [1792/50000]\tLoss: 1.5409\tLR: 0.100000\nTraining Epoch: 2 [1920/50000]\tLoss: 1.3672\tLR: 0.100000\nTraining Epoch: 2 [2048/50000]\tLoss: 1.3425\tLR: 0.100000\nTraining Epoch: 2 [2176/50000]\tLoss: 1.4334\tLR: 0.100000\nTraining Epoch: 2 [2304/50000]\tLoss: 1.4320\tLR: 0.100000\nTraining Epoch: 2 [2432/50000]\tLoss: 1.4283\tLR: 0.100000\nTraining Epoch: 2 [2560/50000]\tLoss: 1.4133\tLR: 0.100000\nTraining Epoch: 2 [2688/50000]\tLoss: 1.1715\tLR: 0.100000\nTraining Epoch: 2 [2816/50000]\tLoss: 1.3466\tLR: 0.100000\nTraining Epoch: 2 [2944/50000]\tLoss: 1.3015\tLR: 0.100000\nTraining Epoch: 2 [3072/50000]\tLoss: 1.3579\tLR: 0.100000\nTraining Epoch: 2 [3200/50000]\tLoss: 1.2383\tLR: 0.100000\nTraining Epoch: 2 [3328/50000]\tLoss: 1.2178\tLR: 0.100000\nTraining Epoch: 2 [3456/50000]\tLoss: 1.2933\tLR: 0.100000\nTraining Epoch: 2 [3584/50000]\tLoss: 1.4532\tLR: 0.100000\nTraining Epoch: 2 [3712/50000]\tLoss: 1.3264\tLR: 0.100000\nTraining Epoch: 2 [3840/50000]\tLoss: 1.3804\tLR: 0.100000\nTraining Epoch: 2 [3968/50000]\tLoss: 1.2943\tLR: 0.100000\nTraining Epoch: 2 [4096/50000]\tLoss: 1.3393\tLR: 0.100000\nTraining Epoch: 2 [4224/50000]\tLoss: 1.3280\tLR: 0.100000\nTraining Epoch: 2 [4352/50000]\tLoss: 1.3509\tLR: 0.100000\nTraining Epoch: 2 [4480/50000]\tLoss: 1.4753\tLR: 0.100000\nTraining Epoch: 2 [4608/50000]\tLoss: 1.3728\tLR: 0.100000\nTraining Epoch: 2 [4736/50000]\tLoss: 1.3070\tLR: 0.100000\nTraining Epoch: 2 [4864/50000]\tLoss: 1.3778\tLR: 0.100000\nTraining Epoch: 2 [4992/50000]\tLoss: 1.4002\tLR: 0.100000\nTraining Epoch: 2 [5120/50000]\tLoss: 1.3120\tLR: 0.100000\nTraining Epoch: 2 [5248/50000]\tLoss: 1.3946\tLR: 0.100000\nTraining Epoch: 2 [5376/50000]\tLoss: 1.4789\tLR: 0.100000\nTraining Epoch: 2 [5504/50000]\tLoss: 1.4315\tLR: 0.100000\nTraining Epoch: 2 [5632/50000]\tLoss: 1.2078\tLR: 0.100000\nTraining Epoch: 2 [5760/50000]\tLoss: 1.2314\tLR: 0.100000\nTraining Epoch: 2 [5888/50000]\tLoss: 1.4258\tLR: 0.100000\nTraining Epoch: 2 [6016/50000]\tLoss: 1.4197\tLR: 0.100000\nTraining Epoch: 2 [6144/50000]\tLoss: 1.2899\tLR: 0.100000\nTraining Epoch: 2 [6272/50000]\tLoss: 1.4368\tLR: 0.100000\nTraining Epoch: 2 [6400/50000]\tLoss: 1.3557\tLR: 0.100000\nTraining Epoch: 2 [6528/50000]\tLoss: 1.2785\tLR: 0.100000\nTraining Epoch: 2 [6656/50000]\tLoss: 1.3231\tLR: 0.100000\nTraining Epoch: 2 [6784/50000]\tLoss: 1.3297\tLR: 0.100000\nTraining Epoch: 2 [6912/50000]\tLoss: 1.2421\tLR: 0.100000\nTraining Epoch: 2 [7040/50000]\tLoss: 1.3912\tLR: 0.100000\nTraining Epoch: 2 [7168/50000]\tLoss: 1.1352\tLR: 0.100000\nTraining Epoch: 2 [7296/50000]\tLoss: 1.3220\tLR: 0.100000\nTraining Epoch: 2 [7424/50000]\tLoss: 1.2355\tLR: 0.100000\nTraining Epoch: 2 [7552/50000]\tLoss: 1.4632\tLR: 0.100000\nTraining Epoch: 2 [7680/50000]\tLoss: 1.1781\tLR: 0.100000\nTraining Epoch: 2 [7808/50000]\tLoss: 1.1971\tLR: 0.100000\nTraining Epoch: 2 [7936/50000]\tLoss: 1.2004\tLR: 0.100000\nTraining Epoch: 2 [8064/50000]\tLoss: 1.3177\tLR: 0.100000\nTraining Epoch: 2 [8192/50000]\tLoss: 0.9969\tLR: 0.100000\nTraining Epoch: 2 [8320/50000]\tLoss: 1.0914\tLR: 0.100000\nTraining Epoch: 2 [8448/50000]\tLoss: 1.2719\tLR: 0.100000\nTraining Epoch: 2 [8576/50000]\tLoss: 1.1805\tLR: 0.100000\nTraining Epoch: 2 [8704/50000]\tLoss: 0.9926\tLR: 0.100000\nTraining Epoch: 2 [8832/50000]\tLoss: 1.1258\tLR: 0.100000\nTraining Epoch: 2 [8960/50000]\tLoss: 1.2769\tLR: 0.100000\nTraining Epoch: 2 [9088/50000]\tLoss: 1.4374\tLR: 0.100000\nTraining Epoch: 2 [9216/50000]\tLoss: 1.2849\tLR: 0.100000\nTraining Epoch: 2 [9344/50000]\tLoss: 1.4236\tLR: 0.100000\nTraining Epoch: 2 [9472/50000]\tLoss: 1.4281\tLR: 0.100000\nTraining Epoch: 2 [9600/50000]\tLoss: 1.0505\tLR: 0.100000\nTraining Epoch: 2 [9728/50000]\tLoss: 1.3730\tLR: 0.100000\nTraining Epoch: 2 [9856/50000]\tLoss: 1.4139\tLR: 0.100000\nTraining Epoch: 2 [9984/50000]\tLoss: 1.2707\tLR: 0.100000\nTraining Epoch: 2 [10112/50000]\tLoss: 1.2849\tLR: 0.100000\nTraining Epoch: 2 [10240/50000]\tLoss: 1.2115\tLR: 0.100000\nTraining Epoch: 2 [10368/50000]\tLoss: 1.3824\tLR: 0.100000\nTraining Epoch: 2 [10496/50000]\tLoss: 1.2116\tLR: 0.100000\nTraining Epoch: 2 [10624/50000]\tLoss: 1.2793\tLR: 0.100000\nTraining Epoch: 2 [10752/50000]\tLoss: 1.3233\tLR: 0.100000\nTraining Epoch: 2 [10880/50000]\tLoss: 1.3991\tLR: 0.100000\nTraining Epoch: 2 [11008/50000]\tLoss: 1.2441\tLR: 0.100000\nTraining Epoch: 2 [11136/50000]\tLoss: 1.1069\tLR: 0.100000\nTraining Epoch: 2 [11264/50000]\tLoss: 1.3287\tLR: 0.100000\nTraining Epoch: 2 [11392/50000]\tLoss: 1.2005\tLR: 0.100000\nTraining Epoch: 2 [11520/50000]\tLoss: 1.2458\tLR: 0.100000\nTraining Epoch: 2 [11648/50000]\tLoss: 1.2828\tLR: 0.100000\nTraining Epoch: 2 [11776/50000]\tLoss: 1.2697\tLR: 0.100000\nTraining Epoch: 2 [11904/50000]\tLoss: 1.3853\tLR: 0.100000\nTraining Epoch: 2 [12032/50000]\tLoss: 1.5680\tLR: 0.100000\nTraining Epoch: 2 [12160/50000]\tLoss: 1.3000\tLR: 0.100000\nTraining Epoch: 2 [12288/50000]\tLoss: 1.0671\tLR: 0.100000\nTraining Epoch: 2 [12416/50000]\tLoss: 1.4236\tLR: 0.100000\nTraining Epoch: 2 [12544/50000]\tLoss: 1.0291\tLR: 0.100000\nTraining Epoch: 2 [12672/50000]\tLoss: 1.3830\tLR: 0.100000\nTraining Epoch: 2 [12800/50000]\tLoss: 1.2069\tLR: 0.100000\nTraining Epoch: 2 [12928/50000]\tLoss: 1.3559\tLR: 0.100000\nTraining Epoch: 2 [13056/50000]\tLoss: 1.2278\tLR: 0.100000\nTraining Epoch: 2 [13184/50000]\tLoss: 1.3174\tLR: 0.100000\nTraining Epoch: 2 [13312/50000]\tLoss: 1.0794\tLR: 0.100000\nTraining Epoch: 2 [13440/50000]\tLoss: 1.0504\tLR: 0.100000\nTraining Epoch: 2 [13568/50000]\tLoss: 1.2171\tLR: 0.100000\nTraining Epoch: 2 [13696/50000]\tLoss: 1.1784\tLR: 0.100000\nTraining Epoch: 2 [13824/50000]\tLoss: 1.1476\tLR: 0.100000\nTraining Epoch: 2 [13952/50000]\tLoss: 1.2551\tLR: 0.100000\nTraining Epoch: 2 [14080/50000]\tLoss: 1.3674\tLR: 0.100000\nTraining Epoch: 2 [14208/50000]\tLoss: 1.2142\tLR: 0.100000\nTraining Epoch: 2 [14336/50000]\tLoss: 1.1301\tLR: 0.100000\nTraining Epoch: 2 [14464/50000]\tLoss: 1.0925\tLR: 0.100000\nTraining Epoch: 2 [14592/50000]\tLoss: 1.1018\tLR: 0.100000\nTraining Epoch: 2 [14720/50000]\tLoss: 1.3809\tLR: 0.100000\nTraining Epoch: 2 [14848/50000]\tLoss: 1.1411\tLR: 0.100000\nTraining Epoch: 2 [14976/50000]\tLoss: 1.2782\tLR: 0.100000\nTraining Epoch: 2 [15104/50000]\tLoss: 1.1163\tLR: 0.100000\nTraining Epoch: 2 [15232/50000]\tLoss: 1.2612\tLR: 0.100000\nTraining Epoch: 2 [15360/50000]\tLoss: 1.1387\tLR: 0.100000\nTraining Epoch: 2 [15488/50000]\tLoss: 1.4350\tLR: 0.100000\nTraining Epoch: 2 [15616/50000]\tLoss: 1.1929\tLR: 0.100000\nTraining Epoch: 2 [15744/50000]\tLoss: 1.2497\tLR: 0.100000\nTraining Epoch: 2 [15872/50000]\tLoss: 1.3482\tLR: 0.100000\nTraining Epoch: 2 [16000/50000]\tLoss: 1.1401\tLR: 0.100000\nTraining Epoch: 2 [16128/50000]\tLoss: 1.3774\tLR: 0.100000\nTraining Epoch: 2 [16256/50000]\tLoss: 1.4027\tLR: 0.100000\nTraining Epoch: 2 [16384/50000]\tLoss: 1.0609\tLR: 0.100000\nTraining Epoch: 2 [16512/50000]\tLoss: 1.3317\tLR: 0.100000\nTraining Epoch: 2 [16640/50000]\tLoss: 1.2704\tLR: 0.100000\nTraining Epoch: 2 [16768/50000]\tLoss: 1.3084\tLR: 0.100000\nTraining Epoch: 2 [16896/50000]\tLoss: 1.2090\tLR: 0.100000\nTraining Epoch: 2 [17024/50000]\tLoss: 1.2607\tLR: 0.100000\nTraining Epoch: 2 [17152/50000]\tLoss: 1.3261\tLR: 0.100000\nTraining Epoch: 2 [17280/50000]\tLoss: 1.2698\tLR: 0.100000\nTraining Epoch: 2 [17408/50000]\tLoss: 1.3185\tLR: 0.100000\nTraining Epoch: 2 [17536/50000]\tLoss: 1.3487\tLR: 0.100000\nTraining Epoch: 2 [17664/50000]\tLoss: 1.1077\tLR: 0.100000\nTraining Epoch: 2 [17792/50000]\tLoss: 1.2084\tLR: 0.100000\nTraining Epoch: 2 [17920/50000]\tLoss: 1.2847\tLR: 0.100000\nTraining Epoch: 2 [18048/50000]\tLoss: 1.4568\tLR: 0.100000\nTraining Epoch: 2 [18176/50000]\tLoss: 1.1086\tLR: 0.100000\nTraining Epoch: 2 [18304/50000]\tLoss: 1.0206\tLR: 0.100000\nTraining Epoch: 2 [18432/50000]\tLoss: 1.1070\tLR: 0.100000\nTraining Epoch: 2 [18560/50000]\tLoss: 1.3033\tLR: 0.100000\nTraining Epoch: 2 [18688/50000]\tLoss: 1.1912\tLR: 0.100000\nTraining Epoch: 2 [18816/50000]\tLoss: 1.3948\tLR: 0.100000\nTraining Epoch: 2 [18944/50000]\tLoss: 1.1600\tLR: 0.100000\nTraining Epoch: 2 [19072/50000]\tLoss: 1.2189\tLR: 0.100000\nTraining Epoch: 2 [19200/50000]\tLoss: 1.3147\tLR: 0.100000\nTraining Epoch: 2 [19328/50000]\tLoss: 1.0976\tLR: 0.100000\nTraining Epoch: 2 [19456/50000]\tLoss: 1.1919\tLR: 0.100000\nTraining Epoch: 2 [19584/50000]\tLoss: 0.9653\tLR: 0.100000\nTraining Epoch: 2 [19712/50000]\tLoss: 1.1960\tLR: 0.100000\nTraining Epoch: 2 [19840/50000]\tLoss: 1.2311\tLR: 0.100000\nTraining Epoch: 2 [19968/50000]\tLoss: 1.0649\tLR: 0.100000\nTraining Epoch: 2 [20096/50000]\tLoss: 1.3774\tLR: 0.100000\nTraining Epoch: 2 [20224/50000]\tLoss: 1.0842\tLR: 0.100000\nTraining Epoch: 2 [20352/50000]\tLoss: 1.1528\tLR: 0.100000\nTraining Epoch: 2 [20480/50000]\tLoss: 1.1335\tLR: 0.100000\nTraining Epoch: 2 [20608/50000]\tLoss: 1.1762\tLR: 0.100000\nTraining Epoch: 2 [20736/50000]\tLoss: 1.1469\tLR: 0.100000\nTraining Epoch: 2 [20864/50000]\tLoss: 1.2986\tLR: 0.100000\nTraining Epoch: 2 [20992/50000]\tLoss: 1.3648\tLR: 0.100000\nTraining Epoch: 2 [21120/50000]\tLoss: 1.2018\tLR: 0.100000\nTraining Epoch: 2 [21248/50000]\tLoss: 1.2490\tLR: 0.100000\nTraining Epoch: 2 [21376/50000]\tLoss: 1.2011\tLR: 0.100000\nTraining Epoch: 2 [21504/50000]\tLoss: 1.2648\tLR: 0.100000\nTraining Epoch: 2 [21632/50000]\tLoss: 1.1565\tLR: 0.100000\nTraining Epoch: 2 [21760/50000]\tLoss: 1.2211\tLR: 0.100000\nTraining Epoch: 2 [21888/50000]\tLoss: 1.1545\tLR: 0.100000\nTraining Epoch: 2 [22016/50000]\tLoss: 1.1634\tLR: 0.100000\nTraining Epoch: 2 [22144/50000]\tLoss: 1.0679\tLR: 0.100000\nTraining Epoch: 2 [22272/50000]\tLoss: 1.2529\tLR: 0.100000\nTraining Epoch: 2 [22400/50000]\tLoss: 1.2826\tLR: 0.100000\nTraining Epoch: 2 [22528/50000]\tLoss: 1.1664\tLR: 0.100000\nTraining Epoch: 2 [22656/50000]\tLoss: 1.0249\tLR: 0.100000\nTraining Epoch: 2 [22784/50000]\tLoss: 1.1020\tLR: 0.100000\nTraining Epoch: 2 [22912/50000]\tLoss: 1.1338\tLR: 0.100000\nTraining Epoch: 2 [23040/50000]\tLoss: 1.2115\tLR: 0.100000\nTraining Epoch: 2 [23168/50000]\tLoss: 1.1983\tLR: 0.100000\nTraining Epoch: 2 [23296/50000]\tLoss: 0.9411\tLR: 0.100000\nTraining Epoch: 2 [23424/50000]\tLoss: 1.1315\tLR: 0.100000\nTraining Epoch: 2 [23552/50000]\tLoss: 1.0863\tLR: 0.100000\nTraining Epoch: 2 [23680/50000]\tLoss: 1.1819\tLR: 0.100000\nTraining Epoch: 2 [23808/50000]\tLoss: 1.1659\tLR: 0.100000\nTraining Epoch: 2 [23936/50000]\tLoss: 1.0817\tLR: 0.100000\nTraining Epoch: 2 [24064/50000]\tLoss: 1.2174\tLR: 0.100000\nTraining Epoch: 2 [24192/50000]\tLoss: 1.1408\tLR: 0.100000\nTraining Epoch: 2 [24320/50000]\tLoss: 1.2856\tLR: 0.100000\nTraining Epoch: 2 [24448/50000]\tLoss: 1.2979\tLR: 0.100000\nTraining Epoch: 2 [24576/50000]\tLoss: 1.1774\tLR: 0.100000\nTraining Epoch: 2 [24704/50000]\tLoss: 1.0812\tLR: 0.100000\nTraining Epoch: 2 [24832/50000]\tLoss: 1.1983\tLR: 0.100000\nTraining Epoch: 2 [24960/50000]\tLoss: 1.2773\tLR: 0.100000\nTraining Epoch: 2 [25088/50000]\tLoss: 1.0579\tLR: 0.100000\nTraining Epoch: 2 [25216/50000]\tLoss: 1.3385\tLR: 0.100000\nTraining Epoch: 2 [25344/50000]\tLoss: 1.1940\tLR: 0.100000\nTraining Epoch: 2 [25472/50000]\tLoss: 1.1147\tLR: 0.100000\nTraining Epoch: 2 [25600/50000]\tLoss: 1.2140\tLR: 0.100000\nTraining Epoch: 2 [25728/50000]\tLoss: 1.2155\tLR: 0.100000\nTraining Epoch: 2 [25856/50000]\tLoss: 1.1818\tLR: 0.100000\nTraining Epoch: 2 [25984/50000]\tLoss: 1.2662\tLR: 0.100000\nTraining Epoch: 2 [26112/50000]\tLoss: 1.1335\tLR: 0.100000\nTraining Epoch: 2 [26240/50000]\tLoss: 1.1703\tLR: 0.100000\nTraining Epoch: 2 [26368/50000]\tLoss: 1.2118\tLR: 0.100000\nTraining Epoch: 2 [26496/50000]\tLoss: 1.0174\tLR: 0.100000\nTraining Epoch: 2 [26624/50000]\tLoss: 1.0616\tLR: 0.100000\nTraining Epoch: 2 [26752/50000]\tLoss: 1.0871\tLR: 0.100000\nTraining Epoch: 2 [26880/50000]\tLoss: 1.2961\tLR: 0.100000\nTraining Epoch: 2 [27008/50000]\tLoss: 1.1174\tLR: 0.100000\nTraining Epoch: 2 [27136/50000]\tLoss: 0.9720\tLR: 0.100000\nTraining Epoch: 2 [27264/50000]\tLoss: 1.1838\tLR: 0.100000\nTraining Epoch: 2 [27392/50000]\tLoss: 1.1042\tLR: 0.100000\nTraining Epoch: 2 [27520/50000]\tLoss: 0.9952\tLR: 0.100000\nTraining Epoch: 2 [27648/50000]\tLoss: 1.0680\tLR: 0.100000\nTraining Epoch: 2 [27776/50000]\tLoss: 1.2840\tLR: 0.100000\nTraining Epoch: 2 [27904/50000]\tLoss: 1.2267\tLR: 0.100000\nTraining Epoch: 2 [28032/50000]\tLoss: 1.1785\tLR: 0.100000\nTraining Epoch: 2 [28160/50000]\tLoss: 1.0883\tLR: 0.100000\nTraining Epoch: 2 [28288/50000]\tLoss: 1.0326\tLR: 0.100000\nTraining Epoch: 2 [28416/50000]\tLoss: 1.0978\tLR: 0.100000\nTraining Epoch: 2 [28544/50000]\tLoss: 1.0872\tLR: 0.100000\nTraining Epoch: 2 [28672/50000]\tLoss: 1.1032\tLR: 0.100000\nTraining Epoch: 2 [28800/50000]\tLoss: 0.9883\tLR: 0.100000\nTraining Epoch: 2 [28928/50000]\tLoss: 1.1865\tLR: 0.100000\nTraining Epoch: 2 [29056/50000]\tLoss: 1.0569\tLR: 0.100000\nTraining Epoch: 2 [29184/50000]\tLoss: 1.0665\tLR: 0.100000\nTraining Epoch: 2 [29312/50000]\tLoss: 1.0590\tLR: 0.100000\nTraining Epoch: 2 [29440/50000]\tLoss: 1.0803\tLR: 0.100000\nTraining Epoch: 2 [29568/50000]\tLoss: 1.1986\tLR: 0.100000\nTraining Epoch: 2 [29696/50000]\tLoss: 1.2009\tLR: 0.100000\nTraining Epoch: 2 [29824/50000]\tLoss: 1.1923\tLR: 0.100000\nTraining Epoch: 2 [29952/50000]\tLoss: 1.0692\tLR: 0.100000\nTraining Epoch: 2 [30080/50000]\tLoss: 1.1890\tLR: 0.100000\nTraining Epoch: 2 [30208/50000]\tLoss: 1.0603\tLR: 0.100000\nTraining Epoch: 2 [30336/50000]\tLoss: 1.1084\tLR: 0.100000\nTraining Epoch: 2 [30464/50000]\tLoss: 0.9903\tLR: 0.100000\nTraining Epoch: 2 [30592/50000]\tLoss: 1.3051\tLR: 0.100000\nTraining Epoch: 2 [30720/50000]\tLoss: 0.9344\tLR: 0.100000\nTraining Epoch: 2 [30848/50000]\tLoss: 1.1182\tLR: 0.100000\nTraining Epoch: 2 [30976/50000]\tLoss: 1.0385\tLR: 0.100000\nTraining Epoch: 2 [31104/50000]\tLoss: 1.4623\tLR: 0.100000\nTraining Epoch: 2 [31232/50000]\tLoss: 0.9059\tLR: 0.100000\nTraining Epoch: 2 [31360/50000]\tLoss: 1.0659\tLR: 0.100000\nTraining Epoch: 2 [31488/50000]\tLoss: 1.1397\tLR: 0.100000\nTraining Epoch: 2 [31616/50000]\tLoss: 1.1952\tLR: 0.100000\nTraining Epoch: 2 [31744/50000]\tLoss: 1.1996\tLR: 0.100000\nTraining Epoch: 2 [31872/50000]\tLoss: 1.1734\tLR: 0.100000\nTraining Epoch: 2 [32000/50000]\tLoss: 1.0777\tLR: 0.100000\nTraining Epoch: 2 [32128/50000]\tLoss: 1.0048\tLR: 0.100000\nTraining Epoch: 2 [32256/50000]\tLoss: 1.0642\tLR: 0.100000\nTraining Epoch: 2 [32384/50000]\tLoss: 1.0540\tLR: 0.100000\nTraining Epoch: 2 [32512/50000]\tLoss: 1.0775\tLR: 0.100000\nTraining Epoch: 2 [32640/50000]\tLoss: 1.1300\tLR: 0.100000\nTraining Epoch: 2 [32768/50000]\tLoss: 0.9617\tLR: 0.100000\nTraining Epoch: 2 [32896/50000]\tLoss: 1.1207\tLR: 0.100000\nTraining Epoch: 2 [33024/50000]\tLoss: 1.0927\tLR: 0.100000\nTraining Epoch: 2 [33152/50000]\tLoss: 1.2670\tLR: 0.100000\nTraining Epoch: 2 [33280/50000]\tLoss: 1.3272\tLR: 0.100000\nTraining Epoch: 2 [33408/50000]\tLoss: 1.2827\tLR: 0.100000\nTraining Epoch: 2 [33536/50000]\tLoss: 0.8618\tLR: 0.100000\nTraining Epoch: 2 [33664/50000]\tLoss: 1.0667\tLR: 0.100000\nTraining Epoch: 2 [33792/50000]\tLoss: 1.2112\tLR: 0.100000\nTraining Epoch: 2 [33920/50000]\tLoss: 1.0930\tLR: 0.100000\nTraining Epoch: 2 [34048/50000]\tLoss: 0.9589\tLR: 0.100000\nTraining Epoch: 2 [34176/50000]\tLoss: 1.1228\tLR: 0.100000\nTraining Epoch: 2 [34304/50000]\tLoss: 0.9912\tLR: 0.100000\nTraining Epoch: 2 [34432/50000]\tLoss: 1.2451\tLR: 0.100000\nTraining Epoch: 2 [34560/50000]\tLoss: 1.1957\tLR: 0.100000\nTraining Epoch: 2 [34688/50000]\tLoss: 0.9300\tLR: 0.100000\nTraining Epoch: 2 [34816/50000]\tLoss: 1.1873\tLR: 0.100000\nTraining Epoch: 2 [34944/50000]\tLoss: 0.9011\tLR: 0.100000\nTraining Epoch: 2 [35072/50000]\tLoss: 1.0711\tLR: 0.100000\nTraining Epoch: 2 [35200/50000]\tLoss: 0.9406\tLR: 0.100000\nTraining Epoch: 2 [35328/50000]\tLoss: 1.2857\tLR: 0.100000\nTraining Epoch: 2 [35456/50000]\tLoss: 0.9680\tLR: 0.100000\nTraining Epoch: 2 [35584/50000]\tLoss: 1.2046\tLR: 0.100000\nTraining Epoch: 2 [35712/50000]\tLoss: 1.1197\tLR: 0.100000\nTraining Epoch: 2 [35840/50000]\tLoss: 1.1261\tLR: 0.100000\nTraining Epoch: 2 [35968/50000]\tLoss: 1.0491\tLR: 0.100000\nTraining Epoch: 2 [36096/50000]\tLoss: 1.2862\tLR: 0.100000\nTraining Epoch: 2 [36224/50000]\tLoss: 1.1563\tLR: 0.100000\nTraining Epoch: 2 [36352/50000]\tLoss: 1.0585\tLR: 0.100000\nTraining Epoch: 2 [36480/50000]\tLoss: 1.1796\tLR: 0.100000\nTraining Epoch: 2 [36608/50000]\tLoss: 1.2030\tLR: 0.100000\nTraining Epoch: 2 [36736/50000]\tLoss: 1.0342\tLR: 0.100000\nTraining Epoch: 2 [36864/50000]\tLoss: 1.0062\tLR: 0.100000\nTraining Epoch: 2 [36992/50000]\tLoss: 1.0366\tLR: 0.100000\nTraining Epoch: 2 [37120/50000]\tLoss: 1.0276\tLR: 0.100000\nTraining Epoch: 2 [37248/50000]\tLoss: 1.1594\tLR: 0.100000\nTraining Epoch: 2 [37376/50000]\tLoss: 0.9383\tLR: 0.100000\nTraining Epoch: 2 [37504/50000]\tLoss: 1.0889\tLR: 0.100000\nTraining Epoch: 2 [37632/50000]\tLoss: 1.1783\tLR: 0.100000\nTraining Epoch: 2 [37760/50000]\tLoss: 1.0967\tLR: 0.100000\nTraining Epoch: 2 [37888/50000]\tLoss: 1.1743\tLR: 0.100000\nTraining Epoch: 2 [38016/50000]\tLoss: 1.2377\tLR: 0.100000\nTraining Epoch: 2 [38144/50000]\tLoss: 1.1561\tLR: 0.100000\nTraining Epoch: 2 [38272/50000]\tLoss: 1.1920\tLR: 0.100000\nTraining Epoch: 2 [38400/50000]\tLoss: 1.2137\tLR: 0.100000\nTraining Epoch: 2 [38528/50000]\tLoss: 1.0626\tLR: 0.100000\nTraining Epoch: 2 [38656/50000]\tLoss: 0.9796\tLR: 0.100000\nTraining Epoch: 2 [38784/50000]\tLoss: 0.9245\tLR: 0.100000\nTraining Epoch: 2 [38912/50000]\tLoss: 1.0166\tLR: 0.100000\nTraining Epoch: 2 [39040/50000]\tLoss: 0.9398\tLR: 0.100000\nTraining Epoch: 2 [39168/50000]\tLoss: 0.9668\tLR: 0.100000\nTraining Epoch: 2 [39296/50000]\tLoss: 1.0729\tLR: 0.100000\nTraining Epoch: 2 [39424/50000]\tLoss: 1.0932\tLR: 0.100000\nTraining Epoch: 2 [39552/50000]\tLoss: 0.8172\tLR: 0.100000\nTraining Epoch: 2 [39680/50000]\tLoss: 1.2470\tLR: 0.100000\nTraining Epoch: 2 [39808/50000]\tLoss: 1.1327\tLR: 0.100000\nTraining Epoch: 2 [39936/50000]\tLoss: 1.1505\tLR: 0.100000\nTraining Epoch: 2 [40064/50000]\tLoss: 1.0819\tLR: 0.100000\nTraining Epoch: 2 [40192/50000]\tLoss: 1.0275\tLR: 0.100000\nTraining Epoch: 2 [40320/50000]\tLoss: 1.0504\tLR: 0.100000\nTraining Epoch: 2 [40448/50000]\tLoss: 1.0530\tLR: 0.100000\nTraining Epoch: 2 [40576/50000]\tLoss: 0.9912\tLR: 0.100000\nTraining Epoch: 2 [40704/50000]\tLoss: 1.1325\tLR: 0.100000\nTraining Epoch: 2 [40832/50000]\tLoss: 1.0596\tLR: 0.100000\nTraining Epoch: 2 [40960/50000]\tLoss: 1.0102\tLR: 0.100000\nTraining Epoch: 2 [41088/50000]\tLoss: 1.1570\tLR: 0.100000\nTraining Epoch: 2 [41216/50000]\tLoss: 1.0817\tLR: 0.100000\nTraining Epoch: 2 [41344/50000]\tLoss: 0.9355\tLR: 0.100000\nTraining Epoch: 2 [41472/50000]\tLoss: 0.9659\tLR: 0.100000\nTraining Epoch: 2 [41600/50000]\tLoss: 0.9321\tLR: 0.100000\nTraining Epoch: 2 [41728/50000]\tLoss: 1.0010\tLR: 0.100000\nTraining Epoch: 2 [41856/50000]\tLoss: 0.9129\tLR: 0.100000\nTraining Epoch: 2 [41984/50000]\tLoss: 1.0894\tLR: 0.100000\nTraining Epoch: 2 [42112/50000]\tLoss: 1.0309\tLR: 0.100000\nTraining Epoch: 2 [42240/50000]\tLoss: 1.0046\tLR: 0.100000\nTraining Epoch: 2 [42368/50000]\tLoss: 1.0406\tLR: 0.100000\nTraining Epoch: 2 [42496/50000]\tLoss: 1.0412\tLR: 0.100000\nTraining Epoch: 2 [42624/50000]\tLoss: 1.1617\tLR: 0.100000\nTraining Epoch: 2 [42752/50000]\tLoss: 1.0469\tLR: 0.100000\nTraining Epoch: 2 [42880/50000]\tLoss: 0.9682\tLR: 0.100000\nTraining Epoch: 2 [43008/50000]\tLoss: 1.0122\tLR: 0.100000\nTraining Epoch: 2 [43136/50000]\tLoss: 0.9087\tLR: 0.100000\nTraining Epoch: 2 [43264/50000]\tLoss: 1.2328\tLR: 0.100000\nTraining Epoch: 2 [43392/50000]\tLoss: 0.9877\tLR: 0.100000\nTraining Epoch: 2 [43520/50000]\tLoss: 0.9630\tLR: 0.100000\nTraining Epoch: 2 [43648/50000]\tLoss: 0.8051\tLR: 0.100000\nTraining Epoch: 2 [43776/50000]\tLoss: 1.0983\tLR: 0.100000\nTraining Epoch: 2 [43904/50000]\tLoss: 1.0013\tLR: 0.100000\nTraining Epoch: 2 [44032/50000]\tLoss: 1.0693\tLR: 0.100000\nTraining Epoch: 2 [44160/50000]\tLoss: 1.1194\tLR: 0.100000\nTraining Epoch: 2 [44288/50000]\tLoss: 0.9907\tLR: 0.100000\nTraining Epoch: 2 [44416/50000]\tLoss: 1.1179\tLR: 0.100000\nTraining Epoch: 2 [44544/50000]\tLoss: 1.1032\tLR: 0.100000\nTraining Epoch: 2 [44672/50000]\tLoss: 1.0252\tLR: 0.100000\nTraining Epoch: 2 [44800/50000]\tLoss: 1.0761\tLR: 0.100000\nTraining Epoch: 2 [44928/50000]\tLoss: 1.0994\tLR: 0.100000\nTraining Epoch: 2 [45056/50000]\tLoss: 1.2097\tLR: 0.100000\nTraining Epoch: 2 [45184/50000]\tLoss: 1.1279\tLR: 0.100000\nTraining Epoch: 2 [45312/50000]\tLoss: 0.8206\tLR: 0.100000\nTraining Epoch: 2 [45440/50000]\tLoss: 1.0727\tLR: 0.100000\nTraining Epoch: 2 [45568/50000]\tLoss: 1.0508\tLR: 0.100000\nTraining Epoch: 2 [45696/50000]\tLoss: 1.1921\tLR: 0.100000\nTraining Epoch: 2 [45824/50000]\tLoss: 1.4059\tLR: 0.100000\nTraining Epoch: 2 [45952/50000]\tLoss: 0.8826\tLR: 0.100000\nTraining Epoch: 2 [46080/50000]\tLoss: 1.1351\tLR: 0.100000\nTraining Epoch: 2 [46208/50000]\tLoss: 1.1161\tLR: 0.100000\nTraining Epoch: 2 [46336/50000]\tLoss: 1.0527\tLR: 0.100000\nTraining Epoch: 2 [46464/50000]\tLoss: 1.0644\tLR: 0.100000\nTraining Epoch: 2 [46592/50000]\tLoss: 1.2070\tLR: 0.100000\nTraining Epoch: 2 [46720/50000]\tLoss: 0.9736\tLR: 0.100000\nTraining Epoch: 2 [46848/50000]\tLoss: 0.9847\tLR: 0.100000\nTraining Epoch: 2 [46976/50000]\tLoss: 1.1830\tLR: 0.100000\nTraining Epoch: 2 [47104/50000]\tLoss: 0.8486\tLR: 0.100000\nTraining Epoch: 2 [47232/50000]\tLoss: 1.0813\tLR: 0.100000\nTraining Epoch: 2 [47360/50000]\tLoss: 0.9882\tLR: 0.100000\nTraining Epoch: 2 [47488/50000]\tLoss: 1.0960\tLR: 0.100000\nTraining Epoch: 2 [47616/50000]\tLoss: 1.1049\tLR: 0.100000\nTraining Epoch: 2 [47744/50000]\tLoss: 0.9000\tLR: 0.100000\nTraining Epoch: 2 [47872/50000]\tLoss: 1.1809\tLR: 0.100000\nTraining Epoch: 2 [48000/50000]\tLoss: 1.1879\tLR: 0.100000\nTraining Epoch: 2 [48128/50000]\tLoss: 1.1286\tLR: 0.100000\nTraining Epoch: 2 [48256/50000]\tLoss: 1.0374\tLR: 0.100000\nTraining Epoch: 2 [48384/50000]\tLoss: 1.0060\tLR: 0.100000\nTraining Epoch: 2 [48512/50000]\tLoss: 0.9070\tLR: 0.100000\nTraining Epoch: 2 [48640/50000]\tLoss: 1.0597\tLR: 0.100000\nTraining Epoch: 2 [48768/50000]\tLoss: 0.8749\tLR: 0.100000\nTraining Epoch: 2 [48896/50000]\tLoss: 0.9929\tLR: 0.100000\nTraining Epoch: 2 [49024/50000]\tLoss: 0.9393\tLR: 0.100000\nTraining Epoch: 2 [49152/50000]\tLoss: 0.8777\tLR: 0.100000\nTraining Epoch: 2 [49280/50000]\tLoss: 0.9653\tLR: 0.100000\nTraining Epoch: 2 [49408/50000]\tLoss: 0.9868\tLR: 0.100000\nTraining Epoch: 2 [49536/50000]\tLoss: 1.1315\tLR: 0.100000\nTraining Epoch: 2 [49664/50000]\tLoss: 0.9670\tLR: 0.100000\nTraining Epoch: 2 [49792/50000]\tLoss: 0.8852\tLR: 0.100000\nTraining Epoch: 2 [49920/50000]\tLoss: 1.1166\tLR: 0.100000\nTraining Epoch: 2 [50000/50000]\tLoss: 1.0864\tLR: 0.100000\nTest set: Average loss: 0.0085, Accuracy: 0.6309\n\nTraining Epoch: 3 [128/50000]\tLoss: 1.0463\tLR: 0.100000\nTraining Epoch: 3 [256/50000]\tLoss: 1.0940\tLR: 0.100000\nTraining Epoch: 3 [384/50000]\tLoss: 1.0358\tLR: 0.100000\nTraining Epoch: 3 [512/50000]\tLoss: 1.0027\tLR: 0.100000\nTraining Epoch: 3 [640/50000]\tLoss: 0.9699\tLR: 0.100000\nTraining Epoch: 3 [768/50000]\tLoss: 1.3491\tLR: 0.100000\nTraining Epoch: 3 [896/50000]\tLoss: 1.0833\tLR: 0.100000\nTraining Epoch: 3 [1024/50000]\tLoss: 0.9465\tLR: 0.100000\nTraining Epoch: 3 [1152/50000]\tLoss: 0.8747\tLR: 0.100000\nTraining Epoch: 3 [1280/50000]\tLoss: 1.0853\tLR: 0.100000\nTraining Epoch: 3 [1408/50000]\tLoss: 0.9175\tLR: 0.100000\nTraining Epoch: 3 [1536/50000]\tLoss: 1.0875\tLR: 0.100000\nTraining Epoch: 3 [1664/50000]\tLoss: 0.7437\tLR: 0.100000\nTraining Epoch: 3 [1792/50000]\tLoss: 1.0657\tLR: 0.100000\nTraining Epoch: 3 [1920/50000]\tLoss: 1.0293\tLR: 0.100000\nTraining Epoch: 3 [2048/50000]\tLoss: 1.1637\tLR: 0.100000\nTraining Epoch: 3 [2176/50000]\tLoss: 1.1034\tLR: 0.100000\nTraining Epoch: 3 [2304/50000]\tLoss: 0.9640\tLR: 0.100000\nTraining Epoch: 3 [2432/50000]\tLoss: 1.0203\tLR: 0.100000\nTraining Epoch: 3 [2560/50000]\tLoss: 1.0091\tLR: 0.100000\nTraining Epoch: 3 [2688/50000]\tLoss: 1.1385\tLR: 0.100000\nTraining Epoch: 3 [2816/50000]\tLoss: 1.1558\tLR: 0.100000\nTraining Epoch: 3 [2944/50000]\tLoss: 1.1550\tLR: 0.100000\nTraining Epoch: 3 [3072/50000]\tLoss: 1.0907\tLR: 0.100000\nTraining Epoch: 3 [3200/50000]\tLoss: 0.9737\tLR: 0.100000\nTraining Epoch: 3 [3328/50000]\tLoss: 1.1081\tLR: 0.100000\nTraining Epoch: 3 [3456/50000]\tLoss: 0.9912\tLR: 0.100000\nTraining Epoch: 3 [3584/50000]\tLoss: 1.0828\tLR: 0.100000\nTraining Epoch: 3 [3712/50000]\tLoss: 1.0438\tLR: 0.100000\nTraining Epoch: 3 [3840/50000]\tLoss: 1.0923\tLR: 0.100000\nTraining Epoch: 3 [3968/50000]\tLoss: 1.0241\tLR: 0.100000\nTraining Epoch: 3 [4096/50000]\tLoss: 1.0744\tLR: 0.100000\nTraining Epoch: 3 [4224/50000]\tLoss: 1.1293\tLR: 0.100000\nTraining Epoch: 3 [4352/50000]\tLoss: 0.9512\tLR: 0.100000\nTraining Epoch: 3 [4480/50000]\tLoss: 0.8211\tLR: 0.100000\nTraining Epoch: 3 [4608/50000]\tLoss: 1.0476\tLR: 0.100000\nTraining Epoch: 3 [4736/50000]\tLoss: 1.0232\tLR: 0.100000\nTraining Epoch: 3 [4864/50000]\tLoss: 0.8977\tLR: 0.100000\nTraining Epoch: 3 [4992/50000]\tLoss: 1.0059\tLR: 0.100000\nTraining Epoch: 3 [5120/50000]\tLoss: 0.8819\tLR: 0.100000\nTraining Epoch: 3 [5248/50000]\tLoss: 1.0165\tLR: 0.100000\nTraining Epoch: 3 [5376/50000]\tLoss: 0.9777\tLR: 0.100000\nTraining Epoch: 3 [5504/50000]\tLoss: 1.0164\tLR: 0.100000\nTraining Epoch: 3 [5632/50000]\tLoss: 0.7655\tLR: 0.100000\nTraining Epoch: 3 [5760/50000]\tLoss: 1.0719\tLR: 0.100000\nTraining Epoch: 3 [5888/50000]\tLoss: 1.0865\tLR: 0.100000\nTraining Epoch: 3 [6016/50000]\tLoss: 1.0324\tLR: 0.100000\nTraining Epoch: 3 [6144/50000]\tLoss: 1.0350\tLR: 0.100000\nTraining Epoch: 3 [6272/50000]\tLoss: 0.9188\tLR: 0.100000\nTraining Epoch: 3 [6400/50000]\tLoss: 0.9703\tLR: 0.100000\nTraining Epoch: 3 [6528/50000]\tLoss: 1.0565\tLR: 0.100000\nTraining Epoch: 3 [6656/50000]\tLoss: 0.9210\tLR: 0.100000\nTraining Epoch: 3 [6784/50000]\tLoss: 0.8720\tLR: 0.100000\nTraining Epoch: 3 [6912/50000]\tLoss: 1.1205\tLR: 0.100000\nTraining Epoch: 3 [7040/50000]\tLoss: 1.1609\tLR: 0.100000\nTraining Epoch: 3 [7168/50000]\tLoss: 0.9981\tLR: 0.100000\nTraining Epoch: 3 [7296/50000]\tLoss: 0.9952\tLR: 0.100000\nTraining Epoch: 3 [7424/50000]\tLoss: 1.0651\tLR: 0.100000\nTraining Epoch: 3 [7552/50000]\tLoss: 1.0828\tLR: 0.100000\nTraining Epoch: 3 [7680/50000]\tLoss: 0.9794\tLR: 0.100000\nTraining Epoch: 3 [7808/50000]\tLoss: 0.8966\tLR: 0.100000\nTraining Epoch: 3 [7936/50000]\tLoss: 0.9634\tLR: 0.100000\nTraining Epoch: 3 [8064/50000]\tLoss: 0.9485\tLR: 0.100000\nTraining Epoch: 3 [8192/50000]\tLoss: 0.9770\tLR: 0.100000\nTraining Epoch: 3 [8320/50000]\tLoss: 0.8772\tLR: 0.100000\nTraining Epoch: 3 [8448/50000]\tLoss: 1.0801\tLR: 0.100000\nTraining Epoch: 3 [8576/50000]\tLoss: 0.7197\tLR: 0.100000\nTraining Epoch: 3 [8704/50000]\tLoss: 1.0219\tLR: 0.100000\nTraining Epoch: 3 [8832/50000]\tLoss: 0.9014\tLR: 0.100000\nTraining Epoch: 3 [8960/50000]\tLoss: 1.0849\tLR: 0.100000\nTraining Epoch: 3 [9088/50000]\tLoss: 0.9111\tLR: 0.100000\nTraining Epoch: 3 [9216/50000]\tLoss: 0.9242\tLR: 0.100000\nTraining Epoch: 3 [9344/50000]\tLoss: 0.9671\tLR: 0.100000\nTraining Epoch: 3 [9472/50000]\tLoss: 0.9524\tLR: 0.100000\nTraining Epoch: 3 [9600/50000]\tLoss: 0.8748\tLR: 0.100000\nTraining Epoch: 3 [9728/50000]\tLoss: 1.0504\tLR: 0.100000\nTraining Epoch: 3 [9856/50000]\tLoss: 0.9679\tLR: 0.100000\nTraining Epoch: 3 [9984/50000]\tLoss: 1.0288\tLR: 0.100000\nTraining Epoch: 3 [10112/50000]\tLoss: 0.9468\tLR: 0.100000\nTraining Epoch: 3 [10240/50000]\tLoss: 0.9625\tLR: 0.100000\nTraining Epoch: 3 [10368/50000]\tLoss: 1.0170\tLR: 0.100000\nTraining Epoch: 3 [10496/50000]\tLoss: 0.7928\tLR: 0.100000\nTraining Epoch: 3 [10624/50000]\tLoss: 1.1292\tLR: 0.100000\nTraining Epoch: 3 [10752/50000]\tLoss: 0.9425\tLR: 0.100000\nTraining Epoch: 3 [10880/50000]\tLoss: 0.8886\tLR: 0.100000\nTraining Epoch: 3 [11008/50000]\tLoss: 1.1618\tLR: 0.100000\nTraining Epoch: 3 [11136/50000]\tLoss: 0.9025\tLR: 0.100000\nTraining Epoch: 3 [11264/50000]\tLoss: 1.1749\tLR: 0.100000\nTraining Epoch: 3 [11392/50000]\tLoss: 0.9434\tLR: 0.100000\nTraining Epoch: 3 [11520/50000]\tLoss: 0.9199\tLR: 0.100000\nTraining Epoch: 3 [11648/50000]\tLoss: 0.9178\tLR: 0.100000\nTraining Epoch: 3 [11776/50000]\tLoss: 1.1412\tLR: 0.100000\nTraining Epoch: 3 [11904/50000]\tLoss: 0.8237\tLR: 0.100000\nTraining Epoch: 3 [12032/50000]\tLoss: 1.0572\tLR: 0.100000\nTraining Epoch: 3 [12160/50000]\tLoss: 0.9319\tLR: 0.100000\nTraining Epoch: 3 [12288/50000]\tLoss: 0.9310\tLR: 0.100000\nTraining Epoch: 3 [12416/50000]\tLoss: 1.3832\tLR: 0.100000\nTraining Epoch: 3 [12544/50000]\tLoss: 0.8843\tLR: 0.100000\nTraining Epoch: 3 [12672/50000]\tLoss: 1.0407\tLR: 0.100000\nTraining Epoch: 3 [12800/50000]\tLoss: 0.9861\tLR: 0.100000\nTraining Epoch: 3 [12928/50000]\tLoss: 0.8604\tLR: 0.100000\nTraining Epoch: 3 [13056/50000]\tLoss: 0.9344\tLR: 0.100000\nTraining Epoch: 3 [13184/50000]\tLoss: 0.9643\tLR: 0.100000\nTraining Epoch: 3 [13312/50000]\tLoss: 0.9866\tLR: 0.100000\nTraining Epoch: 3 [13440/50000]\tLoss: 1.1562\tLR: 0.100000\nTraining Epoch: 3 [13568/50000]\tLoss: 1.1424\tLR: 0.100000\nTraining Epoch: 3 [13696/50000]\tLoss: 0.9963\tLR: 0.100000\nTraining Epoch: 3 [13824/50000]\tLoss: 0.9796\tLR: 0.100000\nTraining Epoch: 3 [13952/50000]\tLoss: 1.0940\tLR: 0.100000\nTraining Epoch: 3 [14080/50000]\tLoss: 0.8486\tLR: 0.100000\nTraining Epoch: 3 [14208/50000]\tLoss: 0.8831\tLR: 0.100000\nTraining Epoch: 3 [14336/50000]\tLoss: 0.8569\tLR: 0.100000\nTraining Epoch: 3 [14464/50000]\tLoss: 1.0743\tLR: 0.100000\nTraining Epoch: 3 [14592/50000]\tLoss: 0.9844\tLR: 0.100000\nTraining Epoch: 3 [14720/50000]\tLoss: 0.9400\tLR: 0.100000\nTraining Epoch: 3 [14848/50000]\tLoss: 0.8842\tLR: 0.100000\nTraining Epoch: 3 [14976/50000]\tLoss: 0.7576\tLR: 0.100000\nTraining Epoch: 3 [15104/50000]\tLoss: 1.0997\tLR: 0.100000\nTraining Epoch: 3 [15232/50000]\tLoss: 0.9265\tLR: 0.100000\nTraining Epoch: 3 [15360/50000]\tLoss: 0.9258\tLR: 0.100000\nTraining Epoch: 3 [15488/50000]\tLoss: 0.7414\tLR: 0.100000\nTraining Epoch: 3 [15616/50000]\tLoss: 0.8660\tLR: 0.100000\nTraining Epoch: 3 [15744/50000]\tLoss: 1.1875\tLR: 0.100000\nTraining Epoch: 3 [15872/50000]\tLoss: 0.9478\tLR: 0.100000\nTraining Epoch: 3 [16000/50000]\tLoss: 0.8246\tLR: 0.100000\nTraining Epoch: 3 [16128/50000]\tLoss: 0.8722\tLR: 0.100000\nTraining Epoch: 3 [16256/50000]\tLoss: 0.6961\tLR: 0.100000\nTraining Epoch: 3 [16384/50000]\tLoss: 1.1177\tLR: 0.100000\nTraining Epoch: 3 [16512/50000]\tLoss: 0.9732\tLR: 0.100000\nTraining Epoch: 3 [16640/50000]\tLoss: 1.0427\tLR: 0.100000\nTraining Epoch: 3 [16768/50000]\tLoss: 1.0242\tLR: 0.100000\nTraining Epoch: 3 [16896/50000]\tLoss: 1.0163\tLR: 0.100000\nTraining Epoch: 3 [17024/50000]\tLoss: 0.7592\tLR: 0.100000\nTraining Epoch: 3 [17152/50000]\tLoss: 0.9618\tLR: 0.100000\nTraining Epoch: 3 [17280/50000]\tLoss: 0.7128\tLR: 0.100000\nTraining Epoch: 3 [17408/50000]\tLoss: 0.9829\tLR: 0.100000\nTraining Epoch: 3 [17536/50000]\tLoss: 1.0336\tLR: 0.100000\nTraining Epoch: 3 [17664/50000]\tLoss: 0.8909\tLR: 0.100000\nTraining Epoch: 3 [17792/50000]\tLoss: 0.8157\tLR: 0.100000\nTraining Epoch: 3 [17920/50000]\tLoss: 1.0730\tLR: 0.100000\nTraining Epoch: 3 [18048/50000]\tLoss: 1.1148\tLR: 0.100000\nTraining Epoch: 3 [18176/50000]\tLoss: 0.9849\tLR: 0.100000\nTraining Epoch: 3 [18304/50000]\tLoss: 0.9647\tLR: 0.100000\nTraining Epoch: 3 [18432/50000]\tLoss: 0.9926\tLR: 0.100000\nTraining Epoch: 3 [18560/50000]\tLoss: 1.0595\tLR: 0.100000\nTraining Epoch: 3 [18688/50000]\tLoss: 0.8573\tLR: 0.100000\nTraining Epoch: 3 [18816/50000]\tLoss: 1.1892\tLR: 0.100000\nTraining Epoch: 3 [18944/50000]\tLoss: 1.0189\tLR: 0.100000\nTraining Epoch: 3 [19072/50000]\tLoss: 0.8514\tLR: 0.100000\nTraining Epoch: 3 [19200/50000]\tLoss: 0.9970\tLR: 0.100000\nTraining Epoch: 3 [19328/50000]\tLoss: 0.8270\tLR: 0.100000\nTraining Epoch: 3 [19456/50000]\tLoss: 0.8862\tLR: 0.100000\nTraining Epoch: 3 [19584/50000]\tLoss: 0.9490\tLR: 0.100000\nTraining Epoch: 3 [19712/50000]\tLoss: 0.8476\tLR: 0.100000\nTraining Epoch: 3 [19840/50000]\tLoss: 1.1869\tLR: 0.100000\nTraining Epoch: 3 [19968/50000]\tLoss: 0.8509\tLR: 0.100000\nTraining Epoch: 3 [20096/50000]\tLoss: 0.7474\tLR: 0.100000\nTraining Epoch: 3 [20224/50000]\tLoss: 0.8496\tLR: 0.100000\nTraining Epoch: 3 [20352/50000]\tLoss: 1.0203\tLR: 0.100000\nTraining Epoch: 3 [20480/50000]\tLoss: 0.9463\tLR: 0.100000\nTraining Epoch: 3 [20608/50000]\tLoss: 0.9824\tLR: 0.100000\nTraining Epoch: 3 [20736/50000]\tLoss: 0.9375\tLR: 0.100000\nTraining Epoch: 3 [20864/50000]\tLoss: 1.0905\tLR: 0.100000\nTraining Epoch: 3 [20992/50000]\tLoss: 0.8370\tLR: 0.100000\nTraining Epoch: 3 [21120/50000]\tLoss: 0.9621\tLR: 0.100000\nTraining Epoch: 3 [21248/50000]\tLoss: 0.6521\tLR: 0.100000\nTraining Epoch: 3 [21376/50000]\tLoss: 0.8240\tLR: 0.100000\nTraining Epoch: 3 [21504/50000]\tLoss: 0.9347\tLR: 0.100000\nTraining Epoch: 3 [21632/50000]\tLoss: 0.9171\tLR: 0.100000\nTraining Epoch: 3 [21760/50000]\tLoss: 0.9830\tLR: 0.100000\nTraining Epoch: 3 [21888/50000]\tLoss: 1.1431\tLR: 0.100000\nTraining Epoch: 3 [22016/50000]\tLoss: 0.8818\tLR: 0.100000\nTraining Epoch: 3 [22144/50000]\tLoss: 0.8979\tLR: 0.100000\nTraining Epoch: 3 [22272/50000]\tLoss: 0.7813\tLR: 0.100000\nTraining Epoch: 3 [22400/50000]\tLoss: 0.8730\tLR: 0.100000\nTraining Epoch: 3 [22528/50000]\tLoss: 0.9765\tLR: 0.100000\nTraining Epoch: 3 [22656/50000]\tLoss: 0.7939\tLR: 0.100000\nTraining Epoch: 3 [22784/50000]\tLoss: 1.0546\tLR: 0.100000\nTraining Epoch: 3 [22912/50000]\tLoss: 0.8854\tLR: 0.100000\nTraining Epoch: 3 [23040/50000]\tLoss: 0.9472\tLR: 0.100000\nTraining Epoch: 3 [23168/50000]\tLoss: 0.9829\tLR: 0.100000\nTraining Epoch: 3 [23296/50000]\tLoss: 0.8911\tLR: 0.100000\nTraining Epoch: 3 [23424/50000]\tLoss: 1.0112\tLR: 0.100000\nTraining Epoch: 3 [23552/50000]\tLoss: 0.9359\tLR: 0.100000\nTraining Epoch: 3 [23680/50000]\tLoss: 0.8590\tLR: 0.100000\nTraining Epoch: 3 [23808/50000]\tLoss: 0.8815\tLR: 0.100000\nTraining Epoch: 3 [23936/50000]\tLoss: 0.9219\tLR: 0.100000\nTraining Epoch: 3 [24064/50000]\tLoss: 1.1208\tLR: 0.100000\nTraining Epoch: 3 [24192/50000]\tLoss: 0.8524\tLR: 0.100000\nTraining Epoch: 3 [24320/50000]\tLoss: 0.9427\tLR: 0.100000\nTraining Epoch: 3 [24448/50000]\tLoss: 0.8984\tLR: 0.100000\nTraining Epoch: 3 [24576/50000]\tLoss: 1.1117\tLR: 0.100000\nTraining Epoch: 3 [24704/50000]\tLoss: 0.7209\tLR: 0.100000\nTraining Epoch: 3 [24832/50000]\tLoss: 1.0068\tLR: 0.100000\nTraining Epoch: 3 [24960/50000]\tLoss: 1.0154\tLR: 0.100000\nTraining Epoch: 3 [25088/50000]\tLoss: 0.9807\tLR: 0.100000\nTraining Epoch: 3 [25216/50000]\tLoss: 0.8741\tLR: 0.100000\nTraining Epoch: 3 [25344/50000]\tLoss: 0.9255\tLR: 0.100000\nTraining Epoch: 3 [25472/50000]\tLoss: 0.9362\tLR: 0.100000\nTraining Epoch: 3 [25600/50000]\tLoss: 0.9418\tLR: 0.100000\nTraining Epoch: 3 [25728/50000]\tLoss: 0.9363\tLR: 0.100000\nTraining Epoch: 3 [25856/50000]\tLoss: 0.8901\tLR: 0.100000\nTraining Epoch: 3 [25984/50000]\tLoss: 0.9306\tLR: 0.100000\nTraining Epoch: 3 [26112/50000]\tLoss: 0.9662\tLR: 0.100000\nTraining Epoch: 3 [26240/50000]\tLoss: 0.7293\tLR: 0.100000\nTraining Epoch: 3 [26368/50000]\tLoss: 0.8635\tLR: 0.100000\nTraining Epoch: 3 [26496/50000]\tLoss: 0.9558\tLR: 0.100000\nTraining Epoch: 3 [26624/50000]\tLoss: 0.6587\tLR: 0.100000\nTraining Epoch: 3 [26752/50000]\tLoss: 0.9229\tLR: 0.100000\nTraining Epoch: 3 [26880/50000]\tLoss: 0.8916\tLR: 0.100000\nTraining Epoch: 3 [27008/50000]\tLoss: 0.9011\tLR: 0.100000\nTraining Epoch: 3 [27136/50000]\tLoss: 0.8769\tLR: 0.100000\nTraining Epoch: 3 [27264/50000]\tLoss: 0.7289\tLR: 0.100000\nTraining Epoch: 3 [27392/50000]\tLoss: 0.7911\tLR: 0.100000\nTraining Epoch: 3 [27520/50000]\tLoss: 0.8530\tLR: 0.100000\nTraining Epoch: 3 [27648/50000]\tLoss: 0.7099\tLR: 0.100000\nTraining Epoch: 3 [27776/50000]\tLoss: 0.8239\tLR: 0.100000\nTraining Epoch: 3 [27904/50000]\tLoss: 0.7417\tLR: 0.100000\nTraining Epoch: 3 [28032/50000]\tLoss: 0.9289\tLR: 0.100000\nTraining Epoch: 3 [28160/50000]\tLoss: 0.7583\tLR: 0.100000\nTraining Epoch: 3 [28288/50000]\tLoss: 0.9892\tLR: 0.100000\nTraining Epoch: 3 [28416/50000]\tLoss: 0.9260\tLR: 0.100000\nTraining Epoch: 3 [28544/50000]\tLoss: 0.9937\tLR: 0.100000\nTraining Epoch: 3 [28672/50000]\tLoss: 0.9854\tLR: 0.100000\nTraining Epoch: 3 [28800/50000]\tLoss: 0.8854\tLR: 0.100000\nTraining Epoch: 3 [28928/50000]\tLoss: 1.0540\tLR: 0.100000\nTraining Epoch: 3 [29056/50000]\tLoss: 0.9941\tLR: 0.100000\nTraining Epoch: 3 [29184/50000]\tLoss: 1.0922\tLR: 0.100000\nTraining Epoch: 3 [29312/50000]\tLoss: 0.8479\tLR: 0.100000\nTraining Epoch: 3 [29440/50000]\tLoss: 0.9202\tLR: 0.100000\nTraining Epoch: 3 [29568/50000]\tLoss: 0.9986\tLR: 0.100000\nTraining Epoch: 3 [29696/50000]\tLoss: 0.8267\tLR: 0.100000\nTraining Epoch: 3 [29824/50000]\tLoss: 0.7348\tLR: 0.100000\nTraining Epoch: 3 [29952/50000]\tLoss: 0.8832\tLR: 0.100000\nTraining Epoch: 3 [30080/50000]\tLoss: 0.8906\tLR: 0.100000\nTraining Epoch: 3 [30208/50000]\tLoss: 1.0498\tLR: 0.100000\nTraining Epoch: 3 [30336/50000]\tLoss: 0.9239\tLR: 0.100000\nTraining Epoch: 3 [30464/50000]\tLoss: 1.1567\tLR: 0.100000\nTraining Epoch: 3 [30592/50000]\tLoss: 1.0666\tLR: 0.100000\nTraining Epoch: 3 [30720/50000]\tLoss: 0.8378\tLR: 0.100000\nTraining Epoch: 3 [30848/50000]\tLoss: 0.9230\tLR: 0.100000\nTraining Epoch: 3 [30976/50000]\tLoss: 0.9892\tLR: 0.100000\nTraining Epoch: 3 [31104/50000]\tLoss: 0.9669\tLR: 0.100000\nTraining Epoch: 3 [31232/50000]\tLoss: 0.7876\tLR: 0.100000\nTraining Epoch: 3 [31360/50000]\tLoss: 1.0261\tLR: 0.100000\nTraining Epoch: 3 [31488/50000]\tLoss: 1.0770\tLR: 0.100000\nTraining Epoch: 3 [31616/50000]\tLoss: 0.8407\tLR: 0.100000\nTraining Epoch: 3 [31744/50000]\tLoss: 0.7787\tLR: 0.100000\nTraining Epoch: 3 [31872/50000]\tLoss: 0.9287\tLR: 0.100000\nTraining Epoch: 3 [32000/50000]\tLoss: 1.2776\tLR: 0.100000\nTraining Epoch: 3 [32128/50000]\tLoss: 0.7403\tLR: 0.100000\nTraining Epoch: 3 [32256/50000]\tLoss: 1.1982\tLR: 0.100000\nTraining Epoch: 3 [32384/50000]\tLoss: 0.8823\tLR: 0.100000\nTraining Epoch: 3 [32512/50000]\tLoss: 0.9750\tLR: 0.100000\nTraining Epoch: 3 [32640/50000]\tLoss: 0.7859\tLR: 0.100000\nTraining Epoch: 3 [32768/50000]\tLoss: 0.9296\tLR: 0.100000\nTraining Epoch: 3 [32896/50000]\tLoss: 1.0459\tLR: 0.100000\nTraining Epoch: 3 [33024/50000]\tLoss: 0.8825\tLR: 0.100000\nTraining Epoch: 3 [33152/50000]\tLoss: 0.9556\tLR: 0.100000\nTraining Epoch: 3 [33280/50000]\tLoss: 0.7880\tLR: 0.100000\nTraining Epoch: 3 [33408/50000]\tLoss: 0.9793\tLR: 0.100000\nTraining Epoch: 3 [33536/50000]\tLoss: 0.9213\tLR: 0.100000\nTraining Epoch: 3 [33664/50000]\tLoss: 0.8884\tLR: 0.100000\nTraining Epoch: 3 [33792/50000]\tLoss: 0.8559\tLR: 0.100000\nTraining Epoch: 3 [33920/50000]\tLoss: 0.8717\tLR: 0.100000\nTraining Epoch: 3 [34048/50000]\tLoss: 1.2060\tLR: 0.100000\nTraining Epoch: 3 [34176/50000]\tLoss: 0.9522\tLR: 0.100000\nTraining Epoch: 3 [34304/50000]\tLoss: 0.7641\tLR: 0.100000\nTraining Epoch: 3 [34432/50000]\tLoss: 0.8557\tLR: 0.100000\nTraining Epoch: 3 [34560/50000]\tLoss: 0.9224\tLR: 0.100000\nTraining Epoch: 3 [34688/50000]\tLoss: 0.8516\tLR: 0.100000\nTraining Epoch: 3 [34816/50000]\tLoss: 0.8945\tLR: 0.100000\nTraining Epoch: 3 [34944/50000]\tLoss: 0.6424\tLR: 0.100000\nTraining Epoch: 3 [35072/50000]\tLoss: 0.9597\tLR: 0.100000\nTraining Epoch: 3 [35200/50000]\tLoss: 0.9475\tLR: 0.100000\nTraining Epoch: 3 [35328/50000]\tLoss: 1.0057\tLR: 0.100000\nTraining Epoch: 3 [35456/50000]\tLoss: 0.9588\tLR: 0.100000\nTraining Epoch: 3 [35584/50000]\tLoss: 1.0312\tLR: 0.100000\nTraining Epoch: 3 [35712/50000]\tLoss: 0.8648\tLR: 0.100000\nTraining Epoch: 3 [35840/50000]\tLoss: 1.0325\tLR: 0.100000\nTraining Epoch: 3 [35968/50000]\tLoss: 0.8567\tLR: 0.100000\nTraining Epoch: 3 [36096/50000]\tLoss: 0.8709\tLR: 0.100000\nTraining Epoch: 3 [36224/50000]\tLoss: 0.9303\tLR: 0.100000\nTraining Epoch: 3 [36352/50000]\tLoss: 0.8873\tLR: 0.100000\nTraining Epoch: 3 [36480/50000]\tLoss: 0.8925\tLR: 0.100000\nTraining Epoch: 3 [36608/50000]\tLoss: 0.9101\tLR: 0.100000\nTraining Epoch: 3 [36736/50000]\tLoss: 0.9584\tLR: 0.100000\nTraining Epoch: 3 [36864/50000]\tLoss: 0.9186\tLR: 0.100000\nTraining Epoch: 3 [36992/50000]\tLoss: 0.9161\tLR: 0.100000\nTraining Epoch: 3 [37120/50000]\tLoss: 0.9523\tLR: 0.100000\nTraining Epoch: 3 [37248/50000]\tLoss: 0.9181\tLR: 0.100000\nTraining Epoch: 3 [37376/50000]\tLoss: 0.7629\tLR: 0.100000\nTraining Epoch: 3 [37504/50000]\tLoss: 0.8569\tLR: 0.100000\nTraining Epoch: 3 [37632/50000]\tLoss: 0.9020\tLR: 0.100000\nTraining Epoch: 3 [37760/50000]\tLoss: 1.0187\tLR: 0.100000\nTraining Epoch: 3 [37888/50000]\tLoss: 0.8000\tLR: 0.100000\nTraining Epoch: 3 [38016/50000]\tLoss: 0.9506\tLR: 0.100000\nTraining Epoch: 3 [38144/50000]\tLoss: 0.7760\tLR: 0.100000\nTraining Epoch: 3 [38272/50000]\tLoss: 0.7451\tLR: 0.100000\nTraining Epoch: 3 [38400/50000]\tLoss: 0.7721\tLR: 0.100000\nTraining Epoch: 3 [38528/50000]\tLoss: 1.0903\tLR: 0.100000\nTraining Epoch: 3 [38656/50000]\tLoss: 0.9750\tLR: 0.100000\nTraining Epoch: 3 [38784/50000]\tLoss: 0.8768\tLR: 0.100000\nTraining Epoch: 3 [38912/50000]\tLoss: 0.8833\tLR: 0.100000\nTraining Epoch: 3 [39040/50000]\tLoss: 0.8324\tLR: 0.100000\nTraining Epoch: 3 [39168/50000]\tLoss: 0.8496\tLR: 0.100000\nTraining Epoch: 3 [39296/50000]\tLoss: 0.9857\tLR: 0.100000\nTraining Epoch: 3 [39424/50000]\tLoss: 1.0626\tLR: 0.100000\nTraining Epoch: 3 [39552/50000]\tLoss: 0.9972\tLR: 0.100000\nTraining Epoch: 3 [39680/50000]\tLoss: 1.0279\tLR: 0.100000\nTraining Epoch: 3 [39808/50000]\tLoss: 1.0313\tLR: 0.100000\nTraining Epoch: 3 [39936/50000]\tLoss: 1.0920\tLR: 0.100000\nTraining Epoch: 3 [40064/50000]\tLoss: 0.7519\tLR: 0.100000\nTraining Epoch: 3 [40192/50000]\tLoss: 0.9502\tLR: 0.100000\nTraining Epoch: 3 [40320/50000]\tLoss: 0.9132\tLR: 0.100000\nTraining Epoch: 3 [40448/50000]\tLoss: 0.8410\tLR: 0.100000\nTraining Epoch: 3 [40576/50000]\tLoss: 0.7799\tLR: 0.100000\nTraining Epoch: 3 [40704/50000]\tLoss: 0.9763\tLR: 0.100000\nTraining Epoch: 3 [40832/50000]\tLoss: 0.9117\tLR: 0.100000\nTraining Epoch: 3 [40960/50000]\tLoss: 1.0172\tLR: 0.100000\nTraining Epoch: 3 [41088/50000]\tLoss: 0.9237\tLR: 0.100000\nTraining Epoch: 3 [41216/50000]\tLoss: 0.8368\tLR: 0.100000\nTraining Epoch: 3 [41344/50000]\tLoss: 0.9215\tLR: 0.100000\nTraining Epoch: 3 [41472/50000]\tLoss: 1.0369\tLR: 0.100000\nTraining Epoch: 3 [41600/50000]\tLoss: 0.9323\tLR: 0.100000\nTraining Epoch: 3 [41728/50000]\tLoss: 0.9390\tLR: 0.100000\nTraining Epoch: 3 [41856/50000]\tLoss: 0.9194\tLR: 0.100000\nTraining Epoch: 3 [41984/50000]\tLoss: 0.8673\tLR: 0.100000\nTraining Epoch: 3 [42112/50000]\tLoss: 0.8661\tLR: 0.100000\nTraining Epoch: 3 [42240/50000]\tLoss: 0.8415\tLR: 0.100000\nTraining Epoch: 3 [42368/50000]\tLoss: 0.8177\tLR: 0.100000\nTraining Epoch: 3 [42496/50000]\tLoss: 0.9551\tLR: 0.100000\nTraining Epoch: 3 [42624/50000]\tLoss: 0.8479\tLR: 0.100000\nTraining Epoch: 3 [42752/50000]\tLoss: 0.9620\tLR: 0.100000\nTraining Epoch: 3 [42880/50000]\tLoss: 0.7986\tLR: 0.100000\nTraining Epoch: 3 [43008/50000]\tLoss: 0.8118\tLR: 0.100000\nTraining Epoch: 3 [43136/50000]\tLoss: 0.9254\tLR: 0.100000\nTraining Epoch: 3 [43264/50000]\tLoss: 1.0351\tLR: 0.100000\nTraining Epoch: 3 [43392/50000]\tLoss: 0.7764\tLR: 0.100000\nTraining Epoch: 3 [43520/50000]\tLoss: 0.8601\tLR: 0.100000\nTraining Epoch: 3 [43648/50000]\tLoss: 0.9105\tLR: 0.100000\nTraining Epoch: 3 [43776/50000]\tLoss: 0.6688\tLR: 0.100000\nTraining Epoch: 3 [43904/50000]\tLoss: 0.8460\tLR: 0.100000\nTraining Epoch: 3 [44032/50000]\tLoss: 0.9647\tLR: 0.100000\nTraining Epoch: 3 [44160/50000]\tLoss: 0.8203\tLR: 0.100000\nTraining Epoch: 3 [44288/50000]\tLoss: 0.8692\tLR: 0.100000\nTraining Epoch: 3 [44416/50000]\tLoss: 0.8247\tLR: 0.100000\nTraining Epoch: 3 [44544/50000]\tLoss: 0.7722\tLR: 0.100000\nTraining Epoch: 3 [44672/50000]\tLoss: 1.1359\tLR: 0.100000\nTraining Epoch: 3 [44800/50000]\tLoss: 0.7931\tLR: 0.100000\nTraining Epoch: 3 [44928/50000]\tLoss: 0.8781\tLR: 0.100000\nTraining Epoch: 3 [45056/50000]\tLoss: 0.7865\tLR: 0.100000\nTraining Epoch: 3 [45184/50000]\tLoss: 1.0354\tLR: 0.100000\nTraining Epoch: 3 [45312/50000]\tLoss: 0.8513\tLR: 0.100000\nTraining Epoch: 3 [45440/50000]\tLoss: 1.0786\tLR: 0.100000\nTraining Epoch: 3 [45568/50000]\tLoss: 1.0355\tLR: 0.100000\nTraining Epoch: 3 [45696/50000]\tLoss: 0.7964\tLR: 0.100000\nTraining Epoch: 3 [45824/50000]\tLoss: 0.8771\tLR: 0.100000\nTraining Epoch: 3 [45952/50000]\tLoss: 0.9312\tLR: 0.100000\nTraining Epoch: 3 [46080/50000]\tLoss: 0.9111\tLR: 0.100000\nTraining Epoch: 3 [46208/50000]\tLoss: 1.0144\tLR: 0.100000\nTraining Epoch: 3 [46336/50000]\tLoss: 0.8943\tLR: 0.100000\nTraining Epoch: 3 [46464/50000]\tLoss: 0.9282\tLR: 0.100000\nTraining Epoch: 3 [46592/50000]\tLoss: 0.8898\tLR: 0.100000\nTraining Epoch: 3 [46720/50000]\tLoss: 0.7689\tLR: 0.100000\nTraining Epoch: 3 [46848/50000]\tLoss: 0.7204\tLR: 0.100000\nTraining Epoch: 3 [46976/50000]\tLoss: 0.8684\tLR: 0.100000\nTraining Epoch: 3 [47104/50000]\tLoss: 0.8307\tLR: 0.100000\nTraining Epoch: 3 [47232/50000]\tLoss: 0.9244\tLR: 0.100000\nTraining Epoch: 3 [47360/50000]\tLoss: 0.7929\tLR: 0.100000\nTraining Epoch: 3 [47488/50000]\tLoss: 0.7917\tLR: 0.100000\nTraining Epoch: 3 [47616/50000]\tLoss: 0.9302\tLR: 0.100000\nTraining Epoch: 3 [47744/50000]\tLoss: 0.7947\tLR: 0.100000\nTraining Epoch: 3 [47872/50000]\tLoss: 0.8192\tLR: 0.100000\nTraining Epoch: 3 [48000/50000]\tLoss: 0.9562\tLR: 0.100000\nTraining Epoch: 3 [48128/50000]\tLoss: 0.6982\tLR: 0.100000\nTraining Epoch: 3 [48256/50000]\tLoss: 0.8783\tLR: 0.100000\nTraining Epoch: 3 [48384/50000]\tLoss: 0.9026\tLR: 0.100000\nTraining Epoch: 3 [48512/50000]\tLoss: 0.8782\tLR: 0.100000\nTraining Epoch: 3 [48640/50000]\tLoss: 0.7717\tLR: 0.100000\nTraining Epoch: 3 [48768/50000]\tLoss: 0.8181\tLR: 0.100000\nTraining Epoch: 3 [48896/50000]\tLoss: 1.0015\tLR: 0.100000\nTraining Epoch: 3 [49024/50000]\tLoss: 0.6932\tLR: 0.100000\nTraining Epoch: 3 [49152/50000]\tLoss: 0.8295\tLR: 0.100000\nTraining Epoch: 3 [49280/50000]\tLoss: 0.7976\tLR: 0.100000\nTraining Epoch: 3 [49408/50000]\tLoss: 0.8600\tLR: 0.100000\nTraining Epoch: 3 [49536/50000]\tLoss: 0.7607\tLR: 0.100000\nTraining Epoch: 3 [49664/50000]\tLoss: 0.7366\tLR: 0.100000\nTraining Epoch: 3 [49792/50000]\tLoss: 0.6948\tLR: 0.100000\nTraining Epoch: 3 [49920/50000]\tLoss: 0.7266\tLR: 0.100000\nTraining Epoch: 3 [50000/50000]\tLoss: 0.9949\tLR: 0.100000\nTest set: Average loss: 0.0075, Accuracy: 0.6885\n\nTraining Epoch: 4 [128/50000]\tLoss: 0.7980\tLR: 0.100000\nTraining Epoch: 4 [256/50000]\tLoss: 0.9203\tLR: 0.100000\nTraining Epoch: 4 [384/50000]\tLoss: 0.8030\tLR: 0.100000\nTraining Epoch: 4 [512/50000]\tLoss: 0.8119\tLR: 0.100000\nTraining Epoch: 4 [640/50000]\tLoss: 0.7507\tLR: 0.100000\nTraining Epoch: 4 [768/50000]\tLoss: 0.7211\tLR: 0.100000\nTraining Epoch: 4 [896/50000]\tLoss: 0.9613\tLR: 0.100000\nTraining Epoch: 4 [1024/50000]\tLoss: 0.9025\tLR: 0.100000\nTraining Epoch: 4 [1152/50000]\tLoss: 0.8241\tLR: 0.100000\nTraining Epoch: 4 [1280/50000]\tLoss: 0.8388\tLR: 0.100000\nTraining Epoch: 4 [1408/50000]\tLoss: 0.8309\tLR: 0.100000\nTraining Epoch: 4 [1536/50000]\tLoss: 0.9710\tLR: 0.100000\nTraining Epoch: 4 [1664/50000]\tLoss: 1.1044\tLR: 0.100000\nTraining Epoch: 4 [1792/50000]\tLoss: 0.9610\tLR: 0.100000\nTraining Epoch: 4 [1920/50000]\tLoss: 0.8664\tLR: 0.100000\nTraining Epoch: 4 [2048/50000]\tLoss: 0.8018\tLR: 0.100000\nTraining Epoch: 4 [2176/50000]\tLoss: 0.8763\tLR: 0.100000\nTraining Epoch: 4 [2304/50000]\tLoss: 0.7639\tLR: 0.100000\nTraining Epoch: 4 [2432/50000]\tLoss: 0.8236\tLR: 0.100000\nTraining Epoch: 4 [2560/50000]\tLoss: 0.7910\tLR: 0.100000\nTraining Epoch: 4 [2688/50000]\tLoss: 1.0144\tLR: 0.100000\nTraining Epoch: 4 [2816/50000]\tLoss: 1.0158\tLR: 0.100000\nTraining Epoch: 4 [2944/50000]\tLoss: 0.7259\tLR: 0.100000\nTraining Epoch: 4 [3072/50000]\tLoss: 0.8819\tLR: 0.100000\nTraining Epoch: 4 [3200/50000]\tLoss: 0.8565\tLR: 0.100000\nTraining Epoch: 4 [3328/50000]\tLoss: 0.7989\tLR: 0.100000\nTraining Epoch: 4 [3456/50000]\tLoss: 0.9064\tLR: 0.100000\nTraining Epoch: 4 [3584/50000]\tLoss: 0.8271\tLR: 0.100000\nTraining Epoch: 4 [3712/50000]\tLoss: 0.6923\tLR: 0.100000\nTraining Epoch: 4 [3840/50000]\tLoss: 0.7619\tLR: 0.100000\nTraining Epoch: 4 [3968/50000]\tLoss: 0.9809\tLR: 0.100000\nTraining Epoch: 4 [4096/50000]\tLoss: 0.8969\tLR: 0.100000\nTraining Epoch: 4 [4224/50000]\tLoss: 0.8021\tLR: 0.100000\nTraining Epoch: 4 [4352/50000]\tLoss: 0.7125\tLR: 0.100000\nTraining Epoch: 4 [4480/50000]\tLoss: 0.8763\tLR: 0.100000\nTraining Epoch: 4 [4608/50000]\tLoss: 0.7924\tLR: 0.100000\nTraining Epoch: 4 [4736/50000]\tLoss: 1.0139\tLR: 0.100000\nTraining Epoch: 4 [4864/50000]\tLoss: 0.9156\tLR: 0.100000\nTraining Epoch: 4 [4992/50000]\tLoss: 0.9850\tLR: 0.100000\nTraining Epoch: 4 [5120/50000]\tLoss: 0.6609\tLR: 0.100000\nTraining Epoch: 4 [5248/50000]\tLoss: 0.8848\tLR: 0.100000\nTraining Epoch: 4 [5376/50000]\tLoss: 0.8360\tLR: 0.100000\nTraining Epoch: 4 [5504/50000]\tLoss: 1.0965\tLR: 0.100000\nTraining Epoch: 4 [5632/50000]\tLoss: 0.9228\tLR: 0.100000\nTraining Epoch: 4 [5760/50000]\tLoss: 1.0204\tLR: 0.100000\nTraining Epoch: 4 [5888/50000]\tLoss: 0.9047\tLR: 0.100000\nTraining Epoch: 4 [6016/50000]\tLoss: 0.8871\tLR: 0.100000\nTraining Epoch: 4 [6144/50000]\tLoss: 0.9519\tLR: 0.100000\nTraining Epoch: 4 [6272/50000]\tLoss: 0.9939\tLR: 0.100000\nTraining Epoch: 4 [6400/50000]\tLoss: 0.9596\tLR: 0.100000\nTraining Epoch: 4 [6528/50000]\tLoss: 0.9093\tLR: 0.100000\nTraining Epoch: 4 [6656/50000]\tLoss: 0.8225\tLR: 0.100000\nTraining Epoch: 4 [6784/50000]\tLoss: 0.7702\tLR: 0.100000\nTraining Epoch: 4 [6912/50000]\tLoss: 0.8909\tLR: 0.100000\nTraining Epoch: 4 [7040/50000]\tLoss: 0.8957\tLR: 0.100000\nTraining Epoch: 4 [7168/50000]\tLoss: 1.1048\tLR: 0.100000\nTraining Epoch: 4 [7296/50000]\tLoss: 0.7516\tLR: 0.100000\nTraining Epoch: 4 [7424/50000]\tLoss: 0.7977\tLR: 0.100000\nTraining Epoch: 4 [7552/50000]\tLoss: 0.9703\tLR: 0.100000\nTraining Epoch: 4 [7680/50000]\tLoss: 0.8367\tLR: 0.100000\nTraining Epoch: 4 [7808/50000]\tLoss: 0.7143\tLR: 0.100000\nTraining Epoch: 4 [7936/50000]\tLoss: 0.7508\tLR: 0.100000\nTraining Epoch: 4 [8064/50000]\tLoss: 0.8359\tLR: 0.100000\nTraining Epoch: 4 [8192/50000]\tLoss: 0.8280\tLR: 0.100000\nTraining Epoch: 4 [8320/50000]\tLoss: 0.8894\tLR: 0.100000\nTraining Epoch: 4 [8448/50000]\tLoss: 0.8156\tLR: 0.100000\nTraining Epoch: 4 [8576/50000]\tLoss: 0.8612\tLR: 0.100000\nTraining Epoch: 4 [8704/50000]\tLoss: 0.9052\tLR: 0.100000\nTraining Epoch: 4 [8832/50000]\tLoss: 0.9320\tLR: 0.100000\nTraining Epoch: 4 [8960/50000]\tLoss: 0.9643\tLR: 0.100000\nTraining Epoch: 4 [9088/50000]\tLoss: 0.8733\tLR: 0.100000\nTraining Epoch: 4 [9216/50000]\tLoss: 0.9825\tLR: 0.100000\nTraining Epoch: 4 [9344/50000]\tLoss: 0.7376\tLR: 0.100000\nTraining Epoch: 4 [9472/50000]\tLoss: 0.9473\tLR: 0.100000\nTraining Epoch: 4 [9600/50000]\tLoss: 1.0156\tLR: 0.100000\nTraining Epoch: 4 [9728/50000]\tLoss: 1.0270\tLR: 0.100000\nTraining Epoch: 4 [9856/50000]\tLoss: 0.9180\tLR: 0.100000\nTraining Epoch: 4 [9984/50000]\tLoss: 1.0501\tLR: 0.100000\nTraining Epoch: 4 [10112/50000]\tLoss: 0.8831\tLR: 0.100000\nTraining Epoch: 4 [10240/50000]\tLoss: 0.7043\tLR: 0.100000\nTraining Epoch: 4 [10368/50000]\tLoss: 0.7331\tLR: 0.100000\nTraining Epoch: 4 [10496/50000]\tLoss: 0.8816\tLR: 0.100000\nTraining Epoch: 4 [10624/50000]\tLoss: 0.8817\tLR: 0.100000\nTraining Epoch: 4 [10752/50000]\tLoss: 0.7445\tLR: 0.100000\nTraining Epoch: 4 [10880/50000]\tLoss: 0.8240\tLR: 0.100000\nTraining Epoch: 4 [11008/50000]\tLoss: 0.8862\tLR: 0.100000\nTraining Epoch: 4 [11136/50000]\tLoss: 0.7588\tLR: 0.100000\nTraining Epoch: 4 [11264/50000]\tLoss: 0.8967\tLR: 0.100000\nTraining Epoch: 4 [11392/50000]\tLoss: 0.8322\tLR: 0.100000\nTraining Epoch: 4 [11520/50000]\tLoss: 0.9865\tLR: 0.100000\nTraining Epoch: 4 [11648/50000]\tLoss: 0.8020\tLR: 0.100000\nTraining Epoch: 4 [11776/50000]\tLoss: 0.8433\tLR: 0.100000\nTraining Epoch: 4 [11904/50000]\tLoss: 0.7667\tLR: 0.100000\nTraining Epoch: 4 [12032/50000]\tLoss: 0.8727\tLR: 0.100000\nTraining Epoch: 4 [12160/50000]\tLoss: 0.8791\tLR: 0.100000\nTraining Epoch: 4 [12288/50000]\tLoss: 0.8029\tLR: 0.100000\nTraining Epoch: 4 [12416/50000]\tLoss: 0.7875\tLR: 0.100000\nTraining Epoch: 4 [12544/50000]\tLoss: 0.8311\tLR: 0.100000\nTraining Epoch: 4 [12672/50000]\tLoss: 0.7313\tLR: 0.100000\nTraining Epoch: 4 [12800/50000]\tLoss: 0.8902\tLR: 0.100000\nTraining Epoch: 4 [12928/50000]\tLoss: 0.6861\tLR: 0.100000\nTraining Epoch: 4 [13056/50000]\tLoss: 0.8561\tLR: 0.100000\nTraining Epoch: 4 [13184/50000]\tLoss: 0.7691\tLR: 0.100000\nTraining Epoch: 4 [13312/50000]\tLoss: 0.8444\tLR: 0.100000\nTraining Epoch: 4 [13440/50000]\tLoss: 0.6728\tLR: 0.100000\nTraining Epoch: 4 [13568/50000]\tLoss: 0.8029\tLR: 0.100000\nTraining Epoch: 4 [13696/50000]\tLoss: 0.7055\tLR: 0.100000\nTraining Epoch: 4 [13824/50000]\tLoss: 0.7955\tLR: 0.100000\nTraining Epoch: 4 [13952/50000]\tLoss: 0.7646\tLR: 0.100000\nTraining Epoch: 4 [14080/50000]\tLoss: 0.6660\tLR: 0.100000\nTraining Epoch: 4 [14208/50000]\tLoss: 0.8732\tLR: 0.100000\nTraining Epoch: 4 [14336/50000]\tLoss: 0.6856\tLR: 0.100000\nTraining Epoch: 4 [14464/50000]\tLoss: 0.8393\tLR: 0.100000\nTraining Epoch: 4 [14592/50000]\tLoss: 0.8335\tLR: 0.100000\nTraining Epoch: 4 [14720/50000]\tLoss: 0.8474\tLR: 0.100000\nTraining Epoch: 4 [14848/50000]\tLoss: 0.8107\tLR: 0.100000\nTraining Epoch: 4 [14976/50000]\tLoss: 0.8891\tLR: 0.100000\nTraining Epoch: 4 [15104/50000]\tLoss: 0.7865\tLR: 0.100000\nTraining Epoch: 4 [15232/50000]\tLoss: 0.8951\tLR: 0.100000\nTraining Epoch: 4 [15360/50000]\tLoss: 0.7544\tLR: 0.100000\nTraining Epoch: 4 [15488/50000]\tLoss: 0.8814\tLR: 0.100000\nTraining Epoch: 4 [15616/50000]\tLoss: 0.8420\tLR: 0.100000\nTraining Epoch: 4 [15744/50000]\tLoss: 0.8922\tLR: 0.100000\nTraining Epoch: 4 [15872/50000]\tLoss: 0.8150\tLR: 0.100000\nTraining Epoch: 4 [16000/50000]\tLoss: 0.7177\tLR: 0.100000\nTraining Epoch: 4 [16128/50000]\tLoss: 0.7370\tLR: 0.100000\nTraining Epoch: 4 [16256/50000]\tLoss: 0.9798\tLR: 0.100000\nTraining Epoch: 4 [16384/50000]\tLoss: 0.7983\tLR: 0.100000\nTraining Epoch: 4 [16512/50000]\tLoss: 0.7489\tLR: 0.100000\nTraining Epoch: 4 [16640/50000]\tLoss: 0.7404\tLR: 0.100000\nTraining Epoch: 4 [16768/50000]\tLoss: 0.6498\tLR: 0.100000\nTraining Epoch: 4 [16896/50000]\tLoss: 0.7218\tLR: 0.100000\nTraining Epoch: 4 [17024/50000]\tLoss: 0.9574\tLR: 0.100000\nTraining Epoch: 4 [17152/50000]\tLoss: 0.7139\tLR: 0.100000\nTraining Epoch: 4 [17280/50000]\tLoss: 0.9682\tLR: 0.100000\nTraining Epoch: 4 [17408/50000]\tLoss: 0.8078\tLR: 0.100000\nTraining Epoch: 4 [17536/50000]\tLoss: 0.8421\tLR: 0.100000\nTraining Epoch: 4 [17664/50000]\tLoss: 0.7569\tLR: 0.100000\nTraining Epoch: 4 [17792/50000]\tLoss: 0.7593\tLR: 0.100000\nTraining Epoch: 4 [17920/50000]\tLoss: 0.9286\tLR: 0.100000\nTraining Epoch: 4 [18048/50000]\tLoss: 0.9137\tLR: 0.100000\nTraining Epoch: 4 [18176/50000]\tLoss: 0.7713\tLR: 0.100000\nTraining Epoch: 4 [18304/50000]\tLoss: 0.7609\tLR: 0.100000\nTraining Epoch: 4 [18432/50000]\tLoss: 0.7930\tLR: 0.100000\nTraining Epoch: 4 [18560/50000]\tLoss: 0.9001\tLR: 0.100000\nTraining Epoch: 4 [18688/50000]\tLoss: 0.7736\tLR: 0.100000\nTraining Epoch: 4 [18816/50000]\tLoss: 0.7814\tLR: 0.100000\nTraining Epoch: 4 [18944/50000]\tLoss: 0.7467\tLR: 0.100000\nTraining Epoch: 4 [19072/50000]\tLoss: 0.9110\tLR: 0.100000\nTraining Epoch: 4 [19200/50000]\tLoss: 0.9092\tLR: 0.100000\nTraining Epoch: 4 [19328/50000]\tLoss: 0.7253\tLR: 0.100000\nTraining Epoch: 4 [19456/50000]\tLoss: 0.9339\tLR: 0.100000\nTraining Epoch: 4 [19584/50000]\tLoss: 0.8763\tLR: 0.100000\nTraining Epoch: 4 [19712/50000]\tLoss: 0.8269\tLR: 0.100000\nTraining Epoch: 4 [19840/50000]\tLoss: 0.7656\tLR: 0.100000\nTraining Epoch: 4 [19968/50000]\tLoss: 0.7594\tLR: 0.100000\nTraining Epoch: 4 [20096/50000]\tLoss: 0.7387\tLR: 0.100000\nTraining Epoch: 4 [20224/50000]\tLoss: 0.8463\tLR: 0.100000\nTraining Epoch: 4 [20352/50000]\tLoss: 1.0423\tLR: 0.100000\nTraining Epoch: 4 [20480/50000]\tLoss: 0.6988\tLR: 0.100000\nTraining Epoch: 4 [20608/50000]\tLoss: 0.8471\tLR: 0.100000\nTraining Epoch: 4 [20736/50000]\tLoss: 0.6648\tLR: 0.100000\nTraining Epoch: 4 [20864/50000]\tLoss: 0.7241\tLR: 0.100000\nTraining Epoch: 4 [20992/50000]\tLoss: 0.6286\tLR: 0.100000\nTraining Epoch: 4 [21120/50000]\tLoss: 0.8467\tLR: 0.100000\nTraining Epoch: 4 [21248/50000]\tLoss: 0.8155\tLR: 0.100000\nTraining Epoch: 4 [21376/50000]\tLoss: 0.9321\tLR: 0.100000\nTraining Epoch: 4 [21504/50000]\tLoss: 0.8288\tLR: 0.100000\nTraining Epoch: 4 [21632/50000]\tLoss: 0.7212\tLR: 0.100000\nTraining Epoch: 4 [21760/50000]\tLoss: 0.9210\tLR: 0.100000\nTraining Epoch: 4 [21888/50000]\tLoss: 0.7320\tLR: 0.100000\nTraining Epoch: 4 [22016/50000]\tLoss: 0.9244\tLR: 0.100000\nTraining Epoch: 4 [22144/50000]\tLoss: 0.8164\tLR: 0.100000\nTraining Epoch: 4 [22272/50000]\tLoss: 0.9302\tLR: 0.100000\nTraining Epoch: 4 [22400/50000]\tLoss: 0.9428\tLR: 0.100000\nTraining Epoch: 4 [22528/50000]\tLoss: 0.7412\tLR: 0.100000\nTraining Epoch: 4 [22656/50000]\tLoss: 0.7495\tLR: 0.100000\nTraining Epoch: 4 [22784/50000]\tLoss: 0.6993\tLR: 0.100000\nTraining Epoch: 4 [22912/50000]\tLoss: 0.7797\tLR: 0.100000\nTraining Epoch: 4 [23040/50000]\tLoss: 0.7119\tLR: 0.100000\nTraining Epoch: 4 [23168/50000]\tLoss: 0.7437\tLR: 0.100000\nTraining Epoch: 4 [23296/50000]\tLoss: 0.8851\tLR: 0.100000\nTraining Epoch: 4 [23424/50000]\tLoss: 0.6808\tLR: 0.100000\nTraining Epoch: 4 [23552/50000]\tLoss: 0.8381\tLR: 0.100000\nTraining Epoch: 4 [23680/50000]\tLoss: 0.7679\tLR: 0.100000\nTraining Epoch: 4 [23808/50000]\tLoss: 0.8070\tLR: 0.100000\nTraining Epoch: 4 [23936/50000]\tLoss: 0.7498\tLR: 0.100000\nTraining Epoch: 4 [24064/50000]\tLoss: 0.7138\tLR: 0.100000\nTraining Epoch: 4 [24192/50000]\tLoss: 0.7427\tLR: 0.100000\nTraining Epoch: 4 [24320/50000]\tLoss: 0.7884\tLR: 0.100000\nTraining Epoch: 4 [24448/50000]\tLoss: 0.7630\tLR: 0.100000\nTraining Epoch: 4 [24576/50000]\tLoss: 0.8814\tLR: 0.100000\nTraining Epoch: 4 [24704/50000]\tLoss: 0.7659\tLR: 0.100000\nTraining Epoch: 4 [24832/50000]\tLoss: 0.7077\tLR: 0.100000\nTraining Epoch: 4 [24960/50000]\tLoss: 0.8410\tLR: 0.100000\nTraining Epoch: 4 [25088/50000]\tLoss: 0.8921\tLR: 0.100000\nTraining Epoch: 4 [25216/50000]\tLoss: 0.7781\tLR: 0.100000\nTraining Epoch: 4 [25344/50000]\tLoss: 0.9061\tLR: 0.100000\nTraining Epoch: 4 [25472/50000]\tLoss: 0.7176\tLR: 0.100000\nTraining Epoch: 4 [25600/50000]\tLoss: 0.8815\tLR: 0.100000\nTraining Epoch: 4 [25728/50000]\tLoss: 0.8404\tLR: 0.100000\nTraining Epoch: 4 [25856/50000]\tLoss: 0.7392\tLR: 0.100000\nTraining Epoch: 4 [25984/50000]\tLoss: 0.7774\tLR: 0.100000\nTraining Epoch: 4 [26112/50000]\tLoss: 0.7070\tLR: 0.100000\nTraining Epoch: 4 [26240/50000]\tLoss: 0.8180\tLR: 0.100000\nTraining Epoch: 4 [26368/50000]\tLoss: 0.6591\tLR: 0.100000\nTraining Epoch: 4 [26496/50000]\tLoss: 0.7175\tLR: 0.100000\nTraining Epoch: 4 [26624/50000]\tLoss: 0.8184\tLR: 0.100000\nTraining Epoch: 4 [26752/50000]\tLoss: 1.0205\tLR: 0.100000\nTraining Epoch: 4 [26880/50000]\tLoss: 0.6925\tLR: 0.100000\nTraining Epoch: 4 [27008/50000]\tLoss: 0.6527\tLR: 0.100000\nTraining Epoch: 4 [27136/50000]\tLoss: 0.6878\tLR: 0.100000\nTraining Epoch: 4 [27264/50000]\tLoss: 0.7697\tLR: 0.100000\nTraining Epoch: 4 [27392/50000]\tLoss: 0.8461\tLR: 0.100000\nTraining Epoch: 4 [27520/50000]\tLoss: 0.8058\tLR: 0.100000\nTraining Epoch: 4 [27648/50000]\tLoss: 0.7783\tLR: 0.100000\nTraining Epoch: 4 [27776/50000]\tLoss: 0.8332\tLR: 0.100000\nTraining Epoch: 4 [27904/50000]\tLoss: 0.8338\tLR: 0.100000\nTraining Epoch: 4 [28032/50000]\tLoss: 0.7500\tLR: 0.100000\nTraining Epoch: 4 [28160/50000]\tLoss: 0.8213\tLR: 0.100000\nTraining Epoch: 4 [28288/50000]\tLoss: 0.7051\tLR: 0.100000\nTraining Epoch: 4 [28416/50000]\tLoss: 0.7902\tLR: 0.100000\nTraining Epoch: 4 [28544/50000]\tLoss: 0.6375\tLR: 0.100000\nTraining Epoch: 4 [28672/50000]\tLoss: 0.6891\tLR: 0.100000\nTraining Epoch: 4 [28800/50000]\tLoss: 0.7814\tLR: 0.100000\nTraining Epoch: 4 [28928/50000]\tLoss: 0.9234\tLR: 0.100000\nTraining Epoch: 4 [29056/50000]\tLoss: 0.8483\tLR: 0.100000\nTraining Epoch: 4 [29184/50000]\tLoss: 0.8079\tLR: 0.100000\nTraining Epoch: 4 [29312/50000]\tLoss: 0.7331\tLR: 0.100000\nTraining Epoch: 4 [29440/50000]\tLoss: 0.7225\tLR: 0.100000\nTraining Epoch: 4 [29568/50000]\tLoss: 0.8308\tLR: 0.100000\nTraining Epoch: 4 [29696/50000]\tLoss: 0.8057\tLR: 0.100000\nTraining Epoch: 4 [29824/50000]\tLoss: 0.7217\tLR: 0.100000\nTraining Epoch: 4 [29952/50000]\tLoss: 0.6753\tLR: 0.100000\nTraining Epoch: 4 [30080/50000]\tLoss: 0.6824\tLR: 0.100000\nTraining Epoch: 4 [30208/50000]\tLoss: 0.9118\tLR: 0.100000\nTraining Epoch: 4 [30336/50000]\tLoss: 0.7723\tLR: 0.100000\nTraining Epoch: 4 [30464/50000]\tLoss: 0.7994\tLR: 0.100000\nTraining Epoch: 4 [30592/50000]\tLoss: 0.6742\tLR: 0.100000\nTraining Epoch: 4 [30720/50000]\tLoss: 0.8558\tLR: 0.100000\nTraining Epoch: 4 [30848/50000]\tLoss: 0.7749\tLR: 0.100000\nTraining Epoch: 4 [30976/50000]\tLoss: 0.8576\tLR: 0.100000\nTraining Epoch: 4 [31104/50000]\tLoss: 0.7423\tLR: 0.100000\nTraining Epoch: 4 [31232/50000]\tLoss: 0.6118\tLR: 0.100000\nTraining Epoch: 4 [31360/50000]\tLoss: 0.7828\tLR: 0.100000\nTraining Epoch: 4 [31488/50000]\tLoss: 0.7579\tLR: 0.100000\nTraining Epoch: 4 [31616/50000]\tLoss: 0.7176\tLR: 0.100000\nTraining Epoch: 4 [31744/50000]\tLoss: 0.6638\tLR: 0.100000\nTraining Epoch: 4 [31872/50000]\tLoss: 0.8704\tLR: 0.100000\nTraining Epoch: 4 [32000/50000]\tLoss: 0.7700\tLR: 0.100000\nTraining Epoch: 4 [32128/50000]\tLoss: 0.7782\tLR: 0.100000\nTraining Epoch: 4 [32256/50000]\tLoss: 0.7459\tLR: 0.100000\nTraining Epoch: 4 [32384/50000]\tLoss: 0.6575\tLR: 0.100000\nTraining Epoch: 4 [32512/50000]\tLoss: 0.7549\tLR: 0.100000\nTraining Epoch: 4 [32640/50000]\tLoss: 0.7475\tLR: 0.100000\nTraining Epoch: 4 [32768/50000]\tLoss: 0.7416\tLR: 0.100000\nTraining Epoch: 4 [32896/50000]\tLoss: 0.8466\tLR: 0.100000\nTraining Epoch: 4 [33024/50000]\tLoss: 0.7842\tLR: 0.100000\nTraining Epoch: 4 [33152/50000]\tLoss: 0.5336\tLR: 0.100000\nTraining Epoch: 4 [33280/50000]\tLoss: 0.6762\tLR: 0.100000\nTraining Epoch: 4 [33408/50000]\tLoss: 0.7613\tLR: 0.100000\nTraining Epoch: 4 [33536/50000]\tLoss: 0.6931\tLR: 0.100000\nTraining Epoch: 4 [33664/50000]\tLoss: 0.6851\tLR: 0.100000\nTraining Epoch: 4 [33792/50000]\tLoss: 0.8823\tLR: 0.100000\nTraining Epoch: 4 [33920/50000]\tLoss: 0.7435\tLR: 0.100000\nTraining Epoch: 4 [34048/50000]\tLoss: 0.7733\tLR: 0.100000\nTraining Epoch: 4 [34176/50000]\tLoss: 0.8060\tLR: 0.100000\nTraining Epoch: 4 [34304/50000]\tLoss: 0.7595\tLR: 0.100000\nTraining Epoch: 4 [34432/50000]\tLoss: 0.7334\tLR: 0.100000\nTraining Epoch: 4 [34560/50000]\tLoss: 0.8034\tLR: 0.100000\nTraining Epoch: 4 [34688/50000]\tLoss: 0.9596\tLR: 0.100000\nTraining Epoch: 4 [34816/50000]\tLoss: 0.8665\tLR: 0.100000\nTraining Epoch: 4 [34944/50000]\tLoss: 0.6914\tLR: 0.100000\nTraining Epoch: 4 [35072/50000]\tLoss: 0.8848\tLR: 0.100000\nTraining Epoch: 4 [35200/50000]\tLoss: 0.8288\tLR: 0.100000\nTraining Epoch: 4 [35328/50000]\tLoss: 0.7332\tLR: 0.100000\nTraining Epoch: 4 [35456/50000]\tLoss: 0.6777\tLR: 0.100000\nTraining Epoch: 4 [35584/50000]\tLoss: 0.9210\tLR: 0.100000\nTraining Epoch: 4 [35712/50000]\tLoss: 0.9361\tLR: 0.100000\nTraining Epoch: 4 [35840/50000]\tLoss: 0.7423\tLR: 0.100000\nTraining Epoch: 4 [35968/50000]\tLoss: 0.8522\tLR: 0.100000\nTraining Epoch: 4 [36096/50000]\tLoss: 0.8623\tLR: 0.100000\nTraining Epoch: 4 [36224/50000]\tLoss: 0.7246\tLR: 0.100000\nTraining Epoch: 4 [36352/50000]\tLoss: 0.7669\tLR: 0.100000\nTraining Epoch: 4 [36480/50000]\tLoss: 0.6783\tLR: 0.100000\nTraining Epoch: 4 [36608/50000]\tLoss: 0.7175\tLR: 0.100000\nTraining Epoch: 4 [36736/50000]\tLoss: 0.8311\tLR: 0.100000\nTraining Epoch: 4 [36864/50000]\tLoss: 0.8064\tLR: 0.100000\nTraining Epoch: 4 [36992/50000]\tLoss: 0.7444\tLR: 0.100000\nTraining Epoch: 4 [37120/50000]\tLoss: 0.7845\tLR: 0.100000\nTraining Epoch: 4 [37248/50000]\tLoss: 0.6830\tLR: 0.100000\nTraining Epoch: 4 [37376/50000]\tLoss: 0.6316\tLR: 0.100000\nTraining Epoch: 4 [37504/50000]\tLoss: 0.7282\tLR: 0.100000\nTraining Epoch: 4 [37632/50000]\tLoss: 0.8273\tLR: 0.100000\nTraining Epoch: 4 [37760/50000]\tLoss: 0.8348\tLR: 0.100000\nTraining Epoch: 4 [37888/50000]\tLoss: 0.5001\tLR: 0.100000\nTraining Epoch: 4 [38016/50000]\tLoss: 0.6225\tLR: 0.100000\nTraining Epoch: 4 [38144/50000]\tLoss: 0.6721\tLR: 0.100000\nTraining Epoch: 4 [38272/50000]\tLoss: 0.7757\tLR: 0.100000\nTraining Epoch: 4 [38400/50000]\tLoss: 0.7935\tLR: 0.100000\nTraining Epoch: 4 [38528/50000]\tLoss: 0.8229\tLR: 0.100000\nTraining Epoch: 4 [38656/50000]\tLoss: 0.7072\tLR: 0.100000\nTraining Epoch: 4 [38784/50000]\tLoss: 0.5594\tLR: 0.100000\nTraining Epoch: 4 [38912/50000]\tLoss: 0.6891\tLR: 0.100000\nTraining Epoch: 4 [39040/50000]\tLoss: 0.8481\tLR: 0.100000\nTraining Epoch: 4 [39168/50000]\tLoss: 0.8660\tLR: 0.100000\nTraining Epoch: 4 [39296/50000]\tLoss: 0.6221\tLR: 0.100000\nTraining Epoch: 4 [39424/50000]\tLoss: 0.7568\tLR: 0.100000\nTraining Epoch: 4 [39552/50000]\tLoss: 0.7473\tLR: 0.100000\nTraining Epoch: 4 [39680/50000]\tLoss: 0.8277\tLR: 0.100000\nTraining Epoch: 4 [39808/50000]\tLoss: 0.8777\tLR: 0.100000\nTraining Epoch: 4 [39936/50000]\tLoss: 0.8593\tLR: 0.100000\nTraining Epoch: 4 [40064/50000]\tLoss: 0.6900\tLR: 0.100000\nTraining Epoch: 4 [40192/50000]\tLoss: 0.9084\tLR: 0.100000\nTraining Epoch: 4 [40320/50000]\tLoss: 0.9064\tLR: 0.100000\nTraining Epoch: 4 [40448/50000]\tLoss: 0.8626\tLR: 0.100000\nTraining Epoch: 4 [40576/50000]\tLoss: 0.9708\tLR: 0.100000\nTraining Epoch: 4 [40704/50000]\tLoss: 0.7123\tLR: 0.100000\nTraining Epoch: 4 [40832/50000]\tLoss: 0.7971\tLR: 0.100000\nTraining Epoch: 4 [40960/50000]\tLoss: 0.8178\tLR: 0.100000\nTraining Epoch: 4 [41088/50000]\tLoss: 0.7225\tLR: 0.100000\nTraining Epoch: 4 [41216/50000]\tLoss: 0.6860\tLR: 0.100000\nTraining Epoch: 4 [41344/50000]\tLoss: 0.7668\tLR: 0.100000\nTraining Epoch: 4 [41472/50000]\tLoss: 1.0506\tLR: 0.100000\nTraining Epoch: 4 [41600/50000]\tLoss: 1.2079\tLR: 0.100000\nTraining Epoch: 4 [41728/50000]\tLoss: 0.8653\tLR: 0.100000\nTraining Epoch: 4 [41856/50000]\tLoss: 0.7333\tLR: 0.100000\nTraining Epoch: 4 [41984/50000]\tLoss: 0.7712\tLR: 0.100000\nTraining Epoch: 4 [42112/50000]\tLoss: 0.6602\tLR: 0.100000\nTraining Epoch: 4 [42240/50000]\tLoss: 0.7067\tLR: 0.100000\nTraining Epoch: 4 [42368/50000]\tLoss: 0.8819\tLR: 0.100000\nTraining Epoch: 4 [42496/50000]\tLoss: 0.7117\tLR: 0.100000\nTraining Epoch: 4 [42624/50000]\tLoss: 0.7675\tLR: 0.100000\nTraining Epoch: 4 [42752/50000]\tLoss: 1.0085\tLR: 0.100000\nTraining Epoch: 4 [42880/50000]\tLoss: 0.7862\tLR: 0.100000\nTraining Epoch: 4 [43008/50000]\tLoss: 0.5688\tLR: 0.100000\nTraining Epoch: 4 [43136/50000]\tLoss: 0.6014\tLR: 0.100000\nTraining Epoch: 4 [43264/50000]\tLoss: 0.7715\tLR: 0.100000\nTraining Epoch: 4 [43392/50000]\tLoss: 0.7946\tLR: 0.100000\nTraining Epoch: 4 [43520/50000]\tLoss: 0.7858\tLR: 0.100000\nTraining Epoch: 4 [43648/50000]\tLoss: 0.8664\tLR: 0.100000\nTraining Epoch: 4 [43776/50000]\tLoss: 0.6184\tLR: 0.100000\nTraining Epoch: 4 [43904/50000]\tLoss: 0.6805\tLR: 0.100000\nTraining Epoch: 4 [44032/50000]\tLoss: 0.8018\tLR: 0.100000\nTraining Epoch: 4 [44160/50000]\tLoss: 0.8554\tLR: 0.100000\nTraining Epoch: 4 [44288/50000]\tLoss: 0.8728\tLR: 0.100000\nTraining Epoch: 4 [44416/50000]\tLoss: 0.7474\tLR: 0.100000\nTraining Epoch: 4 [44544/50000]\tLoss: 0.8303\tLR: 0.100000\nTraining Epoch: 4 [44672/50000]\tLoss: 0.5861\tLR: 0.100000\nTraining Epoch: 4 [44800/50000]\tLoss: 0.6866\tLR: 0.100000\nTraining Epoch: 4 [44928/50000]\tLoss: 0.6408\tLR: 0.100000\nTraining Epoch: 4 [45056/50000]\tLoss: 0.7965\tLR: 0.100000\nTraining Epoch: 4 [45184/50000]\tLoss: 0.7919\tLR: 0.100000\nTraining Epoch: 4 [45312/50000]\tLoss: 0.8432\tLR: 0.100000\nTraining Epoch: 4 [45440/50000]\tLoss: 0.7411\tLR: 0.100000\nTraining Epoch: 4 [45568/50000]\tLoss: 0.7296\tLR: 0.100000\nTraining Epoch: 4 [45696/50000]\tLoss: 0.6979\tLR: 0.100000\nTraining Epoch: 4 [45824/50000]\tLoss: 0.7519\tLR: 0.100000\nTraining Epoch: 4 [45952/50000]\tLoss: 0.7566\tLR: 0.100000\nTraining Epoch: 4 [46080/50000]\tLoss: 0.7202\tLR: 0.100000\nTraining Epoch: 4 [46208/50000]\tLoss: 0.6159\tLR: 0.100000\nTraining Epoch: 4 [46336/50000]\tLoss: 0.6344\tLR: 0.100000\nTraining Epoch: 4 [46464/50000]\tLoss: 0.8564\tLR: 0.100000\nTraining Epoch: 4 [46592/50000]\tLoss: 1.0046\tLR: 0.100000\nTraining Epoch: 4 [46720/50000]\tLoss: 0.7430\tLR: 0.100000\nTraining Epoch: 4 [46848/50000]\tLoss: 0.8008\tLR: 0.100000\nTraining Epoch: 4 [46976/50000]\tLoss: 0.7198\tLR: 0.100000\nTraining Epoch: 4 [47104/50000]\tLoss: 0.5750\tLR: 0.100000\nTraining Epoch: 4 [47232/50000]\tLoss: 0.8834\tLR: 0.100000\nTraining Epoch: 4 [47360/50000]\tLoss: 0.8090\tLR: 0.100000\nTraining Epoch: 4 [47488/50000]\tLoss: 0.8917\tLR: 0.100000\nTraining Epoch: 4 [47616/50000]\tLoss: 0.5953\tLR: 0.100000\nTraining Epoch: 4 [47744/50000]\tLoss: 0.7057\tLR: 0.100000\nTraining Epoch: 4 [47872/50000]\tLoss: 0.8186\tLR: 0.100000\nTraining Epoch: 4 [48000/50000]\tLoss: 0.9647\tLR: 0.100000\nTraining Epoch: 4 [48128/50000]\tLoss: 0.8760\tLR: 0.100000\nTraining Epoch: 4 [48256/50000]\tLoss: 0.7038\tLR: 0.100000\nTraining Epoch: 4 [48384/50000]\tLoss: 0.6652\tLR: 0.100000\nTraining Epoch: 4 [48512/50000]\tLoss: 0.6815\tLR: 0.100000\nTraining Epoch: 4 [48640/50000]\tLoss: 0.7855\tLR: 0.100000\nTraining Epoch: 4 [48768/50000]\tLoss: 0.7420\tLR: 0.100000\nTraining Epoch: 4 [48896/50000]\tLoss: 0.8721\tLR: 0.100000\nTraining Epoch: 4 [49024/50000]\tLoss: 0.7620\tLR: 0.100000\nTraining Epoch: 4 [49152/50000]\tLoss: 0.6132\tLR: 0.100000\nTraining Epoch: 4 [49280/50000]\tLoss: 0.7281\tLR: 0.100000\nTraining Epoch: 4 [49408/50000]\tLoss: 0.8487\tLR: 0.100000\nTraining Epoch: 4 [49536/50000]\tLoss: 0.8121\tLR: 0.100000\nTraining Epoch: 4 [49664/50000]\tLoss: 0.7006\tLR: 0.100000\nTraining Epoch: 4 [49792/50000]\tLoss: 0.7121\tLR: 0.100000\nTraining Epoch: 4 [49920/50000]\tLoss: 1.1100\tLR: 0.100000\nTraining Epoch: 4 [50000/50000]\tLoss: 0.6498\tLR: 0.100000\nTest set: Average loss: 0.0064, Accuracy: 0.7225\n\nTraining Epoch: 5 [128/50000]\tLoss: 0.8336\tLR: 0.100000\nTraining Epoch: 5 [256/50000]\tLoss: 0.6626\tLR: 0.100000\nTraining Epoch: 5 [384/50000]\tLoss: 0.9120\tLR: 0.100000\nTraining Epoch: 5 [512/50000]\tLoss: 0.6415\tLR: 0.100000\nTraining Epoch: 5 [640/50000]\tLoss: 0.6763\tLR: 0.100000\nTraining Epoch: 5 [768/50000]\tLoss: 0.7753\tLR: 0.100000\nTraining Epoch: 5 [896/50000]\tLoss: 0.6968\tLR: 0.100000\nTraining Epoch: 5 [1024/50000]\tLoss: 0.8650\tLR: 0.100000\nTraining Epoch: 5 [1152/50000]\tLoss: 0.8552\tLR: 0.100000\nTraining Epoch: 5 [1280/50000]\tLoss: 0.6285\tLR: 0.100000\nTraining Epoch: 5 [1408/50000]\tLoss: 0.6805\tLR: 0.100000\nTraining Epoch: 5 [1536/50000]\tLoss: 0.8283\tLR: 0.100000\nTraining Epoch: 5 [1664/50000]\tLoss: 0.6195\tLR: 0.100000\nTraining Epoch: 5 [1792/50000]\tLoss: 0.7155\tLR: 0.100000\nTraining Epoch: 5 [1920/50000]\tLoss: 0.6958\tLR: 0.100000\nTraining Epoch: 5 [2048/50000]\tLoss: 0.7739\tLR: 0.100000\nTraining Epoch: 5 [2176/50000]\tLoss: 0.6242\tLR: 0.100000\nTraining Epoch: 5 [2304/50000]\tLoss: 0.7608\tLR: 0.100000\nTraining Epoch: 5 [2432/50000]\tLoss: 0.7592\tLR: 0.100000\nTraining Epoch: 5 [2560/50000]\tLoss: 0.7407\tLR: 0.100000\nTraining Epoch: 5 [2688/50000]\tLoss: 0.5834\tLR: 0.100000\nTraining Epoch: 5 [2816/50000]\tLoss: 0.7225\tLR: 0.100000\nTraining Epoch: 5 [2944/50000]\tLoss: 0.8036\tLR: 0.100000\nTraining Epoch: 5 [3072/50000]\tLoss: 0.4923\tLR: 0.100000\nTraining Epoch: 5 [3200/50000]\tLoss: 0.7993\tLR: 0.100000\nTraining Epoch: 5 [3328/50000]\tLoss: 0.7038\tLR: 0.100000\nTraining Epoch: 5 [3456/50000]\tLoss: 0.5580\tLR: 0.100000\nTraining Epoch: 5 [3584/50000]\tLoss: 0.6601\tLR: 0.100000\nTraining Epoch: 5 [3712/50000]\tLoss: 0.5979\tLR: 0.100000\nTraining Epoch: 5 [3840/50000]\tLoss: 0.8677\tLR: 0.100000\nTraining Epoch: 5 [3968/50000]\tLoss: 0.7572\tLR: 0.100000\nTraining Epoch: 5 [4096/50000]\tLoss: 0.7598\tLR: 0.100000\nTraining Epoch: 5 [4224/50000]\tLoss: 0.6454\tLR: 0.100000\nTraining Epoch: 5 [4352/50000]\tLoss: 0.7203\tLR: 0.100000\nTraining Epoch: 5 [4480/50000]\tLoss: 0.9420\tLR: 0.100000\nTraining Epoch: 5 [4608/50000]\tLoss: 0.8110\tLR: 0.100000\nTraining Epoch: 5 [4736/50000]\tLoss: 0.6854\tLR: 0.100000\nTraining Epoch: 5 [4864/50000]\tLoss: 0.6882\tLR: 0.100000\nTraining Epoch: 5 [4992/50000]\tLoss: 0.6703\tLR: 0.100000\nTraining Epoch: 5 [5120/50000]\tLoss: 0.6259\tLR: 0.100000\nTraining Epoch: 5 [5248/50000]\tLoss: 0.6458\tLR: 0.100000\nTraining Epoch: 5 [5376/50000]\tLoss: 0.5680\tLR: 0.100000\nTraining Epoch: 5 [5504/50000]\tLoss: 0.7131\tLR: 0.100000\nTraining Epoch: 5 [5632/50000]\tLoss: 0.6002\tLR: 0.100000\nTraining Epoch: 5 [5760/50000]\tLoss: 0.7693\tLR: 0.100000\nTraining Epoch: 5 [5888/50000]\tLoss: 0.8817\tLR: 0.100000\nTraining Epoch: 5 [6016/50000]\tLoss: 0.6232\tLR: 0.100000\nTraining Epoch: 5 [6144/50000]\tLoss: 0.8419\tLR: 0.100000\nTraining Epoch: 5 [6272/50000]\tLoss: 0.8354\tLR: 0.100000\nTraining Epoch: 5 [6400/50000]\tLoss: 0.8301\tLR: 0.100000\nTraining Epoch: 5 [6528/50000]\tLoss: 0.7550\tLR: 0.100000\nTraining Epoch: 5 [6656/50000]\tLoss: 0.7592\tLR: 0.100000\nTraining Epoch: 5 [6784/50000]\tLoss: 0.7525\tLR: 0.100000\nTraining Epoch: 5 [6912/50000]\tLoss: 0.6470\tLR: 0.100000\nTraining Epoch: 5 [7040/50000]\tLoss: 0.7255\tLR: 0.100000\nTraining Epoch: 5 [7168/50000]\tLoss: 0.7180\tLR: 0.100000\nTraining Epoch: 5 [7296/50000]\tLoss: 0.7518\tLR: 0.100000\nTraining Epoch: 5 [7424/50000]\tLoss: 0.8730\tLR: 0.100000\nTraining Epoch: 5 [7552/50000]\tLoss: 0.9611\tLR: 0.100000\nTraining Epoch: 5 [7680/50000]\tLoss: 0.7476\tLR: 0.100000\nTraining Epoch: 5 [7808/50000]\tLoss: 0.5416\tLR: 0.100000\nTraining Epoch: 5 [7936/50000]\tLoss: 0.8817\tLR: 0.100000\nTraining Epoch: 5 [8064/50000]\tLoss: 0.8462\tLR: 0.100000\nTraining Epoch: 5 [8192/50000]\tLoss: 0.8249\tLR: 0.100000\nTraining Epoch: 5 [8320/50000]\tLoss: 0.7210\tLR: 0.100000\nTraining Epoch: 5 [8448/50000]\tLoss: 0.7991\tLR: 0.100000\nTraining Epoch: 5 [8576/50000]\tLoss: 0.7170\tLR: 0.100000\nTraining Epoch: 5 [8704/50000]\tLoss: 0.6391\tLR: 0.100000\nTraining Epoch: 5 [8832/50000]\tLoss: 0.8446\tLR: 0.100000\nTraining Epoch: 5 [8960/50000]\tLoss: 0.6372\tLR: 0.100000\nTraining Epoch: 5 [9088/50000]\tLoss: 0.8176\tLR: 0.100000\nTraining Epoch: 5 [9216/50000]\tLoss: 0.8224\tLR: 0.100000\nTraining Epoch: 5 [9344/50000]\tLoss: 0.6519\tLR: 0.100000\nTraining Epoch: 5 [9472/50000]\tLoss: 0.7507\tLR: 0.100000\nTraining Epoch: 5 [9600/50000]\tLoss: 0.7934\tLR: 0.100000\nTraining Epoch: 5 [9728/50000]\tLoss: 0.7402\tLR: 0.100000\nTraining Epoch: 5 [9856/50000]\tLoss: 0.8196\tLR: 0.100000\nTraining Epoch: 5 [9984/50000]\tLoss: 0.7093\tLR: 0.100000\nTraining Epoch: 5 [10112/50000]\tLoss: 0.5445\tLR: 0.100000\nTraining Epoch: 5 [10240/50000]\tLoss: 0.7366\tLR: 0.100000\nTraining Epoch: 5 [10368/50000]\tLoss: 0.8843\tLR: 0.100000\nTraining Epoch: 5 [10496/50000]\tLoss: 0.7403\tLR: 0.100000\nTraining Epoch: 5 [10624/50000]\tLoss: 0.6667\tLR: 0.100000\nTraining Epoch: 5 [10752/50000]\tLoss: 0.7911\tLR: 0.100000\nTraining Epoch: 5 [10880/50000]\tLoss: 0.6804\tLR: 0.100000\nTraining Epoch: 5 [11008/50000]\tLoss: 0.6090\tLR: 0.100000\nTraining Epoch: 5 [11136/50000]\tLoss: 0.6957\tLR: 0.100000\nTraining Epoch: 5 [11264/50000]\tLoss: 0.6238\tLR: 0.100000\nTraining Epoch: 5 [11392/50000]\tLoss: 0.6364\tLR: 0.100000\nTraining Epoch: 5 [11520/50000]\tLoss: 0.7088\tLR: 0.100000\nTraining Epoch: 5 [11648/50000]\tLoss: 0.7041\tLR: 0.100000\nTraining Epoch: 5 [11776/50000]\tLoss: 0.7258\tLR: 0.100000\nTraining Epoch: 5 [11904/50000]\tLoss: 0.6345\tLR: 0.100000\nTraining Epoch: 5 [12032/50000]\tLoss: 0.5836\tLR: 0.100000\nTraining Epoch: 5 [12160/50000]\tLoss: 0.8325\tLR: 0.100000\nTraining Epoch: 5 [12288/50000]\tLoss: 0.8295\tLR: 0.100000\nTraining Epoch: 5 [12416/50000]\tLoss: 0.8803\tLR: 0.100000\nTraining Epoch: 5 [12544/50000]\tLoss: 0.6874\tLR: 0.100000\nTraining Epoch: 5 [12672/50000]\tLoss: 0.6626\tLR: 0.100000\nTraining Epoch: 5 [12800/50000]\tLoss: 0.6130\tLR: 0.100000\nTraining Epoch: 5 [12928/50000]\tLoss: 0.8069\tLR: 0.100000\nTraining Epoch: 5 [13056/50000]\tLoss: 0.7982\tLR: 0.100000\nTraining Epoch: 5 [13184/50000]\tLoss: 0.7428\tLR: 0.100000\nTraining Epoch: 5 [13312/50000]\tLoss: 0.5827\tLR: 0.100000\nTraining Epoch: 5 [13440/50000]\tLoss: 0.6147\tLR: 0.100000\nTraining Epoch: 5 [13568/50000]\tLoss: 0.7386\tLR: 0.100000\nTraining Epoch: 5 [13696/50000]\tLoss: 0.6868\tLR: 0.100000\nTraining Epoch: 5 [13824/50000]\tLoss: 0.7606\tLR: 0.100000\nTraining Epoch: 5 [13952/50000]\tLoss: 0.6874\tLR: 0.100000\nTraining Epoch: 5 [14080/50000]\tLoss: 0.7467\tLR: 0.100000\nTraining Epoch: 5 [14208/50000]\tLoss: 0.6693\tLR: 0.100000\nTraining Epoch: 5 [14336/50000]\tLoss: 0.7282\tLR: 0.100000\nTraining Epoch: 5 [14464/50000]\tLoss: 0.7847\tLR: 0.100000\nTraining Epoch: 5 [14592/50000]\tLoss: 0.8352\tLR: 0.100000\nTraining Epoch: 5 [14720/50000]\tLoss: 0.8142\tLR: 0.100000\nTraining Epoch: 5 [14848/50000]\tLoss: 0.8540\tLR: 0.100000\nTraining Epoch: 5 [14976/50000]\tLoss: 0.6912\tLR: 0.100000\nTraining Epoch: 5 [15104/50000]\tLoss: 0.9486\tLR: 0.100000\nTraining Epoch: 5 [15232/50000]\tLoss: 0.6264\tLR: 0.100000\nTraining Epoch: 5 [15360/50000]\tLoss: 0.7591\tLR: 0.100000\nTraining Epoch: 5 [15488/50000]\tLoss: 0.6950\tLR: 0.100000\nTraining Epoch: 5 [15616/50000]\tLoss: 0.6885\tLR: 0.100000\nTraining Epoch: 5 [15744/50000]\tLoss: 0.7324\tLR: 0.100000\nTraining Epoch: 5 [15872/50000]\tLoss: 0.7626\tLR: 0.100000\nTraining Epoch: 5 [16000/50000]\tLoss: 0.7686\tLR: 0.100000\nTraining Epoch: 5 [16128/50000]\tLoss: 0.6449\tLR: 0.100000\nTraining Epoch: 5 [16256/50000]\tLoss: 0.6389\tLR: 0.100000\nTraining Epoch: 5 [16384/50000]\tLoss: 0.8563\tLR: 0.100000\nTraining Epoch: 5 [16512/50000]\tLoss: 0.6755\tLR: 0.100000\nTraining Epoch: 5 [16640/50000]\tLoss: 0.7552\tLR: 0.100000\nTraining Epoch: 5 [16768/50000]\tLoss: 0.6308\tLR: 0.100000\nTraining Epoch: 5 [16896/50000]\tLoss: 0.8483\tLR: 0.100000\nTraining Epoch: 5 [17024/50000]\tLoss: 0.6579\tLR: 0.100000\nTraining Epoch: 5 [17152/50000]\tLoss: 0.7544\tLR: 0.100000\nTraining Epoch: 5 [17280/50000]\tLoss: 0.7609\tLR: 0.100000\nTraining Epoch: 5 [17408/50000]\tLoss: 0.7790\tLR: 0.100000\nTraining Epoch: 5 [17536/50000]\tLoss: 0.6980\tLR: 0.100000\nTraining Epoch: 5 [17664/50000]\tLoss: 0.4931\tLR: 0.100000\nTraining Epoch: 5 [17792/50000]\tLoss: 0.8606\tLR: 0.100000\nTraining Epoch: 5 [17920/50000]\tLoss: 0.7457\tLR: 0.100000\nTraining Epoch: 5 [18048/50000]\tLoss: 0.7007\tLR: 0.100000\nTraining Epoch: 5 [18176/50000]\tLoss: 0.6070\tLR: 0.100000\nTraining Epoch: 5 [18304/50000]\tLoss: 0.5939\tLR: 0.100000\nTraining Epoch: 5 [18432/50000]\tLoss: 0.6614\tLR: 0.100000\nTraining Epoch: 5 [18560/50000]\tLoss: 0.6841\tLR: 0.100000\nTraining Epoch: 5 [18688/50000]\tLoss: 0.6581\tLR: 0.100000\nTraining Epoch: 5 [18816/50000]\tLoss: 0.7514\tLR: 0.100000\nTraining Epoch: 5 [18944/50000]\tLoss: 0.6575\tLR: 0.100000\nTraining Epoch: 5 [19072/50000]\tLoss: 0.7421\tLR: 0.100000\nTraining Epoch: 5 [19200/50000]\tLoss: 0.6640\tLR: 0.100000\nTraining Epoch: 5 [19328/50000]\tLoss: 0.6331\tLR: 0.100000\nTraining Epoch: 5 [19456/50000]\tLoss: 0.7137\tLR: 0.100000\nTraining Epoch: 5 [19584/50000]\tLoss: 0.7679\tLR: 0.100000\nTraining Epoch: 5 [19712/50000]\tLoss: 0.7208\tLR: 0.100000\nTraining Epoch: 5 [19840/50000]\tLoss: 0.6840\tLR: 0.100000\nTraining Epoch: 5 [19968/50000]\tLoss: 0.8457\tLR: 0.100000\nTraining Epoch: 5 [20096/50000]\tLoss: 0.7155\tLR: 0.100000\nTraining Epoch: 5 [20224/50000]\tLoss: 0.7382\tLR: 0.100000\nTraining Epoch: 5 [20352/50000]\tLoss: 0.6032\tLR: 0.100000\nTraining Epoch: 5 [20480/50000]\tLoss: 0.4856\tLR: 0.100000\nTraining Epoch: 5 [20608/50000]\tLoss: 0.8545\tLR: 0.100000\nTraining Epoch: 5 [20736/50000]\tLoss: 0.7689\tLR: 0.100000\nTraining Epoch: 5 [20864/50000]\tLoss: 0.7200\tLR: 0.100000\nTraining Epoch: 5 [20992/50000]\tLoss: 0.6158\tLR: 0.100000\nTraining Epoch: 5 [21120/50000]\tLoss: 0.6451\tLR: 0.100000\nTraining Epoch: 5 [21248/50000]\tLoss: 0.8129\tLR: 0.100000\nTraining Epoch: 5 [21376/50000]\tLoss: 0.6919\tLR: 0.100000\nTraining Epoch: 5 [21504/50000]\tLoss: 0.6899\tLR: 0.100000\nTraining Epoch: 5 [21632/50000]\tLoss: 0.8932\tLR: 0.100000\nTraining Epoch: 5 [21760/50000]\tLoss: 0.7386\tLR: 0.100000\nTraining Epoch: 5 [21888/50000]\tLoss: 0.6670\tLR: 0.100000\nTraining Epoch: 5 [22016/50000]\tLoss: 0.7866\tLR: 0.100000\nTraining Epoch: 5 [22144/50000]\tLoss: 0.8363\tLR: 0.100000\nTraining Epoch: 5 [22272/50000]\tLoss: 0.8713\tLR: 0.100000\nTraining Epoch: 5 [22400/50000]\tLoss: 0.6553\tLR: 0.100000\nTraining Epoch: 5 [22528/50000]\tLoss: 0.6775\tLR: 0.100000\nTraining Epoch: 5 [22656/50000]\tLoss: 0.8071\tLR: 0.100000\nTraining Epoch: 5 [22784/50000]\tLoss: 0.6823\tLR: 0.100000\nTraining Epoch: 5 [22912/50000]\tLoss: 0.7149\tLR: 0.100000\nTraining Epoch: 5 [23040/50000]\tLoss: 0.9129\tLR: 0.100000\nTraining Epoch: 5 [23168/50000]\tLoss: 0.7346\tLR: 0.100000\nTraining Epoch: 5 [23296/50000]\tLoss: 0.5473\tLR: 0.100000\nTraining Epoch: 5 [23424/50000]\tLoss: 0.7743\tLR: 0.100000\nTraining Epoch: 5 [23552/50000]\tLoss: 0.7122\tLR: 0.100000\nTraining Epoch: 5 [23680/50000]\tLoss: 0.7002\tLR: 0.100000\nTraining Epoch: 5 [23808/50000]\tLoss: 0.6517\tLR: 0.100000\nTraining Epoch: 5 [23936/50000]\tLoss: 0.6591\tLR: 0.100000\nTraining Epoch: 5 [24064/50000]\tLoss: 0.6790\tLR: 0.100000\nTraining Epoch: 5 [24192/50000]\tLoss: 0.6960\tLR: 0.100000\nTraining Epoch: 5 [24320/50000]\tLoss: 0.6639\tLR: 0.100000\nTraining Epoch: 5 [24448/50000]\tLoss: 0.9030\tLR: 0.100000\nTraining Epoch: 5 [24576/50000]\tLoss: 0.9293\tLR: 0.100000\nTraining Epoch: 5 [24704/50000]\tLoss: 0.7666\tLR: 0.100000\nTraining Epoch: 5 [24832/50000]\tLoss: 0.6793\tLR: 0.100000\nTraining Epoch: 5 [24960/50000]\tLoss: 0.7465\tLR: 0.100000\nTraining Epoch: 5 [25088/50000]\tLoss: 0.8402\tLR: 0.100000\nTraining Epoch: 5 [25216/50000]\tLoss: 0.9134\tLR: 0.100000\nTraining Epoch: 5 [25344/50000]\tLoss: 0.7745\tLR: 0.100000\nTraining Epoch: 5 [25472/50000]\tLoss: 0.7098\tLR: 0.100000\nTraining Epoch: 5 [25600/50000]\tLoss: 0.7594\tLR: 0.100000\nTraining Epoch: 5 [25728/50000]\tLoss: 0.6499\tLR: 0.100000\nTraining Epoch: 5 [25856/50000]\tLoss: 0.6182\tLR: 0.100000\nTraining Epoch: 5 [25984/50000]\tLoss: 0.6754\tLR: 0.100000\nTraining Epoch: 5 [26112/50000]\tLoss: 0.8406\tLR: 0.100000\nTraining Epoch: 5 [26240/50000]\tLoss: 0.6393\tLR: 0.100000\nTraining Epoch: 5 [26368/50000]\tLoss: 0.8129\tLR: 0.100000\nTraining Epoch: 5 [26496/50000]\tLoss: 0.7757\tLR: 0.100000\nTraining Epoch: 5 [26624/50000]\tLoss: 0.6064\tLR: 0.100000\nTraining Epoch: 5 [26752/50000]\tLoss: 0.6748\tLR: 0.100000\nTraining Epoch: 5 [26880/50000]\tLoss: 0.6717\tLR: 0.100000\nTraining Epoch: 5 [27008/50000]\tLoss: 0.6911\tLR: 0.100000\nTraining Epoch: 5 [27136/50000]\tLoss: 0.5749\tLR: 0.100000\nTraining Epoch: 5 [27264/50000]\tLoss: 0.9100\tLR: 0.100000\nTraining Epoch: 5 [27392/50000]\tLoss: 0.6994\tLR: 0.100000\nTraining Epoch: 5 [27520/50000]\tLoss: 0.6207\tLR: 0.100000\nTraining Epoch: 5 [27648/50000]\tLoss: 0.6710\tLR: 0.100000\nTraining Epoch: 5 [27776/50000]\tLoss: 0.4988\tLR: 0.100000\nTraining Epoch: 5 [27904/50000]\tLoss: 0.7714\tLR: 0.100000\nTraining Epoch: 5 [28032/50000]\tLoss: 0.6696\tLR: 0.100000\nTraining Epoch: 5 [28160/50000]\tLoss: 0.8217\tLR: 0.100000\nTraining Epoch: 5 [28288/50000]\tLoss: 0.7576\tLR: 0.100000\nTraining Epoch: 5 [28416/50000]\tLoss: 0.6140\tLR: 0.100000\nTraining Epoch: 5 [28544/50000]\tLoss: 0.6979\tLR: 0.100000\nTraining Epoch: 5 [28672/50000]\tLoss: 0.6313\tLR: 0.100000\nTraining Epoch: 5 [28800/50000]\tLoss: 0.8028\tLR: 0.100000\nTraining Epoch: 5 [28928/50000]\tLoss: 0.6945\tLR: 0.100000\nTraining Epoch: 5 [29056/50000]\tLoss: 0.7267\tLR: 0.100000\nTraining Epoch: 5 [29184/50000]\tLoss: 0.7029\tLR: 0.100000\nTraining Epoch: 5 [29312/50000]\tLoss: 0.7876\tLR: 0.100000\nTraining Epoch: 5 [29440/50000]\tLoss: 0.7365\tLR: 0.100000\nTraining Epoch: 5 [29568/50000]\tLoss: 0.6521\tLR: 0.100000\nTraining Epoch: 5 [29696/50000]\tLoss: 0.6870\tLR: 0.100000\nTraining Epoch: 5 [29824/50000]\tLoss: 0.8337\tLR: 0.100000\nTraining Epoch: 5 [29952/50000]\tLoss: 0.7749\tLR: 0.100000\nTraining Epoch: 5 [30080/50000]\tLoss: 0.8060\tLR: 0.100000\nTraining Epoch: 5 [30208/50000]\tLoss: 0.7178\tLR: 0.100000\nTraining Epoch: 5 [30336/50000]\tLoss: 0.7153\tLR: 0.100000\nTraining Epoch: 5 [30464/50000]\tLoss: 0.9660\tLR: 0.100000\nTraining Epoch: 5 [30592/50000]\tLoss: 0.6575\tLR: 0.100000\nTraining Epoch: 5 [30720/50000]\tLoss: 0.5966\tLR: 0.100000\nTraining Epoch: 5 [30848/50000]\tLoss: 0.6831\tLR: 0.100000\nTraining Epoch: 5 [30976/50000]\tLoss: 0.8550\tLR: 0.100000\nTraining Epoch: 5 [31104/50000]\tLoss: 0.5492\tLR: 0.100000\nTraining Epoch: 5 [31232/50000]\tLoss: 0.7618\tLR: 0.100000\nTraining Epoch: 5 [31360/50000]\tLoss: 0.8805\tLR: 0.100000\nTraining Epoch: 5 [31488/50000]\tLoss: 0.7623\tLR: 0.100000\nTraining Epoch: 5 [31616/50000]\tLoss: 0.7003\tLR: 0.100000\nTraining Epoch: 5 [31744/50000]\tLoss: 0.7581\tLR: 0.100000\nTraining Epoch: 5 [31872/50000]\tLoss: 0.6041\tLR: 0.100000\nTraining Epoch: 5 [32000/50000]\tLoss: 0.5969\tLR: 0.100000\nTraining Epoch: 5 [32128/50000]\tLoss: 0.7154\tLR: 0.100000\nTraining Epoch: 5 [32256/50000]\tLoss: 0.7440\tLR: 0.100000\nTraining Epoch: 5 [32384/50000]\tLoss: 0.7376\tLR: 0.100000\nTraining Epoch: 5 [32512/50000]\tLoss: 0.5946\tLR: 0.100000\nTraining Epoch: 5 [32640/50000]\tLoss: 0.7584\tLR: 0.100000\nTraining Epoch: 5 [32768/50000]\tLoss: 0.6217\tLR: 0.100000\nTraining Epoch: 5 [32896/50000]\tLoss: 0.6181\tLR: 0.100000\nTraining Epoch: 5 [33024/50000]\tLoss: 0.5729\tLR: 0.100000\nTraining Epoch: 5 [33152/50000]\tLoss: 0.5268\tLR: 0.100000\nTraining Epoch: 5 [33280/50000]\tLoss: 0.8015\tLR: 0.100000\nTraining Epoch: 5 [33408/50000]\tLoss: 0.6772\tLR: 0.100000\nTraining Epoch: 5 [33536/50000]\tLoss: 0.6498\tLR: 0.100000\nTraining Epoch: 5 [33664/50000]\tLoss: 0.9494\tLR: 0.100000\nTraining Epoch: 5 [33792/50000]\tLoss: 0.7522\tLR: 0.100000\nTraining Epoch: 5 [33920/50000]\tLoss: 0.6516\tLR: 0.100000\nTraining Epoch: 5 [34048/50000]\tLoss: 0.7092\tLR: 0.100000\nTraining Epoch: 5 [34176/50000]\tLoss: 0.8115\tLR: 0.100000\nTraining Epoch: 5 [34304/50000]\tLoss: 1.0538\tLR: 0.100000\nTraining Epoch: 5 [34432/50000]\tLoss: 0.9001\tLR: 0.100000\nTraining Epoch: 5 [34560/50000]\tLoss: 0.7818\tLR: 0.100000\nTraining Epoch: 5 [34688/50000]\tLoss: 0.8649\tLR: 0.100000\nTraining Epoch: 5 [34816/50000]\tLoss: 0.6190\tLR: 0.100000\nTraining Epoch: 5 [34944/50000]\tLoss: 0.7312\tLR: 0.100000\nTraining Epoch: 5 [35072/50000]\tLoss: 0.7144\tLR: 0.100000\nTraining Epoch: 5 [35200/50000]\tLoss: 0.6809\tLR: 0.100000\nTraining Epoch: 5 [35328/50000]\tLoss: 0.6385\tLR: 0.100000\nTraining Epoch: 5 [35456/50000]\tLoss: 0.7816\tLR: 0.100000\nTraining Epoch: 5 [35584/50000]\tLoss: 0.7180\tLR: 0.100000\nTraining Epoch: 5 [35712/50000]\tLoss: 0.6430\tLR: 0.100000\nTraining Epoch: 5 [35840/50000]\tLoss: 0.7899\tLR: 0.100000\nTraining Epoch: 5 [35968/50000]\tLoss: 0.5616\tLR: 0.100000\nTraining Epoch: 5 [36096/50000]\tLoss: 0.7745\tLR: 0.100000\nTraining Epoch: 5 [36224/50000]\tLoss: 0.6543\tLR: 0.100000\nTraining Epoch: 5 [36352/50000]\tLoss: 0.6271\tLR: 0.100000\nTraining Epoch: 5 [36480/50000]\tLoss: 0.7224\tLR: 0.100000\nTraining Epoch: 5 [36608/50000]\tLoss: 0.7766\tLR: 0.100000\nTraining Epoch: 5 [36736/50000]\tLoss: 0.7505\tLR: 0.100000\nTraining Epoch: 5 [36864/50000]\tLoss: 0.7494\tLR: 0.100000\nTraining Epoch: 5 [36992/50000]\tLoss: 0.6708\tLR: 0.100000\nTraining Epoch: 5 [37120/50000]\tLoss: 0.6673\tLR: 0.100000\nTraining Epoch: 5 [37248/50000]\tLoss: 0.6743\tLR: 0.100000\nTraining Epoch: 5 [37376/50000]\tLoss: 0.7489\tLR: 0.100000\nTraining Epoch: 5 [37504/50000]\tLoss: 0.6269\tLR: 0.100000\nTraining Epoch: 5 [37632/50000]\tLoss: 0.6681\tLR: 0.100000\nTraining Epoch: 5 [37760/50000]\tLoss: 0.7373\tLR: 0.100000\nTraining Epoch: 5 [37888/50000]\tLoss: 0.6514\tLR: 0.100000\nTraining Epoch: 5 [38016/50000]\tLoss: 0.7327\tLR: 0.100000\nTraining Epoch: 5 [38144/50000]\tLoss: 0.7357\tLR: 0.100000\nTraining Epoch: 5 [38272/50000]\tLoss: 0.7063\tLR: 0.100000\nTraining Epoch: 5 [38400/50000]\tLoss: 0.6123\tLR: 0.100000\nTraining Epoch: 5 [38528/50000]\tLoss: 0.6617\tLR: 0.100000\nTraining Epoch: 5 [38656/50000]\tLoss: 0.6069\tLR: 0.100000\nTraining Epoch: 5 [38784/50000]\tLoss: 0.8689\tLR: 0.100000\nTraining Epoch: 5 [38912/50000]\tLoss: 0.7097\tLR: 0.100000\nTraining Epoch: 5 [39040/50000]\tLoss: 0.6037\tLR: 0.100000\nTraining Epoch: 5 [39168/50000]\tLoss: 0.8024\tLR: 0.100000\nTraining Epoch: 5 [39296/50000]\tLoss: 0.8561\tLR: 0.100000\nTraining Epoch: 5 [39424/50000]\tLoss: 0.9378\tLR: 0.100000\nTraining Epoch: 5 [39552/50000]\tLoss: 0.7499\tLR: 0.100000\nTraining Epoch: 5 [39680/50000]\tLoss: 0.8033\tLR: 0.100000\nTraining Epoch: 5 [39808/50000]\tLoss: 0.7336\tLR: 0.100000\nTraining Epoch: 5 [39936/50000]\tLoss: 0.6288\tLR: 0.100000\nTraining Epoch: 5 [40064/50000]\tLoss: 0.5523\tLR: 0.100000\nTraining Epoch: 5 [40192/50000]\tLoss: 0.6924\tLR: 0.100000\nTraining Epoch: 5 [40320/50000]\tLoss: 0.6764\tLR: 0.100000\nTraining Epoch: 5 [40448/50000]\tLoss: 0.6219\tLR: 0.100000\nTraining Epoch: 5 [40576/50000]\tLoss: 0.6945\tLR: 0.100000\nTraining Epoch: 5 [40704/50000]\tLoss: 0.8033\tLR: 0.100000\nTraining Epoch: 5 [40832/50000]\tLoss: 0.7368\tLR: 0.100000\nTraining Epoch: 5 [40960/50000]\tLoss: 0.8869\tLR: 0.100000\nTraining Epoch: 5 [41088/50000]\tLoss: 0.7667\tLR: 0.100000\nTraining Epoch: 5 [41216/50000]\tLoss: 0.7599\tLR: 0.100000\nTraining Epoch: 5 [41344/50000]\tLoss: 0.6645\tLR: 0.100000\nTraining Epoch: 5 [41472/50000]\tLoss: 0.8503\tLR: 0.100000\nTraining Epoch: 5 [41600/50000]\tLoss: 0.9734\tLR: 0.100000\nTraining Epoch: 5 [41728/50000]\tLoss: 0.6903\tLR: 0.100000\nTraining Epoch: 5 [41856/50000]\tLoss: 0.8934\tLR: 0.100000\nTraining Epoch: 5 [41984/50000]\tLoss: 0.6637\tLR: 0.100000\nTraining Epoch: 5 [42112/50000]\tLoss: 0.7688\tLR: 0.100000\nTraining Epoch: 5 [42240/50000]\tLoss: 0.8301\tLR: 0.100000\nTraining Epoch: 5 [42368/50000]\tLoss: 0.7991\tLR: 0.100000\nTraining Epoch: 5 [42496/50000]\tLoss: 0.8251\tLR: 0.100000\nTraining Epoch: 5 [42624/50000]\tLoss: 0.7561\tLR: 0.100000\nTraining Epoch: 5 [42752/50000]\tLoss: 0.6734\tLR: 0.100000\nTraining Epoch: 5 [42880/50000]\tLoss: 0.7739\tLR: 0.100000\nTraining Epoch: 5 [43008/50000]\tLoss: 0.8234\tLR: 0.100000\nTraining Epoch: 5 [43136/50000]\tLoss: 0.5824\tLR: 0.100000\nTraining Epoch: 5 [43264/50000]\tLoss: 0.6503\tLR: 0.100000\nTraining Epoch: 5 [43392/50000]\tLoss: 0.6268\tLR: 0.100000\nTraining Epoch: 5 [43520/50000]\tLoss: 0.8966\tLR: 0.100000\nTraining Epoch: 5 [43648/50000]\tLoss: 0.6606\tLR: 0.100000\nTraining Epoch: 5 [43776/50000]\tLoss: 0.7163\tLR: 0.100000\nTraining Epoch: 5 [43904/50000]\tLoss: 0.6833\tLR: 0.100000\nTraining Epoch: 5 [44032/50000]\tLoss: 0.6172\tLR: 0.100000\nTraining Epoch: 5 [44160/50000]\tLoss: 0.7711\tLR: 0.100000\nTraining Epoch: 5 [44288/50000]\tLoss: 0.7879\tLR: 0.100000\nTraining Epoch: 5 [44416/50000]\tLoss: 0.6377\tLR: 0.100000\nTraining Epoch: 5 [44544/50000]\tLoss: 0.5698\tLR: 0.100000\nTraining Epoch: 5 [44672/50000]\tLoss: 0.6639\tLR: 0.100000\nTraining Epoch: 5 [44800/50000]\tLoss: 0.7067\tLR: 0.100000\nTraining Epoch: 5 [44928/50000]\tLoss: 0.6940\tLR: 0.100000\nTraining Epoch: 5 [45056/50000]\tLoss: 0.6897\tLR: 0.100000\nTraining Epoch: 5 [45184/50000]\tLoss: 0.6837\tLR: 0.100000\nTraining Epoch: 5 [45312/50000]\tLoss: 0.8980\tLR: 0.100000\nTraining Epoch: 5 [45440/50000]\tLoss: 0.5919\tLR: 0.100000\nTraining Epoch: 5 [45568/50000]\tLoss: 0.6841\tLR: 0.100000\nTraining Epoch: 5 [45696/50000]\tLoss: 0.6342\tLR: 0.100000\nTraining Epoch: 5 [45824/50000]\tLoss: 0.6551\tLR: 0.100000\nTraining Epoch: 5 [45952/50000]\tLoss: 0.6300\tLR: 0.100000\nTraining Epoch: 5 [46080/50000]\tLoss: 0.7567\tLR: 0.100000\nTraining Epoch: 5 [46208/50000]\tLoss: 0.6899\tLR: 0.100000\nTraining Epoch: 5 [46336/50000]\tLoss: 0.6941\tLR: 0.100000\nTraining Epoch: 5 [46464/50000]\tLoss: 0.6334\tLR: 0.100000\nTraining Epoch: 5 [46592/50000]\tLoss: 0.7429\tLR: 0.100000\nTraining Epoch: 5 [46720/50000]\tLoss: 0.7221\tLR: 0.100000\nTraining Epoch: 5 [46848/50000]\tLoss: 0.5922\tLR: 0.100000\nTraining Epoch: 5 [46976/50000]\tLoss: 0.7767\tLR: 0.100000\nTraining Epoch: 5 [47104/50000]\tLoss: 0.6661\tLR: 0.100000\nTraining Epoch: 5 [47232/50000]\tLoss: 0.6943\tLR: 0.100000\nTraining Epoch: 5 [47360/50000]\tLoss: 0.4483\tLR: 0.100000\nTraining Epoch: 5 [47488/50000]\tLoss: 0.7396\tLR: 0.100000\nTraining Epoch: 5 [47616/50000]\tLoss: 0.6047\tLR: 0.100000\nTraining Epoch: 5 [47744/50000]\tLoss: 0.5515\tLR: 0.100000\nTraining Epoch: 5 [47872/50000]\tLoss: 0.8465\tLR: 0.100000\nTraining Epoch: 5 [48000/50000]\tLoss: 0.8238\tLR: 0.100000\nTraining Epoch: 5 [48128/50000]\tLoss: 0.6048\tLR: 0.100000\nTraining Epoch: 5 [48256/50000]\tLoss: 0.7482\tLR: 0.100000\nTraining Epoch: 5 [48384/50000]\tLoss: 0.7974\tLR: 0.100000\nTraining Epoch: 5 [48512/50000]\tLoss: 0.6950\tLR: 0.100000\nTraining Epoch: 5 [48640/50000]\tLoss: 0.6785\tLR: 0.100000\nTraining Epoch: 5 [48768/50000]\tLoss: 0.7330\tLR: 0.100000\nTraining Epoch: 5 [48896/50000]\tLoss: 0.7687\tLR: 0.100000\nTraining Epoch: 5 [49024/50000]\tLoss: 0.6939\tLR: 0.100000\nTraining Epoch: 5 [49152/50000]\tLoss: 0.6841\tLR: 0.100000\nTraining Epoch: 5 [49280/50000]\tLoss: 0.7083\tLR: 0.100000\nTraining Epoch: 5 [49408/50000]\tLoss: 0.7954\tLR: 0.100000\nTraining Epoch: 5 [49536/50000]\tLoss: 0.7079\tLR: 0.100000\nTraining Epoch: 5 [49664/50000]\tLoss: 0.6699\tLR: 0.100000\nTraining Epoch: 5 [49792/50000]\tLoss: 0.7542\tLR: 0.100000\nTraining Epoch: 5 [49920/50000]\tLoss: 0.8697\tLR: 0.100000\nTraining Epoch: 5 [50000/50000]\tLoss: 0.6260\tLR: 0.100000\nTest set: Average loss: 0.0065, Accuracy: 0.7240\n\nTraining Epoch: 6 [128/50000]\tLoss: 0.7525\tLR: 0.015000\nTraining Epoch: 6 [256/50000]\tLoss: 0.5455\tLR: 0.015000\nTraining Epoch: 6 [384/50000]\tLoss: 0.6280\tLR: 0.015000\nTraining Epoch: 6 [512/50000]\tLoss: 0.6639\tLR: 0.015000\nTraining Epoch: 6 [640/50000]\tLoss: 0.7162\tLR: 0.015000\nTraining Epoch: 6 [768/50000]\tLoss: 0.6375\tLR: 0.015000\nTraining Epoch: 6 [896/50000]\tLoss: 0.6703\tLR: 0.015000\nTraining Epoch: 6 [1024/50000]\tLoss: 0.8018\tLR: 0.015000\nTraining Epoch: 6 [1152/50000]\tLoss: 0.5917\tLR: 0.015000\nTraining Epoch: 6 [1280/50000]\tLoss: 0.5197\tLR: 0.015000\nTraining Epoch: 6 [1408/50000]\tLoss: 0.6769\tLR: 0.015000\nTraining Epoch: 6 [1536/50000]\tLoss: 0.6002\tLR: 0.015000\nTraining Epoch: 6 [1664/50000]\tLoss: 0.5803\tLR: 0.015000\nTraining Epoch: 6 [1792/50000]\tLoss: 0.6874\tLR: 0.015000\nTraining Epoch: 6 [1920/50000]\tLoss: 0.5469\tLR: 0.015000\nTraining Epoch: 6 [2048/50000]\tLoss: 0.5777\tLR: 0.015000\nTraining Epoch: 6 [2176/50000]\tLoss: 0.7912\tLR: 0.015000\nTraining Epoch: 6 [2304/50000]\tLoss: 0.6707\tLR: 0.015000\nTraining Epoch: 6 [2432/50000]\tLoss: 0.4880\tLR: 0.015000\nTraining Epoch: 6 [2560/50000]\tLoss: 0.4896\tLR: 0.015000\nTraining Epoch: 6 [2688/50000]\tLoss: 0.5374\tLR: 0.015000\nTraining Epoch: 6 [2816/50000]\tLoss: 0.5475\tLR: 0.015000\nTraining Epoch: 6 [2944/50000]\tLoss: 0.5677\tLR: 0.015000\nTraining Epoch: 6 [3072/50000]\tLoss: 0.6057\tLR: 0.015000\nTraining Epoch: 6 [3200/50000]\tLoss: 0.5519\tLR: 0.015000\nTraining Epoch: 6 [3328/50000]\tLoss: 0.7377\tLR: 0.015000\nTraining Epoch: 6 [3456/50000]\tLoss: 0.5830\tLR: 0.015000\nTraining Epoch: 6 [3584/50000]\tLoss: 0.5036\tLR: 0.015000\nTraining Epoch: 6 [3712/50000]\tLoss: 0.7621\tLR: 0.015000\nTraining Epoch: 6 [3840/50000]\tLoss: 0.6832\tLR: 0.015000\nTraining Epoch: 6 [3968/50000]\tLoss: 0.4931\tLR: 0.015000\nTraining Epoch: 6 [4096/50000]\tLoss: 0.5009\tLR: 0.015000\nTraining Epoch: 6 [4224/50000]\tLoss: 0.6266\tLR: 0.015000\nTraining Epoch: 6 [4352/50000]\tLoss: 0.6424\tLR: 0.015000\nTraining Epoch: 6 [4480/50000]\tLoss: 0.7056\tLR: 0.015000\nTraining Epoch: 6 [4608/50000]\tLoss: 0.4071\tLR: 0.015000\nTraining Epoch: 6 [4736/50000]\tLoss: 0.5673\tLR: 0.015000\nTraining Epoch: 6 [4864/50000]\tLoss: 0.5903\tLR: 0.015000\nTraining Epoch: 6 [4992/50000]\tLoss: 0.5175\tLR: 0.015000\nTraining Epoch: 6 [5120/50000]\tLoss: 0.7020\tLR: 0.015000\nTraining Epoch: 6 [5248/50000]\tLoss: 0.5244\tLR: 0.015000\nTraining Epoch: 6 [5376/50000]\tLoss: 0.4131\tLR: 0.015000\nTraining Epoch: 6 [5504/50000]\tLoss: 0.5177\tLR: 0.015000\nTraining Epoch: 6 [5632/50000]\tLoss: 0.4906\tLR: 0.015000\nTraining Epoch: 6 [5760/50000]\tLoss: 0.5012\tLR: 0.015000\nTraining Epoch: 6 [5888/50000]\tLoss: 0.4765\tLR: 0.015000\nTraining Epoch: 6 [6016/50000]\tLoss: 0.4385\tLR: 0.015000\nTraining Epoch: 6 [6144/50000]\tLoss: 0.5673\tLR: 0.015000\nTraining Epoch: 6 [6272/50000]\tLoss: 0.6180\tLR: 0.015000\nTraining Epoch: 6 [6400/50000]\tLoss: 0.6454\tLR: 0.015000\nTraining Epoch: 6 [6528/50000]\tLoss: 0.6050\tLR: 0.015000\nTraining Epoch: 6 [6656/50000]\tLoss: 0.4401\tLR: 0.015000\nTraining Epoch: 6 [6784/50000]\tLoss: 0.6818\tLR: 0.015000\nTraining Epoch: 6 [6912/50000]\tLoss: 0.4135\tLR: 0.015000\nTraining Epoch: 6 [7040/50000]\tLoss: 0.4356\tLR: 0.015000\nTraining Epoch: 6 [7168/50000]\tLoss: 0.5315\tLR: 0.015000\nTraining Epoch: 6 [7296/50000]\tLoss: 0.5205\tLR: 0.015000\nTraining Epoch: 6 [7424/50000]\tLoss: 0.4394\tLR: 0.015000\nTraining Epoch: 6 [7552/50000]\tLoss: 0.6005\tLR: 0.015000\nTraining Epoch: 6 [7680/50000]\tLoss: 0.5337\tLR: 0.015000\nTraining Epoch: 6 [7808/50000]\tLoss: 0.5762\tLR: 0.015000\nTraining Epoch: 6 [7936/50000]\tLoss: 0.7057\tLR: 0.015000\nTraining Epoch: 6 [8064/50000]\tLoss: 0.6045\tLR: 0.015000\nTraining Epoch: 6 [8192/50000]\tLoss: 0.5475\tLR: 0.015000\nTraining Epoch: 6 [8320/50000]\tLoss: 0.5019\tLR: 0.015000\nTraining Epoch: 6 [8448/50000]\tLoss: 0.5765\tLR: 0.015000\nTraining Epoch: 6 [8576/50000]\tLoss: 0.5081\tLR: 0.015000\nTraining Epoch: 6 [8704/50000]\tLoss: 0.6563\tLR: 0.015000\nTraining Epoch: 6 [8832/50000]\tLoss: 0.5512\tLR: 0.015000\nTraining Epoch: 6 [8960/50000]\tLoss: 0.5619\tLR: 0.015000\nTraining Epoch: 6 [9088/50000]\tLoss: 0.5291\tLR: 0.015000\nTraining Epoch: 6 [9216/50000]\tLoss: 0.6154\tLR: 0.015000\nTraining Epoch: 6 [9344/50000]\tLoss: 0.5672\tLR: 0.015000\nTraining Epoch: 6 [9472/50000]\tLoss: 0.4931\tLR: 0.015000\nTraining Epoch: 6 [9600/50000]\tLoss: 0.5082\tLR: 0.015000\nTraining Epoch: 6 [9728/50000]\tLoss: 0.4968\tLR: 0.015000\nTraining Epoch: 6 [9856/50000]\tLoss: 0.5168\tLR: 0.015000\nTraining Epoch: 6 [9984/50000]\tLoss: 0.5686\tLR: 0.015000\nTraining Epoch: 6 [10112/50000]\tLoss: 0.5474\tLR: 0.015000\nTraining Epoch: 6 [10240/50000]\tLoss: 0.7166\tLR: 0.015000\nTraining Epoch: 6 [10368/50000]\tLoss: 0.4791\tLR: 0.015000\nTraining Epoch: 6 [10496/50000]\tLoss: 0.3713\tLR: 0.015000\nTraining Epoch: 6 [10624/50000]\tLoss: 0.5316\tLR: 0.015000\nTraining Epoch: 6 [10752/50000]\tLoss: 0.7031\tLR: 0.015000\nTraining Epoch: 6 [10880/50000]\tLoss: 0.6824\tLR: 0.015000\nTraining Epoch: 6 [11008/50000]\tLoss: 0.4890\tLR: 0.015000\nTraining Epoch: 6 [11136/50000]\tLoss: 0.5501\tLR: 0.015000\nTraining Epoch: 6 [11264/50000]\tLoss: 0.4861\tLR: 0.015000\nTraining Epoch: 6 [11392/50000]\tLoss: 0.4996\tLR: 0.015000\nTraining Epoch: 6 [11520/50000]\tLoss: 0.4474\tLR: 0.015000\nTraining Epoch: 6 [11648/50000]\tLoss: 0.6357\tLR: 0.015000\nTraining Epoch: 6 [11776/50000]\tLoss: 0.5912\tLR: 0.015000\nTraining Epoch: 6 [11904/50000]\tLoss: 0.5827\tLR: 0.015000\nTraining Epoch: 6 [12032/50000]\tLoss: 0.5565\tLR: 0.015000\nTraining Epoch: 6 [12160/50000]\tLoss: 0.6044\tLR: 0.015000\nTraining Epoch: 6 [12288/50000]\tLoss: 0.6733\tLR: 0.015000\nTraining Epoch: 6 [12416/50000]\tLoss: 0.5229\tLR: 0.015000\nTraining Epoch: 6 [12544/50000]\tLoss: 0.5426\tLR: 0.015000\nTraining Epoch: 6 [12672/50000]\tLoss: 0.5697\tLR: 0.015000\nTraining Epoch: 6 [12800/50000]\tLoss: 0.4135\tLR: 0.015000\nTraining Epoch: 6 [12928/50000]\tLoss: 0.5982\tLR: 0.015000\nTraining Epoch: 6 [13056/50000]\tLoss: 0.5523\tLR: 0.015000\nTraining Epoch: 6 [13184/50000]\tLoss: 0.6117\tLR: 0.015000\nTraining Epoch: 6 [13312/50000]\tLoss: 0.5004\tLR: 0.015000\nTraining Epoch: 6 [13440/50000]\tLoss: 0.4841\tLR: 0.015000\nTraining Epoch: 6 [13568/50000]\tLoss: 0.5000\tLR: 0.015000\nTraining Epoch: 6 [13696/50000]\tLoss: 0.6306\tLR: 0.015000\nTraining Epoch: 6 [13824/50000]\tLoss: 0.5876\tLR: 0.015000\nTraining Epoch: 6 [13952/50000]\tLoss: 0.5703\tLR: 0.015000\nTraining Epoch: 6 [14080/50000]\tLoss: 0.5541\tLR: 0.015000\nTraining Epoch: 6 [14208/50000]\tLoss: 0.5615\tLR: 0.015000\nTraining Epoch: 6 [14336/50000]\tLoss: 0.4679\tLR: 0.015000\nTraining Epoch: 6 [14464/50000]\tLoss: 0.5546\tLR: 0.015000\nTraining Epoch: 6 [14592/50000]\tLoss: 0.5610\tLR: 0.015000\nTraining Epoch: 6 [14720/50000]\tLoss: 0.6972\tLR: 0.015000\nTraining Epoch: 6 [14848/50000]\tLoss: 0.4879\tLR: 0.015000\nTraining Epoch: 6 [14976/50000]\tLoss: 0.6646\tLR: 0.015000\nTraining Epoch: 6 [15104/50000]\tLoss: 0.5611\tLR: 0.015000\nTraining Epoch: 6 [15232/50000]\tLoss: 0.4789\tLR: 0.015000\nTraining Epoch: 6 [15360/50000]\tLoss: 0.4295\tLR: 0.015000\nTraining Epoch: 6 [15488/50000]\tLoss: 0.5552\tLR: 0.015000\nTraining Epoch: 6 [15616/50000]\tLoss: 0.5861\tLR: 0.015000\nTraining Epoch: 6 [15744/50000]\tLoss: 0.5194\tLR: 0.015000\nTraining Epoch: 6 [15872/50000]\tLoss: 0.5315\tLR: 0.015000\nTraining Epoch: 6 [16000/50000]\tLoss: 0.4818\tLR: 0.015000\nTraining Epoch: 6 [16128/50000]\tLoss: 0.5065\tLR: 0.015000\nTraining Epoch: 6 [16256/50000]\tLoss: 0.6958\tLR: 0.015000\nTraining Epoch: 6 [16384/50000]\tLoss: 0.6046\tLR: 0.015000\nTraining Epoch: 6 [16512/50000]\tLoss: 0.5190\tLR: 0.015000\nTraining Epoch: 6 [16640/50000]\tLoss: 0.7748\tLR: 0.015000\nTraining Epoch: 6 [16768/50000]\tLoss: 0.5548\tLR: 0.015000\nTraining Epoch: 6 [16896/50000]\tLoss: 0.5253\tLR: 0.015000\nTraining Epoch: 6 [17024/50000]\tLoss: 0.6668\tLR: 0.015000\nTraining Epoch: 6 [17152/50000]\tLoss: 0.4530\tLR: 0.015000\nTraining Epoch: 6 [17280/50000]\tLoss: 0.5564\tLR: 0.015000\nTraining Epoch: 6 [17408/50000]\tLoss: 0.6047\tLR: 0.015000\nTraining Epoch: 6 [17536/50000]\tLoss: 0.4883\tLR: 0.015000\nTraining Epoch: 6 [17664/50000]\tLoss: 0.4954\tLR: 0.015000\nTraining Epoch: 6 [17792/50000]\tLoss: 0.4865\tLR: 0.015000\nTraining Epoch: 6 [17920/50000]\tLoss: 0.4727\tLR: 0.015000\nTraining Epoch: 6 [18048/50000]\tLoss: 0.5914\tLR: 0.015000\nTraining Epoch: 6 [18176/50000]\tLoss: 0.4866\tLR: 0.015000\nTraining Epoch: 6 [18304/50000]\tLoss: 0.5835\tLR: 0.015000\nTraining Epoch: 6 [18432/50000]\tLoss: 0.6211\tLR: 0.015000\nTraining Epoch: 6 [18560/50000]\tLoss: 0.4953\tLR: 0.015000\nTraining Epoch: 6 [18688/50000]\tLoss: 0.4572\tLR: 0.015000\nTraining Epoch: 6 [18816/50000]\tLoss: 0.5186\tLR: 0.015000\nTraining Epoch: 6 [18944/50000]\tLoss: 0.5281\tLR: 0.015000\nTraining Epoch: 6 [19072/50000]\tLoss: 0.5102\tLR: 0.015000\nTraining Epoch: 6 [19200/50000]\tLoss: 0.5649\tLR: 0.015000\nTraining Epoch: 6 [19328/50000]\tLoss: 0.4180\tLR: 0.015000\nTraining Epoch: 6 [19456/50000]\tLoss: 0.5066\tLR: 0.015000\nTraining Epoch: 6 [19584/50000]\tLoss: 0.5998\tLR: 0.015000\nTraining Epoch: 6 [19712/50000]\tLoss: 0.5078\tLR: 0.015000\nTraining Epoch: 6 [19840/50000]\tLoss: 0.5608\tLR: 0.015000\nTraining Epoch: 6 [19968/50000]\tLoss: 0.4288\tLR: 0.015000\nTraining Epoch: 6 [20096/50000]\tLoss: 0.3408\tLR: 0.015000\nTraining Epoch: 6 [20224/50000]\tLoss: 0.4214\tLR: 0.015000\nTraining Epoch: 6 [20352/50000]\tLoss: 0.5032\tLR: 0.015000\nTraining Epoch: 6 [20480/50000]\tLoss: 0.6440\tLR: 0.015000\nTraining Epoch: 6 [20608/50000]\tLoss: 0.4136\tLR: 0.015000\nTraining Epoch: 6 [20736/50000]\tLoss: 0.5564\tLR: 0.015000\nTraining Epoch: 6 [20864/50000]\tLoss: 0.6329\tLR: 0.015000\nTraining Epoch: 6 [20992/50000]\tLoss: 0.6274\tLR: 0.015000\nTraining Epoch: 6 [21120/50000]\tLoss: 0.5822\tLR: 0.015000\nTraining Epoch: 6 [21248/50000]\tLoss: 0.4460\tLR: 0.015000\nTraining Epoch: 6 [21376/50000]\tLoss: 0.4304\tLR: 0.015000\nTraining Epoch: 6 [21504/50000]\tLoss: 0.5427\tLR: 0.015000\nTraining Epoch: 6 [21632/50000]\tLoss: 0.4767\tLR: 0.015000\nTraining Epoch: 6 [21760/50000]\tLoss: 0.6033\tLR: 0.015000\nTraining Epoch: 6 [21888/50000]\tLoss: 0.4853\tLR: 0.015000\nTraining Epoch: 6 [22016/50000]\tLoss: 0.3793\tLR: 0.015000\nTraining Epoch: 6 [22144/50000]\tLoss: 0.5065\tLR: 0.015000\nTraining Epoch: 6 [22272/50000]\tLoss: 0.4041\tLR: 0.015000\nTraining Epoch: 6 [22400/50000]\tLoss: 0.6837\tLR: 0.015000\nTraining Epoch: 6 [22528/50000]\tLoss: 0.5218\tLR: 0.015000\nTraining Epoch: 6 [22656/50000]\tLoss: 0.4167\tLR: 0.015000\nTraining Epoch: 6 [22784/50000]\tLoss: 0.5121\tLR: 0.015000\nTraining Epoch: 6 [22912/50000]\tLoss: 0.5638\tLR: 0.015000\nTraining Epoch: 6 [23040/50000]\tLoss: 0.5155\tLR: 0.015000\nTraining Epoch: 6 [23168/50000]\tLoss: 0.4019\tLR: 0.015000\nTraining Epoch: 6 [23296/50000]\tLoss: 0.4625\tLR: 0.015000\nTraining Epoch: 6 [23424/50000]\tLoss: 0.4435\tLR: 0.015000\nTraining Epoch: 6 [23552/50000]\tLoss: 0.6596\tLR: 0.015000\nTraining Epoch: 6 [23680/50000]\tLoss: 0.4536\tLR: 0.015000\nTraining Epoch: 6 [23808/50000]\tLoss: 0.4391\tLR: 0.015000\nTraining Epoch: 6 [23936/50000]\tLoss: 0.4488\tLR: 0.015000\nTraining Epoch: 6 [24064/50000]\tLoss: 0.5610\tLR: 0.015000\nTraining Epoch: 6 [24192/50000]\tLoss: 0.3655\tLR: 0.015000\nTraining Epoch: 6 [24320/50000]\tLoss: 0.4461\tLR: 0.015000\nTraining Epoch: 6 [24448/50000]\tLoss: 0.4445\tLR: 0.015000\nTraining Epoch: 6 [24576/50000]\tLoss: 0.4805\tLR: 0.015000\nTraining Epoch: 6 [24704/50000]\tLoss: 0.4474\tLR: 0.015000\nTraining Epoch: 6 [24832/50000]\tLoss: 0.5173\tLR: 0.015000\nTraining Epoch: 6 [24960/50000]\tLoss: 0.3899\tLR: 0.015000\nTraining Epoch: 6 [25088/50000]\tLoss: 0.4496\tLR: 0.015000\nTraining Epoch: 6 [25216/50000]\tLoss: 0.5492\tLR: 0.015000\nTraining Epoch: 6 [25344/50000]\tLoss: 0.6138\tLR: 0.015000\nTraining Epoch: 6 [25472/50000]\tLoss: 0.5003\tLR: 0.015000\nTraining Epoch: 6 [25600/50000]\tLoss: 0.5286\tLR: 0.015000\nTraining Epoch: 6 [25728/50000]\tLoss: 0.4142\tLR: 0.015000\nTraining Epoch: 6 [25856/50000]\tLoss: 0.4176\tLR: 0.015000\nTraining Epoch: 6 [25984/50000]\tLoss: 0.6116\tLR: 0.015000\nTraining Epoch: 6 [26112/50000]\tLoss: 0.4554\tLR: 0.015000\nTraining Epoch: 6 [26240/50000]\tLoss: 0.4349\tLR: 0.015000\nTraining Epoch: 6 [26368/50000]\tLoss: 0.5765\tLR: 0.015000\nTraining Epoch: 6 [26496/50000]\tLoss: 0.4014\tLR: 0.015000\nTraining Epoch: 6 [26624/50000]\tLoss: 0.6404\tLR: 0.015000\nTraining Epoch: 6 [26752/50000]\tLoss: 0.4564\tLR: 0.015000\nTraining Epoch: 6 [26880/50000]\tLoss: 0.5215\tLR: 0.015000\nTraining Epoch: 6 [27008/50000]\tLoss: 0.5159\tLR: 0.015000\nTraining Epoch: 6 [27136/50000]\tLoss: 0.5674\tLR: 0.015000\nTraining Epoch: 6 [27264/50000]\tLoss: 0.6434\tLR: 0.015000\nTraining Epoch: 6 [27392/50000]\tLoss: 0.5363\tLR: 0.015000\nTraining Epoch: 6 [27520/50000]\tLoss: 0.6979\tLR: 0.015000\nTraining Epoch: 6 [27648/50000]\tLoss: 0.5825\tLR: 0.015000\nTraining Epoch: 6 [27776/50000]\tLoss: 0.4554\tLR: 0.015000\nTraining Epoch: 6 [27904/50000]\tLoss: 0.4192\tLR: 0.015000\nTraining Epoch: 6 [28032/50000]\tLoss: 0.7206\tLR: 0.015000\nTraining Epoch: 6 [28160/50000]\tLoss: 0.4538\tLR: 0.015000\nTraining Epoch: 6 [28288/50000]\tLoss: 0.5339\tLR: 0.015000\nTraining Epoch: 6 [28416/50000]\tLoss: 0.4920\tLR: 0.015000\nTraining Epoch: 6 [28544/50000]\tLoss: 0.5611\tLR: 0.015000\nTraining Epoch: 6 [28672/50000]\tLoss: 0.5907\tLR: 0.015000\nTraining Epoch: 6 [28800/50000]\tLoss: 0.6291\tLR: 0.015000\nTraining Epoch: 6 [28928/50000]\tLoss: 0.6486\tLR: 0.015000\nTraining Epoch: 6 [29056/50000]\tLoss: 0.6009\tLR: 0.015000\nTraining Epoch: 6 [29184/50000]\tLoss: 0.4082\tLR: 0.015000\nTraining Epoch: 6 [29312/50000]\tLoss: 0.6353\tLR: 0.015000\nTraining Epoch: 6 [29440/50000]\tLoss: 0.4989\tLR: 0.015000\nTraining Epoch: 6 [29568/50000]\tLoss: 0.5506\tLR: 0.015000\nTraining Epoch: 6 [29696/50000]\tLoss: 0.5415\tLR: 0.015000\nTraining Epoch: 6 [29824/50000]\tLoss: 0.5569\tLR: 0.015000\nTraining Epoch: 6 [29952/50000]\tLoss: 0.4745\tLR: 0.015000\nTraining Epoch: 6 [30080/50000]\tLoss: 0.4868\tLR: 0.015000\nTraining Epoch: 6 [30208/50000]\tLoss: 0.3512\tLR: 0.015000\nTraining Epoch: 6 [30336/50000]\tLoss: 0.3706\tLR: 0.015000\nTraining Epoch: 6 [30464/50000]\tLoss: 0.4160\tLR: 0.015000\nTraining Epoch: 6 [30592/50000]\tLoss: 0.5154\tLR: 0.015000\nTraining Epoch: 6 [30720/50000]\tLoss: 0.5538\tLR: 0.015000\nTraining Epoch: 6 [30848/50000]\tLoss: 0.5185\tLR: 0.015000\nTraining Epoch: 6 [30976/50000]\tLoss: 0.4333\tLR: 0.015000\nTraining Epoch: 6 [31104/50000]\tLoss: 0.4548\tLR: 0.015000\nTraining Epoch: 6 [31232/50000]\tLoss: 0.6491\tLR: 0.015000\nTraining Epoch: 6 [31360/50000]\tLoss: 0.5919\tLR: 0.015000\nTraining Epoch: 6 [31488/50000]\tLoss: 0.4309\tLR: 0.015000\nTraining Epoch: 6 [31616/50000]\tLoss: 0.5328\tLR: 0.015000\nTraining Epoch: 6 [31744/50000]\tLoss: 0.5156\tLR: 0.015000\nTraining Epoch: 6 [31872/50000]\tLoss: 0.6085\tLR: 0.015000\nTraining Epoch: 6 [32000/50000]\tLoss: 0.4655\tLR: 0.015000\nTraining Epoch: 6 [32128/50000]\tLoss: 0.6455\tLR: 0.015000\nTraining Epoch: 6 [32256/50000]\tLoss: 0.4188\tLR: 0.015000\nTraining Epoch: 6 [32384/50000]\tLoss: 0.4719\tLR: 0.015000\nTraining Epoch: 6 [32512/50000]\tLoss: 0.5669\tLR: 0.015000\nTraining Epoch: 6 [32640/50000]\tLoss: 0.5313\tLR: 0.015000\nTraining Epoch: 6 [32768/50000]\tLoss: 0.6424\tLR: 0.015000\nTraining Epoch: 6 [32896/50000]\tLoss: 0.4256\tLR: 0.015000\nTraining Epoch: 6 [33024/50000]\tLoss: 0.4424\tLR: 0.015000\nTraining Epoch: 6 [33152/50000]\tLoss: 0.5172\tLR: 0.015000\nTraining Epoch: 6 [33280/50000]\tLoss: 0.5617\tLR: 0.015000\nTraining Epoch: 6 [33408/50000]\tLoss: 0.6308\tLR: 0.015000\nTraining Epoch: 6 [33536/50000]\tLoss: 0.4148\tLR: 0.015000\nTraining Epoch: 6 [33664/50000]\tLoss: 0.4715\tLR: 0.015000\nTraining Epoch: 6 [33792/50000]\tLoss: 0.6307\tLR: 0.015000\nTraining Epoch: 6 [33920/50000]\tLoss: 0.5169\tLR: 0.015000\nTraining Epoch: 6 [34048/50000]\tLoss: 0.7523\tLR: 0.015000\nTraining Epoch: 6 [34176/50000]\tLoss: 0.4867\tLR: 0.015000\nTraining Epoch: 6 [34304/50000]\tLoss: 0.5266\tLR: 0.015000\nTraining Epoch: 6 [34432/50000]\tLoss: 0.5971\tLR: 0.015000\nTraining Epoch: 6 [34560/50000]\tLoss: 0.4807\tLR: 0.015000\nTraining Epoch: 6 [34688/50000]\tLoss: 0.4217\tLR: 0.015000\nTraining Epoch: 6 [34816/50000]\tLoss: 0.5793\tLR: 0.015000\nTraining Epoch: 6 [34944/50000]\tLoss: 0.4234\tLR: 0.015000\nTraining Epoch: 6 [35072/50000]\tLoss: 0.4674\tLR: 0.015000\nTraining Epoch: 6 [35200/50000]\tLoss: 0.5024\tLR: 0.015000\nTraining Epoch: 6 [35328/50000]\tLoss: 0.4488\tLR: 0.015000\nTraining Epoch: 6 [35456/50000]\tLoss: 0.5836\tLR: 0.015000\nTraining Epoch: 6 [35584/50000]\tLoss: 0.5063\tLR: 0.015000\nTraining Epoch: 6 [35712/50000]\tLoss: 0.4966\tLR: 0.015000\nTraining Epoch: 6 [35840/50000]\tLoss: 0.4337\tLR: 0.015000\nTraining Epoch: 6 [35968/50000]\tLoss: 0.5025\tLR: 0.015000\nTraining Epoch: 6 [36096/50000]\tLoss: 0.4530\tLR: 0.015000\nTraining Epoch: 6 [36224/50000]\tLoss: 0.3912\tLR: 0.015000\nTraining Epoch: 6 [36352/50000]\tLoss: 0.5890\tLR: 0.015000\nTraining Epoch: 6 [36480/50000]\tLoss: 0.4652\tLR: 0.015000\nTraining Epoch: 6 [36608/50000]\tLoss: 0.6015\tLR: 0.015000\nTraining Epoch: 6 [36736/50000]\tLoss: 0.3710\tLR: 0.015000\nTraining Epoch: 6 [36864/50000]\tLoss: 0.5757\tLR: 0.015000\nTraining Epoch: 6 [36992/50000]\tLoss: 0.4137\tLR: 0.015000\nTraining Epoch: 6 [37120/50000]\tLoss: 0.4219\tLR: 0.015000\nTraining Epoch: 6 [37248/50000]\tLoss: 0.4060\tLR: 0.015000\nTraining Epoch: 6 [37376/50000]\tLoss: 0.5805\tLR: 0.015000\nTraining Epoch: 6 [37504/50000]\tLoss: 0.5850\tLR: 0.015000\nTraining Epoch: 6 [37632/50000]\tLoss: 0.4887\tLR: 0.015000\nTraining Epoch: 6 [37760/50000]\tLoss: 0.5148\tLR: 0.015000\nTraining Epoch: 6 [37888/50000]\tLoss: 0.5793\tLR: 0.015000\nTraining Epoch: 6 [38016/50000]\tLoss: 0.4452\tLR: 0.015000\nTraining Epoch: 6 [38144/50000]\tLoss: 0.4937\tLR: 0.015000\nTraining Epoch: 6 [38272/50000]\tLoss: 0.4580\tLR: 0.015000\nTraining Epoch: 6 [38400/50000]\tLoss: 0.4706\tLR: 0.015000\nTraining Epoch: 6 [38528/50000]\tLoss: 0.6451\tLR: 0.015000\nTraining Epoch: 6 [38656/50000]\tLoss: 0.5817\tLR: 0.015000\nTraining Epoch: 6 [38784/50000]\tLoss: 0.4577\tLR: 0.015000\nTraining Epoch: 6 [38912/50000]\tLoss: 0.4181\tLR: 0.015000\nTraining Epoch: 6 [39040/50000]\tLoss: 0.5406\tLR: 0.015000\nTraining Epoch: 6 [39168/50000]\tLoss: 0.6020\tLR: 0.015000\nTraining Epoch: 6 [39296/50000]\tLoss: 0.4527\tLR: 0.015000\nTraining Epoch: 6 [39424/50000]\tLoss: 0.5609\tLR: 0.015000\nTraining Epoch: 6 [39552/50000]\tLoss: 0.4252\tLR: 0.015000\nTraining Epoch: 6 [39680/50000]\tLoss: 0.6021\tLR: 0.015000\nTraining Epoch: 6 [39808/50000]\tLoss: 0.4264\tLR: 0.015000\nTraining Epoch: 6 [39936/50000]\tLoss: 0.6069\tLR: 0.015000\nTraining Epoch: 6 [40064/50000]\tLoss: 0.4274\tLR: 0.015000\nTraining Epoch: 6 [40192/50000]\tLoss: 0.5447\tLR: 0.015000\nTraining Epoch: 6 [40320/50000]\tLoss: 0.5930\tLR: 0.015000\nTraining Epoch: 6 [40448/50000]\tLoss: 0.4286\tLR: 0.015000\nTraining Epoch: 6 [40576/50000]\tLoss: 0.5784\tLR: 0.015000\nTraining Epoch: 6 [40704/50000]\tLoss: 0.5599\tLR: 0.015000\nTraining Epoch: 6 [40832/50000]\tLoss: 0.5178\tLR: 0.015000\nTraining Epoch: 6 [40960/50000]\tLoss: 0.7714\tLR: 0.015000\nTraining Epoch: 6 [41088/50000]\tLoss: 0.4662\tLR: 0.015000\nTraining Epoch: 6 [41216/50000]\tLoss: 0.4168\tLR: 0.015000\nTraining Epoch: 6 [41344/50000]\tLoss: 0.4003\tLR: 0.015000\nTraining Epoch: 6 [41472/50000]\tLoss: 0.5705\tLR: 0.015000\nTraining Epoch: 6 [41600/50000]\tLoss: 0.5326\tLR: 0.015000\nTraining Epoch: 6 [41728/50000]\tLoss: 0.5204\tLR: 0.015000\nTraining Epoch: 6 [41856/50000]\tLoss: 0.5685\tLR: 0.015000\nTraining Epoch: 6 [41984/50000]\tLoss: 0.4198\tLR: 0.015000\nTraining Epoch: 6 [42112/50000]\tLoss: 0.5245\tLR: 0.015000\nTraining Epoch: 6 [42240/50000]\tLoss: 0.4409\tLR: 0.015000\nTraining Epoch: 6 [42368/50000]\tLoss: 0.5299\tLR: 0.015000\nTraining Epoch: 6 [42496/50000]\tLoss: 0.5488\tLR: 0.015000\nTraining Epoch: 6 [42624/50000]\tLoss: 0.5274\tLR: 0.015000\nTraining Epoch: 6 [42752/50000]\tLoss: 0.5164\tLR: 0.015000\nTraining Epoch: 6 [42880/50000]\tLoss: 0.4468\tLR: 0.015000\nTraining Epoch: 6 [43008/50000]\tLoss: 0.4450\tLR: 0.015000\nTraining Epoch: 6 [43136/50000]\tLoss: 0.5624\tLR: 0.015000\nTraining Epoch: 6 [43264/50000]\tLoss: 0.5351\tLR: 0.015000\nTraining Epoch: 6 [43392/50000]\tLoss: 0.5688\tLR: 0.015000\nTraining Epoch: 6 [43520/50000]\tLoss: 0.4865\tLR: 0.015000\nTraining Epoch: 6 [43648/50000]\tLoss: 0.3707\tLR: 0.015000\nTraining Epoch: 6 [43776/50000]\tLoss: 0.5109\tLR: 0.015000\nTraining Epoch: 6 [43904/50000]\tLoss: 0.4058\tLR: 0.015000\nTraining Epoch: 6 [44032/50000]\tLoss: 0.4006\tLR: 0.015000\nTraining Epoch: 6 [44160/50000]\tLoss: 0.4713\tLR: 0.015000\nTraining Epoch: 6 [44288/50000]\tLoss: 0.4709\tLR: 0.015000\nTraining Epoch: 6 [44416/50000]\tLoss: 0.5243\tLR: 0.015000\nTraining Epoch: 6 [44544/50000]\tLoss: 0.5214\tLR: 0.015000\nTraining Epoch: 6 [44672/50000]\tLoss: 0.5389\tLR: 0.015000\nTraining Epoch: 6 [44800/50000]\tLoss: 0.6100\tLR: 0.015000\nTraining Epoch: 6 [44928/50000]\tLoss: 0.4893\tLR: 0.015000\nTraining Epoch: 6 [45056/50000]\tLoss: 0.5871\tLR: 0.015000\nTraining Epoch: 6 [45184/50000]\tLoss: 0.5215\tLR: 0.015000\nTraining Epoch: 6 [45312/50000]\tLoss: 0.4540\tLR: 0.015000\nTraining Epoch: 6 [45440/50000]\tLoss: 0.4539\tLR: 0.015000\nTraining Epoch: 6 [45568/50000]\tLoss: 0.5281\tLR: 0.015000\nTraining Epoch: 6 [45696/50000]\tLoss: 0.5321\tLR: 0.015000\nTraining Epoch: 6 [45824/50000]\tLoss: 0.5958\tLR: 0.015000\nTraining Epoch: 6 [45952/50000]\tLoss: 0.5512\tLR: 0.015000\nTraining Epoch: 6 [46080/50000]\tLoss: 0.5337\tLR: 0.015000\nTraining Epoch: 6 [46208/50000]\tLoss: 0.5132\tLR: 0.015000\nTraining Epoch: 6 [46336/50000]\tLoss: 0.6792\tLR: 0.015000\nTraining Epoch: 6 [46464/50000]\tLoss: 0.6312\tLR: 0.015000\nTraining Epoch: 6 [46592/50000]\tLoss: 0.5024\tLR: 0.015000\nTraining Epoch: 6 [46720/50000]\tLoss: 0.4679\tLR: 0.015000\nTraining Epoch: 6 [46848/50000]\tLoss: 0.4139\tLR: 0.015000\nTraining Epoch: 6 [46976/50000]\tLoss: 0.5496\tLR: 0.015000\nTraining Epoch: 6 [47104/50000]\tLoss: 0.4921\tLR: 0.015000\nTraining Epoch: 6 [47232/50000]\tLoss: 0.4767\tLR: 0.015000\nTraining Epoch: 6 [47360/50000]\tLoss: 0.5797\tLR: 0.015000\nTraining Epoch: 6 [47488/50000]\tLoss: 0.4600\tLR: 0.015000\nTraining Epoch: 6 [47616/50000]\tLoss: 0.4971\tLR: 0.015000\nTraining Epoch: 6 [47744/50000]\tLoss: 0.5991\tLR: 0.015000\nTraining Epoch: 6 [47872/50000]\tLoss: 0.4518\tLR: 0.015000\nTraining Epoch: 6 [48000/50000]\tLoss: 0.5579\tLR: 0.015000\nTraining Epoch: 6 [48128/50000]\tLoss: 0.4267\tLR: 0.015000\nTraining Epoch: 6 [48256/50000]\tLoss: 0.4812\tLR: 0.015000\nTraining Epoch: 6 [48384/50000]\tLoss: 0.4550\tLR: 0.015000\nTraining Epoch: 6 [48512/50000]\tLoss: 0.4970\tLR: 0.015000\nTraining Epoch: 6 [48640/50000]\tLoss: 0.4669\tLR: 0.015000\nTraining Epoch: 6 [48768/50000]\tLoss: 0.4944\tLR: 0.015000\nTraining Epoch: 6 [48896/50000]\tLoss: 0.5119\tLR: 0.015000\nTraining Epoch: 6 [49024/50000]\tLoss: 0.3694\tLR: 0.015000\nTraining Epoch: 6 [49152/50000]\tLoss: 0.5279\tLR: 0.015000\nTraining Epoch: 6 [49280/50000]\tLoss: 0.3796\tLR: 0.015000\nTraining Epoch: 6 [49408/50000]\tLoss: 0.4537\tLR: 0.015000\nTraining Epoch: 6 [49536/50000]\tLoss: 0.5136\tLR: 0.015000\nTraining Epoch: 6 [49664/50000]\tLoss: 0.5172\tLR: 0.015000\nTraining Epoch: 6 [49792/50000]\tLoss: 0.4433\tLR: 0.015000\nTraining Epoch: 6 [49920/50000]\tLoss: 0.6230\tLR: 0.015000\nTraining Epoch: 6 [50000/50000]\tLoss: 0.4724\tLR: 0.015000\nTest set: Average loss: 0.0036, Accuracy: 0.8428\n\nTraining Epoch: 7 [128/50000]\tLoss: 0.5837\tLR: 0.015000\nTraining Epoch: 7 [256/50000]\tLoss: 0.4284\tLR: 0.015000\nTraining Epoch: 7 [384/50000]\tLoss: 0.5301\tLR: 0.015000\nTraining Epoch: 7 [512/50000]\tLoss: 0.4652\tLR: 0.015000\nTraining Epoch: 7 [640/50000]\tLoss: 0.5718\tLR: 0.015000\nTraining Epoch: 7 [768/50000]\tLoss: 0.6020\tLR: 0.015000\nTraining Epoch: 7 [896/50000]\tLoss: 0.4730\tLR: 0.015000\nTraining Epoch: 7 [1024/50000]\tLoss: 0.5043\tLR: 0.015000\nTraining Epoch: 7 [1152/50000]\tLoss: 0.4898\tLR: 0.015000\nTraining Epoch: 7 [1280/50000]\tLoss: 0.6087\tLR: 0.015000\nTraining Epoch: 7 [1408/50000]\tLoss: 0.4821\tLR: 0.015000\nTraining Epoch: 7 [1536/50000]\tLoss: 0.5422\tLR: 0.015000\nTraining Epoch: 7 [1664/50000]\tLoss: 0.5592\tLR: 0.015000\nTraining Epoch: 7 [1792/50000]\tLoss: 0.6263\tLR: 0.015000\nTraining Epoch: 7 [1920/50000]\tLoss: 0.4682\tLR: 0.015000\nTraining Epoch: 7 [2048/50000]\tLoss: 0.4351\tLR: 0.015000\nTraining Epoch: 7 [2176/50000]\tLoss: 0.4305\tLR: 0.015000\nTraining Epoch: 7 [2304/50000]\tLoss: 0.5186\tLR: 0.015000\nTraining Epoch: 7 [2432/50000]\tLoss: 0.5177\tLR: 0.015000\nTraining Epoch: 7 [2560/50000]\tLoss: 0.4735\tLR: 0.015000\nTraining Epoch: 7 [2688/50000]\tLoss: 0.3736\tLR: 0.015000\nTraining Epoch: 7 [2816/50000]\tLoss: 0.4453\tLR: 0.015000\nTraining Epoch: 7 [2944/50000]\tLoss: 0.4808\tLR: 0.015000\nTraining Epoch: 7 [3072/50000]\tLoss: 0.4146\tLR: 0.015000\nTraining Epoch: 7 [3200/50000]\tLoss: 0.4891\tLR: 0.015000\nTraining Epoch: 7 [3328/50000]\tLoss: 0.5616\tLR: 0.015000\nTraining Epoch: 7 [3456/50000]\tLoss: 0.4497\tLR: 0.015000\nTraining Epoch: 7 [3584/50000]\tLoss: 0.4563\tLR: 0.015000\nTraining Epoch: 7 [3712/50000]\tLoss: 0.4801\tLR: 0.015000\nTraining Epoch: 7 [3840/50000]\tLoss: 0.4488\tLR: 0.015000\nTraining Epoch: 7 [3968/50000]\tLoss: 0.5219\tLR: 0.015000\nTraining Epoch: 7 [4096/50000]\tLoss: 0.5216\tLR: 0.015000\nTraining Epoch: 7 [4224/50000]\tLoss: 0.5533\tLR: 0.015000\nTraining Epoch: 7 [4352/50000]\tLoss: 0.3932\tLR: 0.015000\nTraining Epoch: 7 [4480/50000]\tLoss: 0.3557\tLR: 0.015000\nTraining Epoch: 7 [4608/50000]\tLoss: 0.4184\tLR: 0.015000\nTraining Epoch: 7 [4736/50000]\tLoss: 0.4757\tLR: 0.015000\nTraining Epoch: 7 [4864/50000]\tLoss: 0.4014\tLR: 0.015000\nTraining Epoch: 7 [4992/50000]\tLoss: 0.6059\tLR: 0.015000\nTraining Epoch: 7 [5120/50000]\tLoss: 0.5310\tLR: 0.015000\nTraining Epoch: 7 [5248/50000]\tLoss: 0.4943\tLR: 0.015000\nTraining Epoch: 7 [5376/50000]\tLoss: 0.4763\tLR: 0.015000\nTraining Epoch: 7 [5504/50000]\tLoss: 0.5779\tLR: 0.015000\nTraining Epoch: 7 [5632/50000]\tLoss: 0.3416\tLR: 0.015000\nTraining Epoch: 7 [5760/50000]\tLoss: 0.3349\tLR: 0.015000\nTraining Epoch: 7 [5888/50000]\tLoss: 0.5877\tLR: 0.015000\nTraining Epoch: 7 [6016/50000]\tLoss: 0.5419\tLR: 0.015000\nTraining Epoch: 7 [6144/50000]\tLoss: 0.4234\tLR: 0.015000\nTraining Epoch: 7 [6272/50000]\tLoss: 0.5686\tLR: 0.015000\nTraining Epoch: 7 [6400/50000]\tLoss: 0.4935\tLR: 0.015000\nTraining Epoch: 7 [6528/50000]\tLoss: 0.5463\tLR: 0.015000\nTraining Epoch: 7 [6656/50000]\tLoss: 0.5349\tLR: 0.015000\nTraining Epoch: 7 [6784/50000]\tLoss: 0.4182\tLR: 0.015000\nTraining Epoch: 7 [6912/50000]\tLoss: 0.5003\tLR: 0.015000\nTraining Epoch: 7 [7040/50000]\tLoss: 0.3424\tLR: 0.015000\nTraining Epoch: 7 [7168/50000]\tLoss: 0.4736\tLR: 0.015000\nTraining Epoch: 7 [7296/50000]\tLoss: 0.3561\tLR: 0.015000\nTraining Epoch: 7 [7424/50000]\tLoss: 0.4430\tLR: 0.015000\nTraining Epoch: 7 [7552/50000]\tLoss: 0.4203\tLR: 0.015000\nTraining Epoch: 7 [7680/50000]\tLoss: 0.5302\tLR: 0.015000\nTraining Epoch: 7 [7808/50000]\tLoss: 0.5143\tLR: 0.015000\nTraining Epoch: 7 [7936/50000]\tLoss: 0.5071\tLR: 0.015000\nTraining Epoch: 7 [8064/50000]\tLoss: 0.4086\tLR: 0.015000\nTraining Epoch: 7 [8192/50000]\tLoss: 0.3712\tLR: 0.015000\nTraining Epoch: 7 [8320/50000]\tLoss: 0.3606\tLR: 0.015000\nTraining Epoch: 7 [8448/50000]\tLoss: 0.3171\tLR: 0.015000\nTraining Epoch: 7 [8576/50000]\tLoss: 0.5508\tLR: 0.015000\nTraining Epoch: 7 [8704/50000]\tLoss: 0.4306\tLR: 0.015000\nTraining Epoch: 7 [8832/50000]\tLoss: 0.4177\tLR: 0.015000\nTraining Epoch: 7 [8960/50000]\tLoss: 0.5046\tLR: 0.015000\nTraining Epoch: 7 [9088/50000]\tLoss: 0.4834\tLR: 0.015000\nTraining Epoch: 7 [9216/50000]\tLoss: 0.5374\tLR: 0.015000\nTraining Epoch: 7 [9344/50000]\tLoss: 0.5670\tLR: 0.015000\nTraining Epoch: 7 [9472/50000]\tLoss: 0.4624\tLR: 0.015000\nTraining Epoch: 7 [9600/50000]\tLoss: 0.4638\tLR: 0.015000\nTraining Epoch: 7 [9728/50000]\tLoss: 0.4356\tLR: 0.015000\nTraining Epoch: 7 [9856/50000]\tLoss: 0.4961\tLR: 0.015000\nTraining Epoch: 7 [9984/50000]\tLoss: 0.4718\tLR: 0.015000\nTraining Epoch: 7 [10112/50000]\tLoss: 0.5441\tLR: 0.015000\nTraining Epoch: 7 [10240/50000]\tLoss: 0.4368\tLR: 0.015000\nTraining Epoch: 7 [10368/50000]\tLoss: 0.6247\tLR: 0.015000\nTraining Epoch: 7 [10496/50000]\tLoss: 0.6364\tLR: 0.015000\nTraining Epoch: 7 [10624/50000]\tLoss: 0.7837\tLR: 0.015000\nTraining Epoch: 7 [10752/50000]\tLoss: 0.4879\tLR: 0.015000\nTraining Epoch: 7 [10880/50000]\tLoss: 0.3875\tLR: 0.015000\nTraining Epoch: 7 [11008/50000]\tLoss: 0.3694\tLR: 0.015000\nTraining Epoch: 7 [11136/50000]\tLoss: 0.3772\tLR: 0.015000\nTraining Epoch: 7 [11264/50000]\tLoss: 0.3677\tLR: 0.015000\nTraining Epoch: 7 [11392/50000]\tLoss: 0.4049\tLR: 0.015000\nTraining Epoch: 7 [11520/50000]\tLoss: 0.4338\tLR: 0.015000\nTraining Epoch: 7 [11648/50000]\tLoss: 0.4968\tLR: 0.015000\nTraining Epoch: 7 [11776/50000]\tLoss: 0.3818\tLR: 0.015000\nTraining Epoch: 7 [11904/50000]\tLoss: 0.6067\tLR: 0.015000\nTraining Epoch: 7 [12032/50000]\tLoss: 0.4049\tLR: 0.015000\nTraining Epoch: 7 [12160/50000]\tLoss: 0.5867\tLR: 0.015000\nTraining Epoch: 7 [12288/50000]\tLoss: 0.5454\tLR: 0.015000\nTraining Epoch: 7 [12416/50000]\tLoss: 0.5528\tLR: 0.015000\nTraining Epoch: 7 [12544/50000]\tLoss: 0.3810\tLR: 0.015000\nTraining Epoch: 7 [12672/50000]\tLoss: 0.5298\tLR: 0.015000\nTraining Epoch: 7 [12800/50000]\tLoss: 0.6115\tLR: 0.015000\nTraining Epoch: 7 [12928/50000]\tLoss: 0.4318\tLR: 0.015000\nTraining Epoch: 7 [13056/50000]\tLoss: 0.5569\tLR: 0.015000\nTraining Epoch: 7 [13184/50000]\tLoss: 0.4470\tLR: 0.015000\nTraining Epoch: 7 [13312/50000]\tLoss: 0.5124\tLR: 0.015000\nTraining Epoch: 7 [13440/50000]\tLoss: 0.3544\tLR: 0.015000\nTraining Epoch: 7 [13568/50000]\tLoss: 0.4782\tLR: 0.015000\nTraining Epoch: 7 [13696/50000]\tLoss: 0.4227\tLR: 0.015000\nTraining Epoch: 7 [13824/50000]\tLoss: 0.7190\tLR: 0.015000\nTraining Epoch: 7 [13952/50000]\tLoss: 0.5879\tLR: 0.015000\nTraining Epoch: 7 [14080/50000]\tLoss: 0.4654\tLR: 0.015000\nTraining Epoch: 7 [14208/50000]\tLoss: 0.4491\tLR: 0.015000\nTraining Epoch: 7 [14336/50000]\tLoss: 0.5738\tLR: 0.015000\nTraining Epoch: 7 [14464/50000]\tLoss: 0.4922\tLR: 0.015000\nTraining Epoch: 7 [14592/50000]\tLoss: 0.4754\tLR: 0.015000\nTraining Epoch: 7 [14720/50000]\tLoss: 0.4274\tLR: 0.015000\nTraining Epoch: 7 [14848/50000]\tLoss: 0.3976\tLR: 0.015000\nTraining Epoch: 7 [14976/50000]\tLoss: 0.3830\tLR: 0.015000\nTraining Epoch: 7 [15104/50000]\tLoss: 0.6200\tLR: 0.015000\nTraining Epoch: 7 [15232/50000]\tLoss: 0.4310\tLR: 0.015000\nTraining Epoch: 7 [15360/50000]\tLoss: 0.5724\tLR: 0.015000\nTraining Epoch: 7 [15488/50000]\tLoss: 0.4927\tLR: 0.015000\nTraining Epoch: 7 [15616/50000]\tLoss: 0.2992\tLR: 0.015000\nTraining Epoch: 7 [15744/50000]\tLoss: 0.5022\tLR: 0.015000\nTraining Epoch: 7 [15872/50000]\tLoss: 0.3702\tLR: 0.015000\nTraining Epoch: 7 [16000/50000]\tLoss: 0.4483\tLR: 0.015000\nTraining Epoch: 7 [16128/50000]\tLoss: 0.4507\tLR: 0.015000\nTraining Epoch: 7 [16256/50000]\tLoss: 0.5787\tLR: 0.015000\nTraining Epoch: 7 [16384/50000]\tLoss: 0.6771\tLR: 0.015000\nTraining Epoch: 7 [16512/50000]\tLoss: 0.4024\tLR: 0.015000\nTraining Epoch: 7 [16640/50000]\tLoss: 0.5641\tLR: 0.015000\nTraining Epoch: 7 [16768/50000]\tLoss: 0.3793\tLR: 0.015000\nTraining Epoch: 7 [16896/50000]\tLoss: 0.5806\tLR: 0.015000\nTraining Epoch: 7 [17024/50000]\tLoss: 0.4900\tLR: 0.015000\nTraining Epoch: 7 [17152/50000]\tLoss: 0.4308\tLR: 0.015000\nTraining Epoch: 7 [17280/50000]\tLoss: 0.5006\tLR: 0.015000\nTraining Epoch: 7 [17408/50000]\tLoss: 0.6246\tLR: 0.015000\nTraining Epoch: 7 [17536/50000]\tLoss: 0.3382\tLR: 0.015000\nTraining Epoch: 7 [17664/50000]\tLoss: 0.5173\tLR: 0.015000\nTraining Epoch: 7 [17792/50000]\tLoss: 0.6298\tLR: 0.015000\nTraining Epoch: 7 [17920/50000]\tLoss: 0.3891\tLR: 0.015000\nTraining Epoch: 7 [18048/50000]\tLoss: 0.4657\tLR: 0.015000\nTraining Epoch: 7 [18176/50000]\tLoss: 0.5456\tLR: 0.015000\nTraining Epoch: 7 [18304/50000]\tLoss: 0.6936\tLR: 0.015000\nTraining Epoch: 7 [18432/50000]\tLoss: 0.3935\tLR: 0.015000\nTraining Epoch: 7 [18560/50000]\tLoss: 0.4285\tLR: 0.015000\nTraining Epoch: 7 [18688/50000]\tLoss: 0.5592\tLR: 0.015000\nTraining Epoch: 7 [18816/50000]\tLoss: 0.5350\tLR: 0.015000\nTraining Epoch: 7 [18944/50000]\tLoss: 0.3995\tLR: 0.015000\nTraining Epoch: 7 [19072/50000]\tLoss: 0.5517\tLR: 0.015000\nTraining Epoch: 7 [19200/50000]\tLoss: 0.4553\tLR: 0.015000\nTraining Epoch: 7 [19328/50000]\tLoss: 0.3501\tLR: 0.015000\nTraining Epoch: 7 [19456/50000]\tLoss: 0.4136\tLR: 0.015000\nTraining Epoch: 7 [19584/50000]\tLoss: 0.4952\tLR: 0.015000\nTraining Epoch: 7 [19712/50000]\tLoss: 0.4442\tLR: 0.015000\nTraining Epoch: 7 [19840/50000]\tLoss: 0.4709\tLR: 0.015000\nTraining Epoch: 7 [19968/50000]\tLoss: 0.6520\tLR: 0.015000\nTraining Epoch: 7 [20096/50000]\tLoss: 0.3899\tLR: 0.015000\nTraining Epoch: 7 [20224/50000]\tLoss: 0.5704\tLR: 0.015000\nTraining Epoch: 7 [20352/50000]\tLoss: 0.5587\tLR: 0.015000\nTraining Epoch: 7 [20480/50000]\tLoss: 0.5137\tLR: 0.015000\nTraining Epoch: 7 [20608/50000]\tLoss: 0.4215\tLR: 0.015000\nTraining Epoch: 7 [20736/50000]\tLoss: 0.4142\tLR: 0.015000\nTraining Epoch: 7 [20864/50000]\tLoss: 0.4709\tLR: 0.015000\nTraining Epoch: 7 [20992/50000]\tLoss: 0.5357\tLR: 0.015000\nTraining Epoch: 7 [21120/50000]\tLoss: 0.5614\tLR: 0.015000\nTraining Epoch: 7 [21248/50000]\tLoss: 0.5547\tLR: 0.015000\nTraining Epoch: 7 [21376/50000]\tLoss: 0.5702\tLR: 0.015000\nTraining Epoch: 7 [21504/50000]\tLoss: 0.3918\tLR: 0.015000\nTraining Epoch: 7 [21632/50000]\tLoss: 0.4302\tLR: 0.015000\nTraining Epoch: 7 [21760/50000]\tLoss: 0.4937\tLR: 0.015000\nTraining Epoch: 7 [21888/50000]\tLoss: 0.5832\tLR: 0.015000\nTraining Epoch: 7 [22016/50000]\tLoss: 0.3737\tLR: 0.015000\nTraining Epoch: 7 [22144/50000]\tLoss: 0.6302\tLR: 0.015000\nTraining Epoch: 7 [22272/50000]\tLoss: 0.4755\tLR: 0.015000\nTraining Epoch: 7 [22400/50000]\tLoss: 0.5151\tLR: 0.015000\nTraining Epoch: 7 [22528/50000]\tLoss: 0.4750\tLR: 0.015000\nTraining Epoch: 7 [22656/50000]\tLoss: 0.4798\tLR: 0.015000\nTraining Epoch: 7 [22784/50000]\tLoss: 0.4600\tLR: 0.015000\nTraining Epoch: 7 [22912/50000]\tLoss: 0.3716\tLR: 0.015000\nTraining Epoch: 7 [23040/50000]\tLoss: 0.5013\tLR: 0.015000\nTraining Epoch: 7 [23168/50000]\tLoss: 0.5144\tLR: 0.015000\nTraining Epoch: 7 [23296/50000]\tLoss: 0.4055\tLR: 0.015000\nTraining Epoch: 7 [23424/50000]\tLoss: 0.4191\tLR: 0.015000\nTraining Epoch: 7 [23552/50000]\tLoss: 0.5823\tLR: 0.015000\nTraining Epoch: 7 [23680/50000]\tLoss: 0.3808\tLR: 0.015000\nTraining Epoch: 7 [23808/50000]\tLoss: 0.5109\tLR: 0.015000\nTraining Epoch: 7 [23936/50000]\tLoss: 0.4241\tLR: 0.015000\nTraining Epoch: 7 [24064/50000]\tLoss: 0.4462\tLR: 0.015000\nTraining Epoch: 7 [24192/50000]\tLoss: 0.3399\tLR: 0.015000\nTraining Epoch: 7 [24320/50000]\tLoss: 0.4866\tLR: 0.015000\nTraining Epoch: 7 [24448/50000]\tLoss: 0.4985\tLR: 0.015000\nTraining Epoch: 7 [24576/50000]\tLoss: 0.5545\tLR: 0.015000\nTraining Epoch: 7 [24704/50000]\tLoss: 0.4015\tLR: 0.015000\nTraining Epoch: 7 [24832/50000]\tLoss: 0.3288\tLR: 0.015000\nTraining Epoch: 7 [24960/50000]\tLoss: 0.3386\tLR: 0.015000\nTraining Epoch: 7 [25088/50000]\tLoss: 0.3948\tLR: 0.015000\nTraining Epoch: 7 [25216/50000]\tLoss: 0.4562\tLR: 0.015000\nTraining Epoch: 7 [25344/50000]\tLoss: 0.3623\tLR: 0.015000\nTraining Epoch: 7 [25472/50000]\tLoss: 0.4359\tLR: 0.015000\nTraining Epoch: 7 [25600/50000]\tLoss: 0.4417\tLR: 0.015000\nTraining Epoch: 7 [25728/50000]\tLoss: 0.4582\tLR: 0.015000\nTraining Epoch: 7 [25856/50000]\tLoss: 0.4405\tLR: 0.015000\nTraining Epoch: 7 [25984/50000]\tLoss: 0.6073\tLR: 0.015000\nTraining Epoch: 7 [26112/50000]\tLoss: 0.5225\tLR: 0.015000\nTraining Epoch: 7 [26240/50000]\tLoss: 0.4804\tLR: 0.015000\nTraining Epoch: 7 [26368/50000]\tLoss: 0.5405\tLR: 0.015000\nTraining Epoch: 7 [26496/50000]\tLoss: 0.3732\tLR: 0.015000\nTraining Epoch: 7 [26624/50000]\tLoss: 0.4814\tLR: 0.015000\nTraining Epoch: 7 [26752/50000]\tLoss: 0.4025\tLR: 0.015000\nTraining Epoch: 7 [26880/50000]\tLoss: 0.4061\tLR: 0.015000\nTraining Epoch: 7 [27008/50000]\tLoss: 0.4381\tLR: 0.015000\nTraining Epoch: 7 [27136/50000]\tLoss: 0.4235\tLR: 0.015000\nTraining Epoch: 7 [27264/50000]\tLoss: 0.6158\tLR: 0.015000\nTraining Epoch: 7 [27392/50000]\tLoss: 0.5611\tLR: 0.015000\nTraining Epoch: 7 [27520/50000]\tLoss: 0.3184\tLR: 0.015000\nTraining Epoch: 7 [27648/50000]\tLoss: 0.4771\tLR: 0.015000\nTraining Epoch: 7 [27776/50000]\tLoss: 0.6256\tLR: 0.015000\nTraining Epoch: 7 [27904/50000]\tLoss: 0.4822\tLR: 0.015000\nTraining Epoch: 7 [28032/50000]\tLoss: 0.4786\tLR: 0.015000\nTraining Epoch: 7 [28160/50000]\tLoss: 0.4378\tLR: 0.015000\nTraining Epoch: 7 [28288/50000]\tLoss: 0.4185\tLR: 0.015000\nTraining Epoch: 7 [28416/50000]\tLoss: 0.6871\tLR: 0.015000\nTraining Epoch: 7 [28544/50000]\tLoss: 0.4615\tLR: 0.015000\nTraining Epoch: 7 [28672/50000]\tLoss: 0.4641\tLR: 0.015000\nTraining Epoch: 7 [28800/50000]\tLoss: 0.5585\tLR: 0.015000\nTraining Epoch: 7 [28928/50000]\tLoss: 0.4351\tLR: 0.015000\nTraining Epoch: 7 [29056/50000]\tLoss: 0.4436\tLR: 0.015000\nTraining Epoch: 7 [29184/50000]\tLoss: 0.5100\tLR: 0.015000\nTraining Epoch: 7 [29312/50000]\tLoss: 0.4046\tLR: 0.015000\nTraining Epoch: 7 [29440/50000]\tLoss: 0.5524\tLR: 0.015000\nTraining Epoch: 7 [29568/50000]\tLoss: 0.4222\tLR: 0.015000\nTraining Epoch: 7 [29696/50000]\tLoss: 0.4714\tLR: 0.015000\nTraining Epoch: 7 [29824/50000]\tLoss: 0.3949\tLR: 0.015000\nTraining Epoch: 7 [29952/50000]\tLoss: 0.5017\tLR: 0.015000\nTraining Epoch: 7 [30080/50000]\tLoss: 0.6243\tLR: 0.015000\nTraining Epoch: 7 [30208/50000]\tLoss: 0.4001\tLR: 0.015000\nTraining Epoch: 7 [30336/50000]\tLoss: 0.5936\tLR: 0.015000\nTraining Epoch: 7 [30464/50000]\tLoss: 0.6716\tLR: 0.015000\nTraining Epoch: 7 [30592/50000]\tLoss: 0.4757\tLR: 0.015000\nTraining Epoch: 7 [30720/50000]\tLoss: 0.3397\tLR: 0.015000\nTraining Epoch: 7 [30848/50000]\tLoss: 0.5996\tLR: 0.015000\nTraining Epoch: 7 [30976/50000]\tLoss: 0.5359\tLR: 0.015000\nTraining Epoch: 7 [31104/50000]\tLoss: 0.4201\tLR: 0.015000\nTraining Epoch: 7 [31232/50000]\tLoss: 0.5957\tLR: 0.015000\nTraining Epoch: 7 [31360/50000]\tLoss: 0.5072\tLR: 0.015000\nTraining Epoch: 7 [31488/50000]\tLoss: 0.5767\tLR: 0.015000\nTraining Epoch: 7 [31616/50000]\tLoss: 0.5060\tLR: 0.015000\nTraining Epoch: 7 [31744/50000]\tLoss: 0.5041\tLR: 0.015000\nTraining Epoch: 7 [31872/50000]\tLoss: 0.4377\tLR: 0.015000\nTraining Epoch: 7 [32000/50000]\tLoss: 0.3889\tLR: 0.015000\nTraining Epoch: 7 [32128/50000]\tLoss: 0.5789\tLR: 0.015000\nTraining Epoch: 7 [32256/50000]\tLoss: 0.3949\tLR: 0.015000\nTraining Epoch: 7 [32384/50000]\tLoss: 0.5214\tLR: 0.015000\nTraining Epoch: 7 [32512/50000]\tLoss: 0.4896\tLR: 0.015000\nTraining Epoch: 7 [32640/50000]\tLoss: 0.5161\tLR: 0.015000\nTraining Epoch: 7 [32768/50000]\tLoss: 0.5347\tLR: 0.015000\nTraining Epoch: 7 [32896/50000]\tLoss: 0.5135\tLR: 0.015000\nTraining Epoch: 7 [33024/50000]\tLoss: 0.3825\tLR: 0.015000\nTraining Epoch: 7 [33152/50000]\tLoss: 0.4058\tLR: 0.015000\nTraining Epoch: 7 [33280/50000]\tLoss: 0.4340\tLR: 0.015000\nTraining Epoch: 7 [33408/50000]\tLoss: 0.3984\tLR: 0.015000\nTraining Epoch: 7 [33536/50000]\tLoss: 0.5463\tLR: 0.015000\nTraining Epoch: 7 [33664/50000]\tLoss: 0.3895\tLR: 0.015000\nTraining Epoch: 7 [33792/50000]\tLoss: 0.3771\tLR: 0.015000\nTraining Epoch: 7 [33920/50000]\tLoss: 0.4567\tLR: 0.015000\nTraining Epoch: 7 [34048/50000]\tLoss: 0.2367\tLR: 0.015000\nTraining Epoch: 7 [34176/50000]\tLoss: 0.5151\tLR: 0.015000\nTraining Epoch: 7 [34304/50000]\tLoss: 0.5140\tLR: 0.015000\nTraining Epoch: 7 [34432/50000]\tLoss: 0.5727\tLR: 0.015000\nTraining Epoch: 7 [34560/50000]\tLoss: 0.5039\tLR: 0.015000\nTraining Epoch: 7 [34688/50000]\tLoss: 0.5040\tLR: 0.015000\nTraining Epoch: 7 [34816/50000]\tLoss: 0.5626\tLR: 0.015000\nTraining Epoch: 7 [34944/50000]\tLoss: 0.4988\tLR: 0.015000\nTraining Epoch: 7 [35072/50000]\tLoss: 0.4957\tLR: 0.015000\nTraining Epoch: 7 [35200/50000]\tLoss: 0.3854\tLR: 0.015000\nTraining Epoch: 7 [35328/50000]\tLoss: 0.4508\tLR: 0.015000\nTraining Epoch: 7 [35456/50000]\tLoss: 0.5879\tLR: 0.015000\nTraining Epoch: 7 [35584/50000]\tLoss: 0.5447\tLR: 0.015000\nTraining Epoch: 7 [35712/50000]\tLoss: 0.4585\tLR: 0.015000\nTraining Epoch: 7 [35840/50000]\tLoss: 0.4548\tLR: 0.015000\nTraining Epoch: 7 [35968/50000]\tLoss: 0.3867\tLR: 0.015000\nTraining Epoch: 7 [36096/50000]\tLoss: 0.4284\tLR: 0.015000\nTraining Epoch: 7 [36224/50000]\tLoss: 0.4574\tLR: 0.015000\nTraining Epoch: 7 [36352/50000]\tLoss: 0.4977\tLR: 0.015000\nTraining Epoch: 7 [36480/50000]\tLoss: 0.3485\tLR: 0.015000\nTraining Epoch: 7 [36608/50000]\tLoss: 0.4821\tLR: 0.015000\nTraining Epoch: 7 [36736/50000]\tLoss: 0.5510\tLR: 0.015000\nTraining Epoch: 7 [36864/50000]\tLoss: 0.4992\tLR: 0.015000\nTraining Epoch: 7 [36992/50000]\tLoss: 0.3861\tLR: 0.015000\nTraining Epoch: 7 [37120/50000]\tLoss: 0.3553\tLR: 0.015000\nTraining Epoch: 7 [37248/50000]\tLoss: 0.4165\tLR: 0.015000\nTraining Epoch: 7 [37376/50000]\tLoss: 0.4302\tLR: 0.015000\nTraining Epoch: 7 [37504/50000]\tLoss: 0.3262\tLR: 0.015000\nTraining Epoch: 7 [37632/50000]\tLoss: 0.4591\tLR: 0.015000\nTraining Epoch: 7 [37760/50000]\tLoss: 0.5875\tLR: 0.015000\nTraining Epoch: 7 [37888/50000]\tLoss: 0.5187\tLR: 0.015000\nTraining Epoch: 7 [38016/50000]\tLoss: 0.4440\tLR: 0.015000\nTraining Epoch: 7 [38144/50000]\tLoss: 0.4716\tLR: 0.015000\nTraining Epoch: 7 [38272/50000]\tLoss: 0.5010\tLR: 0.015000\nTraining Epoch: 7 [38400/50000]\tLoss: 0.4621\tLR: 0.015000\nTraining Epoch: 7 [38528/50000]\tLoss: 0.5126\tLR: 0.015000\nTraining Epoch: 7 [38656/50000]\tLoss: 0.3319\tLR: 0.015000\nTraining Epoch: 7 [38784/50000]\tLoss: 0.4526\tLR: 0.015000\nTraining Epoch: 7 [38912/50000]\tLoss: 0.5154\tLR: 0.015000\nTraining Epoch: 7 [39040/50000]\tLoss: 0.5474\tLR: 0.015000\nTraining Epoch: 7 [39168/50000]\tLoss: 0.3231\tLR: 0.015000\nTraining Epoch: 7 [39296/50000]\tLoss: 0.4003\tLR: 0.015000\nTraining Epoch: 7 [39424/50000]\tLoss: 0.4785\tLR: 0.015000\nTraining Epoch: 7 [39552/50000]\tLoss: 0.3689\tLR: 0.015000\nTraining Epoch: 7 [39680/50000]\tLoss: 0.5870\tLR: 0.015000\nTraining Epoch: 7 [39808/50000]\tLoss: 0.5825\tLR: 0.015000\nTraining Epoch: 7 [39936/50000]\tLoss: 0.6035\tLR: 0.015000\nTraining Epoch: 7 [40064/50000]\tLoss: 0.6323\tLR: 0.015000\nTraining Epoch: 7 [40192/50000]\tLoss: 0.5148\tLR: 0.015000\nTraining Epoch: 7 [40320/50000]\tLoss: 0.3974\tLR: 0.015000\nTraining Epoch: 7 [40448/50000]\tLoss: 0.4201\tLR: 0.015000\nTraining Epoch: 7 [40576/50000]\tLoss: 0.4244\tLR: 0.015000\nTraining Epoch: 7 [40704/50000]\tLoss: 0.4592\tLR: 0.015000\nTraining Epoch: 7 [40832/50000]\tLoss: 0.4004\tLR: 0.015000\nTraining Epoch: 7 [40960/50000]\tLoss: 0.4294\tLR: 0.015000\nTraining Epoch: 7 [41088/50000]\tLoss: 0.4974\tLR: 0.015000\nTraining Epoch: 7 [41216/50000]\tLoss: 0.4424\tLR: 0.015000\nTraining Epoch: 7 [41344/50000]\tLoss: 0.4087\tLR: 0.015000\nTraining Epoch: 7 [41472/50000]\tLoss: 0.5158\tLR: 0.015000\nTraining Epoch: 7 [41600/50000]\tLoss: 0.2818\tLR: 0.015000\nTraining Epoch: 7 [41728/50000]\tLoss: 0.3409\tLR: 0.015000\nTraining Epoch: 7 [41856/50000]\tLoss: 0.5398\tLR: 0.015000\nTraining Epoch: 7 [41984/50000]\tLoss: 0.4261\tLR: 0.015000\nTraining Epoch: 7 [42112/50000]\tLoss: 0.5667\tLR: 0.015000\nTraining Epoch: 7 [42240/50000]\tLoss: 0.6253\tLR: 0.015000\nTraining Epoch: 7 [42368/50000]\tLoss: 0.6597\tLR: 0.015000\nTraining Epoch: 7 [42496/50000]\tLoss: 0.5000\tLR: 0.015000\nTraining Epoch: 7 [42624/50000]\tLoss: 0.4650\tLR: 0.015000\nTraining Epoch: 7 [42752/50000]\tLoss: 0.5344\tLR: 0.015000\nTraining Epoch: 7 [42880/50000]\tLoss: 0.4290\tLR: 0.015000\nTraining Epoch: 7 [43008/50000]\tLoss: 0.4675\tLR: 0.015000\nTraining Epoch: 7 [43136/50000]\tLoss: 0.4545\tLR: 0.015000\nTraining Epoch: 7 [43264/50000]\tLoss: 0.3864\tLR: 0.015000\nTraining Epoch: 7 [43392/50000]\tLoss: 0.4432\tLR: 0.015000\nTraining Epoch: 7 [43520/50000]\tLoss: 0.5077\tLR: 0.015000\nTraining Epoch: 7 [43648/50000]\tLoss: 0.4593\tLR: 0.015000\nTraining Epoch: 7 [43776/50000]\tLoss: 0.4098\tLR: 0.015000\nTraining Epoch: 7 [43904/50000]\tLoss: 0.3156\tLR: 0.015000\nTraining Epoch: 7 [44032/50000]\tLoss: 0.3427\tLR: 0.015000\nTraining Epoch: 7 [44160/50000]\tLoss: 0.4748\tLR: 0.015000\nTraining Epoch: 7 [44288/50000]\tLoss: 0.4444\tLR: 0.015000\nTraining Epoch: 7 [44416/50000]\tLoss: 0.4435\tLR: 0.015000\nTraining Epoch: 7 [44544/50000]\tLoss: 0.4783\tLR: 0.015000\nTraining Epoch: 7 [44672/50000]\tLoss: 0.5940\tLR: 0.015000\nTraining Epoch: 7 [44800/50000]\tLoss: 0.5264\tLR: 0.015000\nTraining Epoch: 7 [44928/50000]\tLoss: 0.5839\tLR: 0.015000\nTraining Epoch: 7 [45056/50000]\tLoss: 0.4342\tLR: 0.015000\nTraining Epoch: 7 [45184/50000]\tLoss: 0.5105\tLR: 0.015000\nTraining Epoch: 7 [45312/50000]\tLoss: 0.3885\tLR: 0.015000\nTraining Epoch: 7 [45440/50000]\tLoss: 0.3990\tLR: 0.015000\nTraining Epoch: 7 [45568/50000]\tLoss: 0.4853\tLR: 0.015000\nTraining Epoch: 7 [45696/50000]\tLoss: 0.5276\tLR: 0.015000\nTraining Epoch: 7 [45824/50000]\tLoss: 0.4960\tLR: 0.015000\nTraining Epoch: 7 [45952/50000]\tLoss: 0.4374\tLR: 0.015000\nTraining Epoch: 7 [46080/50000]\tLoss: 0.4152\tLR: 0.015000\nTraining Epoch: 7 [46208/50000]\tLoss: 0.5354\tLR: 0.015000\nTraining Epoch: 7 [46336/50000]\tLoss: 0.5389\tLR: 0.015000\nTraining Epoch: 7 [46464/50000]\tLoss: 0.5218\tLR: 0.015000\nTraining Epoch: 7 [46592/50000]\tLoss: 0.4863\tLR: 0.015000\nTraining Epoch: 7 [46720/50000]\tLoss: 0.4912\tLR: 0.015000\nTraining Epoch: 7 [46848/50000]\tLoss: 0.4248\tLR: 0.015000\nTraining Epoch: 7 [46976/50000]\tLoss: 0.5155\tLR: 0.015000\nTraining Epoch: 7 [47104/50000]\tLoss: 0.5247\tLR: 0.015000\nTraining Epoch: 7 [47232/50000]\tLoss: 0.4747\tLR: 0.015000\nTraining Epoch: 7 [47360/50000]\tLoss: 0.5452\tLR: 0.015000\nTraining Epoch: 7 [47488/50000]\tLoss: 0.6155\tLR: 0.015000\nTraining Epoch: 7 [47616/50000]\tLoss: 0.3657\tLR: 0.015000\nTraining Epoch: 7 [47744/50000]\tLoss: 0.3514\tLR: 0.015000\nTraining Epoch: 7 [47872/50000]\tLoss: 0.6591\tLR: 0.015000\nTraining Epoch: 7 [48000/50000]\tLoss: 0.5184\tLR: 0.015000\nTraining Epoch: 7 [48128/50000]\tLoss: 0.4542\tLR: 0.015000\nTraining Epoch: 7 [48256/50000]\tLoss: 0.3883\tLR: 0.015000\nTraining Epoch: 7 [48384/50000]\tLoss: 0.2903\tLR: 0.015000\nTraining Epoch: 7 [48512/50000]\tLoss: 0.4044\tLR: 0.015000\nTraining Epoch: 7 [48640/50000]\tLoss: 0.5800\tLR: 0.015000\nTraining Epoch: 7 [48768/50000]\tLoss: 0.4949\tLR: 0.015000\nTraining Epoch: 7 [48896/50000]\tLoss: 0.4674\tLR: 0.015000\nTraining Epoch: 7 [49024/50000]\tLoss: 0.3863\tLR: 0.015000\nTraining Epoch: 7 [49152/50000]\tLoss: 0.5533\tLR: 0.015000\nTraining Epoch: 7 [49280/50000]\tLoss: 0.5281\tLR: 0.015000\nTraining Epoch: 7 [49408/50000]\tLoss: 0.4623\tLR: 0.015000\nTraining Epoch: 7 [49536/50000]\tLoss: 0.4880\tLR: 0.015000\nTraining Epoch: 7 [49664/50000]\tLoss: 0.5130\tLR: 0.015000\nTraining Epoch: 7 [49792/50000]\tLoss: 0.3658\tLR: 0.015000\nTraining Epoch: 7 [49920/50000]\tLoss: 0.3576\tLR: 0.015000\nTraining Epoch: 7 [50000/50000]\tLoss: 0.4298\tLR: 0.015000\nTest set: Average loss: 0.0037, Accuracy: 0.8438\n\nTraining Epoch: 8 [128/50000]\tLoss: 0.4507\tLR: 0.015000\nTraining Epoch: 8 [256/50000]\tLoss: 0.3758\tLR: 0.015000\nTraining Epoch: 8 [384/50000]\tLoss: 0.4845\tLR: 0.015000\nTraining Epoch: 8 [512/50000]\tLoss: 0.3772\tLR: 0.015000\nTraining Epoch: 8 [640/50000]\tLoss: 0.3996\tLR: 0.015000\nTraining Epoch: 8 [768/50000]\tLoss: 0.4553\tLR: 0.015000\nTraining Epoch: 8 [896/50000]\tLoss: 0.3465\tLR: 0.015000\nTraining Epoch: 8 [1024/50000]\tLoss: 0.3583\tLR: 0.015000\nTraining Epoch: 8 [1152/50000]\tLoss: 0.5524\tLR: 0.015000\nTraining Epoch: 8 [1280/50000]\tLoss: 0.5196\tLR: 0.015000\nTraining Epoch: 8 [1408/50000]\tLoss: 0.4672\tLR: 0.015000\nTraining Epoch: 8 [1536/50000]\tLoss: 0.6140\tLR: 0.015000\nTraining Epoch: 8 [1664/50000]\tLoss: 0.4511\tLR: 0.015000\nTraining Epoch: 8 [1792/50000]\tLoss: 0.3146\tLR: 0.015000\nTraining Epoch: 8 [1920/50000]\tLoss: 0.4164\tLR: 0.015000\nTraining Epoch: 8 [2048/50000]\tLoss: 0.4532\tLR: 0.015000\nTraining Epoch: 8 [2176/50000]\tLoss: 0.2295\tLR: 0.015000\nTraining Epoch: 8 [2304/50000]\tLoss: 0.5030\tLR: 0.015000\nTraining Epoch: 8 [2432/50000]\tLoss: 0.4320\tLR: 0.015000\nTraining Epoch: 8 [2560/50000]\tLoss: 0.5440\tLR: 0.015000\nTraining Epoch: 8 [2688/50000]\tLoss: 0.4071\tLR: 0.015000\nTraining Epoch: 8 [2816/50000]\tLoss: 0.5288\tLR: 0.015000\nTraining Epoch: 8 [2944/50000]\tLoss: 0.4160\tLR: 0.015000\nTraining Epoch: 8 [3072/50000]\tLoss: 0.3977\tLR: 0.015000\nTraining Epoch: 8 [3200/50000]\tLoss: 0.3137\tLR: 0.015000\nTraining Epoch: 8 [3328/50000]\tLoss: 0.3768\tLR: 0.015000\nTraining Epoch: 8 [3456/50000]\tLoss: 0.4813\tLR: 0.015000\nTraining Epoch: 8 [3584/50000]\tLoss: 0.4319\tLR: 0.015000\nTraining Epoch: 8 [3712/50000]\tLoss: 0.4316\tLR: 0.015000\nTraining Epoch: 8 [3840/50000]\tLoss: 0.3550\tLR: 0.015000\nTraining Epoch: 8 [3968/50000]\tLoss: 0.4072\tLR: 0.015000\nTraining Epoch: 8 [4096/50000]\tLoss: 0.4003\tLR: 0.015000\nTraining Epoch: 8 [4224/50000]\tLoss: 0.4917\tLR: 0.015000\nTraining Epoch: 8 [4352/50000]\tLoss: 0.5032\tLR: 0.015000\nTraining Epoch: 8 [4480/50000]\tLoss: 0.3783\tLR: 0.015000\nTraining Epoch: 8 [4608/50000]\tLoss: 0.4095\tLR: 0.015000\nTraining Epoch: 8 [4736/50000]\tLoss: 0.4840\tLR: 0.015000\nTraining Epoch: 8 [4864/50000]\tLoss: 0.5385\tLR: 0.015000\nTraining Epoch: 8 [4992/50000]\tLoss: 0.3011\tLR: 0.015000\nTraining Epoch: 8 [5120/50000]\tLoss: 0.3772\tLR: 0.015000\nTraining Epoch: 8 [5248/50000]\tLoss: 0.5228\tLR: 0.015000\nTraining Epoch: 8 [5376/50000]\tLoss: 0.4396\tLR: 0.015000\nTraining Epoch: 8 [5504/50000]\tLoss: 0.4201\tLR: 0.015000\nTraining Epoch: 8 [5632/50000]\tLoss: 0.3302\tLR: 0.015000\nTraining Epoch: 8 [5760/50000]\tLoss: 0.5444\tLR: 0.015000\nTraining Epoch: 8 [5888/50000]\tLoss: 0.4147\tLR: 0.015000\nTraining Epoch: 8 [6016/50000]\tLoss: 0.4449\tLR: 0.015000\nTraining Epoch: 8 [6144/50000]\tLoss: 0.4328\tLR: 0.015000\nTraining Epoch: 8 [6272/50000]\tLoss: 0.6123\tLR: 0.015000\nTraining Epoch: 8 [6400/50000]\tLoss: 0.4306\tLR: 0.015000\nTraining Epoch: 8 [6528/50000]\tLoss: 0.5570\tLR: 0.015000\nTraining Epoch: 8 [6656/50000]\tLoss: 0.4331\tLR: 0.015000\nTraining Epoch: 8 [6784/50000]\tLoss: 0.4115\tLR: 0.015000\nTraining Epoch: 8 [6912/50000]\tLoss: 0.5509\tLR: 0.015000\nTraining Epoch: 8 [7040/50000]\tLoss: 0.4606\tLR: 0.015000\nTraining Epoch: 8 [7168/50000]\tLoss: 0.3772\tLR: 0.015000\nTraining Epoch: 8 [7296/50000]\tLoss: 0.4119\tLR: 0.015000\nTraining Epoch: 8 [7424/50000]\tLoss: 0.3304\tLR: 0.015000\nTraining Epoch: 8 [7552/50000]\tLoss: 0.5395\tLR: 0.015000\nTraining Epoch: 8 [7680/50000]\tLoss: 0.5057\tLR: 0.015000\nTraining Epoch: 8 [7808/50000]\tLoss: 0.4902\tLR: 0.015000\nTraining Epoch: 8 [7936/50000]\tLoss: 0.3513\tLR: 0.015000\nTraining Epoch: 8 [8064/50000]\tLoss: 0.5264\tLR: 0.015000\nTraining Epoch: 8 [8192/50000]\tLoss: 0.3766\tLR: 0.015000\nTraining Epoch: 8 [8320/50000]\tLoss: 0.4560\tLR: 0.015000\nTraining Epoch: 8 [8448/50000]\tLoss: 0.4533\tLR: 0.015000\nTraining Epoch: 8 [8576/50000]\tLoss: 0.4611\tLR: 0.015000\nTraining Epoch: 8 [8704/50000]\tLoss: 0.3315\tLR: 0.015000\nTraining Epoch: 8 [8832/50000]\tLoss: 0.5295\tLR: 0.015000\nTraining Epoch: 8 [8960/50000]\tLoss: 0.4787\tLR: 0.015000\nTraining Epoch: 8 [9088/50000]\tLoss: 0.5343\tLR: 0.015000\nTraining Epoch: 8 [9216/50000]\tLoss: 0.5683\tLR: 0.015000\nTraining Epoch: 8 [9344/50000]\tLoss: 0.3733\tLR: 0.015000\nTraining Epoch: 8 [9472/50000]\tLoss: 0.4950\tLR: 0.015000\nTraining Epoch: 8 [9600/50000]\tLoss: 0.3724\tLR: 0.015000\nTraining Epoch: 8 [9728/50000]\tLoss: 0.4415\tLR: 0.015000\nTraining Epoch: 8 [9856/50000]\tLoss: 0.3298\tLR: 0.015000\nTraining Epoch: 8 [9984/50000]\tLoss: 0.3859\tLR: 0.015000\nTraining Epoch: 8 [10112/50000]\tLoss: 0.3749\tLR: 0.015000\nTraining Epoch: 8 [10240/50000]\tLoss: 0.4983\tLR: 0.015000\nTraining Epoch: 8 [10368/50000]\tLoss: 0.3708\tLR: 0.015000\nTraining Epoch: 8 [10496/50000]\tLoss: 0.5163\tLR: 0.015000\nTraining Epoch: 8 [10624/50000]\tLoss: 0.3583\tLR: 0.015000\nTraining Epoch: 8 [10752/50000]\tLoss: 0.5043\tLR: 0.015000\nTraining Epoch: 8 [10880/50000]\tLoss: 0.4881\tLR: 0.015000\nTraining Epoch: 8 [11008/50000]\tLoss: 0.4141\tLR: 0.015000\nTraining Epoch: 8 [11136/50000]\tLoss: 0.4978\tLR: 0.015000\nTraining Epoch: 8 [11264/50000]\tLoss: 0.5401\tLR: 0.015000\nTraining Epoch: 8 [11392/50000]\tLoss: 0.3976\tLR: 0.015000\nTraining Epoch: 8 [11520/50000]\tLoss: 0.3714\tLR: 0.015000\nTraining Epoch: 8 [11648/50000]\tLoss: 0.5401\tLR: 0.015000\nTraining Epoch: 8 [11776/50000]\tLoss: 0.4666\tLR: 0.015000\nTraining Epoch: 8 [11904/50000]\tLoss: 0.4135\tLR: 0.015000\nTraining Epoch: 8 [12032/50000]\tLoss: 0.4657\tLR: 0.015000\nTraining Epoch: 8 [12160/50000]\tLoss: 0.5086\tLR: 0.015000\nTraining Epoch: 8 [12288/50000]\tLoss: 0.5099\tLR: 0.015000\nTraining Epoch: 8 [12416/50000]\tLoss: 0.3836\tLR: 0.015000\nTraining Epoch: 8 [12544/50000]\tLoss: 0.3543\tLR: 0.015000\nTraining Epoch: 8 [12672/50000]\tLoss: 0.3799\tLR: 0.015000\nTraining Epoch: 8 [12800/50000]\tLoss: 0.5540\tLR: 0.015000\nTraining Epoch: 8 [12928/50000]\tLoss: 0.3960\tLR: 0.015000\nTraining Epoch: 8 [13056/50000]\tLoss: 0.4282\tLR: 0.015000\nTraining Epoch: 8 [13184/50000]\tLoss: 0.4834\tLR: 0.015000\nTraining Epoch: 8 [13312/50000]\tLoss: 0.5475\tLR: 0.015000\nTraining Epoch: 8 [13440/50000]\tLoss: 0.5014\tLR: 0.015000\nTraining Epoch: 8 [13568/50000]\tLoss: 0.3893\tLR: 0.015000\nTraining Epoch: 8 [13696/50000]\tLoss: 0.5330\tLR: 0.015000\nTraining Epoch: 8 [13824/50000]\tLoss: 0.4669\tLR: 0.015000\nTraining Epoch: 8 [13952/50000]\tLoss: 0.3410\tLR: 0.015000\nTraining Epoch: 8 [14080/50000]\tLoss: 0.4591\tLR: 0.015000\nTraining Epoch: 8 [14208/50000]\tLoss: 0.4152\tLR: 0.015000\nTraining Epoch: 8 [14336/50000]\tLoss: 0.4834\tLR: 0.015000\nTraining Epoch: 8 [14464/50000]\tLoss: 0.4516\tLR: 0.015000\nTraining Epoch: 8 [14592/50000]\tLoss: 0.4234\tLR: 0.015000\nTraining Epoch: 8 [14720/50000]\tLoss: 0.4483\tLR: 0.015000\nTraining Epoch: 8 [14848/50000]\tLoss: 0.3696\tLR: 0.015000\nTraining Epoch: 8 [14976/50000]\tLoss: 0.3931\tLR: 0.015000\nTraining Epoch: 8 [15104/50000]\tLoss: 0.4444\tLR: 0.015000\nTraining Epoch: 8 [15232/50000]\tLoss: 0.4524\tLR: 0.015000\nTraining Epoch: 8 [15360/50000]\tLoss: 0.3281\tLR: 0.015000\nTraining Epoch: 8 [15488/50000]\tLoss: 0.4039\tLR: 0.015000\nTraining Epoch: 8 [15616/50000]\tLoss: 0.4160\tLR: 0.015000\nTraining Epoch: 8 [15744/50000]\tLoss: 0.4193\tLR: 0.015000\nTraining Epoch: 8 [15872/50000]\tLoss: 0.3523\tLR: 0.015000\nTraining Epoch: 8 [16000/50000]\tLoss: 0.5148\tLR: 0.015000\nTraining Epoch: 8 [16128/50000]\tLoss: 0.3695\tLR: 0.015000\nTraining Epoch: 8 [16256/50000]\tLoss: 0.3884\tLR: 0.015000\nTraining Epoch: 8 [16384/50000]\tLoss: 0.3014\tLR: 0.015000\nTraining Epoch: 8 [16512/50000]\tLoss: 0.3670\tLR: 0.015000\nTraining Epoch: 8 [16640/50000]\tLoss: 0.5252\tLR: 0.015000\nTraining Epoch: 8 [16768/50000]\tLoss: 0.5986\tLR: 0.015000\nTraining Epoch: 8 [16896/50000]\tLoss: 0.3544\tLR: 0.015000\nTraining Epoch: 8 [17024/50000]\tLoss: 0.4548\tLR: 0.015000\nTraining Epoch: 8 [17152/50000]\tLoss: 0.5851\tLR: 0.015000\nTraining Epoch: 8 [17280/50000]\tLoss: 0.3967\tLR: 0.015000\nTraining Epoch: 8 [17408/50000]\tLoss: 0.6030\tLR: 0.015000\nTraining Epoch: 8 [17536/50000]\tLoss: 0.3338\tLR: 0.015000\nTraining Epoch: 8 [17664/50000]\tLoss: 0.4320\tLR: 0.015000\nTraining Epoch: 8 [17792/50000]\tLoss: 0.4078\tLR: 0.015000\nTraining Epoch: 8 [17920/50000]\tLoss: 0.5894\tLR: 0.015000\nTraining Epoch: 8 [18048/50000]\tLoss: 0.4069\tLR: 0.015000\nTraining Epoch: 8 [18176/50000]\tLoss: 0.4820\tLR: 0.015000\nTraining Epoch: 8 [18304/50000]\tLoss: 0.4639\tLR: 0.015000\nTraining Epoch: 8 [18432/50000]\tLoss: 0.4155\tLR: 0.015000\nTraining Epoch: 8 [18560/50000]\tLoss: 0.4228\tLR: 0.015000\nTraining Epoch: 8 [18688/50000]\tLoss: 0.3227\tLR: 0.015000\nTraining Epoch: 8 [18816/50000]\tLoss: 0.4295\tLR: 0.015000\nTraining Epoch: 8 [18944/50000]\tLoss: 0.3667\tLR: 0.015000\nTraining Epoch: 8 [19072/50000]\tLoss: 0.3916\tLR: 0.015000\nTraining Epoch: 8 [19200/50000]\tLoss: 0.4516\tLR: 0.015000\nTraining Epoch: 8 [19328/50000]\tLoss: 0.3379\tLR: 0.015000\nTraining Epoch: 8 [19456/50000]\tLoss: 0.4249\tLR: 0.015000\nTraining Epoch: 8 [19584/50000]\tLoss: 0.5235\tLR: 0.015000\nTraining Epoch: 8 [19712/50000]\tLoss: 0.3412\tLR: 0.015000\nTraining Epoch: 8 [19840/50000]\tLoss: 0.4275\tLR: 0.015000\nTraining Epoch: 8 [19968/50000]\tLoss: 0.5807\tLR: 0.015000\nTraining Epoch: 8 [20096/50000]\tLoss: 0.4136\tLR: 0.015000\nTraining Epoch: 8 [20224/50000]\tLoss: 0.4755\tLR: 0.015000\nTraining Epoch: 8 [20352/50000]\tLoss: 0.4119\tLR: 0.015000\nTraining Epoch: 8 [20480/50000]\tLoss: 0.3239\tLR: 0.015000\nTraining Epoch: 8 [20608/50000]\tLoss: 0.5047\tLR: 0.015000\nTraining Epoch: 8 [20736/50000]\tLoss: 0.3521\tLR: 0.015000\nTraining Epoch: 8 [20864/50000]\tLoss: 0.5176\tLR: 0.015000\nTraining Epoch: 8 [20992/50000]\tLoss: 0.3768\tLR: 0.015000\nTraining Epoch: 8 [21120/50000]\tLoss: 0.4566\tLR: 0.015000\nTraining Epoch: 8 [21248/50000]\tLoss: 0.5171\tLR: 0.015000\nTraining Epoch: 8 [21376/50000]\tLoss: 0.4343\tLR: 0.015000\nTraining Epoch: 8 [21504/50000]\tLoss: 0.5171\tLR: 0.015000\nTraining Epoch: 8 [21632/50000]\tLoss: 0.5732\tLR: 0.015000\nTraining Epoch: 8 [21760/50000]\tLoss: 0.3995\tLR: 0.015000\nTraining Epoch: 8 [21888/50000]\tLoss: 0.4198\tLR: 0.015000\nTraining Epoch: 8 [22016/50000]\tLoss: 0.3795\tLR: 0.015000\nTraining Epoch: 8 [22144/50000]\tLoss: 0.3820\tLR: 0.015000\nTraining Epoch: 8 [22272/50000]\tLoss: 0.4526\tLR: 0.015000\nTraining Epoch: 8 [22400/50000]\tLoss: 0.3791\tLR: 0.015000\nTraining Epoch: 8 [22528/50000]\tLoss: 0.4701\tLR: 0.015000\nTraining Epoch: 8 [22656/50000]\tLoss: 0.5073\tLR: 0.015000\nTraining Epoch: 8 [22784/50000]\tLoss: 0.3766\tLR: 0.015000\nTraining Epoch: 8 [22912/50000]\tLoss: 0.4693\tLR: 0.015000\nTraining Epoch: 8 [23040/50000]\tLoss: 0.5028\tLR: 0.015000\nTraining Epoch: 8 [23168/50000]\tLoss: 0.3993\tLR: 0.015000\nTraining Epoch: 8 [23296/50000]\tLoss: 0.3696\tLR: 0.015000\nTraining Epoch: 8 [23424/50000]\tLoss: 0.4417\tLR: 0.015000\nTraining Epoch: 8 [23552/50000]\tLoss: 0.2985\tLR: 0.015000\nTraining Epoch: 8 [23680/50000]\tLoss: 0.3176\tLR: 0.015000\nTraining Epoch: 8 [23808/50000]\tLoss: 0.4926\tLR: 0.015000\nTraining Epoch: 8 [23936/50000]\tLoss: 0.6402\tLR: 0.015000\nTraining Epoch: 8 [24064/50000]\tLoss: 0.4265\tLR: 0.015000\nTraining Epoch: 8 [24192/50000]\tLoss: 0.3790\tLR: 0.015000\nTraining Epoch: 8 [24320/50000]\tLoss: 0.5121\tLR: 0.015000\nTraining Epoch: 8 [24448/50000]\tLoss: 0.7150\tLR: 0.015000\nTraining Epoch: 8 [24576/50000]\tLoss: 0.5362\tLR: 0.015000\nTraining Epoch: 8 [24704/50000]\tLoss: 0.5787\tLR: 0.015000\nTraining Epoch: 8 [24832/50000]\tLoss: 0.4015\tLR: 0.015000\nTraining Epoch: 8 [24960/50000]\tLoss: 0.5145\tLR: 0.015000\nTraining Epoch: 8 [25088/50000]\tLoss: 0.3949\tLR: 0.015000\nTraining Epoch: 8 [25216/50000]\tLoss: 0.3391\tLR: 0.015000\nTraining Epoch: 8 [25344/50000]\tLoss: 0.4447\tLR: 0.015000\nTraining Epoch: 8 [25472/50000]\tLoss: 0.4188\tLR: 0.015000\nTraining Epoch: 8 [25600/50000]\tLoss: 0.4086\tLR: 0.015000\nTraining Epoch: 8 [25728/50000]\tLoss: 0.3481\tLR: 0.015000\nTraining Epoch: 8 [25856/50000]\tLoss: 0.4222\tLR: 0.015000\nTraining Epoch: 8 [25984/50000]\tLoss: 0.3949\tLR: 0.015000\nTraining Epoch: 8 [26112/50000]\tLoss: 0.4260\tLR: 0.015000\nTraining Epoch: 8 [26240/50000]\tLoss: 0.4936\tLR: 0.015000\nTraining Epoch: 8 [26368/50000]\tLoss: 0.4730\tLR: 0.015000\nTraining Epoch: 8 [26496/50000]\tLoss: 0.4156\tLR: 0.015000\nTraining Epoch: 8 [26624/50000]\tLoss: 0.4320\tLR: 0.015000\nTraining Epoch: 8 [26752/50000]\tLoss: 0.4293\tLR: 0.015000\nTraining Epoch: 8 [26880/50000]\tLoss: 0.4428\tLR: 0.015000\nTraining Epoch: 8 [27008/50000]\tLoss: 0.4866\tLR: 0.015000\nTraining Epoch: 8 [27136/50000]\tLoss: 0.3713\tLR: 0.015000\nTraining Epoch: 8 [27264/50000]\tLoss: 0.3955\tLR: 0.015000\nTraining Epoch: 8 [27392/50000]\tLoss: 0.3679\tLR: 0.015000\nTraining Epoch: 8 [27520/50000]\tLoss: 0.5064\tLR: 0.015000\nTraining Epoch: 8 [27648/50000]\tLoss: 0.6290\tLR: 0.015000\nTraining Epoch: 8 [27776/50000]\tLoss: 0.4920\tLR: 0.015000\nTraining Epoch: 8 [27904/50000]\tLoss: 0.5897\tLR: 0.015000\nTraining Epoch: 8 [28032/50000]\tLoss: 0.4411\tLR: 0.015000\nTraining Epoch: 8 [28160/50000]\tLoss: 0.3670\tLR: 0.015000\nTraining Epoch: 8 [28288/50000]\tLoss: 0.3483\tLR: 0.015000\nTraining Epoch: 8 [28416/50000]\tLoss: 0.5895\tLR: 0.015000\nTraining Epoch: 8 [28544/50000]\tLoss: 0.5729\tLR: 0.015000\nTraining Epoch: 8 [28672/50000]\tLoss: 0.4860\tLR: 0.015000\nTraining Epoch: 8 [28800/50000]\tLoss: 0.4530\tLR: 0.015000\nTraining Epoch: 8 [28928/50000]\tLoss: 0.4649\tLR: 0.015000\nTraining Epoch: 8 [29056/50000]\tLoss: 0.4215\tLR: 0.015000\nTraining Epoch: 8 [29184/50000]\tLoss: 0.4224\tLR: 0.015000\nTraining Epoch: 8 [29312/50000]\tLoss: 0.3243\tLR: 0.015000\nTraining Epoch: 8 [29440/50000]\tLoss: 0.5101\tLR: 0.015000\nTraining Epoch: 8 [29568/50000]\tLoss: 0.4834\tLR: 0.015000\nTraining Epoch: 8 [29696/50000]\tLoss: 0.5334\tLR: 0.015000\nTraining Epoch: 8 [29824/50000]\tLoss: 0.5565\tLR: 0.015000\nTraining Epoch: 8 [29952/50000]\tLoss: 0.4778\tLR: 0.015000\nTraining Epoch: 8 [30080/50000]\tLoss: 0.3942\tLR: 0.015000\nTraining Epoch: 8 [30208/50000]\tLoss: 0.4572\tLR: 0.015000\nTraining Epoch: 8 [30336/50000]\tLoss: 0.5789\tLR: 0.015000\nTraining Epoch: 8 [30464/50000]\tLoss: 0.4572\tLR: 0.015000\nTraining Epoch: 8 [30592/50000]\tLoss: 0.4860\tLR: 0.015000\nTraining Epoch: 8 [30720/50000]\tLoss: 0.5515\tLR: 0.015000\nTraining Epoch: 8 [30848/50000]\tLoss: 0.5698\tLR: 0.015000\nTraining Epoch: 8 [30976/50000]\tLoss: 0.4804\tLR: 0.015000\nTraining Epoch: 8 [31104/50000]\tLoss: 0.3165\tLR: 0.015000\nTraining Epoch: 8 [31232/50000]\tLoss: 0.4341\tLR: 0.015000\nTraining Epoch: 8 [31360/50000]\tLoss: 0.5157\tLR: 0.015000\nTraining Epoch: 8 [31488/50000]\tLoss: 0.3519\tLR: 0.015000\nTraining Epoch: 8 [31616/50000]\tLoss: 0.5232\tLR: 0.015000\nTraining Epoch: 8 [31744/50000]\tLoss: 0.4682\tLR: 0.015000\nTraining Epoch: 8 [31872/50000]\tLoss: 0.4144\tLR: 0.015000\nTraining Epoch: 8 [32000/50000]\tLoss: 0.5002\tLR: 0.015000\nTraining Epoch: 8 [32128/50000]\tLoss: 0.5236\tLR: 0.015000\nTraining Epoch: 8 [32256/50000]\tLoss: 0.5269\tLR: 0.015000\nTraining Epoch: 8 [32384/50000]\tLoss: 0.4241\tLR: 0.015000\nTraining Epoch: 8 [32512/50000]\tLoss: 0.5419\tLR: 0.015000\nTraining Epoch: 8 [32640/50000]\tLoss: 0.2964\tLR: 0.015000\nTraining Epoch: 8 [32768/50000]\tLoss: 0.4546\tLR: 0.015000\nTraining Epoch: 8 [32896/50000]\tLoss: 0.4306\tLR: 0.015000\nTraining Epoch: 8 [33024/50000]\tLoss: 0.4669\tLR: 0.015000\nTraining Epoch: 8 [33152/50000]\tLoss: 0.4431\tLR: 0.015000\nTraining Epoch: 8 [33280/50000]\tLoss: 0.3342\tLR: 0.015000\nTraining Epoch: 8 [33408/50000]\tLoss: 0.2562\tLR: 0.015000\nTraining Epoch: 8 [33536/50000]\tLoss: 0.4150\tLR: 0.015000\nTraining Epoch: 8 [33664/50000]\tLoss: 0.3809\tLR: 0.015000\nTraining Epoch: 8 [33792/50000]\tLoss: 0.4454\tLR: 0.015000\nTraining Epoch: 8 [33920/50000]\tLoss: 0.4206\tLR: 0.015000\nTraining Epoch: 8 [34048/50000]\tLoss: 0.5491\tLR: 0.015000\nTraining Epoch: 8 [34176/50000]\tLoss: 0.4849\tLR: 0.015000\nTraining Epoch: 8 [34304/50000]\tLoss: 0.5915\tLR: 0.015000\nTraining Epoch: 8 [34432/50000]\tLoss: 0.3274\tLR: 0.015000\nTraining Epoch: 8 [34560/50000]\tLoss: 0.5301\tLR: 0.015000\nTraining Epoch: 8 [34688/50000]\tLoss: 0.4872\tLR: 0.015000\nTraining Epoch: 8 [34816/50000]\tLoss: 0.3803\tLR: 0.015000\nTraining Epoch: 8 [34944/50000]\tLoss: 0.3512\tLR: 0.015000\nTraining Epoch: 8 [35072/50000]\tLoss: 0.2956\tLR: 0.015000\nTraining Epoch: 8 [35200/50000]\tLoss: 0.4561\tLR: 0.015000\nTraining Epoch: 8 [35328/50000]\tLoss: 0.4954\tLR: 0.015000\nTraining Epoch: 8 [35456/50000]\tLoss: 0.3401\tLR: 0.015000\nTraining Epoch: 8 [35584/50000]\tLoss: 0.4158\tLR: 0.015000\nTraining Epoch: 8 [35712/50000]\tLoss: 0.4090\tLR: 0.015000\nTraining Epoch: 8 [35840/50000]\tLoss: 0.4414\tLR: 0.015000\nTraining Epoch: 8 [35968/50000]\tLoss: 0.4907\tLR: 0.015000\nTraining Epoch: 8 [36096/50000]\tLoss: 0.3601\tLR: 0.015000\nTraining Epoch: 8 [36224/50000]\tLoss: 0.6202\tLR: 0.015000\nTraining Epoch: 8 [36352/50000]\tLoss: 0.3155\tLR: 0.015000\nTraining Epoch: 8 [36480/50000]\tLoss: 0.4447\tLR: 0.015000\nTraining Epoch: 8 [36608/50000]\tLoss: 0.4292\tLR: 0.015000\nTraining Epoch: 8 [36736/50000]\tLoss: 0.4703\tLR: 0.015000\nTraining Epoch: 8 [36864/50000]\tLoss: 0.4835\tLR: 0.015000\nTraining Epoch: 8 [36992/50000]\tLoss: 0.3129\tLR: 0.015000\nTraining Epoch: 8 [37120/50000]\tLoss: 0.3652\tLR: 0.015000\nTraining Epoch: 8 [37248/50000]\tLoss: 0.5114\tLR: 0.015000\nTraining Epoch: 8 [37376/50000]\tLoss: 0.6424\tLR: 0.015000\nTraining Epoch: 8 [37504/50000]\tLoss: 0.5654\tLR: 0.015000\nTraining Epoch: 8 [37632/50000]\tLoss: 0.4771\tLR: 0.015000\nTraining Epoch: 8 [37760/50000]\tLoss: 0.5292\tLR: 0.015000\nTraining Epoch: 8 [37888/50000]\tLoss: 0.4436\tLR: 0.015000\nTraining Epoch: 8 [38016/50000]\tLoss: 0.3587\tLR: 0.015000\nTraining Epoch: 8 [38144/50000]\tLoss: 0.3608\tLR: 0.015000\nTraining Epoch: 8 [38272/50000]\tLoss: 0.3675\tLR: 0.015000\nTraining Epoch: 8 [38400/50000]\tLoss: 0.4353\tLR: 0.015000\nTraining Epoch: 8 [38528/50000]\tLoss: 0.4445\tLR: 0.015000\nTraining Epoch: 8 [38656/50000]\tLoss: 0.4305\tLR: 0.015000\nTraining Epoch: 8 [38784/50000]\tLoss: 0.4885\tLR: 0.015000\nTraining Epoch: 8 [38912/50000]\tLoss: 0.4719\tLR: 0.015000\nTraining Epoch: 8 [39040/50000]\tLoss: 0.4717\tLR: 0.015000\nTraining Epoch: 8 [39168/50000]\tLoss: 0.5096\tLR: 0.015000\nTraining Epoch: 8 [39296/50000]\tLoss: 0.4559\tLR: 0.015000\nTraining Epoch: 8 [39424/50000]\tLoss: 0.6443\tLR: 0.015000\nTraining Epoch: 8 [39552/50000]\tLoss: 0.3972\tLR: 0.015000\nTraining Epoch: 8 [39680/50000]\tLoss: 0.4710\tLR: 0.015000\nTraining Epoch: 8 [39808/50000]\tLoss: 0.3845\tLR: 0.015000\nTraining Epoch: 8 [39936/50000]\tLoss: 0.5527\tLR: 0.015000\nTraining Epoch: 8 [40064/50000]\tLoss: 0.3923\tLR: 0.015000\nTraining Epoch: 8 [40192/50000]\tLoss: 0.3309\tLR: 0.015000\nTraining Epoch: 8 [40320/50000]\tLoss: 0.5485\tLR: 0.015000\nTraining Epoch: 8 [40448/50000]\tLoss: 0.4742\tLR: 0.015000\nTraining Epoch: 8 [40576/50000]\tLoss: 0.4620\tLR: 0.015000\nTraining Epoch: 8 [40704/50000]\tLoss: 0.5160\tLR: 0.015000\nTraining Epoch: 8 [40832/50000]\tLoss: 0.3598\tLR: 0.015000\nTraining Epoch: 8 [40960/50000]\tLoss: 0.4120\tLR: 0.015000\nTraining Epoch: 8 [41088/50000]\tLoss: 0.5583\tLR: 0.015000\nTraining Epoch: 8 [41216/50000]\tLoss: 0.3798\tLR: 0.015000\nTraining Epoch: 8 [41344/50000]\tLoss: 0.5832\tLR: 0.015000\nTraining Epoch: 8 [41472/50000]\tLoss: 0.4622\tLR: 0.015000\nTraining Epoch: 8 [41600/50000]\tLoss: 0.4922\tLR: 0.015000\nTraining Epoch: 8 [41728/50000]\tLoss: 0.4933\tLR: 0.015000\nTraining Epoch: 8 [41856/50000]\tLoss: 0.4813\tLR: 0.015000\nTraining Epoch: 8 [41984/50000]\tLoss: 0.3159\tLR: 0.015000\nTraining Epoch: 8 [42112/50000]\tLoss: 0.4931\tLR: 0.015000\nTraining Epoch: 8 [42240/50000]\tLoss: 0.4686\tLR: 0.015000\nTraining Epoch: 8 [42368/50000]\tLoss: 0.3277\tLR: 0.015000\nTraining Epoch: 8 [42496/50000]\tLoss: 0.6091\tLR: 0.015000\nTraining Epoch: 8 [42624/50000]\tLoss: 0.5761\tLR: 0.015000\nTraining Epoch: 8 [42752/50000]\tLoss: 0.3851\tLR: 0.015000\nTraining Epoch: 8 [42880/50000]\tLoss: 0.4228\tLR: 0.015000\nTraining Epoch: 8 [43008/50000]\tLoss: 0.4558\tLR: 0.015000\nTraining Epoch: 8 [43136/50000]\tLoss: 0.5475\tLR: 0.015000\nTraining Epoch: 8 [43264/50000]\tLoss: 0.4039\tLR: 0.015000\nTraining Epoch: 8 [43392/50000]\tLoss: 0.3718\tLR: 0.015000\nTraining Epoch: 8 [43520/50000]\tLoss: 0.4409\tLR: 0.015000\nTraining Epoch: 8 [43648/50000]\tLoss: 0.3863\tLR: 0.015000\nTraining Epoch: 8 [43776/50000]\tLoss: 0.4888\tLR: 0.015000\nTraining Epoch: 8 [43904/50000]\tLoss: 0.4890\tLR: 0.015000\nTraining Epoch: 8 [44032/50000]\tLoss: 0.4277\tLR: 0.015000\nTraining Epoch: 8 [44160/50000]\tLoss: 0.5547\tLR: 0.015000\nTraining Epoch: 8 [44288/50000]\tLoss: 0.3760\tLR: 0.015000\nTraining Epoch: 8 [44416/50000]\tLoss: 0.5203\tLR: 0.015000\nTraining Epoch: 8 [44544/50000]\tLoss: 0.5405\tLR: 0.015000\nTraining Epoch: 8 [44672/50000]\tLoss: 0.3628\tLR: 0.015000\nTraining Epoch: 8 [44800/50000]\tLoss: 0.5077\tLR: 0.015000\nTraining Epoch: 8 [44928/50000]\tLoss: 0.5064\tLR: 0.015000\nTraining Epoch: 8 [45056/50000]\tLoss: 0.6075\tLR: 0.015000\nTraining Epoch: 8 [45184/50000]\tLoss: 0.3759\tLR: 0.015000\nTraining Epoch: 8 [45312/50000]\tLoss: 0.5470\tLR: 0.015000\nTraining Epoch: 8 [45440/50000]\tLoss: 0.4119\tLR: 0.015000\nTraining Epoch: 8 [45568/50000]\tLoss: 0.4180\tLR: 0.015000\nTraining Epoch: 8 [45696/50000]\tLoss: 0.4959\tLR: 0.015000\nTraining Epoch: 8 [45824/50000]\tLoss: 0.2915\tLR: 0.015000\nTraining Epoch: 8 [45952/50000]\tLoss: 0.5403\tLR: 0.015000\nTraining Epoch: 8 [46080/50000]\tLoss: 0.4579\tLR: 0.015000\nTraining Epoch: 8 [46208/50000]\tLoss: 0.3492\tLR: 0.015000\nTraining Epoch: 8 [46336/50000]\tLoss: 0.5271\tLR: 0.015000\nTraining Epoch: 8 [46464/50000]\tLoss: 0.3861\tLR: 0.015000\nTraining Epoch: 8 [46592/50000]\tLoss: 0.4135\tLR: 0.015000\nTraining Epoch: 8 [46720/50000]\tLoss: 0.5450\tLR: 0.015000\nTraining Epoch: 8 [46848/50000]\tLoss: 0.4633\tLR: 0.015000\nTraining Epoch: 8 [46976/50000]\tLoss: 0.4938\tLR: 0.015000\nTraining Epoch: 8 [47104/50000]\tLoss: 0.4668\tLR: 0.015000\nTraining Epoch: 8 [47232/50000]\tLoss: 0.2796\tLR: 0.015000\nTraining Epoch: 8 [47360/50000]\tLoss: 0.3458\tLR: 0.015000\nTraining Epoch: 8 [47488/50000]\tLoss: 0.5677\tLR: 0.015000\nTraining Epoch: 8 [47616/50000]\tLoss: 0.4483\tLR: 0.015000\nTraining Epoch: 8 [47744/50000]\tLoss: 0.3953\tLR: 0.015000\nTraining Epoch: 8 [47872/50000]\tLoss: 0.4668\tLR: 0.015000\nTraining Epoch: 8 [48000/50000]\tLoss: 0.4218\tLR: 0.015000\nTraining Epoch: 8 [48128/50000]\tLoss: 0.3874\tLR: 0.015000\nTraining Epoch: 8 [48256/50000]\tLoss: 0.3635\tLR: 0.015000\nTraining Epoch: 8 [48384/50000]\tLoss: 0.4766\tLR: 0.015000\nTraining Epoch: 8 [48512/50000]\tLoss: 0.5055\tLR: 0.015000\nTraining Epoch: 8 [48640/50000]\tLoss: 0.5086\tLR: 0.015000\nTraining Epoch: 8 [48768/50000]\tLoss: 0.4549\tLR: 0.015000\nTraining Epoch: 8 [48896/50000]\tLoss: 0.5245\tLR: 0.015000\nTraining Epoch: 8 [49024/50000]\tLoss: 0.3819\tLR: 0.015000\nTraining Epoch: 8 [49152/50000]\tLoss: 0.4200\tLR: 0.015000\nTraining Epoch: 8 [49280/50000]\tLoss: 0.3478\tLR: 0.015000\nTraining Epoch: 8 [49408/50000]\tLoss: 0.4050\tLR: 0.015000\nTraining Epoch: 8 [49536/50000]\tLoss: 0.5360\tLR: 0.015000\nTraining Epoch: 8 [49664/50000]\tLoss: 0.3342\tLR: 0.015000\nTraining Epoch: 8 [49792/50000]\tLoss: 0.4491\tLR: 0.015000\nTraining Epoch: 8 [49920/50000]\tLoss: 0.4195\tLR: 0.015000\nTraining Epoch: 8 [50000/50000]\tLoss: 0.5320\tLR: 0.015000\nTest set: Average loss: 0.0034, Accuracy: 0.8520\n\nTraining Epoch: 9 [128/50000]\tLoss: 0.3316\tLR: 0.015000\nTraining Epoch: 9 [256/50000]\tLoss: 0.5026\tLR: 0.015000\nTraining Epoch: 9 [384/50000]\tLoss: 0.5045\tLR: 0.015000\nTraining Epoch: 9 [512/50000]\tLoss: 0.3972\tLR: 0.015000\nTraining Epoch: 9 [640/50000]\tLoss: 0.4592\tLR: 0.015000\nTraining Epoch: 9 [768/50000]\tLoss: 0.3976\tLR: 0.015000\nTraining Epoch: 9 [896/50000]\tLoss: 0.4007\tLR: 0.015000\nTraining Epoch: 9 [1024/50000]\tLoss: 0.4569\tLR: 0.015000\nTraining Epoch: 9 [1152/50000]\tLoss: 0.5232\tLR: 0.015000\nTraining Epoch: 9 [1280/50000]\tLoss: 0.5520\tLR: 0.015000\nTraining Epoch: 9 [1408/50000]\tLoss: 0.3746\tLR: 0.015000\nTraining Epoch: 9 [1536/50000]\tLoss: 0.5054\tLR: 0.015000\nTraining Epoch: 9 [1664/50000]\tLoss: 0.3574\tLR: 0.015000\nTraining Epoch: 9 [1792/50000]\tLoss: 0.4195\tLR: 0.015000\nTraining Epoch: 9 [1920/50000]\tLoss: 0.4341\tLR: 0.015000\nTraining Epoch: 9 [2048/50000]\tLoss: 0.3167\tLR: 0.015000\nTraining Epoch: 9 [2176/50000]\tLoss: 0.3423\tLR: 0.015000\nTraining Epoch: 9 [2304/50000]\tLoss: 0.5168\tLR: 0.015000\nTraining Epoch: 9 [2432/50000]\tLoss: 0.5135\tLR: 0.015000\nTraining Epoch: 9 [2560/50000]\tLoss: 0.4073\tLR: 0.015000\nTraining Epoch: 9 [2688/50000]\tLoss: 0.4425\tLR: 0.015000\nTraining Epoch: 9 [2816/50000]\tLoss: 0.4301\tLR: 0.015000\nTraining Epoch: 9 [2944/50000]\tLoss: 0.2631\tLR: 0.015000\nTraining Epoch: 9 [3072/50000]\tLoss: 0.4424\tLR: 0.015000\nTraining Epoch: 9 [3200/50000]\tLoss: 0.4189\tLR: 0.015000\nTraining Epoch: 9 [3328/50000]\tLoss: 0.4957\tLR: 0.015000\nTraining Epoch: 9 [3456/50000]\tLoss: 0.3690\tLR: 0.015000\nTraining Epoch: 9 [3584/50000]\tLoss: 0.4719\tLR: 0.015000\nTraining Epoch: 9 [3712/50000]\tLoss: 0.3570\tLR: 0.015000\nTraining Epoch: 9 [3840/50000]\tLoss: 0.3897\tLR: 0.015000\nTraining Epoch: 9 [3968/50000]\tLoss: 0.4088\tLR: 0.015000\nTraining Epoch: 9 [4096/50000]\tLoss: 0.4063\tLR: 0.015000\nTraining Epoch: 9 [4224/50000]\tLoss: 0.3280\tLR: 0.015000\nTraining Epoch: 9 [4352/50000]\tLoss: 0.4787\tLR: 0.015000\nTraining Epoch: 9 [4480/50000]\tLoss: 0.3443\tLR: 0.015000\nTraining Epoch: 9 [4608/50000]\tLoss: 0.3365\tLR: 0.015000\nTraining Epoch: 9 [4736/50000]\tLoss: 0.4228\tLR: 0.015000\nTraining Epoch: 9 [4864/50000]\tLoss: 0.4375\tLR: 0.015000\nTraining Epoch: 9 [4992/50000]\tLoss: 0.3023\tLR: 0.015000\nTraining Epoch: 9 [5120/50000]\tLoss: 0.4076\tLR: 0.015000\nTraining Epoch: 9 [5248/50000]\tLoss: 0.3833\tLR: 0.015000\nTraining Epoch: 9 [5376/50000]\tLoss: 0.4779\tLR: 0.015000\nTraining Epoch: 9 [5504/50000]\tLoss: 0.4439\tLR: 0.015000\nTraining Epoch: 9 [5632/50000]\tLoss: 0.3326\tLR: 0.015000\nTraining Epoch: 9 [5760/50000]\tLoss: 0.4702\tLR: 0.015000\nTraining Epoch: 9 [5888/50000]\tLoss: 0.4132\tLR: 0.015000\nTraining Epoch: 9 [6016/50000]\tLoss: 0.3686\tLR: 0.015000\nTraining Epoch: 9 [6144/50000]\tLoss: 0.4641\tLR: 0.015000\nTraining Epoch: 9 [6272/50000]\tLoss: 0.4251\tLR: 0.015000\nTraining Epoch: 9 [6400/50000]\tLoss: 0.4444\tLR: 0.015000\nTraining Epoch: 9 [6528/50000]\tLoss: 0.4295\tLR: 0.015000\nTraining Epoch: 9 [6656/50000]\tLoss: 0.4082\tLR: 0.015000\nTraining Epoch: 9 [6784/50000]\tLoss: 0.3219\tLR: 0.015000\nTraining Epoch: 9 [6912/50000]\tLoss: 0.4473\tLR: 0.015000\nTraining Epoch: 9 [7040/50000]\tLoss: 0.4172\tLR: 0.015000\nTraining Epoch: 9 [7168/50000]\tLoss: 0.4606\tLR: 0.015000\nTraining Epoch: 9 [7296/50000]\tLoss: 0.4050\tLR: 0.015000\nTraining Epoch: 9 [7424/50000]\tLoss: 0.4397\tLR: 0.015000\nTraining Epoch: 9 [7552/50000]\tLoss: 0.4541\tLR: 0.015000\nTraining Epoch: 9 [7680/50000]\tLoss: 0.3552\tLR: 0.015000\nTraining Epoch: 9 [7808/50000]\tLoss: 0.3772\tLR: 0.015000\nTraining Epoch: 9 [7936/50000]\tLoss: 0.4912\tLR: 0.015000\nTraining Epoch: 9 [8064/50000]\tLoss: 0.4923\tLR: 0.015000\nTraining Epoch: 9 [8192/50000]\tLoss: 0.4210\tLR: 0.015000\nTraining Epoch: 9 [8320/50000]\tLoss: 0.4558\tLR: 0.015000\nTraining Epoch: 9 [8448/50000]\tLoss: 0.3850\tLR: 0.015000\nTraining Epoch: 9 [8576/50000]\tLoss: 0.3963\tLR: 0.015000\nTraining Epoch: 9 [8704/50000]\tLoss: 0.5027\tLR: 0.015000\nTraining Epoch: 9 [8832/50000]\tLoss: 0.3900\tLR: 0.015000\nTraining Epoch: 9 [8960/50000]\tLoss: 0.3102\tLR: 0.015000\nTraining Epoch: 9 [9088/50000]\tLoss: 0.3007\tLR: 0.015000\nTraining Epoch: 9 [9216/50000]\tLoss: 0.4653\tLR: 0.015000\nTraining Epoch: 9 [9344/50000]\tLoss: 0.4233\tLR: 0.015000\nTraining Epoch: 9 [9472/50000]\tLoss: 0.5588\tLR: 0.015000\nTraining Epoch: 9 [9600/50000]\tLoss: 0.4591\tLR: 0.015000\nTraining Epoch: 9 [9728/50000]\tLoss: 0.5130\tLR: 0.015000\nTraining Epoch: 9 [9856/50000]\tLoss: 0.4361\tLR: 0.015000\nTraining Epoch: 9 [9984/50000]\tLoss: 0.4395\tLR: 0.015000\nTraining Epoch: 9 [10112/50000]\tLoss: 0.3934\tLR: 0.015000\nTraining Epoch: 9 [10240/50000]\tLoss: 0.5433\tLR: 0.015000\nTraining Epoch: 9 [10368/50000]\tLoss: 0.4306\tLR: 0.015000\nTraining Epoch: 9 [10496/50000]\tLoss: 0.3314\tLR: 0.015000\nTraining Epoch: 9 [10624/50000]\tLoss: 0.3122\tLR: 0.015000\nTraining Epoch: 9 [10752/50000]\tLoss: 0.4757\tLR: 0.015000\nTraining Epoch: 9 [10880/50000]\tLoss: 0.3179\tLR: 0.015000\nTraining Epoch: 9 [11008/50000]\tLoss: 0.5600\tLR: 0.015000\nTraining Epoch: 9 [11136/50000]\tLoss: 0.5548\tLR: 0.015000\nTraining Epoch: 9 [11264/50000]\tLoss: 0.4420\tLR: 0.015000\nTraining Epoch: 9 [11392/50000]\tLoss: 0.4706\tLR: 0.015000\nTraining Epoch: 9 [11520/50000]\tLoss: 0.4202\tLR: 0.015000\nTraining Epoch: 9 [11648/50000]\tLoss: 0.3179\tLR: 0.015000\nTraining Epoch: 9 [11776/50000]\tLoss: 0.3779\tLR: 0.015000\nTraining Epoch: 9 [11904/50000]\tLoss: 0.5036\tLR: 0.015000\nTraining Epoch: 9 [12032/50000]\tLoss: 0.3874\tLR: 0.015000\nTraining Epoch: 9 [12160/50000]\tLoss: 0.4428\tLR: 0.015000\nTraining Epoch: 9 [12288/50000]\tLoss: 0.4432\tLR: 0.015000\nTraining Epoch: 9 [12416/50000]\tLoss: 0.4237\tLR: 0.015000\nTraining Epoch: 9 [12544/50000]\tLoss: 0.4183\tLR: 0.015000\nTraining Epoch: 9 [12672/50000]\tLoss: 0.4265\tLR: 0.015000\nTraining Epoch: 9 [12800/50000]\tLoss: 0.3749\tLR: 0.015000\nTraining Epoch: 9 [12928/50000]\tLoss: 0.5131\tLR: 0.015000\nTraining Epoch: 9 [13056/50000]\tLoss: 0.4227\tLR: 0.015000\nTraining Epoch: 9 [13184/50000]\tLoss: 0.5302\tLR: 0.015000\nTraining Epoch: 9 [13312/50000]\tLoss: 0.4452\tLR: 0.015000\nTraining Epoch: 9 [13440/50000]\tLoss: 0.3739\tLR: 0.015000\nTraining Epoch: 9 [13568/50000]\tLoss: 0.3401\tLR: 0.015000\nTraining Epoch: 9 [13696/50000]\tLoss: 0.4568\tLR: 0.015000\nTraining Epoch: 9 [13824/50000]\tLoss: 0.5045\tLR: 0.015000\nTraining Epoch: 9 [13952/50000]\tLoss: 0.3970\tLR: 0.015000\nTraining Epoch: 9 [14080/50000]\tLoss: 0.3648\tLR: 0.015000\nTraining Epoch: 9 [14208/50000]\tLoss: 0.3996\tLR: 0.015000\nTraining Epoch: 9 [14336/50000]\tLoss: 0.4891\tLR: 0.015000\nTraining Epoch: 9 [14464/50000]\tLoss: 0.4092\tLR: 0.015000\nTraining Epoch: 9 [14592/50000]\tLoss: 0.3704\tLR: 0.015000\nTraining Epoch: 9 [14720/50000]\tLoss: 0.3697\tLR: 0.015000\nTraining Epoch: 9 [14848/50000]\tLoss: 0.4772\tLR: 0.015000\nTraining Epoch: 9 [14976/50000]\tLoss: 0.3092\tLR: 0.015000\nTraining Epoch: 9 [15104/50000]\tLoss: 0.5079\tLR: 0.015000\nTraining Epoch: 9 [15232/50000]\tLoss: 0.3492\tLR: 0.015000\nTraining Epoch: 9 [15360/50000]\tLoss: 0.4829\tLR: 0.015000\nTraining Epoch: 9 [15488/50000]\tLoss: 0.4812\tLR: 0.015000\nTraining Epoch: 9 [15616/50000]\tLoss: 0.5243\tLR: 0.015000\nTraining Epoch: 9 [15744/50000]\tLoss: 0.3153\tLR: 0.015000\nTraining Epoch: 9 [15872/50000]\tLoss: 0.3462\tLR: 0.015000\nTraining Epoch: 9 [16000/50000]\tLoss: 0.3091\tLR: 0.015000\nTraining Epoch: 9 [16128/50000]\tLoss: 0.2938\tLR: 0.015000\nTraining Epoch: 9 [16256/50000]\tLoss: 0.3447\tLR: 0.015000\nTraining Epoch: 9 [16384/50000]\tLoss: 0.4667\tLR: 0.015000\nTraining Epoch: 9 [16512/50000]\tLoss: 0.4002\tLR: 0.015000\nTraining Epoch: 9 [16640/50000]\tLoss: 0.4993\tLR: 0.015000\nTraining Epoch: 9 [16768/50000]\tLoss: 0.4236\tLR: 0.015000\nTraining Epoch: 9 [16896/50000]\tLoss: 0.4688\tLR: 0.015000\nTraining Epoch: 9 [17024/50000]\tLoss: 0.3517\tLR: 0.015000\nTraining Epoch: 9 [17152/50000]\tLoss: 0.4091\tLR: 0.015000\nTraining Epoch: 9 [17280/50000]\tLoss: 0.4156\tLR: 0.015000\nTraining Epoch: 9 [17408/50000]\tLoss: 0.5657\tLR: 0.015000\nTraining Epoch: 9 [17536/50000]\tLoss: 0.3632\tLR: 0.015000\nTraining Epoch: 9 [17664/50000]\tLoss: 0.4562\tLR: 0.015000\nTraining Epoch: 9 [17792/50000]\tLoss: 0.6019\tLR: 0.015000\nTraining Epoch: 9 [17920/50000]\tLoss: 0.3625\tLR: 0.015000\nTraining Epoch: 9 [18048/50000]\tLoss: 0.4250\tLR: 0.015000\nTraining Epoch: 9 [18176/50000]\tLoss: 0.3392\tLR: 0.015000\nTraining Epoch: 9 [18304/50000]\tLoss: 0.5005\tLR: 0.015000\nTraining Epoch: 9 [18432/50000]\tLoss: 0.4224\tLR: 0.015000\nTraining Epoch: 9 [18560/50000]\tLoss: 0.3947\tLR: 0.015000\nTraining Epoch: 9 [18688/50000]\tLoss: 0.4360\tLR: 0.015000\nTraining Epoch: 9 [18816/50000]\tLoss: 0.2888\tLR: 0.015000\nTraining Epoch: 9 [18944/50000]\tLoss: 0.3599\tLR: 0.015000\nTraining Epoch: 9 [19072/50000]\tLoss: 0.3229\tLR: 0.015000\nTraining Epoch: 9 [19200/50000]\tLoss: 0.3271\tLR: 0.015000\nTraining Epoch: 9 [19328/50000]\tLoss: 0.3734\tLR: 0.015000\nTraining Epoch: 9 [19456/50000]\tLoss: 0.4020\tLR: 0.015000\nTraining Epoch: 9 [19584/50000]\tLoss: 0.4270\tLR: 0.015000\nTraining Epoch: 9 [19712/50000]\tLoss: 0.4319\tLR: 0.015000\nTraining Epoch: 9 [19840/50000]\tLoss: 0.3994\tLR: 0.015000\nTraining Epoch: 9 [19968/50000]\tLoss: 0.4539\tLR: 0.015000\nTraining Epoch: 9 [20096/50000]\tLoss: 0.5003\tLR: 0.015000\nTraining Epoch: 9 [20224/50000]\tLoss: 0.5512\tLR: 0.015000\nTraining Epoch: 9 [20352/50000]\tLoss: 0.4752\tLR: 0.015000\nTraining Epoch: 9 [20480/50000]\tLoss: 0.2981\tLR: 0.015000\nTraining Epoch: 9 [20608/50000]\tLoss: 0.4746\tLR: 0.015000\nTraining Epoch: 9 [20736/50000]\tLoss: 0.4516\tLR: 0.015000\nTraining Epoch: 9 [20864/50000]\tLoss: 0.2909\tLR: 0.015000\nTraining Epoch: 9 [20992/50000]\tLoss: 0.3327\tLR: 0.015000\nTraining Epoch: 9 [21120/50000]\tLoss: 0.4121\tLR: 0.015000\nTraining Epoch: 9 [21248/50000]\tLoss: 0.6053\tLR: 0.015000\nTraining Epoch: 9 [21376/50000]\tLoss: 0.4488\tLR: 0.015000\nTraining Epoch: 9 [21504/50000]\tLoss: 0.4385\tLR: 0.015000\nTraining Epoch: 9 [21632/50000]\tLoss: 0.4303\tLR: 0.015000\nTraining Epoch: 9 [21760/50000]\tLoss: 0.5104\tLR: 0.015000\nTraining Epoch: 9 [21888/50000]\tLoss: 0.4413\tLR: 0.015000\nTraining Epoch: 9 [22016/50000]\tLoss: 0.5211\tLR: 0.015000\nTraining Epoch: 9 [22144/50000]\tLoss: 0.4591\tLR: 0.015000\nTraining Epoch: 9 [22272/50000]\tLoss: 0.3332\tLR: 0.015000\nTraining Epoch: 9 [22400/50000]\tLoss: 0.5312\tLR: 0.015000\nTraining Epoch: 9 [22528/50000]\tLoss: 0.5326\tLR: 0.015000\nTraining Epoch: 9 [22656/50000]\tLoss: 0.3794\tLR: 0.015000\nTraining Epoch: 9 [22784/50000]\tLoss: 0.4963\tLR: 0.015000\nTraining Epoch: 9 [22912/50000]\tLoss: 0.4516\tLR: 0.015000\nTraining Epoch: 9 [23040/50000]\tLoss: 0.3724\tLR: 0.015000\nTraining Epoch: 9 [23168/50000]\tLoss: 0.4305\tLR: 0.015000\nTraining Epoch: 9 [23296/50000]\tLoss: 0.4466\tLR: 0.015000\nTraining Epoch: 9 [23424/50000]\tLoss: 0.4128\tLR: 0.015000\nTraining Epoch: 9 [23552/50000]\tLoss: 0.3854\tLR: 0.015000\nTraining Epoch: 9 [23680/50000]\tLoss: 0.3762\tLR: 0.015000\nTraining Epoch: 9 [23808/50000]\tLoss: 0.2902\tLR: 0.015000\nTraining Epoch: 9 [23936/50000]\tLoss: 0.4041\tLR: 0.015000\nTraining Epoch: 9 [24064/50000]\tLoss: 0.4764\tLR: 0.015000\nTraining Epoch: 9 [24192/50000]\tLoss: 0.5499\tLR: 0.015000\nTraining Epoch: 9 [24320/50000]\tLoss: 0.5399\tLR: 0.015000\nTraining Epoch: 9 [24448/50000]\tLoss: 0.4398\tLR: 0.015000\nTraining Epoch: 9 [24576/50000]\tLoss: 0.4537\tLR: 0.015000\nTraining Epoch: 9 [24704/50000]\tLoss: 0.3728\tLR: 0.015000\nTraining Epoch: 9 [24832/50000]\tLoss: 0.6752\tLR: 0.015000\nTraining Epoch: 9 [24960/50000]\tLoss: 0.4049\tLR: 0.015000\nTraining Epoch: 9 [25088/50000]\tLoss: 0.3543\tLR: 0.015000\nTraining Epoch: 9 [25216/50000]\tLoss: 0.2756\tLR: 0.015000\nTraining Epoch: 9 [25344/50000]\tLoss: 0.4946\tLR: 0.015000\nTraining Epoch: 9 [25472/50000]\tLoss: 0.4269\tLR: 0.015000\nTraining Epoch: 9 [25600/50000]\tLoss: 0.4818\tLR: 0.015000\nTraining Epoch: 9 [25728/50000]\tLoss: 0.5406\tLR: 0.015000\nTraining Epoch: 9 [25856/50000]\tLoss: 0.4765\tLR: 0.015000\nTraining Epoch: 9 [25984/50000]\tLoss: 0.3978\tLR: 0.015000\nTraining Epoch: 9 [26112/50000]\tLoss: 0.3625\tLR: 0.015000\nTraining Epoch: 9 [26240/50000]\tLoss: 0.3080\tLR: 0.015000\nTraining Epoch: 9 [26368/50000]\tLoss: 0.5716\tLR: 0.015000\nTraining Epoch: 9 [26496/50000]\tLoss: 0.4538\tLR: 0.015000\nTraining Epoch: 9 [26624/50000]\tLoss: 0.4594\tLR: 0.015000\nTraining Epoch: 9 [26752/50000]\tLoss: 0.3563\tLR: 0.015000\nTraining Epoch: 9 [26880/50000]\tLoss: 0.3065\tLR: 0.015000\nTraining Epoch: 9 [27008/50000]\tLoss: 0.4133\tLR: 0.015000\nTraining Epoch: 9 [27136/50000]\tLoss: 0.3100\tLR: 0.015000\nTraining Epoch: 9 [27264/50000]\tLoss: 0.5060\tLR: 0.015000\nTraining Epoch: 9 [27392/50000]\tLoss: 0.5126\tLR: 0.015000\nTraining Epoch: 9 [27520/50000]\tLoss: 0.3732\tLR: 0.015000\nTraining Epoch: 9 [27648/50000]\tLoss: 0.4053\tLR: 0.015000\nTraining Epoch: 9 [27776/50000]\tLoss: 0.5846\tLR: 0.015000\nTraining Epoch: 9 [27904/50000]\tLoss: 0.4432\tLR: 0.015000\nTraining Epoch: 9 [28032/50000]\tLoss: 0.3698\tLR: 0.015000\nTraining Epoch: 9 [28160/50000]\tLoss: 0.5592\tLR: 0.015000\nTraining Epoch: 9 [28288/50000]\tLoss: 0.4404\tLR: 0.015000\nTraining Epoch: 9 [28416/50000]\tLoss: 0.4448\tLR: 0.015000\nTraining Epoch: 9 [28544/50000]\tLoss: 0.3703\tLR: 0.015000\nTraining Epoch: 9 [28672/50000]\tLoss: 0.4228\tLR: 0.015000\nTraining Epoch: 9 [28800/50000]\tLoss: 0.3891\tLR: 0.015000\nTraining Epoch: 9 [28928/50000]\tLoss: 0.4017\tLR: 0.015000\nTraining Epoch: 9 [29056/50000]\tLoss: 0.3782\tLR: 0.015000\nTraining Epoch: 9 [29184/50000]\tLoss: 0.3851\tLR: 0.015000\nTraining Epoch: 9 [29312/50000]\tLoss: 0.4867\tLR: 0.015000\nTraining Epoch: 9 [29440/50000]\tLoss: 0.5458\tLR: 0.015000\nTraining Epoch: 9 [29568/50000]\tLoss: 0.3327\tLR: 0.015000\nTraining Epoch: 9 [29696/50000]\tLoss: 0.4420\tLR: 0.015000\nTraining Epoch: 9 [29824/50000]\tLoss: 0.4575\tLR: 0.015000\nTraining Epoch: 9 [29952/50000]\tLoss: 0.4461\tLR: 0.015000\nTraining Epoch: 9 [30080/50000]\tLoss: 0.4126\tLR: 0.015000\nTraining Epoch: 9 [30208/50000]\tLoss: 0.3780\tLR: 0.015000\nTraining Epoch: 9 [30336/50000]\tLoss: 0.5500\tLR: 0.015000\nTraining Epoch: 9 [30464/50000]\tLoss: 0.4104\tLR: 0.015000\nTraining Epoch: 9 [30592/50000]\tLoss: 0.3720\tLR: 0.015000\nTraining Epoch: 9 [30720/50000]\tLoss: 0.3962\tLR: 0.015000\nTraining Epoch: 9 [30848/50000]\tLoss: 0.5561\tLR: 0.015000\nTraining Epoch: 9 [30976/50000]\tLoss: 0.3265\tLR: 0.015000\nTraining Epoch: 9 [31104/50000]\tLoss: 0.3682\tLR: 0.015000\nTraining Epoch: 9 [31232/50000]\tLoss: 0.4375\tLR: 0.015000\nTraining Epoch: 9 [31360/50000]\tLoss: 0.5439\tLR: 0.015000\nTraining Epoch: 9 [31488/50000]\tLoss: 0.3464\tLR: 0.015000\nTraining Epoch: 9 [31616/50000]\tLoss: 0.3953\tLR: 0.015000\nTraining Epoch: 9 [31744/50000]\tLoss: 0.3540\tLR: 0.015000\nTraining Epoch: 9 [31872/50000]\tLoss: 0.5051\tLR: 0.015000\nTraining Epoch: 9 [32000/50000]\tLoss: 0.2732\tLR: 0.015000\nTraining Epoch: 9 [32128/50000]\tLoss: 0.3569\tLR: 0.015000\nTraining Epoch: 9 [32256/50000]\tLoss: 0.4471\tLR: 0.015000\nTraining Epoch: 9 [32384/50000]\tLoss: 0.4186\tLR: 0.015000\nTraining Epoch: 9 [32512/50000]\tLoss: 0.3889\tLR: 0.015000\nTraining Epoch: 9 [32640/50000]\tLoss: 0.3507\tLR: 0.015000\nTraining Epoch: 9 [32768/50000]\tLoss: 0.5056\tLR: 0.015000\nTraining Epoch: 9 [32896/50000]\tLoss: 0.5136\tLR: 0.015000\nTraining Epoch: 9 [33024/50000]\tLoss: 0.4019\tLR: 0.015000\nTraining Epoch: 9 [33152/50000]\tLoss: 0.5051\tLR: 0.015000\nTraining Epoch: 9 [33280/50000]\tLoss: 0.5849\tLR: 0.015000\nTraining Epoch: 9 [33408/50000]\tLoss: 0.4061\tLR: 0.015000\nTraining Epoch: 9 [33536/50000]\tLoss: 0.4407\tLR: 0.015000\nTraining Epoch: 9 [33664/50000]\tLoss: 0.4811\tLR: 0.015000\nTraining Epoch: 9 [33792/50000]\tLoss: 0.4148\tLR: 0.015000\nTraining Epoch: 9 [33920/50000]\tLoss: 0.4335\tLR: 0.015000\nTraining Epoch: 9 [34048/50000]\tLoss: 0.4198\tLR: 0.015000\nTraining Epoch: 9 [34176/50000]\tLoss: 0.3733\tLR: 0.015000\nTraining Epoch: 9 [34304/50000]\tLoss: 0.5220\tLR: 0.015000\nTraining Epoch: 9 [34432/50000]\tLoss: 0.6625\tLR: 0.015000\nTraining Epoch: 9 [34560/50000]\tLoss: 0.3203\tLR: 0.015000\nTraining Epoch: 9 [34688/50000]\tLoss: 0.4924\tLR: 0.015000\nTraining Epoch: 9 [34816/50000]\tLoss: 0.4146\tLR: 0.015000\nTraining Epoch: 9 [34944/50000]\tLoss: 0.3877\tLR: 0.015000\nTraining Epoch: 9 [35072/50000]\tLoss: 0.3963\tLR: 0.015000\nTraining Epoch: 9 [35200/50000]\tLoss: 0.2828\tLR: 0.015000\nTraining Epoch: 9 [35328/50000]\tLoss: 0.3694\tLR: 0.015000\nTraining Epoch: 9 [35456/50000]\tLoss: 0.3170\tLR: 0.015000\nTraining Epoch: 9 [35584/50000]\tLoss: 0.3743\tLR: 0.015000\nTraining Epoch: 9 [35712/50000]\tLoss: 0.3283\tLR: 0.015000\nTraining Epoch: 9 [35840/50000]\tLoss: 0.3792\tLR: 0.015000\nTraining Epoch: 9 [35968/50000]\tLoss: 0.4099\tLR: 0.015000\nTraining Epoch: 9 [36096/50000]\tLoss: 0.2478\tLR: 0.015000\nTraining Epoch: 9 [36224/50000]\tLoss: 0.3915\tLR: 0.015000\nTraining Epoch: 9 [36352/50000]\tLoss: 0.4551\tLR: 0.015000\nTraining Epoch: 9 [36480/50000]\tLoss: 0.3789\tLR: 0.015000\nTraining Epoch: 9 [36608/50000]\tLoss: 0.3863\tLR: 0.015000\nTraining Epoch: 9 [36736/50000]\tLoss: 0.4088\tLR: 0.015000\nTraining Epoch: 9 [36864/50000]\tLoss: 0.4225\tLR: 0.015000\nTraining Epoch: 9 [36992/50000]\tLoss: 0.4597\tLR: 0.015000\nTraining Epoch: 9 [37120/50000]\tLoss: 0.2617\tLR: 0.015000\nTraining Epoch: 9 [37248/50000]\tLoss: 0.4645\tLR: 0.015000\nTraining Epoch: 9 [37376/50000]\tLoss: 0.4630\tLR: 0.015000\nTraining Epoch: 9 [37504/50000]\tLoss: 0.4097\tLR: 0.015000\nTraining Epoch: 9 [37632/50000]\tLoss: 0.3518\tLR: 0.015000\nTraining Epoch: 9 [37760/50000]\tLoss: 0.4294\tLR: 0.015000\nTraining Epoch: 9 [37888/50000]\tLoss: 0.2700\tLR: 0.015000\nTraining Epoch: 9 [38016/50000]\tLoss: 0.3764\tLR: 0.015000\nTraining Epoch: 9 [38144/50000]\tLoss: 0.4992\tLR: 0.015000\nTraining Epoch: 9 [38272/50000]\tLoss: 0.3585\tLR: 0.015000\nTraining Epoch: 9 [38400/50000]\tLoss: 0.3125\tLR: 0.015000\nTraining Epoch: 9 [38528/50000]\tLoss: 0.5339\tLR: 0.015000\nTraining Epoch: 9 [38656/50000]\tLoss: 0.3155\tLR: 0.015000\nTraining Epoch: 9 [38784/50000]\tLoss: 0.3622\tLR: 0.015000\nTraining Epoch: 9 [38912/50000]\tLoss: 0.4022\tLR: 0.015000\nTraining Epoch: 9 [39040/50000]\tLoss: 0.4522\tLR: 0.015000\nTraining Epoch: 9 [39168/50000]\tLoss: 0.4665\tLR: 0.015000\nTraining Epoch: 9 [39296/50000]\tLoss: 0.3908\tLR: 0.015000\nTraining Epoch: 9 [39424/50000]\tLoss: 0.5522\tLR: 0.015000\nTraining Epoch: 9 [39552/50000]\tLoss: 0.4159\tLR: 0.015000\nTraining Epoch: 9 [39680/50000]\tLoss: 0.4103\tLR: 0.015000\nTraining Epoch: 9 [39808/50000]\tLoss: 0.5439\tLR: 0.015000\nTraining Epoch: 9 [39936/50000]\tLoss: 0.6132\tLR: 0.015000\nTraining Epoch: 9 [40064/50000]\tLoss: 0.2914\tLR: 0.015000\nTraining Epoch: 9 [40192/50000]\tLoss: 0.3810\tLR: 0.015000\nTraining Epoch: 9 [40320/50000]\tLoss: 0.4983\tLR: 0.015000\nTraining Epoch: 9 [40448/50000]\tLoss: 0.3694\tLR: 0.015000\nTraining Epoch: 9 [40576/50000]\tLoss: 0.5515\tLR: 0.015000\nTraining Epoch: 9 [40704/50000]\tLoss: 0.4235\tLR: 0.015000\nTraining Epoch: 9 [40832/50000]\tLoss: 0.4802\tLR: 0.015000\nTraining Epoch: 9 [40960/50000]\tLoss: 0.4097\tLR: 0.015000\nTraining Epoch: 9 [41088/50000]\tLoss: 0.3381\tLR: 0.015000\nTraining Epoch: 9 [41216/50000]\tLoss: 0.3966\tLR: 0.015000\nTraining Epoch: 9 [41344/50000]\tLoss: 0.4686\tLR: 0.015000\nTraining Epoch: 9 [41472/50000]\tLoss: 0.3958\tLR: 0.015000\nTraining Epoch: 9 [41600/50000]\tLoss: 0.3823\tLR: 0.015000\nTraining Epoch: 9 [41728/50000]\tLoss: 0.4355\tLR: 0.015000\nTraining Epoch: 9 [41856/50000]\tLoss: 0.3227\tLR: 0.015000\nTraining Epoch: 9 [41984/50000]\tLoss: 0.3519\tLR: 0.015000\nTraining Epoch: 9 [42112/50000]\tLoss: 0.3990\tLR: 0.015000\nTraining Epoch: 9 [42240/50000]\tLoss: 0.4343\tLR: 0.015000\nTraining Epoch: 9 [42368/50000]\tLoss: 0.4723\tLR: 0.015000\nTraining Epoch: 9 [42496/50000]\tLoss: 0.3875\tLR: 0.015000\nTraining Epoch: 9 [42624/50000]\tLoss: 0.6328\tLR: 0.015000\nTraining Epoch: 9 [42752/50000]\tLoss: 0.3759\tLR: 0.015000\nTraining Epoch: 9 [42880/50000]\tLoss: 0.4157\tLR: 0.015000\nTraining Epoch: 9 [43008/50000]\tLoss: 0.5804\tLR: 0.015000\nTraining Epoch: 9 [43136/50000]\tLoss: 0.3755\tLR: 0.015000\nTraining Epoch: 9 [43264/50000]\tLoss: 0.5763\tLR: 0.015000\nTraining Epoch: 9 [43392/50000]\tLoss: 0.3050\tLR: 0.015000\nTraining Epoch: 9 [43520/50000]\tLoss: 0.3411\tLR: 0.015000\nTraining Epoch: 9 [43648/50000]\tLoss: 0.3854\tLR: 0.015000\nTraining Epoch: 9 [43776/50000]\tLoss: 0.4310\tLR: 0.015000\nTraining Epoch: 9 [43904/50000]\tLoss: 0.6728\tLR: 0.015000\nTraining Epoch: 9 [44032/50000]\tLoss: 0.4120\tLR: 0.015000\nTraining Epoch: 9 [44160/50000]\tLoss: 0.4162\tLR: 0.015000\nTraining Epoch: 9 [44288/50000]\tLoss: 0.3783\tLR: 0.015000\nTraining Epoch: 9 [44416/50000]\tLoss: 0.4178\tLR: 0.015000\nTraining Epoch: 9 [44544/50000]\tLoss: 0.3962\tLR: 0.015000\nTraining Epoch: 9 [44672/50000]\tLoss: 0.3640\tLR: 0.015000\nTraining Epoch: 9 [44800/50000]\tLoss: 0.4148\tLR: 0.015000\nTraining Epoch: 9 [44928/50000]\tLoss: 0.3989\tLR: 0.015000\nTraining Epoch: 9 [45056/50000]\tLoss: 0.4101\tLR: 0.015000\nTraining Epoch: 9 [45184/50000]\tLoss: 0.4197\tLR: 0.015000\nTraining Epoch: 9 [45312/50000]\tLoss: 0.4958\tLR: 0.015000\nTraining Epoch: 9 [45440/50000]\tLoss: 0.3642\tLR: 0.015000\nTraining Epoch: 9 [45568/50000]\tLoss: 0.4104\tLR: 0.015000\nTraining Epoch: 9 [45696/50000]\tLoss: 0.4432\tLR: 0.015000\nTraining Epoch: 9 [45824/50000]\tLoss: 0.4415\tLR: 0.015000\nTraining Epoch: 9 [45952/50000]\tLoss: 0.3388\tLR: 0.015000\nTraining Epoch: 9 [46080/50000]\tLoss: 0.3184\tLR: 0.015000\nTraining Epoch: 9 [46208/50000]\tLoss: 0.4754\tLR: 0.015000\nTraining Epoch: 9 [46336/50000]\tLoss: 0.3200\tLR: 0.015000\nTraining Epoch: 9 [46464/50000]\tLoss: 0.4541\tLR: 0.015000\nTraining Epoch: 9 [46592/50000]\tLoss: 0.4440\tLR: 0.015000\nTraining Epoch: 9 [46720/50000]\tLoss: 0.4047\tLR: 0.015000\nTraining Epoch: 9 [46848/50000]\tLoss: 0.4736\tLR: 0.015000\nTraining Epoch: 9 [46976/50000]\tLoss: 0.3879\tLR: 0.015000\nTraining Epoch: 9 [47104/50000]\tLoss: 0.3515\tLR: 0.015000\nTraining Epoch: 9 [47232/50000]\tLoss: 0.4660\tLR: 0.015000\nTraining Epoch: 9 [47360/50000]\tLoss: 0.3829\tLR: 0.015000\nTraining Epoch: 9 [47488/50000]\tLoss: 0.4439\tLR: 0.015000\nTraining Epoch: 9 [47616/50000]\tLoss: 0.3845\tLR: 0.015000\nTraining Epoch: 9 [47744/50000]\tLoss: 0.4601\tLR: 0.015000\nTraining Epoch: 9 [47872/50000]\tLoss: 0.3906\tLR: 0.015000\nTraining Epoch: 9 [48000/50000]\tLoss: 0.3574\tLR: 0.015000\nTraining Epoch: 9 [48128/50000]\tLoss: 0.3339\tLR: 0.015000\nTraining Epoch: 9 [48256/50000]\tLoss: 0.6207\tLR: 0.015000\nTraining Epoch: 9 [48384/50000]\tLoss: 0.7004\tLR: 0.015000\nTraining Epoch: 9 [48512/50000]\tLoss: 0.4264\tLR: 0.015000\nTraining Epoch: 9 [48640/50000]\tLoss: 0.4667\tLR: 0.015000\nTraining Epoch: 9 [48768/50000]\tLoss: 0.3899\tLR: 0.015000\nTraining Epoch: 9 [48896/50000]\tLoss: 0.5345\tLR: 0.015000\nTraining Epoch: 9 [49024/50000]\tLoss: 0.5655\tLR: 0.015000\nTraining Epoch: 9 [49152/50000]\tLoss: 0.4167\tLR: 0.015000\nTraining Epoch: 9 [49280/50000]\tLoss: 0.4199\tLR: 0.015000\nTraining Epoch: 9 [49408/50000]\tLoss: 0.3576\tLR: 0.015000\nTraining Epoch: 9 [49536/50000]\tLoss: 0.3359\tLR: 0.015000\nTraining Epoch: 9 [49664/50000]\tLoss: 0.3293\tLR: 0.015000\nTraining Epoch: 9 [49792/50000]\tLoss: 0.4993\tLR: 0.015000\nTraining Epoch: 9 [49920/50000]\tLoss: 0.4143\tLR: 0.015000\nTraining Epoch: 9 [50000/50000]\tLoss: 0.6868\tLR: 0.015000\nTest set: Average loss: 0.0033, Accuracy: 0.8547\n\nTraining Epoch: 10 [128/50000]\tLoss: 0.4926\tLR: 0.015000\nTraining Epoch: 10 [256/50000]\tLoss: 0.3123\tLR: 0.015000\nTraining Epoch: 10 [384/50000]\tLoss: 0.4263\tLR: 0.015000\nTraining Epoch: 10 [512/50000]\tLoss: 0.2919\tLR: 0.015000\nTraining Epoch: 10 [640/50000]\tLoss: 0.3712\tLR: 0.015000\nTraining Epoch: 10 [768/50000]\tLoss: 0.3313\tLR: 0.015000\nTraining Epoch: 10 [896/50000]\tLoss: 0.3674\tLR: 0.015000\nTraining Epoch: 10 [1024/50000]\tLoss: 0.4907\tLR: 0.015000\nTraining Epoch: 10 [1152/50000]\tLoss: 0.4593\tLR: 0.015000\nTraining Epoch: 10 [1280/50000]\tLoss: 0.5450\tLR: 0.015000\nTraining Epoch: 10 [1408/50000]\tLoss: 0.4696\tLR: 0.015000\nTraining Epoch: 10 [1536/50000]\tLoss: 0.4466\tLR: 0.015000\nTraining Epoch: 10 [1664/50000]\tLoss: 0.3510\tLR: 0.015000\nTraining Epoch: 10 [1792/50000]\tLoss: 0.4233\tLR: 0.015000\nTraining Epoch: 10 [1920/50000]\tLoss: 0.4567\tLR: 0.015000\nTraining Epoch: 10 [2048/50000]\tLoss: 0.4119\tLR: 0.015000\nTraining Epoch: 10 [2176/50000]\tLoss: 0.4273\tLR: 0.015000\nTraining Epoch: 10 [2304/50000]\tLoss: 0.5086\tLR: 0.015000\nTraining Epoch: 10 [2432/50000]\tLoss: 0.3710\tLR: 0.015000\nTraining Epoch: 10 [2560/50000]\tLoss: 0.4540\tLR: 0.015000\nTraining Epoch: 10 [2688/50000]\tLoss: 0.3466\tLR: 0.015000\nTraining Epoch: 10 [2816/50000]\tLoss: 0.4702\tLR: 0.015000\nTraining Epoch: 10 [2944/50000]\tLoss: 0.4059\tLR: 0.015000\nTraining Epoch: 10 [3072/50000]\tLoss: 0.5181\tLR: 0.015000\nTraining Epoch: 10 [3200/50000]\tLoss: 0.4721\tLR: 0.015000\nTraining Epoch: 10 [3328/50000]\tLoss: 0.3934\tLR: 0.015000\nTraining Epoch: 10 [3456/50000]\tLoss: 0.3356\tLR: 0.015000\nTraining Epoch: 10 [3584/50000]\tLoss: 0.3976\tLR: 0.015000\nTraining Epoch: 10 [3712/50000]\tLoss: 0.3356\tLR: 0.015000\nTraining Epoch: 10 [3840/50000]\tLoss: 0.3934\tLR: 0.015000\nTraining Epoch: 10 [3968/50000]\tLoss: 0.4723\tLR: 0.015000\nTraining Epoch: 10 [4096/50000]\tLoss: 0.4028\tLR: 0.015000\nTraining Epoch: 10 [4224/50000]\tLoss: 0.4119\tLR: 0.015000\nTraining Epoch: 10 [4352/50000]\tLoss: 0.3781\tLR: 0.015000\nTraining Epoch: 10 [4480/50000]\tLoss: 0.4789\tLR: 0.015000\nTraining Epoch: 10 [4608/50000]\tLoss: 0.4098\tLR: 0.015000\nTraining Epoch: 10 [4736/50000]\tLoss: 0.3962\tLR: 0.015000\nTraining Epoch: 10 [4864/50000]\tLoss: 0.3318\tLR: 0.015000\nTraining Epoch: 10 [4992/50000]\tLoss: 0.4976\tLR: 0.015000\nTraining Epoch: 10 [5120/50000]\tLoss: 0.4933\tLR: 0.015000\nTraining Epoch: 10 [5248/50000]\tLoss: 0.3599\tLR: 0.015000\nTraining Epoch: 10 [5376/50000]\tLoss: 0.2628\tLR: 0.015000\nTraining Epoch: 10 [5504/50000]\tLoss: 0.4441\tLR: 0.015000\nTraining Epoch: 10 [5632/50000]\tLoss: 0.3471\tLR: 0.015000\nTraining Epoch: 10 [5760/50000]\tLoss: 0.3511\tLR: 0.015000\nTraining Epoch: 10 [5888/50000]\tLoss: 0.4598\tLR: 0.015000\nTraining Epoch: 10 [6016/50000]\tLoss: 0.4847\tLR: 0.015000\nTraining Epoch: 10 [6144/50000]\tLoss: 0.2631\tLR: 0.015000\nTraining Epoch: 10 [6272/50000]\tLoss: 0.3791\tLR: 0.015000\nTraining Epoch: 10 [6400/50000]\tLoss: 0.4731\tLR: 0.015000\nTraining Epoch: 10 [6528/50000]\tLoss: 0.4068\tLR: 0.015000\nTraining Epoch: 10 [6656/50000]\tLoss: 0.3256\tLR: 0.015000\nTraining Epoch: 10 [6784/50000]\tLoss: 0.4470\tLR: 0.015000\nTraining Epoch: 10 [6912/50000]\tLoss: 0.4366\tLR: 0.015000\nTraining Epoch: 10 [7040/50000]\tLoss: 0.3689\tLR: 0.015000\nTraining Epoch: 10 [7168/50000]\tLoss: 0.3237\tLR: 0.015000\nTraining Epoch: 10 [7296/50000]\tLoss: 0.3796\tLR: 0.015000\nTraining Epoch: 10 [7424/50000]\tLoss: 0.3295\tLR: 0.015000\nTraining Epoch: 10 [7552/50000]\tLoss: 0.5336\tLR: 0.015000\nTraining Epoch: 10 [7680/50000]\tLoss: 0.4304\tLR: 0.015000\nTraining Epoch: 10 [7808/50000]\tLoss: 0.3899\tLR: 0.015000\nTraining Epoch: 10 [7936/50000]\tLoss: 0.4733\tLR: 0.015000\nTraining Epoch: 10 [8064/50000]\tLoss: 0.3774\tLR: 0.015000\nTraining Epoch: 10 [8192/50000]\tLoss: 0.4648\tLR: 0.015000\nTraining Epoch: 10 [8320/50000]\tLoss: 0.5114\tLR: 0.015000\nTraining Epoch: 10 [8448/50000]\tLoss: 0.4911\tLR: 0.015000\nTraining Epoch: 10 [8576/50000]\tLoss: 0.2401\tLR: 0.015000\nTraining Epoch: 10 [8704/50000]\tLoss: 0.3605\tLR: 0.015000\nTraining Epoch: 10 [8832/50000]\tLoss: 0.4784\tLR: 0.015000\nTraining Epoch: 10 [8960/50000]\tLoss: 0.3995\tLR: 0.015000\nTraining Epoch: 10 [9088/50000]\tLoss: 0.3119\tLR: 0.015000\nTraining Epoch: 10 [9216/50000]\tLoss: 0.3310\tLR: 0.015000\nTraining Epoch: 10 [9344/50000]\tLoss: 0.4687\tLR: 0.015000\nTraining Epoch: 10 [9472/50000]\tLoss: 0.4877\tLR: 0.015000\nTraining Epoch: 10 [9600/50000]\tLoss: 0.4587\tLR: 0.015000\nTraining Epoch: 10 [9728/50000]\tLoss: 0.5012\tLR: 0.015000\nTraining Epoch: 10 [9856/50000]\tLoss: 0.4439\tLR: 0.015000\nTraining Epoch: 10 [9984/50000]\tLoss: 0.4296\tLR: 0.015000\nTraining Epoch: 10 [10112/50000]\tLoss: 0.4041\tLR: 0.015000\nTraining Epoch: 10 [10240/50000]\tLoss: 0.3261\tLR: 0.015000\nTraining Epoch: 10 [10368/50000]\tLoss: 0.3444\tLR: 0.015000\nTraining Epoch: 10 [10496/50000]\tLoss: 0.4418\tLR: 0.015000\nTraining Epoch: 10 [10624/50000]\tLoss: 0.4575\tLR: 0.015000\nTraining Epoch: 10 [10752/50000]\tLoss: 0.3750\tLR: 0.015000\nTraining Epoch: 10 [10880/50000]\tLoss: 0.3452\tLR: 0.015000\nTraining Epoch: 10 [11008/50000]\tLoss: 0.5682\tLR: 0.015000\nTraining Epoch: 10 [11136/50000]\tLoss: 0.3242\tLR: 0.015000\nTraining Epoch: 10 [11264/50000]\tLoss: 0.4354\tLR: 0.015000\nTraining Epoch: 10 [11392/50000]\tLoss: 0.3834\tLR: 0.015000\nTraining Epoch: 10 [11520/50000]\tLoss: 0.4205\tLR: 0.015000\nTraining Epoch: 10 [11648/50000]\tLoss: 0.4690\tLR: 0.015000\nTraining Epoch: 10 [11776/50000]\tLoss: 0.3485\tLR: 0.015000\nTraining Epoch: 10 [11904/50000]\tLoss: 0.3674\tLR: 0.015000\nTraining Epoch: 10 [12032/50000]\tLoss: 0.5810\tLR: 0.015000\nTraining Epoch: 10 [12160/50000]\tLoss: 0.5047\tLR: 0.015000\nTraining Epoch: 10 [12288/50000]\tLoss: 0.3440\tLR: 0.015000\nTraining Epoch: 10 [12416/50000]\tLoss: 0.3963\tLR: 0.015000\nTraining Epoch: 10 [12544/50000]\tLoss: 0.3899\tLR: 0.015000\nTraining Epoch: 10 [12672/50000]\tLoss: 0.3744\tLR: 0.015000\nTraining Epoch: 10 [12800/50000]\tLoss: 0.3164\tLR: 0.015000\nTraining Epoch: 10 [12928/50000]\tLoss: 0.3609\tLR: 0.015000\nTraining Epoch: 10 [13056/50000]\tLoss: 0.3759\tLR: 0.015000\nTraining Epoch: 10 [13184/50000]\tLoss: 0.4012\tLR: 0.015000\nTraining Epoch: 10 [13312/50000]\tLoss: 0.4310\tLR: 0.015000\nTraining Epoch: 10 [13440/50000]\tLoss: 0.4219\tLR: 0.015000\nTraining Epoch: 10 [13568/50000]\tLoss: 0.4301\tLR: 0.015000\nTraining Epoch: 10 [13696/50000]\tLoss: 0.4234\tLR: 0.015000\nTraining Epoch: 10 [13824/50000]\tLoss: 0.3898\tLR: 0.015000\nTraining Epoch: 10 [13952/50000]\tLoss: 0.5437\tLR: 0.015000\nTraining Epoch: 10 [14080/50000]\tLoss: 0.3965\tLR: 0.015000\nTraining Epoch: 10 [14208/50000]\tLoss: 0.4586\tLR: 0.015000\nTraining Epoch: 10 [14336/50000]\tLoss: 0.4802\tLR: 0.015000\nTraining Epoch: 10 [14464/50000]\tLoss: 0.3682\tLR: 0.015000\nTraining Epoch: 10 [14592/50000]\tLoss: 0.4174\tLR: 0.015000\nTraining Epoch: 10 [14720/50000]\tLoss: 0.4673\tLR: 0.015000\nTraining Epoch: 10 [14848/50000]\tLoss: 0.2769\tLR: 0.015000\nTraining Epoch: 10 [14976/50000]\tLoss: 0.2077\tLR: 0.015000\nTraining Epoch: 10 [15104/50000]\tLoss: 0.3981\tLR: 0.015000\nTraining Epoch: 10 [15232/50000]\tLoss: 0.3166\tLR: 0.015000\nTraining Epoch: 10 [15360/50000]\tLoss: 0.3018\tLR: 0.015000\nTraining Epoch: 10 [15488/50000]\tLoss: 0.4810\tLR: 0.015000\nTraining Epoch: 10 [15616/50000]\tLoss: 0.4499\tLR: 0.015000\nTraining Epoch: 10 [15744/50000]\tLoss: 0.3544\tLR: 0.015000\nTraining Epoch: 10 [15872/50000]\tLoss: 0.4428\tLR: 0.015000\nTraining Epoch: 10 [16000/50000]\tLoss: 0.4384\tLR: 0.015000\nTraining Epoch: 10 [16128/50000]\tLoss: 0.4502\tLR: 0.015000\nTraining Epoch: 10 [16256/50000]\tLoss: 0.4448\tLR: 0.015000\nTraining Epoch: 10 [16384/50000]\tLoss: 0.3501\tLR: 0.015000\nTraining Epoch: 10 [16512/50000]\tLoss: 0.4842\tLR: 0.015000\nTraining Epoch: 10 [16640/50000]\tLoss: 0.3424\tLR: 0.015000\nTraining Epoch: 10 [16768/50000]\tLoss: 0.3762\tLR: 0.015000\nTraining Epoch: 10 [16896/50000]\tLoss: 0.4153\tLR: 0.015000\nTraining Epoch: 10 [17024/50000]\tLoss: 0.3966\tLR: 0.015000\nTraining Epoch: 10 [17152/50000]\tLoss: 0.4627\tLR: 0.015000\nTraining Epoch: 10 [17280/50000]\tLoss: 0.2795\tLR: 0.015000\nTraining Epoch: 10 [17408/50000]\tLoss: 0.3784\tLR: 0.015000\nTraining Epoch: 10 [17536/50000]\tLoss: 0.3701\tLR: 0.015000\nTraining Epoch: 10 [17664/50000]\tLoss: 0.4429\tLR: 0.015000\nTraining Epoch: 10 [17792/50000]\tLoss: 0.6818\tLR: 0.015000\nTraining Epoch: 10 [17920/50000]\tLoss: 0.2233\tLR: 0.015000\nTraining Epoch: 10 [18048/50000]\tLoss: 0.3594\tLR: 0.015000\nTraining Epoch: 10 [18176/50000]\tLoss: 0.4720\tLR: 0.015000\nTraining Epoch: 10 [18304/50000]\tLoss: 0.4612\tLR: 0.015000\nTraining Epoch: 10 [18432/50000]\tLoss: 0.5285\tLR: 0.015000\nTraining Epoch: 10 [18560/50000]\tLoss: 0.4156\tLR: 0.015000\nTraining Epoch: 10 [18688/50000]\tLoss: 0.3696\tLR: 0.015000\nTraining Epoch: 10 [18816/50000]\tLoss: 0.4170\tLR: 0.015000\nTraining Epoch: 10 [18944/50000]\tLoss: 0.3748\tLR: 0.015000\nTraining Epoch: 10 [19072/50000]\tLoss: 0.3923\tLR: 0.015000\nTraining Epoch: 10 [19200/50000]\tLoss: 0.2654\tLR: 0.015000\nTraining Epoch: 10 [19328/50000]\tLoss: 0.4092\tLR: 0.015000\nTraining Epoch: 10 [19456/50000]\tLoss: 0.2544\tLR: 0.015000\nTraining Epoch: 10 [19584/50000]\tLoss: 0.4438\tLR: 0.015000\nTraining Epoch: 10 [19712/50000]\tLoss: 0.3478\tLR: 0.015000\nTraining Epoch: 10 [19840/50000]\tLoss: 0.3609\tLR: 0.015000\nTraining Epoch: 10 [19968/50000]\tLoss: 0.3863\tLR: 0.015000\nTraining Epoch: 10 [20096/50000]\tLoss: 0.5654\tLR: 0.015000\nTraining Epoch: 10 [20224/50000]\tLoss: 0.4243\tLR: 0.015000\nTraining Epoch: 10 [20352/50000]\tLoss: 0.4351\tLR: 0.015000\nTraining Epoch: 10 [20480/50000]\tLoss: 0.4447\tLR: 0.015000\nTraining Epoch: 10 [20608/50000]\tLoss: 0.3911\tLR: 0.015000\nTraining Epoch: 10 [20736/50000]\tLoss: 0.3039\tLR: 0.015000\nTraining Epoch: 10 [20864/50000]\tLoss: 0.4013\tLR: 0.015000\nTraining Epoch: 10 [20992/50000]\tLoss: 0.4162\tLR: 0.015000\nTraining Epoch: 10 [21120/50000]\tLoss: 0.4410\tLR: 0.015000\nTraining Epoch: 10 [21248/50000]\tLoss: 0.3572\tLR: 0.015000\nTraining Epoch: 10 [21376/50000]\tLoss: 0.4388\tLR: 0.015000\nTraining Epoch: 10 [21504/50000]\tLoss: 0.3931\tLR: 0.015000\nTraining Epoch: 10 [21632/50000]\tLoss: 0.4559\tLR: 0.015000\nTraining Epoch: 10 [21760/50000]\tLoss: 0.4036\tLR: 0.015000\nTraining Epoch: 10 [21888/50000]\tLoss: 0.4237\tLR: 0.015000\nTraining Epoch: 10 [22016/50000]\tLoss: 0.4639\tLR: 0.015000\nTraining Epoch: 10 [22144/50000]\tLoss: 0.2929\tLR: 0.015000\nTraining Epoch: 10 [22272/50000]\tLoss: 0.3775\tLR: 0.015000\nTraining Epoch: 10 [22400/50000]\tLoss: 0.3693\tLR: 0.015000\nTraining Epoch: 10 [22528/50000]\tLoss: 0.4327\tLR: 0.015000\nTraining Epoch: 10 [22656/50000]\tLoss: 0.3905\tLR: 0.015000\nTraining Epoch: 10 [22784/50000]\tLoss: 0.4403\tLR: 0.015000\nTraining Epoch: 10 [22912/50000]\tLoss: 0.4052\tLR: 0.015000\nTraining Epoch: 10 [23040/50000]\tLoss: 0.3170\tLR: 0.015000\nTraining Epoch: 10 [23168/50000]\tLoss: 0.4349\tLR: 0.015000\nTraining Epoch: 10 [23296/50000]\tLoss: 0.4173\tLR: 0.015000\nTraining Epoch: 10 [23424/50000]\tLoss: 0.3316\tLR: 0.015000\nTraining Epoch: 10 [23552/50000]\tLoss: 0.3591\tLR: 0.015000\nTraining Epoch: 10 [23680/50000]\tLoss: 0.4625\tLR: 0.015000\nTraining Epoch: 10 [23808/50000]\tLoss: 0.4740\tLR: 0.015000\nTraining Epoch: 10 [23936/50000]\tLoss: 0.4264\tLR: 0.015000\nTraining Epoch: 10 [24064/50000]\tLoss: 0.1968\tLR: 0.015000\nTraining Epoch: 10 [24192/50000]\tLoss: 0.4757\tLR: 0.015000\nTraining Epoch: 10 [24320/50000]\tLoss: 0.4559\tLR: 0.015000\nTraining Epoch: 10 [24448/50000]\tLoss: 0.4297\tLR: 0.015000\nTraining Epoch: 10 [24576/50000]\tLoss: 0.3994\tLR: 0.015000\nTraining Epoch: 10 [24704/50000]\tLoss: 0.3523\tLR: 0.015000\nTraining Epoch: 10 [24832/50000]\tLoss: 0.4046\tLR: 0.015000\nTraining Epoch: 10 [24960/50000]\tLoss: 0.3779\tLR: 0.015000\nTraining Epoch: 10 [25088/50000]\tLoss: 0.3649\tLR: 0.015000\nTraining Epoch: 10 [25216/50000]\tLoss: 0.3852\tLR: 0.015000\nTraining Epoch: 10 [25344/50000]\tLoss: 0.3804\tLR: 0.015000\nTraining Epoch: 10 [25472/50000]\tLoss: 0.3433\tLR: 0.015000\nTraining Epoch: 10 [25600/50000]\tLoss: 0.4161\tLR: 0.015000\nTraining Epoch: 10 [25728/50000]\tLoss: 0.3927\tLR: 0.015000\nTraining Epoch: 10 [25856/50000]\tLoss: 0.4667\tLR: 0.015000\nTraining Epoch: 10 [25984/50000]\tLoss: 0.3419\tLR: 0.015000\nTraining Epoch: 10 [26112/50000]\tLoss: 0.2687\tLR: 0.015000\nTraining Epoch: 10 [26240/50000]\tLoss: 0.4038\tLR: 0.015000\nTraining Epoch: 10 [26368/50000]\tLoss: 0.4602\tLR: 0.015000\nTraining Epoch: 10 [26496/50000]\tLoss: 0.3482\tLR: 0.015000\nTraining Epoch: 10 [26624/50000]\tLoss: 0.2560\tLR: 0.015000\nTraining Epoch: 10 [26752/50000]\tLoss: 0.5846\tLR: 0.015000\nTraining Epoch: 10 [26880/50000]\tLoss: 0.5543\tLR: 0.015000\nTraining Epoch: 10 [27008/50000]\tLoss: 0.3762\tLR: 0.015000\nTraining Epoch: 10 [27136/50000]\tLoss: 0.3253\tLR: 0.015000\nTraining Epoch: 10 [27264/50000]\tLoss: 0.4089\tLR: 0.015000\nTraining Epoch: 10 [27392/50000]\tLoss: 0.3439\tLR: 0.015000\nTraining Epoch: 10 [27520/50000]\tLoss: 0.5820\tLR: 0.015000\nTraining Epoch: 10 [27648/50000]\tLoss: 0.4630\tLR: 0.015000\nTraining Epoch: 10 [27776/50000]\tLoss: 0.4627\tLR: 0.015000\nTraining Epoch: 10 [27904/50000]\tLoss: 0.4563\tLR: 0.015000\nTraining Epoch: 10 [28032/50000]\tLoss: 0.2780\tLR: 0.015000\nTraining Epoch: 10 [28160/50000]\tLoss: 0.3925\tLR: 0.015000\nTraining Epoch: 10 [28288/50000]\tLoss: 0.4361\tLR: 0.015000\nTraining Epoch: 10 [28416/50000]\tLoss: 0.3924\tLR: 0.015000\nTraining Epoch: 10 [28544/50000]\tLoss: 0.4190\tLR: 0.015000\nTraining Epoch: 10 [28672/50000]\tLoss: 0.2684\tLR: 0.015000\nTraining Epoch: 10 [28800/50000]\tLoss: 0.3234\tLR: 0.015000\nTraining Epoch: 10 [28928/50000]\tLoss: 0.3461\tLR: 0.015000\nTraining Epoch: 10 [29056/50000]\tLoss: 0.4003\tLR: 0.015000\nTraining Epoch: 10 [29184/50000]\tLoss: 0.4520\tLR: 0.015000\nTraining Epoch: 10 [29312/50000]\tLoss: 0.3577\tLR: 0.015000\nTraining Epoch: 10 [29440/50000]\tLoss: 0.4518\tLR: 0.015000\nTraining Epoch: 10 [29568/50000]\tLoss: 0.4415\tLR: 0.015000\nTraining Epoch: 10 [29696/50000]\tLoss: 0.3589\tLR: 0.015000\nTraining Epoch: 10 [29824/50000]\tLoss: 0.3523\tLR: 0.015000\nTraining Epoch: 10 [29952/50000]\tLoss: 0.3192\tLR: 0.015000\nTraining Epoch: 10 [30080/50000]\tLoss: 0.5213\tLR: 0.015000\nTraining Epoch: 10 [30208/50000]\tLoss: 0.3349\tLR: 0.015000\nTraining Epoch: 10 [30336/50000]\tLoss: 0.3707\tLR: 0.015000\nTraining Epoch: 10 [30464/50000]\tLoss: 0.3806\tLR: 0.015000\nTraining Epoch: 10 [30592/50000]\tLoss: 0.3087\tLR: 0.015000\nTraining Epoch: 10 [30720/50000]\tLoss: 0.2559\tLR: 0.015000\nTraining Epoch: 10 [30848/50000]\tLoss: 0.4525\tLR: 0.015000\nTraining Epoch: 10 [30976/50000]\tLoss: 0.3331\tLR: 0.015000\nTraining Epoch: 10 [31104/50000]\tLoss: 0.4498\tLR: 0.015000\nTraining Epoch: 10 [31232/50000]\tLoss: 0.3503\tLR: 0.015000\nTraining Epoch: 10 [31360/50000]\tLoss: 0.3160\tLR: 0.015000\nTraining Epoch: 10 [31488/50000]\tLoss: 0.4017\tLR: 0.015000\nTraining Epoch: 10 [31616/50000]\tLoss: 0.3435\tLR: 0.015000\nTraining Epoch: 10 [31744/50000]\tLoss: 0.3571\tLR: 0.015000\nTraining Epoch: 10 [31872/50000]\tLoss: 0.5035\tLR: 0.015000\nTraining Epoch: 10 [32000/50000]\tLoss: 0.3598\tLR: 0.015000\nTraining Epoch: 10 [32128/50000]\tLoss: 0.5237\tLR: 0.015000\nTraining Epoch: 10 [32256/50000]\tLoss: 0.4111\tLR: 0.015000\nTraining Epoch: 10 [32384/50000]\tLoss: 0.5137\tLR: 0.015000\nTraining Epoch: 10 [32512/50000]\tLoss: 0.4337\tLR: 0.015000\nTraining Epoch: 10 [32640/50000]\tLoss: 0.3440\tLR: 0.015000\nTraining Epoch: 10 [32768/50000]\tLoss: 0.4248\tLR: 0.015000\nTraining Epoch: 10 [32896/50000]\tLoss: 0.3032\tLR: 0.015000\nTraining Epoch: 10 [33024/50000]\tLoss: 0.4469\tLR: 0.015000\nTraining Epoch: 10 [33152/50000]\tLoss: 0.3896\tLR: 0.015000\nTraining Epoch: 10 [33280/50000]\tLoss: 0.3985\tLR: 0.015000\nTraining Epoch: 10 [33408/50000]\tLoss: 0.3612\tLR: 0.015000\nTraining Epoch: 10 [33536/50000]\tLoss: 0.4221\tLR: 0.015000\nTraining Epoch: 10 [33664/50000]\tLoss: 0.4157\tLR: 0.015000\nTraining Epoch: 10 [33792/50000]\tLoss: 0.4426\tLR: 0.015000\nTraining Epoch: 10 [33920/50000]\tLoss: 0.3755\tLR: 0.015000\nTraining Epoch: 10 [34048/50000]\tLoss: 0.3565\tLR: 0.015000\nTraining Epoch: 10 [34176/50000]\tLoss: 0.6540\tLR: 0.015000\nTraining Epoch: 10 [34304/50000]\tLoss: 0.5194\tLR: 0.015000\nTraining Epoch: 10 [34432/50000]\tLoss: 0.4706\tLR: 0.015000\nTraining Epoch: 10 [34560/50000]\tLoss: 0.3968\tLR: 0.015000\nTraining Epoch: 10 [34688/50000]\tLoss: 0.3941\tLR: 0.015000\nTraining Epoch: 10 [34816/50000]\tLoss: 0.4856\tLR: 0.015000\nTraining Epoch: 10 [34944/50000]\tLoss: 0.4498\tLR: 0.015000\nTraining Epoch: 10 [35072/50000]\tLoss: 0.4054\tLR: 0.015000\nTraining Epoch: 10 [35200/50000]\tLoss: 0.5228\tLR: 0.015000\nTraining Epoch: 10 [35328/50000]\tLoss: 0.5598\tLR: 0.015000\nTraining Epoch: 10 [35456/50000]\tLoss: 0.5259\tLR: 0.015000\nTraining Epoch: 10 [35584/50000]\tLoss: 0.3220\tLR: 0.015000\nTraining Epoch: 10 [35712/50000]\tLoss: 0.3812\tLR: 0.015000\nTraining Epoch: 10 [35840/50000]\tLoss: 0.3156\tLR: 0.015000\nTraining Epoch: 10 [35968/50000]\tLoss: 0.4058\tLR: 0.015000\nTraining Epoch: 10 [36096/50000]\tLoss: 0.5202\tLR: 0.015000\nTraining Epoch: 10 [36224/50000]\tLoss: 0.4441\tLR: 0.015000\nTraining Epoch: 10 [36352/50000]\tLoss: 0.3566\tLR: 0.015000\nTraining Epoch: 10 [36480/50000]\tLoss: 0.3534\tLR: 0.015000\nTraining Epoch: 10 [36608/50000]\tLoss: 0.2803\tLR: 0.015000\nTraining Epoch: 10 [36736/50000]\tLoss: 0.4027\tLR: 0.015000\nTraining Epoch: 10 [36864/50000]\tLoss: 0.4126\tLR: 0.015000\nTraining Epoch: 10 [36992/50000]\tLoss: 0.3550\tLR: 0.015000\nTraining Epoch: 10 [37120/50000]\tLoss: 0.2936\tLR: 0.015000\nTraining Epoch: 10 [37248/50000]\tLoss: 0.4765\tLR: 0.015000\nTraining Epoch: 10 [37376/50000]\tLoss: 0.5585\tLR: 0.015000\nTraining Epoch: 10 [37504/50000]\tLoss: 0.4392\tLR: 0.015000\nTraining Epoch: 10 [37632/50000]\tLoss: 0.5799\tLR: 0.015000\nTraining Epoch: 10 [37760/50000]\tLoss: 0.3787\tLR: 0.015000\nTraining Epoch: 10 [37888/50000]\tLoss: 0.4720\tLR: 0.015000\nTraining Epoch: 10 [38016/50000]\tLoss: 0.5026\tLR: 0.015000\nTraining Epoch: 10 [38144/50000]\tLoss: 0.2940\tLR: 0.015000\nTraining Epoch: 10 [38272/50000]\tLoss: 0.2628\tLR: 0.015000\nTraining Epoch: 10 [38400/50000]\tLoss: 0.4783\tLR: 0.015000\nTraining Epoch: 10 [38528/50000]\tLoss: 0.3490\tLR: 0.015000\nTraining Epoch: 10 [38656/50000]\tLoss: 0.3438\tLR: 0.015000\nTraining Epoch: 10 [38784/50000]\tLoss: 0.3351\tLR: 0.015000\nTraining Epoch: 10 [38912/50000]\tLoss: 0.4062\tLR: 0.015000\nTraining Epoch: 10 [39040/50000]\tLoss: 0.4069\tLR: 0.015000\nTraining Epoch: 10 [39168/50000]\tLoss: 0.4585\tLR: 0.015000\nTraining Epoch: 10 [39296/50000]\tLoss: 0.4181\tLR: 0.015000\nTraining Epoch: 10 [39424/50000]\tLoss: 0.3860\tLR: 0.015000\nTraining Epoch: 10 [39552/50000]\tLoss: 0.5619\tLR: 0.015000\nTraining Epoch: 10 [39680/50000]\tLoss: 0.3184\tLR: 0.015000\nTraining Epoch: 10 [39808/50000]\tLoss: 0.5203\tLR: 0.015000\nTraining Epoch: 10 [39936/50000]\tLoss: 0.3798\tLR: 0.015000\nTraining Epoch: 10 [40064/50000]\tLoss: 0.3776\tLR: 0.015000\nTraining Epoch: 10 [40192/50000]\tLoss: 0.2637\tLR: 0.015000\nTraining Epoch: 10 [40320/50000]\tLoss: 0.4189\tLR: 0.015000\nTraining Epoch: 10 [40448/50000]\tLoss: 0.4346\tLR: 0.015000\nTraining Epoch: 10 [40576/50000]\tLoss: 0.4265\tLR: 0.015000\nTraining Epoch: 10 [40704/50000]\tLoss: 0.4327\tLR: 0.015000\nTraining Epoch: 10 [40832/50000]\tLoss: 0.2936\tLR: 0.015000\nTraining Epoch: 10 [40960/50000]\tLoss: 0.2831\tLR: 0.015000\nTraining Epoch: 10 [41088/50000]\tLoss: 0.3673\tLR: 0.015000\nTraining Epoch: 10 [41216/50000]\tLoss: 0.3173\tLR: 0.015000\nTraining Epoch: 10 [41344/50000]\tLoss: 0.4777\tLR: 0.015000\nTraining Epoch: 10 [41472/50000]\tLoss: 0.3218\tLR: 0.015000\nTraining Epoch: 10 [41600/50000]\tLoss: 0.4742\tLR: 0.015000\nTraining Epoch: 10 [41728/50000]\tLoss: 0.4052\tLR: 0.015000\nTraining Epoch: 10 [41856/50000]\tLoss: 0.3186\tLR: 0.015000\nTraining Epoch: 10 [41984/50000]\tLoss: 0.3935\tLR: 0.015000\nTraining Epoch: 10 [42112/50000]\tLoss: 0.3705\tLR: 0.015000\nTraining Epoch: 10 [42240/50000]\tLoss: 0.3131\tLR: 0.015000\nTraining Epoch: 10 [42368/50000]\tLoss: 0.6055\tLR: 0.015000\nTraining Epoch: 10 [42496/50000]\tLoss: 0.3008\tLR: 0.015000\nTraining Epoch: 10 [42624/50000]\tLoss: 0.3728\tLR: 0.015000\nTraining Epoch: 10 [42752/50000]\tLoss: 0.3752\tLR: 0.015000\nTraining Epoch: 10 [42880/50000]\tLoss: 0.3771\tLR: 0.015000\nTraining Epoch: 10 [43008/50000]\tLoss: 0.3901\tLR: 0.015000\nTraining Epoch: 10 [43136/50000]\tLoss: 0.4531\tLR: 0.015000\nTraining Epoch: 10 [43264/50000]\tLoss: 0.3258\tLR: 0.015000\nTraining Epoch: 10 [43392/50000]\tLoss: 0.3549\tLR: 0.015000\nTraining Epoch: 10 [43520/50000]\tLoss: 0.5437\tLR: 0.015000\nTraining Epoch: 10 [43648/50000]\tLoss: 0.4354\tLR: 0.015000\nTraining Epoch: 10 [43776/50000]\tLoss: 0.4280\tLR: 0.015000\nTraining Epoch: 10 [43904/50000]\tLoss: 0.4635\tLR: 0.015000\nTraining Epoch: 10 [44032/50000]\tLoss: 0.4402\tLR: 0.015000\nTraining Epoch: 10 [44160/50000]\tLoss: 0.3493\tLR: 0.015000\nTraining Epoch: 10 [44288/50000]\tLoss: 0.5216\tLR: 0.015000\nTraining Epoch: 10 [44416/50000]\tLoss: 0.4557\tLR: 0.015000\nTraining Epoch: 10 [44544/50000]\tLoss: 0.4772\tLR: 0.015000\nTraining Epoch: 10 [44672/50000]\tLoss: 0.4589\tLR: 0.015000\nTraining Epoch: 10 [44800/50000]\tLoss: 0.3776\tLR: 0.015000\nTraining Epoch: 10 [44928/50000]\tLoss: 0.3206\tLR: 0.015000\nTraining Epoch: 10 [45056/50000]\tLoss: 0.3293\tLR: 0.015000\nTraining Epoch: 10 [45184/50000]\tLoss: 0.2620\tLR: 0.015000\nTraining Epoch: 10 [45312/50000]\tLoss: 0.3827\tLR: 0.015000\nTraining Epoch: 10 [45440/50000]\tLoss: 0.3446\tLR: 0.015000\nTraining Epoch: 10 [45568/50000]\tLoss: 0.4637\tLR: 0.015000\nTraining Epoch: 10 [45696/50000]\tLoss: 0.3789\tLR: 0.015000\nTraining Epoch: 10 [45824/50000]\tLoss: 0.4648\tLR: 0.015000\nTraining Epoch: 10 [45952/50000]\tLoss: 0.5460\tLR: 0.015000\nTraining Epoch: 10 [46080/50000]\tLoss: 0.4515\tLR: 0.015000\nTraining Epoch: 10 [46208/50000]\tLoss: 0.3699\tLR: 0.015000\nTraining Epoch: 10 [46336/50000]\tLoss: 0.3049\tLR: 0.015000\nTraining Epoch: 10 [46464/50000]\tLoss: 0.5003\tLR: 0.015000\nTraining Epoch: 10 [46592/50000]\tLoss: 0.3544\tLR: 0.015000\nTraining Epoch: 10 [46720/50000]\tLoss: 0.4055\tLR: 0.015000\nTraining Epoch: 10 [46848/50000]\tLoss: 0.4168\tLR: 0.015000\nTraining Epoch: 10 [46976/50000]\tLoss: 0.4220\tLR: 0.015000\nTraining Epoch: 10 [47104/50000]\tLoss: 0.3375\tLR: 0.015000\nTraining Epoch: 10 [47232/50000]\tLoss: 0.4028\tLR: 0.015000\nTraining Epoch: 10 [47360/50000]\tLoss: 0.4937\tLR: 0.015000\nTraining Epoch: 10 [47488/50000]\tLoss: 0.4489\tLR: 0.015000\nTraining Epoch: 10 [47616/50000]\tLoss: 0.3958\tLR: 0.015000\nTraining Epoch: 10 [47744/50000]\tLoss: 0.3860\tLR: 0.015000\nTraining Epoch: 10 [47872/50000]\tLoss: 0.3763\tLR: 0.015000\nTraining Epoch: 10 [48000/50000]\tLoss: 0.2696\tLR: 0.015000\nTraining Epoch: 10 [48128/50000]\tLoss: 0.4575\tLR: 0.015000\nTraining Epoch: 10 [48256/50000]\tLoss: 0.5312\tLR: 0.015000\nTraining Epoch: 10 [48384/50000]\tLoss: 0.3960\tLR: 0.015000\nTraining Epoch: 10 [48512/50000]\tLoss: 0.3750\tLR: 0.015000\nTraining Epoch: 10 [48640/50000]\tLoss: 0.3047\tLR: 0.015000\nTraining Epoch: 10 [48768/50000]\tLoss: 0.3168\tLR: 0.015000\nTraining Epoch: 10 [48896/50000]\tLoss: 0.2847\tLR: 0.015000\nTraining Epoch: 10 [49024/50000]\tLoss: 0.2979\tLR: 0.015000\nTraining Epoch: 10 [49152/50000]\tLoss: 0.3872\tLR: 0.015000\nTraining Epoch: 10 [49280/50000]\tLoss: 0.3908\tLR: 0.015000\nTraining Epoch: 10 [49408/50000]\tLoss: 0.5287\tLR: 0.015000\nTraining Epoch: 10 [49536/50000]\tLoss: 0.4014\tLR: 0.015000\nTraining Epoch: 10 [49664/50000]\tLoss: 0.3850\tLR: 0.015000\nTraining Epoch: 10 [49792/50000]\tLoss: 0.4287\tLR: 0.015000\nTraining Epoch: 10 [49920/50000]\tLoss: 0.4101\tLR: 0.015000\nTraining Epoch: 10 [50000/50000]\tLoss: 0.3711\tLR: 0.015000\nTest set: Average loss: 0.0034, Accuracy: 0.8526\n\nTraining Epoch: 11 [128/50000]\tLoss: 0.4210\tLR: 0.015000\nTraining Epoch: 11 [256/50000]\tLoss: 0.3555\tLR: 0.015000\nTraining Epoch: 11 [384/50000]\tLoss: 0.4351\tLR: 0.015000\nTraining Epoch: 11 [512/50000]\tLoss: 0.3046\tLR: 0.015000\nTraining Epoch: 11 [640/50000]\tLoss: 0.3791\tLR: 0.015000\nTraining Epoch: 11 [768/50000]\tLoss: 0.4336\tLR: 0.015000\nTraining Epoch: 11 [896/50000]\tLoss: 0.2954\tLR: 0.015000\nTraining Epoch: 11 [1024/50000]\tLoss: 0.3395\tLR: 0.015000\nTraining Epoch: 11 [1152/50000]\tLoss: 0.3542\tLR: 0.015000\nTraining Epoch: 11 [1280/50000]\tLoss: 0.4029\tLR: 0.015000\nTraining Epoch: 11 [1408/50000]\tLoss: 0.4314\tLR: 0.015000\nTraining Epoch: 11 [1536/50000]\tLoss: 0.3344\tLR: 0.015000\nTraining Epoch: 11 [1664/50000]\tLoss: 0.3315\tLR: 0.015000\nTraining Epoch: 11 [1792/50000]\tLoss: 0.3531\tLR: 0.015000\nTraining Epoch: 11 [1920/50000]\tLoss: 0.3699\tLR: 0.015000\nTraining Epoch: 11 [2048/50000]\tLoss: 0.4033\tLR: 0.015000\nTraining Epoch: 11 [2176/50000]\tLoss: 0.3892\tLR: 0.015000\nTraining Epoch: 11 [2304/50000]\tLoss: 0.4437\tLR: 0.015000\nTraining Epoch: 11 [2432/50000]\tLoss: 0.3407\tLR: 0.015000\nTraining Epoch: 11 [2560/50000]\tLoss: 0.3938\tLR: 0.015000\nTraining Epoch: 11 [2688/50000]\tLoss: 0.4482\tLR: 0.015000\nTraining Epoch: 11 [2816/50000]\tLoss: 0.3536\tLR: 0.015000\nTraining Epoch: 11 [2944/50000]\tLoss: 0.2611\tLR: 0.015000\nTraining Epoch: 11 [3072/50000]\tLoss: 0.3207\tLR: 0.015000\nTraining Epoch: 11 [3200/50000]\tLoss: 0.3186\tLR: 0.015000\nTraining Epoch: 11 [3328/50000]\tLoss: 0.4483\tLR: 0.015000\nTraining Epoch: 11 [3456/50000]\tLoss: 0.4025\tLR: 0.015000\nTraining Epoch: 11 [3584/50000]\tLoss: 0.4827\tLR: 0.015000\nTraining Epoch: 11 [3712/50000]\tLoss: 0.3874\tLR: 0.015000\nTraining Epoch: 11 [3840/50000]\tLoss: 0.4379\tLR: 0.015000\nTraining Epoch: 11 [3968/50000]\tLoss: 0.3174\tLR: 0.015000\nTraining Epoch: 11 [4096/50000]\tLoss: 0.4823\tLR: 0.015000\nTraining Epoch: 11 [4224/50000]\tLoss: 0.4844\tLR: 0.015000\nTraining Epoch: 11 [4352/50000]\tLoss: 0.2638\tLR: 0.015000\nTraining Epoch: 11 [4480/50000]\tLoss: 0.4795\tLR: 0.015000\nTraining Epoch: 11 [4608/50000]\tLoss: 0.4048\tLR: 0.015000\nTraining Epoch: 11 [4736/50000]\tLoss: 0.2726\tLR: 0.015000\nTraining Epoch: 11 [4864/50000]\tLoss: 0.3728\tLR: 0.015000\nTraining Epoch: 11 [4992/50000]\tLoss: 0.3895\tLR: 0.015000\nTraining Epoch: 11 [5120/50000]\tLoss: 0.3389\tLR: 0.015000\nTraining Epoch: 11 [5248/50000]\tLoss: 0.2930\tLR: 0.015000\nTraining Epoch: 11 [5376/50000]\tLoss: 0.2750\tLR: 0.015000\nTraining Epoch: 11 [5504/50000]\tLoss: 0.3668\tLR: 0.015000\nTraining Epoch: 11 [5632/50000]\tLoss: 0.5271\tLR: 0.015000\nTraining Epoch: 11 [5760/50000]\tLoss: 0.3791\tLR: 0.015000\nTraining Epoch: 11 [5888/50000]\tLoss: 0.3378\tLR: 0.015000\nTraining Epoch: 11 [6016/50000]\tLoss: 0.4179\tLR: 0.015000\nTraining Epoch: 11 [6144/50000]\tLoss: 0.3409\tLR: 0.015000\nTraining Epoch: 11 [6272/50000]\tLoss: 0.4834\tLR: 0.015000\nTraining Epoch: 11 [6400/50000]\tLoss: 0.3166\tLR: 0.015000\nTraining Epoch: 11 [6528/50000]\tLoss: 0.4132\tLR: 0.015000\nTraining Epoch: 11 [6656/50000]\tLoss: 0.3628\tLR: 0.015000\nTraining Epoch: 11 [6784/50000]\tLoss: 0.3031\tLR: 0.015000\nTraining Epoch: 11 [6912/50000]\tLoss: 0.4690\tLR: 0.015000\nTraining Epoch: 11 [7040/50000]\tLoss: 0.3053\tLR: 0.015000\nTraining Epoch: 11 [7168/50000]\tLoss: 0.3812\tLR: 0.015000\nTraining Epoch: 11 [7296/50000]\tLoss: 0.2644\tLR: 0.015000\nTraining Epoch: 11 [7424/50000]\tLoss: 0.3535\tLR: 0.015000\nTraining Epoch: 11 [7552/50000]\tLoss: 0.4265\tLR: 0.015000\nTraining Epoch: 11 [7680/50000]\tLoss: 0.3674\tLR: 0.015000\nTraining Epoch: 11 [7808/50000]\tLoss: 0.3975\tLR: 0.015000\nTraining Epoch: 11 [7936/50000]\tLoss: 0.3433\tLR: 0.015000\nTraining Epoch: 11 [8064/50000]\tLoss: 0.4830\tLR: 0.015000\nTraining Epoch: 11 [8192/50000]\tLoss: 0.2872\tLR: 0.015000\nTraining Epoch: 11 [8320/50000]\tLoss: 0.3154\tLR: 0.015000\nTraining Epoch: 11 [8448/50000]\tLoss: 0.3455\tLR: 0.015000\nTraining Epoch: 11 [8576/50000]\tLoss: 0.4391\tLR: 0.015000\nTraining Epoch: 11 [8704/50000]\tLoss: 0.3422\tLR: 0.015000\nTraining Epoch: 11 [8832/50000]\tLoss: 0.3848\tLR: 0.015000\nTraining Epoch: 11 [8960/50000]\tLoss: 0.3633\tLR: 0.015000\nTraining Epoch: 11 [9088/50000]\tLoss: 0.4166\tLR: 0.015000\nTraining Epoch: 11 [9216/50000]\tLoss: 0.2866\tLR: 0.015000\nTraining Epoch: 11 [9344/50000]\tLoss: 0.4731\tLR: 0.015000\nTraining Epoch: 11 [9472/50000]\tLoss: 0.3543\tLR: 0.015000\nTraining Epoch: 11 [9600/50000]\tLoss: 0.4370\tLR: 0.015000\nTraining Epoch: 11 [9728/50000]\tLoss: 0.4460\tLR: 0.015000\nTraining Epoch: 11 [9856/50000]\tLoss: 0.4713\tLR: 0.015000\nTraining Epoch: 11 [9984/50000]\tLoss: 0.4466\tLR: 0.015000\nTraining Epoch: 11 [10112/50000]\tLoss: 0.3425\tLR: 0.015000\nTraining Epoch: 11 [10240/50000]\tLoss: 0.4177\tLR: 0.015000\nTraining Epoch: 11 [10368/50000]\tLoss: 0.3026\tLR: 0.015000\nTraining Epoch: 11 [10496/50000]\tLoss: 0.5030\tLR: 0.015000\nTraining Epoch: 11 [10624/50000]\tLoss: 0.3952\tLR: 0.015000\nTraining Epoch: 11 [10752/50000]\tLoss: 0.3220\tLR: 0.015000\nTraining Epoch: 11 [10880/50000]\tLoss: 0.5873\tLR: 0.015000\nTraining Epoch: 11 [11008/50000]\tLoss: 0.4471\tLR: 0.015000\nTraining Epoch: 11 [11136/50000]\tLoss: 0.2982\tLR: 0.015000\nTraining Epoch: 11 [11264/50000]\tLoss: 0.3905\tLR: 0.015000\nTraining Epoch: 11 [11392/50000]\tLoss: 0.2887\tLR: 0.015000\nTraining Epoch: 11 [11520/50000]\tLoss: 0.3926\tLR: 0.015000\nTraining Epoch: 11 [11648/50000]\tLoss: 0.3010\tLR: 0.015000\nTraining Epoch: 11 [11776/50000]\tLoss: 0.4684\tLR: 0.015000\nTraining Epoch: 11 [11904/50000]\tLoss: 0.4096\tLR: 0.015000\nTraining Epoch: 11 [12032/50000]\tLoss: 0.3621\tLR: 0.015000\nTraining Epoch: 11 [12160/50000]\tLoss: 0.4145\tLR: 0.015000\nTraining Epoch: 11 [12288/50000]\tLoss: 0.5849\tLR: 0.015000\nTraining Epoch: 11 [12416/50000]\tLoss: 0.5290\tLR: 0.015000\nTraining Epoch: 11 [12544/50000]\tLoss: 0.4029\tLR: 0.015000\nTraining Epoch: 11 [12672/50000]\tLoss: 0.3330\tLR: 0.015000\nTraining Epoch: 11 [12800/50000]\tLoss: 0.4436\tLR: 0.015000\nTraining Epoch: 11 [12928/50000]\tLoss: 0.3128\tLR: 0.015000\nTraining Epoch: 11 [13056/50000]\tLoss: 0.3663\tLR: 0.015000\nTraining Epoch: 11 [13184/50000]\tLoss: 0.5378\tLR: 0.015000\nTraining Epoch: 11 [13312/50000]\tLoss: 0.3872\tLR: 0.015000\nTraining Epoch: 11 [13440/50000]\tLoss: 0.4010\tLR: 0.015000\nTraining Epoch: 11 [13568/50000]\tLoss: 0.4644\tLR: 0.015000\nTraining Epoch: 11 [13696/50000]\tLoss: 0.3919\tLR: 0.015000\nTraining Epoch: 11 [13824/50000]\tLoss: 0.3689\tLR: 0.015000\nTraining Epoch: 11 [13952/50000]\tLoss: 0.3316\tLR: 0.015000\nTraining Epoch: 11 [14080/50000]\tLoss: 0.5269\tLR: 0.015000\nTraining Epoch: 11 [14208/50000]\tLoss: 0.4545\tLR: 0.015000\nTraining Epoch: 11 [14336/50000]\tLoss: 0.4564\tLR: 0.015000\nTraining Epoch: 11 [14464/50000]\tLoss: 0.3103\tLR: 0.015000\nTraining Epoch: 11 [14592/50000]\tLoss: 0.4519\tLR: 0.015000\nTraining Epoch: 11 [14720/50000]\tLoss: 0.3569\tLR: 0.015000\nTraining Epoch: 11 [14848/50000]\tLoss: 0.4026\tLR: 0.015000\nTraining Epoch: 11 [14976/50000]\tLoss: 0.5764\tLR: 0.015000\nTraining Epoch: 11 [15104/50000]\tLoss: 0.4813\tLR: 0.015000\nTraining Epoch: 11 [15232/50000]\tLoss: 0.4306\tLR: 0.015000\nTraining Epoch: 11 [15360/50000]\tLoss: 0.3978\tLR: 0.015000\nTraining Epoch: 11 [15488/50000]\tLoss: 0.2469\tLR: 0.015000\nTraining Epoch: 11 [15616/50000]\tLoss: 0.3526\tLR: 0.015000\nTraining Epoch: 11 [15744/50000]\tLoss: 0.3579\tLR: 0.015000\nTraining Epoch: 11 [15872/50000]\tLoss: 0.2852\tLR: 0.015000\nTraining Epoch: 11 [16000/50000]\tLoss: 0.3806\tLR: 0.015000\nTraining Epoch: 11 [16128/50000]\tLoss: 0.2319\tLR: 0.015000\nTraining Epoch: 11 [16256/50000]\tLoss: 0.2873\tLR: 0.015000\nTraining Epoch: 11 [16384/50000]\tLoss: 0.3126\tLR: 0.015000\nTraining Epoch: 11 [16512/50000]\tLoss: 0.3744\tLR: 0.015000\nTraining Epoch: 11 [16640/50000]\tLoss: 0.3345\tLR: 0.015000\nTraining Epoch: 11 [16768/50000]\tLoss: 0.4152\tLR: 0.015000\nTraining Epoch: 11 [16896/50000]\tLoss: 0.3265\tLR: 0.015000\nTraining Epoch: 11 [17024/50000]\tLoss: 0.4032\tLR: 0.015000\nTraining Epoch: 11 [17152/50000]\tLoss: 0.4162\tLR: 0.015000\nTraining Epoch: 11 [17280/50000]\tLoss: 0.3982\tLR: 0.015000\nTraining Epoch: 11 [17408/50000]\tLoss: 0.3647\tLR: 0.015000\nTraining Epoch: 11 [17536/50000]\tLoss: 0.2715\tLR: 0.015000\nTraining Epoch: 11 [17664/50000]\tLoss: 0.4150\tLR: 0.015000\nTraining Epoch: 11 [17792/50000]\tLoss: 0.4757\tLR: 0.015000\nTraining Epoch: 11 [17920/50000]\tLoss: 0.3816\tLR: 0.015000\nTraining Epoch: 11 [18048/50000]\tLoss: 0.3568\tLR: 0.015000\nTraining Epoch: 11 [18176/50000]\tLoss: 0.4723\tLR: 0.015000\nTraining Epoch: 11 [18304/50000]\tLoss: 0.3189\tLR: 0.015000\nTraining Epoch: 11 [18432/50000]\tLoss: 0.3726\tLR: 0.015000\nTraining Epoch: 11 [18560/50000]\tLoss: 0.2979\tLR: 0.015000\nTraining Epoch: 11 [18688/50000]\tLoss: 0.3844\tLR: 0.015000\nTraining Epoch: 11 [18816/50000]\tLoss: 0.4519\tLR: 0.015000\nTraining Epoch: 11 [18944/50000]\tLoss: 0.3490\tLR: 0.015000\nTraining Epoch: 11 [19072/50000]\tLoss: 0.4372\tLR: 0.015000\nTraining Epoch: 11 [19200/50000]\tLoss: 0.2916\tLR: 0.015000\nTraining Epoch: 11 [19328/50000]\tLoss: 0.4272\tLR: 0.015000\nTraining Epoch: 11 [19456/50000]\tLoss: 0.4123\tLR: 0.015000\nTraining Epoch: 11 [19584/50000]\tLoss: 0.4705\tLR: 0.015000\nTraining Epoch: 11 [19712/50000]\tLoss: 0.4109\tLR: 0.015000\nTraining Epoch: 11 [19840/50000]\tLoss: 0.5880\tLR: 0.015000\nTraining Epoch: 11 [19968/50000]\tLoss: 0.3888\tLR: 0.015000\nTraining Epoch: 11 [20096/50000]\tLoss: 0.5147\tLR: 0.015000\nTraining Epoch: 11 [20224/50000]\tLoss: 0.3083\tLR: 0.015000\nTraining Epoch: 11 [20352/50000]\tLoss: 0.4434\tLR: 0.015000\nTraining Epoch: 11 [20480/50000]\tLoss: 0.4295\tLR: 0.015000\nTraining Epoch: 11 [20608/50000]\tLoss: 0.5537\tLR: 0.015000\nTraining Epoch: 11 [20736/50000]\tLoss: 0.3701\tLR: 0.015000\nTraining Epoch: 11 [20864/50000]\tLoss: 0.2941\tLR: 0.015000\nTraining Epoch: 11 [20992/50000]\tLoss: 0.3801\tLR: 0.015000\nTraining Epoch: 11 [21120/50000]\tLoss: 0.3968\tLR: 0.015000\nTraining Epoch: 11 [21248/50000]\tLoss: 0.4070\tLR: 0.015000\nTraining Epoch: 11 [21376/50000]\tLoss: 0.4628\tLR: 0.015000\nTraining Epoch: 11 [21504/50000]\tLoss: 0.3703\tLR: 0.015000\nTraining Epoch: 11 [21632/50000]\tLoss: 0.4364\tLR: 0.015000\nTraining Epoch: 11 [21760/50000]\tLoss: 0.4223\tLR: 0.015000\nTraining Epoch: 11 [21888/50000]\tLoss: 0.3123\tLR: 0.015000\nTraining Epoch: 11 [22016/50000]\tLoss: 0.4298\tLR: 0.015000\nTraining Epoch: 11 [22144/50000]\tLoss: 0.3958\tLR: 0.015000\nTraining Epoch: 11 [22272/50000]\tLoss: 0.3460\tLR: 0.015000\nTraining Epoch: 11 [22400/50000]\tLoss: 0.2876\tLR: 0.015000\nTraining Epoch: 11 [22528/50000]\tLoss: 0.3668\tLR: 0.015000\nTraining Epoch: 11 [22656/50000]\tLoss: 0.4084\tLR: 0.015000\nTraining Epoch: 11 [22784/50000]\tLoss: 0.3600\tLR: 0.015000\nTraining Epoch: 11 [22912/50000]\tLoss: 0.3635\tLR: 0.015000\nTraining Epoch: 11 [23040/50000]\tLoss: 0.3639\tLR: 0.015000\nTraining Epoch: 11 [23168/50000]\tLoss: 0.4622\tLR: 0.015000\nTraining Epoch: 11 [23296/50000]\tLoss: 0.2724\tLR: 0.015000\nTraining Epoch: 11 [23424/50000]\tLoss: 0.3336\tLR: 0.015000\nTraining Epoch: 11 [23552/50000]\tLoss: 0.2529\tLR: 0.015000\nTraining Epoch: 11 [23680/50000]\tLoss: 0.4299\tLR: 0.015000\nTraining Epoch: 11 [23808/50000]\tLoss: 0.2792\tLR: 0.015000\nTraining Epoch: 11 [23936/50000]\tLoss: 0.4197\tLR: 0.015000\nTraining Epoch: 11 [24064/50000]\tLoss: 0.3285\tLR: 0.015000\nTraining Epoch: 11 [24192/50000]\tLoss: 0.3462\tLR: 0.015000\nTraining Epoch: 11 [24320/50000]\tLoss: 0.4173\tLR: 0.015000\nTraining Epoch: 11 [24448/50000]\tLoss: 0.2577\tLR: 0.015000\nTraining Epoch: 11 [24576/50000]\tLoss: 0.3423\tLR: 0.015000\nTraining Epoch: 11 [24704/50000]\tLoss: 0.4850\tLR: 0.015000\nTraining Epoch: 11 [24832/50000]\tLoss: 0.3226\tLR: 0.015000\nTraining Epoch: 11 [24960/50000]\tLoss: 0.3158\tLR: 0.015000\nTraining Epoch: 11 [25088/50000]\tLoss: 0.3896\tLR: 0.015000\nTraining Epoch: 11 [25216/50000]\tLoss: 0.5016\tLR: 0.015000\nTraining Epoch: 11 [25344/50000]\tLoss: 0.5066\tLR: 0.015000\nTraining Epoch: 11 [25472/50000]\tLoss: 0.3530\tLR: 0.015000\nTraining Epoch: 11 [25600/50000]\tLoss: 0.3057\tLR: 0.015000\nTraining Epoch: 11 [25728/50000]\tLoss: 0.4155\tLR: 0.015000\nTraining Epoch: 11 [25856/50000]\tLoss: 0.5703\tLR: 0.015000\nTraining Epoch: 11 [25984/50000]\tLoss: 0.4347\tLR: 0.015000\nTraining Epoch: 11 [26112/50000]\tLoss: 0.3779\tLR: 0.015000\nTraining Epoch: 11 [26240/50000]\tLoss: 0.4540\tLR: 0.015000\nTraining Epoch: 11 [26368/50000]\tLoss: 0.4336\tLR: 0.015000\nTraining Epoch: 11 [26496/50000]\tLoss: 0.3769\tLR: 0.015000\nTraining Epoch: 11 [26624/50000]\tLoss: 0.3690\tLR: 0.015000\nTraining Epoch: 11 [26752/50000]\tLoss: 0.4249\tLR: 0.015000\nTraining Epoch: 11 [26880/50000]\tLoss: 0.4223\tLR: 0.015000\nTraining Epoch: 11 [27008/50000]\tLoss: 0.3887\tLR: 0.015000\nTraining Epoch: 11 [27136/50000]\tLoss: 0.4139\tLR: 0.015000\nTraining Epoch: 11 [27264/50000]\tLoss: 0.3539\tLR: 0.015000\nTraining Epoch: 11 [27392/50000]\tLoss: 0.3347\tLR: 0.015000\nTraining Epoch: 11 [27520/50000]\tLoss: 0.4256\tLR: 0.015000\nTraining Epoch: 11 [27648/50000]\tLoss: 0.3888\tLR: 0.015000\nTraining Epoch: 11 [27776/50000]\tLoss: 0.4065\tLR: 0.015000\nTraining Epoch: 11 [27904/50000]\tLoss: 0.4700\tLR: 0.015000\nTraining Epoch: 11 [28032/50000]\tLoss: 0.3670\tLR: 0.015000\nTraining Epoch: 11 [28160/50000]\tLoss: 0.4383\tLR: 0.015000\nTraining Epoch: 11 [28288/50000]\tLoss: 0.3547\tLR: 0.015000\nTraining Epoch: 11 [28416/50000]\tLoss: 0.4714\tLR: 0.015000\nTraining Epoch: 11 [28544/50000]\tLoss: 0.3644\tLR: 0.015000\nTraining Epoch: 11 [28672/50000]\tLoss: 0.3672\tLR: 0.015000\nTraining Epoch: 11 [28800/50000]\tLoss: 0.5985\tLR: 0.015000\nTraining Epoch: 11 [28928/50000]\tLoss: 0.4388\tLR: 0.015000\nTraining Epoch: 11 [29056/50000]\tLoss: 0.5774\tLR: 0.015000\nTraining Epoch: 11 [29184/50000]\tLoss: 0.3716\tLR: 0.015000\nTraining Epoch: 11 [29312/50000]\tLoss: 0.2448\tLR: 0.015000\nTraining Epoch: 11 [29440/50000]\tLoss: 0.4340\tLR: 0.015000\nTraining Epoch: 11 [29568/50000]\tLoss: 0.4114\tLR: 0.015000\nTraining Epoch: 11 [29696/50000]\tLoss: 0.4394\tLR: 0.015000\nTraining Epoch: 11 [29824/50000]\tLoss: 0.4860\tLR: 0.015000\nTraining Epoch: 11 [29952/50000]\tLoss: 0.2707\tLR: 0.015000\nTraining Epoch: 11 [30080/50000]\tLoss: 0.3038\tLR: 0.015000\nTraining Epoch: 11 [30208/50000]\tLoss: 0.3864\tLR: 0.015000\nTraining Epoch: 11 [30336/50000]\tLoss: 0.3048\tLR: 0.015000\nTraining Epoch: 11 [30464/50000]\tLoss: 0.4235\tLR: 0.015000\nTraining Epoch: 11 [30592/50000]\tLoss: 0.3111\tLR: 0.015000\nTraining Epoch: 11 [30720/50000]\tLoss: 0.3873\tLR: 0.015000\nTraining Epoch: 11 [30848/50000]\tLoss: 0.5729\tLR: 0.015000\nTraining Epoch: 11 [30976/50000]\tLoss: 0.2625\tLR: 0.015000\nTraining Epoch: 11 [31104/50000]\tLoss: 0.4161\tLR: 0.015000\nTraining Epoch: 11 [31232/50000]\tLoss: 0.3947\tLR: 0.015000\nTraining Epoch: 11 [31360/50000]\tLoss: 0.3305\tLR: 0.015000\nTraining Epoch: 11 [31488/50000]\tLoss: 0.3845\tLR: 0.015000\nTraining Epoch: 11 [31616/50000]\tLoss: 0.4472\tLR: 0.015000\nTraining Epoch: 11 [31744/50000]\tLoss: 0.4222\tLR: 0.015000\nTraining Epoch: 11 [31872/50000]\tLoss: 0.3548\tLR: 0.015000\nTraining Epoch: 11 [32000/50000]\tLoss: 0.4243\tLR: 0.015000\nTraining Epoch: 11 [32128/50000]\tLoss: 0.4647\tLR: 0.015000\nTraining Epoch: 11 [32256/50000]\tLoss: 0.4117\tLR: 0.015000\nTraining Epoch: 11 [32384/50000]\tLoss: 0.4482\tLR: 0.015000\nTraining Epoch: 11 [32512/50000]\tLoss: 0.4367\tLR: 0.015000\nTraining Epoch: 11 [32640/50000]\tLoss: 0.2900\tLR: 0.015000\nTraining Epoch: 11 [32768/50000]\tLoss: 0.3881\tLR: 0.015000\nTraining Epoch: 11 [32896/50000]\tLoss: 0.4147\tLR: 0.015000\nTraining Epoch: 11 [33024/50000]\tLoss: 0.4007\tLR: 0.015000\nTraining Epoch: 11 [33152/50000]\tLoss: 0.2972\tLR: 0.015000\nTraining Epoch: 11 [33280/50000]\tLoss: 0.3045\tLR: 0.015000\nTraining Epoch: 11 [33408/50000]\tLoss: 0.5772\tLR: 0.015000\nTraining Epoch: 11 [33536/50000]\tLoss: 0.5010\tLR: 0.015000\nTraining Epoch: 11 [33664/50000]\tLoss: 0.3597\tLR: 0.015000\nTraining Epoch: 11 [33792/50000]\tLoss: 0.4108\tLR: 0.015000\nTraining Epoch: 11 [33920/50000]\tLoss: 0.3005\tLR: 0.015000\nTraining Epoch: 11 [34048/50000]\tLoss: 0.4691\tLR: 0.015000\nTraining Epoch: 11 [34176/50000]\tLoss: 0.3232\tLR: 0.015000\nTraining Epoch: 11 [34304/50000]\tLoss: 0.4023\tLR: 0.015000\nTraining Epoch: 11 [34432/50000]\tLoss: 0.3755\tLR: 0.015000\nTraining Epoch: 11 [34560/50000]\tLoss: 0.4461\tLR: 0.015000\nTraining Epoch: 11 [34688/50000]\tLoss: 0.4068\tLR: 0.015000\nTraining Epoch: 11 [34816/50000]\tLoss: 0.2655\tLR: 0.015000\nTraining Epoch: 11 [34944/50000]\tLoss: 0.3034\tLR: 0.015000\nTraining Epoch: 11 [35072/50000]\tLoss: 0.4631\tLR: 0.015000\nTraining Epoch: 11 [35200/50000]\tLoss: 0.3967\tLR: 0.015000\nTraining Epoch: 11 [35328/50000]\tLoss: 0.4051\tLR: 0.015000\nTraining Epoch: 11 [35456/50000]\tLoss: 0.3877\tLR: 0.015000\nTraining Epoch: 11 [35584/50000]\tLoss: 0.4412\tLR: 0.015000\nTraining Epoch: 11 [35712/50000]\tLoss: 0.4140\tLR: 0.015000\nTraining Epoch: 11 [35840/50000]\tLoss: 0.4720\tLR: 0.015000\nTraining Epoch: 11 [35968/50000]\tLoss: 0.3575\tLR: 0.015000\nTraining Epoch: 11 [36096/50000]\tLoss: 0.3331\tLR: 0.015000\nTraining Epoch: 11 [36224/50000]\tLoss: 0.3139\tLR: 0.015000\nTraining Epoch: 11 [36352/50000]\tLoss: 0.2394\tLR: 0.015000\nTraining Epoch: 11 [36480/50000]\tLoss: 0.3483\tLR: 0.015000\nTraining Epoch: 11 [36608/50000]\tLoss: 0.3158\tLR: 0.015000\nTraining Epoch: 11 [36736/50000]\tLoss: 0.4285\tLR: 0.015000\nTraining Epoch: 11 [36864/50000]\tLoss: 0.5756\tLR: 0.015000\nTraining Epoch: 11 [36992/50000]\tLoss: 0.4160\tLR: 0.015000\nTraining Epoch: 11 [37120/50000]\tLoss: 0.3892\tLR: 0.015000\nTraining Epoch: 11 [37248/50000]\tLoss: 0.3648\tLR: 0.015000\nTraining Epoch: 11 [37376/50000]\tLoss: 0.3661\tLR: 0.015000\nTraining Epoch: 11 [37504/50000]\tLoss: 0.5645\tLR: 0.015000\nTraining Epoch: 11 [37632/50000]\tLoss: 0.3193\tLR: 0.015000\nTraining Epoch: 11 [37760/50000]\tLoss: 0.4456\tLR: 0.015000\nTraining Epoch: 11 [37888/50000]\tLoss: 0.2689\tLR: 0.015000\nTraining Epoch: 11 [38016/50000]\tLoss: 0.6208\tLR: 0.015000\nTraining Epoch: 11 [38144/50000]\tLoss: 0.3496\tLR: 0.015000\nTraining Epoch: 11 [38272/50000]\tLoss: 0.3895\tLR: 0.015000\nTraining Epoch: 11 [38400/50000]\tLoss: 0.3281\tLR: 0.015000\nTraining Epoch: 11 [38528/50000]\tLoss: 0.3486\tLR: 0.015000\nTraining Epoch: 11 [38656/50000]\tLoss: 0.4537\tLR: 0.015000\nTraining Epoch: 11 [38784/50000]\tLoss: 0.3969\tLR: 0.015000\nTraining Epoch: 11 [38912/50000]\tLoss: 0.5487\tLR: 0.015000\nTraining Epoch: 11 [39040/50000]\tLoss: 0.3488\tLR: 0.015000\nTraining Epoch: 11 [39168/50000]\tLoss: 0.3005\tLR: 0.015000\nTraining Epoch: 11 [39296/50000]\tLoss: 0.3825\tLR: 0.015000\nTraining Epoch: 11 [39424/50000]\tLoss: 0.2934\tLR: 0.015000\nTraining Epoch: 11 [39552/50000]\tLoss: 0.3154\tLR: 0.015000\nTraining Epoch: 11 [39680/50000]\tLoss: 0.2812\tLR: 0.015000\nTraining Epoch: 11 [39808/50000]\tLoss: 0.4533\tLR: 0.015000\nTraining Epoch: 11 [39936/50000]\tLoss: 0.3672\tLR: 0.015000\nTraining Epoch: 11 [40064/50000]\tLoss: 0.4647\tLR: 0.015000\nTraining Epoch: 11 [40192/50000]\tLoss: 0.3594\tLR: 0.015000\nTraining Epoch: 11 [40320/50000]\tLoss: 0.4115\tLR: 0.015000\nTraining Epoch: 11 [40448/50000]\tLoss: 0.3726\tLR: 0.015000\nTraining Epoch: 11 [40576/50000]\tLoss: 0.4725\tLR: 0.015000\nTraining Epoch: 11 [40704/50000]\tLoss: 0.4310\tLR: 0.015000\nTraining Epoch: 11 [40832/50000]\tLoss: 0.5126\tLR: 0.015000\nTraining Epoch: 11 [40960/50000]\tLoss: 0.3441\tLR: 0.015000\nTraining Epoch: 11 [41088/50000]\tLoss: 0.4713\tLR: 0.015000\nTraining Epoch: 11 [41216/50000]\tLoss: 0.4215\tLR: 0.015000\nTraining Epoch: 11 [41344/50000]\tLoss: 0.4015\tLR: 0.015000\nTraining Epoch: 11 [41472/50000]\tLoss: 0.3937\tLR: 0.015000\nTraining Epoch: 11 [41600/50000]\tLoss: 0.3983\tLR: 0.015000\nTraining Epoch: 11 [41728/50000]\tLoss: 0.4389\tLR: 0.015000\nTraining Epoch: 11 [41856/50000]\tLoss: 0.3990\tLR: 0.015000\nTraining Epoch: 11 [41984/50000]\tLoss: 0.4187\tLR: 0.015000\nTraining Epoch: 11 [42112/50000]\tLoss: 0.4679\tLR: 0.015000\nTraining Epoch: 11 [42240/50000]\tLoss: 0.2892\tLR: 0.015000\nTraining Epoch: 11 [42368/50000]\tLoss: 0.5041\tLR: 0.015000\nTraining Epoch: 11 [42496/50000]\tLoss: 0.3612\tLR: 0.015000\nTraining Epoch: 11 [42624/50000]\tLoss: 0.4100\tLR: 0.015000\nTraining Epoch: 11 [42752/50000]\tLoss: 0.4869\tLR: 0.015000\nTraining Epoch: 11 [42880/50000]\tLoss: 0.3309\tLR: 0.015000\nTraining Epoch: 11 [43008/50000]\tLoss: 0.2844\tLR: 0.015000\nTraining Epoch: 11 [43136/50000]\tLoss: 0.3666\tLR: 0.015000\nTraining Epoch: 11 [43264/50000]\tLoss: 0.3459\tLR: 0.015000\nTraining Epoch: 11 [43392/50000]\tLoss: 0.3577\tLR: 0.015000\nTraining Epoch: 11 [43520/50000]\tLoss: 0.3631\tLR: 0.015000\nTraining Epoch: 11 [43648/50000]\tLoss: 0.4659\tLR: 0.015000\nTraining Epoch: 11 [43776/50000]\tLoss: 0.4416\tLR: 0.015000\nTraining Epoch: 11 [43904/50000]\tLoss: 0.4134\tLR: 0.015000\nTraining Epoch: 11 [44032/50000]\tLoss: 0.5980\tLR: 0.015000\nTraining Epoch: 11 [44160/50000]\tLoss: 0.3176\tLR: 0.015000\nTraining Epoch: 11 [44288/50000]\tLoss: 0.3948\tLR: 0.015000\nTraining Epoch: 11 [44416/50000]\tLoss: 0.3969\tLR: 0.015000\nTraining Epoch: 11 [44544/50000]\tLoss: 0.3816\tLR: 0.015000\nTraining Epoch: 11 [44672/50000]\tLoss: 0.4412\tLR: 0.015000\nTraining Epoch: 11 [44800/50000]\tLoss: 0.5089\tLR: 0.015000\nTraining Epoch: 11 [44928/50000]\tLoss: 0.3212\tLR: 0.015000\nTraining Epoch: 11 [45056/50000]\tLoss: 0.4404\tLR: 0.015000\nTraining Epoch: 11 [45184/50000]\tLoss: 0.2857\tLR: 0.015000\nTraining Epoch: 11 [45312/50000]\tLoss: 0.4278\tLR: 0.015000\nTraining Epoch: 11 [45440/50000]\tLoss: 0.4054\tLR: 0.015000\nTraining Epoch: 11 [45568/50000]\tLoss: 0.4316\tLR: 0.015000\nTraining Epoch: 11 [45696/50000]\tLoss: 0.3725\tLR: 0.015000\nTraining Epoch: 11 [45824/50000]\tLoss: 0.2788\tLR: 0.015000\nTraining Epoch: 11 [45952/50000]\tLoss: 0.3851\tLR: 0.015000\nTraining Epoch: 11 [46080/50000]\tLoss: 0.4533\tLR: 0.015000\nTraining Epoch: 11 [46208/50000]\tLoss: 0.3221\tLR: 0.015000\nTraining Epoch: 11 [46336/50000]\tLoss: 0.3796\tLR: 0.015000\nTraining Epoch: 11 [46464/50000]\tLoss: 0.3053\tLR: 0.015000\nTraining Epoch: 11 [46592/50000]\tLoss: 0.4089\tLR: 0.015000\nTraining Epoch: 11 [46720/50000]\tLoss: 0.4373\tLR: 0.015000\nTraining Epoch: 11 [46848/50000]\tLoss: 0.3494\tLR: 0.015000\nTraining Epoch: 11 [46976/50000]\tLoss: 0.2973\tLR: 0.015000\nTraining Epoch: 11 [47104/50000]\tLoss: 0.3460\tLR: 0.015000\nTraining Epoch: 11 [47232/50000]\tLoss: 0.2423\tLR: 0.015000\nTraining Epoch: 11 [47360/50000]\tLoss: 0.4115\tLR: 0.015000\nTraining Epoch: 11 [47488/50000]\tLoss: 0.4053\tLR: 0.015000\nTraining Epoch: 11 [47616/50000]\tLoss: 0.4870\tLR: 0.015000\nTraining Epoch: 11 [47744/50000]\tLoss: 0.4588\tLR: 0.015000\nTraining Epoch: 11 [47872/50000]\tLoss: 0.5474\tLR: 0.015000\nTraining Epoch: 11 [48000/50000]\tLoss: 0.4466\tLR: 0.015000\nTraining Epoch: 11 [48128/50000]\tLoss: 0.3048\tLR: 0.015000\nTraining Epoch: 11 [48256/50000]\tLoss: 0.2951\tLR: 0.015000\nTraining Epoch: 11 [48384/50000]\tLoss: 0.2787\tLR: 0.015000\nTraining Epoch: 11 [48512/50000]\tLoss: 0.3127\tLR: 0.015000\nTraining Epoch: 11 [48640/50000]\tLoss: 0.4196\tLR: 0.015000\nTraining Epoch: 11 [48768/50000]\tLoss: 0.3935\tLR: 0.015000\nTraining Epoch: 11 [48896/50000]\tLoss: 0.3720\tLR: 0.015000\nTraining Epoch: 11 [49024/50000]\tLoss: 0.4326\tLR: 0.015000\nTraining Epoch: 11 [49152/50000]\tLoss: 0.4030\tLR: 0.015000\nTraining Epoch: 11 [49280/50000]\tLoss: 0.3947\tLR: 0.015000\nTraining Epoch: 11 [49408/50000]\tLoss: 0.3504\tLR: 0.015000\nTraining Epoch: 11 [49536/50000]\tLoss: 0.3379\tLR: 0.015000\nTraining Epoch: 11 [49664/50000]\tLoss: 0.4416\tLR: 0.015000\nTraining Epoch: 11 [49792/50000]\tLoss: 0.3677\tLR: 0.015000\nTraining Epoch: 11 [49920/50000]\tLoss: 0.3601\tLR: 0.015000\nTraining Epoch: 11 [50000/50000]\tLoss: 0.3462\tLR: 0.015000\nTest set: Average loss: 0.0032, Accuracy: 0.8678\n\nTraining Epoch: 12 [128/50000]\tLoss: 0.3003\tLR: 0.002250\nTraining Epoch: 12 [256/50000]\tLoss: 0.3135\tLR: 0.002250\nTraining Epoch: 12 [384/50000]\tLoss: 0.4853\tLR: 0.002250\nTraining Epoch: 12 [512/50000]\tLoss: 0.3078\tLR: 0.002250\nTraining Epoch: 12 [640/50000]\tLoss: 0.5148\tLR: 0.002250\nTraining Epoch: 12 [768/50000]\tLoss: 0.4004\tLR: 0.002250\nTraining Epoch: 12 [896/50000]\tLoss: 0.3467\tLR: 0.002250\nTraining Epoch: 12 [1024/50000]\tLoss: 0.3728\tLR: 0.002250\nTraining Epoch: 12 [1152/50000]\tLoss: 0.5302\tLR: 0.002250\nTraining Epoch: 12 [1280/50000]\tLoss: 0.3077\tLR: 0.002250\nTraining Epoch: 12 [1408/50000]\tLoss: 0.2906\tLR: 0.002250\nTraining Epoch: 12 [1536/50000]\tLoss: 0.4264\tLR: 0.002250\nTraining Epoch: 12 [1664/50000]\tLoss: 0.3740\tLR: 0.002250\nTraining Epoch: 12 [1792/50000]\tLoss: 0.4245\tLR: 0.002250\nTraining Epoch: 12 [1920/50000]\tLoss: 0.2900\tLR: 0.002250\nTraining Epoch: 12 [2048/50000]\tLoss: 0.4681\tLR: 0.002250\nTraining Epoch: 12 [2176/50000]\tLoss: 0.3495\tLR: 0.002250\nTraining Epoch: 12 [2304/50000]\tLoss: 0.3968\tLR: 0.002250\nTraining Epoch: 12 [2432/50000]\tLoss: 0.3910\tLR: 0.002250\nTraining Epoch: 12 [2560/50000]\tLoss: 0.2182\tLR: 0.002250\nTraining Epoch: 12 [2688/50000]\tLoss: 0.3130\tLR: 0.002250\nTraining Epoch: 12 [2816/50000]\tLoss: 0.2589\tLR: 0.002250\nTraining Epoch: 12 [2944/50000]\tLoss: 0.4558\tLR: 0.002250\nTraining Epoch: 12 [3072/50000]\tLoss: 0.3631\tLR: 0.002250\nTraining Epoch: 12 [3200/50000]\tLoss: 0.3063\tLR: 0.002250\nTraining Epoch: 12 [3328/50000]\tLoss: 0.3749\tLR: 0.002250\nTraining Epoch: 12 [3456/50000]\tLoss: 0.3027\tLR: 0.002250\nTraining Epoch: 12 [3584/50000]\tLoss: 0.2823\tLR: 0.002250\nTraining Epoch: 12 [3712/50000]\tLoss: 0.2590\tLR: 0.002250\nTraining Epoch: 12 [3840/50000]\tLoss: 0.4190\tLR: 0.002250\nTraining Epoch: 12 [3968/50000]\tLoss: 0.4944\tLR: 0.002250\nTraining Epoch: 12 [4096/50000]\tLoss: 0.3083\tLR: 0.002250\nTraining Epoch: 12 [4224/50000]\tLoss: 0.2936\tLR: 0.002250\nTraining Epoch: 12 [4352/50000]\tLoss: 0.3154\tLR: 0.002250\nTraining Epoch: 12 [4480/50000]\tLoss: 0.3157\tLR: 0.002250\nTraining Epoch: 12 [4608/50000]\tLoss: 0.4564\tLR: 0.002250\nTraining Epoch: 12 [4736/50000]\tLoss: 0.3528\tLR: 0.002250\nTraining Epoch: 12 [4864/50000]\tLoss: 0.3082\tLR: 0.002250\nTraining Epoch: 12 [4992/50000]\tLoss: 0.3796\tLR: 0.002250\nTraining Epoch: 12 [5120/50000]\tLoss: 0.3322\tLR: 0.002250\nTraining Epoch: 12 [5248/50000]\tLoss: 0.3295\tLR: 0.002250\nTraining Epoch: 12 [5376/50000]\tLoss: 0.2502\tLR: 0.002250\nTraining Epoch: 12 [5504/50000]\tLoss: 0.3368\tLR: 0.002250\nTraining Epoch: 12 [5632/50000]\tLoss: 0.3977\tLR: 0.002250\nTraining Epoch: 12 [5760/50000]\tLoss: 0.3359\tLR: 0.002250\nTraining Epoch: 12 [5888/50000]\tLoss: 0.4387\tLR: 0.002250\nTraining Epoch: 12 [6016/50000]\tLoss: 0.3614\tLR: 0.002250\nTraining Epoch: 12 [6144/50000]\tLoss: 0.3422\tLR: 0.002250\nTraining Epoch: 12 [6272/50000]\tLoss: 0.3306\tLR: 0.002250\nTraining Epoch: 12 [6400/50000]\tLoss: 0.3317\tLR: 0.002250\nTraining Epoch: 12 [6528/50000]\tLoss: 0.2668\tLR: 0.002250\nTraining Epoch: 12 [6656/50000]\tLoss: 0.3358\tLR: 0.002250\nTraining Epoch: 12 [6784/50000]\tLoss: 0.3101\tLR: 0.002250\nTraining Epoch: 12 [6912/50000]\tLoss: 0.3497\tLR: 0.002250\nTraining Epoch: 12 [7040/50000]\tLoss: 0.4312\tLR: 0.002250\nTraining Epoch: 12 [7168/50000]\tLoss: 0.3773\tLR: 0.002250\nTraining Epoch: 12 [7296/50000]\tLoss: 0.4329\tLR: 0.002250\nTraining Epoch: 12 [7424/50000]\tLoss: 0.4193\tLR: 0.002250\nTraining Epoch: 12 [7552/50000]\tLoss: 0.3107\tLR: 0.002250\nTraining Epoch: 12 [7680/50000]\tLoss: 0.3265\tLR: 0.002250\nTraining Epoch: 12 [7808/50000]\tLoss: 0.4589\tLR: 0.002250\nTraining Epoch: 12 [7936/50000]\tLoss: 0.2487\tLR: 0.002250\nTraining Epoch: 12 [8064/50000]\tLoss: 0.2650\tLR: 0.002250\nTraining Epoch: 12 [8192/50000]\tLoss: 0.3736\tLR: 0.002250\nTraining Epoch: 12 [8320/50000]\tLoss: 0.3779\tLR: 0.002250\nTraining Epoch: 12 [8448/50000]\tLoss: 0.3418\tLR: 0.002250\nTraining Epoch: 12 [8576/50000]\tLoss: 0.3018\tLR: 0.002250\nTraining Epoch: 12 [8704/50000]\tLoss: 0.3686\tLR: 0.002250\nTraining Epoch: 12 [8832/50000]\tLoss: 0.3157\tLR: 0.002250\nTraining Epoch: 12 [8960/50000]\tLoss: 0.5346\tLR: 0.002250\nTraining Epoch: 12 [9088/50000]\tLoss: 0.2919\tLR: 0.002250\nTraining Epoch: 12 [9216/50000]\tLoss: 0.2756\tLR: 0.002250\nTraining Epoch: 12 [9344/50000]\tLoss: 0.4488\tLR: 0.002250\nTraining Epoch: 12 [9472/50000]\tLoss: 0.2533\tLR: 0.002250\nTraining Epoch: 12 [9600/50000]\tLoss: 0.2734\tLR: 0.002250\nTraining Epoch: 12 [9728/50000]\tLoss: 0.3286\tLR: 0.002250\nTraining Epoch: 12 [9856/50000]\tLoss: 0.3318\tLR: 0.002250\nTraining Epoch: 12 [9984/50000]\tLoss: 0.3041\tLR: 0.002250\nTraining Epoch: 12 [10112/50000]\tLoss: 0.3315\tLR: 0.002250\nTraining Epoch: 12 [10240/50000]\tLoss: 0.2705\tLR: 0.002250\nTraining Epoch: 12 [10368/50000]\tLoss: 0.2720\tLR: 0.002250\nTraining Epoch: 12 [10496/50000]\tLoss: 0.3434\tLR: 0.002250\nTraining Epoch: 12 [10624/50000]\tLoss: 0.2649\tLR: 0.002250\nTraining Epoch: 12 [10752/50000]\tLoss: 0.3530\tLR: 0.002250\nTraining Epoch: 12 [10880/50000]\tLoss: 0.3212\tLR: 0.002250\nTraining Epoch: 12 [11008/50000]\tLoss: 0.2123\tLR: 0.002250\nTraining Epoch: 12 [11136/50000]\tLoss: 0.4210\tLR: 0.002250\nTraining Epoch: 12 [11264/50000]\tLoss: 0.3095\tLR: 0.002250\nTraining Epoch: 12 [11392/50000]\tLoss: 0.2676\tLR: 0.002250\nTraining Epoch: 12 [11520/50000]\tLoss: 0.3170\tLR: 0.002250\nTraining Epoch: 12 [11648/50000]\tLoss: 0.2878\tLR: 0.002250\nTraining Epoch: 12 [11776/50000]\tLoss: 0.3269\tLR: 0.002250\nTraining Epoch: 12 [11904/50000]\tLoss: 0.3578\tLR: 0.002250\nTraining Epoch: 12 [12032/50000]\tLoss: 0.2674\tLR: 0.002250\nTraining Epoch: 12 [12160/50000]\tLoss: 0.3716\tLR: 0.002250\nTraining Epoch: 12 [12288/50000]\tLoss: 0.3434\tLR: 0.002250\nTraining Epoch: 12 [12416/50000]\tLoss: 0.2711\tLR: 0.002250\nTraining Epoch: 12 [12544/50000]\tLoss: 0.1728\tLR: 0.002250\nTraining Epoch: 12 [12672/50000]\tLoss: 0.4164\tLR: 0.002250\nTraining Epoch: 12 [12800/50000]\tLoss: 0.3244\tLR: 0.002250\nTraining Epoch: 12 [12928/50000]\tLoss: 0.4175\tLR: 0.002250\nTraining Epoch: 12 [13056/50000]\tLoss: 0.1962\tLR: 0.002250\nTraining Epoch: 12 [13184/50000]\tLoss: 0.2661\tLR: 0.002250\nTraining Epoch: 12 [13312/50000]\tLoss: 0.3008\tLR: 0.002250\nTraining Epoch: 12 [13440/50000]\tLoss: 0.3657\tLR: 0.002250\nTraining Epoch: 12 [13568/50000]\tLoss: 0.2830\tLR: 0.002250\nTraining Epoch: 12 [13696/50000]\tLoss: 0.3156\tLR: 0.002250\nTraining Epoch: 12 [13824/50000]\tLoss: 0.2787\tLR: 0.002250\nTraining Epoch: 12 [13952/50000]\tLoss: 0.3861\tLR: 0.002250\nTraining Epoch: 12 [14080/50000]\tLoss: 0.4426\tLR: 0.002250\nTraining Epoch: 12 [14208/50000]\tLoss: 0.4002\tLR: 0.002250\nTraining Epoch: 12 [14336/50000]\tLoss: 0.3566\tLR: 0.002250\nTraining Epoch: 12 [14464/50000]\tLoss: 0.3549\tLR: 0.002250\nTraining Epoch: 12 [14592/50000]\tLoss: 0.4841\tLR: 0.002250\nTraining Epoch: 12 [14720/50000]\tLoss: 0.2834\tLR: 0.002250\nTraining Epoch: 12 [14848/50000]\tLoss: 0.2701\tLR: 0.002250\nTraining Epoch: 12 [14976/50000]\tLoss: 0.3411\tLR: 0.002250\nTraining Epoch: 12 [15104/50000]\tLoss: 0.3469\tLR: 0.002250\nTraining Epoch: 12 [15232/50000]\tLoss: 0.2745\tLR: 0.002250\nTraining Epoch: 12 [15360/50000]\tLoss: 0.3917\tLR: 0.002250\nTraining Epoch: 12 [15488/50000]\tLoss: 0.3267\tLR: 0.002250\nTraining Epoch: 12 [15616/50000]\tLoss: 0.4295\tLR: 0.002250\nTraining Epoch: 12 [15744/50000]\tLoss: 0.3217\tLR: 0.002250\nTraining Epoch: 12 [15872/50000]\tLoss: 0.2319\tLR: 0.002250\nTraining Epoch: 12 [16000/50000]\tLoss: 0.4283\tLR: 0.002250\nTraining Epoch: 12 [16128/50000]\tLoss: 0.3426\tLR: 0.002250\nTraining Epoch: 12 [16256/50000]\tLoss: 0.2944\tLR: 0.002250\nTraining Epoch: 12 [16384/50000]\tLoss: 0.4271\tLR: 0.002250\nTraining Epoch: 12 [16512/50000]\tLoss: 0.3377\tLR: 0.002250\nTraining Epoch: 12 [16640/50000]\tLoss: 0.2039\tLR: 0.002250\nTraining Epoch: 12 [16768/50000]\tLoss: 0.3365\tLR: 0.002250\nTraining Epoch: 12 [16896/50000]\tLoss: 0.2629\tLR: 0.002250\nTraining Epoch: 12 [17024/50000]\tLoss: 0.2575\tLR: 0.002250\nTraining Epoch: 12 [17152/50000]\tLoss: 0.4143\tLR: 0.002250\nTraining Epoch: 12 [17280/50000]\tLoss: 0.3912\tLR: 0.002250\nTraining Epoch: 12 [17408/50000]\tLoss: 0.3745\tLR: 0.002250\nTraining Epoch: 12 [17536/50000]\tLoss: 0.2355\tLR: 0.002250\nTraining Epoch: 12 [17664/50000]\tLoss: 0.2867\tLR: 0.002250\nTraining Epoch: 12 [17792/50000]\tLoss: 0.2838\tLR: 0.002250\nTraining Epoch: 12 [17920/50000]\tLoss: 0.3567\tLR: 0.002250\nTraining Epoch: 12 [18048/50000]\tLoss: 0.3149\tLR: 0.002250\nTraining Epoch: 12 [18176/50000]\tLoss: 0.2846\tLR: 0.002250\nTraining Epoch: 12 [18304/50000]\tLoss: 0.4525\tLR: 0.002250\nTraining Epoch: 12 [18432/50000]\tLoss: 0.2656\tLR: 0.002250\nTraining Epoch: 12 [18560/50000]\tLoss: 0.2210\tLR: 0.002250\nTraining Epoch: 12 [18688/50000]\tLoss: 0.3837\tLR: 0.002250\nTraining Epoch: 12 [18816/50000]\tLoss: 0.3563\tLR: 0.002250\nTraining Epoch: 12 [18944/50000]\tLoss: 0.4468\tLR: 0.002250\nTraining Epoch: 12 [19072/50000]\tLoss: 0.2564\tLR: 0.002250\nTraining Epoch: 12 [19200/50000]\tLoss: 0.2319\tLR: 0.002250\nTraining Epoch: 12 [19328/50000]\tLoss: 0.3740\tLR: 0.002250\nTraining Epoch: 12 [19456/50000]\tLoss: 0.3413\tLR: 0.002250\nTraining Epoch: 12 [19584/50000]\tLoss: 0.3069\tLR: 0.002250\nTraining Epoch: 12 [19712/50000]\tLoss: 0.2385\tLR: 0.002250\nTraining Epoch: 12 [19840/50000]\tLoss: 0.3783\tLR: 0.002250\nTraining Epoch: 12 [19968/50000]\tLoss: 0.3813\tLR: 0.002250\nTraining Epoch: 12 [20096/50000]\tLoss: 0.2875\tLR: 0.002250\nTraining Epoch: 12 [20224/50000]\tLoss: 0.3522\tLR: 0.002250\nTraining Epoch: 12 [20352/50000]\tLoss: 0.3621\tLR: 0.002250\nTraining Epoch: 12 [20480/50000]\tLoss: 0.2239\tLR: 0.002250\nTraining Epoch: 12 [20608/50000]\tLoss: 0.3873\tLR: 0.002250\nTraining Epoch: 12 [20736/50000]\tLoss: 0.2690\tLR: 0.002250\nTraining Epoch: 12 [20864/50000]\tLoss: 0.3052\tLR: 0.002250\nTraining Epoch: 12 [20992/50000]\tLoss: 0.3687\tLR: 0.002250\nTraining Epoch: 12 [21120/50000]\tLoss: 0.3394\tLR: 0.002250\nTraining Epoch: 12 [21248/50000]\tLoss: 0.3532\tLR: 0.002250\nTraining Epoch: 12 [21376/50000]\tLoss: 0.3192\tLR: 0.002250\nTraining Epoch: 12 [21504/50000]\tLoss: 0.3728\tLR: 0.002250\nTraining Epoch: 12 [21632/50000]\tLoss: 0.3007\tLR: 0.002250\nTraining Epoch: 12 [21760/50000]\tLoss: 0.4217\tLR: 0.002250\nTraining Epoch: 12 [21888/50000]\tLoss: 0.2262\tLR: 0.002250\nTraining Epoch: 12 [22016/50000]\tLoss: 0.2978\tLR: 0.002250\nTraining Epoch: 12 [22144/50000]\tLoss: 0.5946\tLR: 0.002250\nTraining Epoch: 12 [22272/50000]\tLoss: 0.3260\tLR: 0.002250\nTraining Epoch: 12 [22400/50000]\tLoss: 0.2689\tLR: 0.002250\nTraining Epoch: 12 [22528/50000]\tLoss: 0.2684\tLR: 0.002250\nTraining Epoch: 12 [22656/50000]\tLoss: 0.4272\tLR: 0.002250\nTraining Epoch: 12 [22784/50000]\tLoss: 0.3673\tLR: 0.002250\nTraining Epoch: 12 [22912/50000]\tLoss: 0.3285\tLR: 0.002250\nTraining Epoch: 12 [23040/50000]\tLoss: 0.2421\tLR: 0.002250\nTraining Epoch: 12 [23168/50000]\tLoss: 0.2502\tLR: 0.002250\nTraining Epoch: 12 [23296/50000]\tLoss: 0.3072\tLR: 0.002250\nTraining Epoch: 12 [23424/50000]\tLoss: 0.2627\tLR: 0.002250\nTraining Epoch: 12 [23552/50000]\tLoss: 0.3147\tLR: 0.002250\nTraining Epoch: 12 [23680/50000]\tLoss: 0.2883\tLR: 0.002250\nTraining Epoch: 12 [23808/50000]\tLoss: 0.3754\tLR: 0.002250\nTraining Epoch: 12 [23936/50000]\tLoss: 0.3056\tLR: 0.002250\nTraining Epoch: 12 [24064/50000]\tLoss: 0.3214\tLR: 0.002250\nTraining Epoch: 12 [24192/50000]\tLoss: 0.2505\tLR: 0.002250\nTraining Epoch: 12 [24320/50000]\tLoss: 0.2887\tLR: 0.002250\nTraining Epoch: 12 [24448/50000]\tLoss: 0.3631\tLR: 0.002250\nTraining Epoch: 12 [24576/50000]\tLoss: 0.3587\tLR: 0.002250\nTraining Epoch: 12 [24704/50000]\tLoss: 0.3024\tLR: 0.002250\nTraining Epoch: 12 [24832/50000]\tLoss: 0.3183\tLR: 0.002250\nTraining Epoch: 12 [24960/50000]\tLoss: 0.3718\tLR: 0.002250\nTraining Epoch: 12 [25088/50000]\tLoss: 0.3603\tLR: 0.002250\nTraining Epoch: 12 [25216/50000]\tLoss: 0.3338\tLR: 0.002250\nTraining Epoch: 12 [25344/50000]\tLoss: 0.3562\tLR: 0.002250\nTraining Epoch: 12 [25472/50000]\tLoss: 0.3078\tLR: 0.002250\nTraining Epoch: 12 [25600/50000]\tLoss: 0.2188\tLR: 0.002250\nTraining Epoch: 12 [25728/50000]\tLoss: 0.2776\tLR: 0.002250\nTraining Epoch: 12 [25856/50000]\tLoss: 0.3286\tLR: 0.002250\nTraining Epoch: 12 [25984/50000]\tLoss: 0.3265\tLR: 0.002250\nTraining Epoch: 12 [26112/50000]\tLoss: 0.3863\tLR: 0.002250\nTraining Epoch: 12 [26240/50000]\tLoss: 0.2953\tLR: 0.002250\nTraining Epoch: 12 [26368/50000]\tLoss: 0.3276\tLR: 0.002250\nTraining Epoch: 12 [26496/50000]\tLoss: 0.3816\tLR: 0.002250\nTraining Epoch: 12 [26624/50000]\tLoss: 0.2401\tLR: 0.002250\nTraining Epoch: 12 [26752/50000]\tLoss: 0.2338\tLR: 0.002250\nTraining Epoch: 12 [26880/50000]\tLoss: 0.3174\tLR: 0.002250\nTraining Epoch: 12 [27008/50000]\tLoss: 0.3871\tLR: 0.002250\nTraining Epoch: 12 [27136/50000]\tLoss: 0.2547\tLR: 0.002250\nTraining Epoch: 12 [27264/50000]\tLoss: 0.2775\tLR: 0.002250\nTraining Epoch: 12 [27392/50000]\tLoss: 0.2606\tLR: 0.002250\nTraining Epoch: 12 [27520/50000]\tLoss: 0.3256\tLR: 0.002250\nTraining Epoch: 12 [27648/50000]\tLoss: 0.3698\tLR: 0.002250\nTraining Epoch: 12 [27776/50000]\tLoss: 0.2364\tLR: 0.002250\nTraining Epoch: 12 [27904/50000]\tLoss: 0.1986\tLR: 0.002250\nTraining Epoch: 12 [28032/50000]\tLoss: 0.4759\tLR: 0.002250\nTraining Epoch: 12 [28160/50000]\tLoss: 0.3147\tLR: 0.002250\nTraining Epoch: 12 [28288/50000]\tLoss: 0.3442\tLR: 0.002250\nTraining Epoch: 12 [28416/50000]\tLoss: 0.4179\tLR: 0.002250\nTraining Epoch: 12 [28544/50000]\tLoss: 0.3842\tLR: 0.002250\nTraining Epoch: 12 [28672/50000]\tLoss: 0.3451\tLR: 0.002250\nTraining Epoch: 12 [28800/50000]\tLoss: 0.3208\tLR: 0.002250\nTraining Epoch: 12 [28928/50000]\tLoss: 0.2680\tLR: 0.002250\nTraining Epoch: 12 [29056/50000]\tLoss: 0.3187\tLR: 0.002250\nTraining Epoch: 12 [29184/50000]\tLoss: 0.3484\tLR: 0.002250\nTraining Epoch: 12 [29312/50000]\tLoss: 0.3635\tLR: 0.002250\nTraining Epoch: 12 [29440/50000]\tLoss: 0.4794\tLR: 0.002250\nTraining Epoch: 12 [29568/50000]\tLoss: 0.3275\tLR: 0.002250\nTraining Epoch: 12 [29696/50000]\tLoss: 0.3662\tLR: 0.002250\nTraining Epoch: 12 [29824/50000]\tLoss: 0.3757\tLR: 0.002250\nTraining Epoch: 12 [29952/50000]\tLoss: 0.3030\tLR: 0.002250\nTraining Epoch: 12 [30080/50000]\tLoss: 0.2892\tLR: 0.002250\nTraining Epoch: 12 [30208/50000]\tLoss: 0.3586\tLR: 0.002250\nTraining Epoch: 12 [30336/50000]\tLoss: 0.2002\tLR: 0.002250\nTraining Epoch: 12 [30464/50000]\tLoss: 0.3483\tLR: 0.002250\nTraining Epoch: 12 [30592/50000]\tLoss: 0.2888\tLR: 0.002250\nTraining Epoch: 12 [30720/50000]\tLoss: 0.3991\tLR: 0.002250\nTraining Epoch: 12 [30848/50000]\tLoss: 0.3823\tLR: 0.002250\nTraining Epoch: 12 [30976/50000]\tLoss: 0.3329\tLR: 0.002250\nTraining Epoch: 12 [31104/50000]\tLoss: 0.3086\tLR: 0.002250\nTraining Epoch: 12 [31232/50000]\tLoss: 0.3020\tLR: 0.002250\nTraining Epoch: 12 [31360/50000]\tLoss: 0.3251\tLR: 0.002250\nTraining Epoch: 12 [31488/50000]\tLoss: 0.2327\tLR: 0.002250\nTraining Epoch: 12 [31616/50000]\tLoss: 0.3797\tLR: 0.002250\nTraining Epoch: 12 [31744/50000]\tLoss: 0.2697\tLR: 0.002250\nTraining Epoch: 12 [31872/50000]\tLoss: 0.3919\tLR: 0.002250\nTraining Epoch: 12 [32000/50000]\tLoss: 0.3535\tLR: 0.002250\nTraining Epoch: 12 [32128/50000]\tLoss: 0.3684\tLR: 0.002250\nTraining Epoch: 12 [32256/50000]\tLoss: 0.2897\tLR: 0.002250\nTraining Epoch: 12 [32384/50000]\tLoss: 0.3538\tLR: 0.002250\nTraining Epoch: 12 [32512/50000]\tLoss: 0.3425\tLR: 0.002250\nTraining Epoch: 12 [32640/50000]\tLoss: 0.4233\tLR: 0.002250\nTraining Epoch: 12 [32768/50000]\tLoss: 0.2978\tLR: 0.002250\nTraining Epoch: 12 [32896/50000]\tLoss: 0.5512\tLR: 0.002250\nTraining Epoch: 12 [33024/50000]\tLoss: 0.2949\tLR: 0.002250\nTraining Epoch: 12 [33152/50000]\tLoss: 0.2689\tLR: 0.002250\nTraining Epoch: 12 [33280/50000]\tLoss: 0.3146\tLR: 0.002250\nTraining Epoch: 12 [33408/50000]\tLoss: 0.4929\tLR: 0.002250\nTraining Epoch: 12 [33536/50000]\tLoss: 0.3623\tLR: 0.002250\nTraining Epoch: 12 [33664/50000]\tLoss: 0.3974\tLR: 0.002250\nTraining Epoch: 12 [33792/50000]\tLoss: 0.3321\tLR: 0.002250\nTraining Epoch: 12 [33920/50000]\tLoss: 0.3628\tLR: 0.002250\nTraining Epoch: 12 [34048/50000]\tLoss: 0.4037\tLR: 0.002250\nTraining Epoch: 12 [34176/50000]\tLoss: 0.3630\tLR: 0.002250\nTraining Epoch: 12 [34304/50000]\tLoss: 0.3678\tLR: 0.002250\nTraining Epoch: 12 [34432/50000]\tLoss: 0.3074\tLR: 0.002250\nTraining Epoch: 12 [34560/50000]\tLoss: 0.3463\tLR: 0.002250\nTraining Epoch: 12 [34688/50000]\tLoss: 0.3204\tLR: 0.002250\nTraining Epoch: 12 [34816/50000]\tLoss: 0.1805\tLR: 0.002250\nTraining Epoch: 12 [34944/50000]\tLoss: 0.2686\tLR: 0.002250\nTraining Epoch: 12 [35072/50000]\tLoss: 0.2874\tLR: 0.002250\nTraining Epoch: 12 [35200/50000]\tLoss: 0.2975\tLR: 0.002250\nTraining Epoch: 12 [35328/50000]\tLoss: 0.4851\tLR: 0.002250\nTraining Epoch: 12 [35456/50000]\tLoss: 0.2848\tLR: 0.002250\nTraining Epoch: 12 [35584/50000]\tLoss: 0.3228\tLR: 0.002250\nTraining Epoch: 12 [35712/50000]\tLoss: 0.2320\tLR: 0.002250\nTraining Epoch: 12 [35840/50000]\tLoss: 0.2392\tLR: 0.002250\nTraining Epoch: 12 [35968/50000]\tLoss: 0.2505\tLR: 0.002250\nTraining Epoch: 12 [36096/50000]\tLoss: 0.3261\tLR: 0.002250\nTraining Epoch: 12 [36224/50000]\tLoss: 0.5109\tLR: 0.002250\nTraining Epoch: 12 [36352/50000]\tLoss: 0.2796\tLR: 0.002250\nTraining Epoch: 12 [36480/50000]\tLoss: 0.2977\tLR: 0.002250\nTraining Epoch: 12 [36608/50000]\tLoss: 0.3051\tLR: 0.002250\nTraining Epoch: 12 [36736/50000]\tLoss: 0.3638\tLR: 0.002250\nTraining Epoch: 12 [36864/50000]\tLoss: 0.3245\tLR: 0.002250\nTraining Epoch: 12 [36992/50000]\tLoss: 0.3398\tLR: 0.002250\nTraining Epoch: 12 [37120/50000]\tLoss: 0.2948\tLR: 0.002250\nTraining Epoch: 12 [37248/50000]\tLoss: 0.3611\tLR: 0.002250\nTraining Epoch: 12 [37376/50000]\tLoss: 0.2566\tLR: 0.002250\nTraining Epoch: 12 [37504/50000]\tLoss: 0.3752\tLR: 0.002250\nTraining Epoch: 12 [37632/50000]\tLoss: 0.3429\tLR: 0.002250\nTraining Epoch: 12 [37760/50000]\tLoss: 0.3505\tLR: 0.002250\nTraining Epoch: 12 [37888/50000]\tLoss: 0.2917\tLR: 0.002250\nTraining Epoch: 12 [38016/50000]\tLoss: 0.3097\tLR: 0.002250\nTraining Epoch: 12 [38144/50000]\tLoss: 0.3356\tLR: 0.002250\nTraining Epoch: 12 [38272/50000]\tLoss: 0.2415\tLR: 0.002250\nTraining Epoch: 12 [38400/50000]\tLoss: 0.2349\tLR: 0.002250\nTraining Epoch: 12 [38528/50000]\tLoss: 0.2398\tLR: 0.002250\nTraining Epoch: 12 [38656/50000]\tLoss: 0.5216\tLR: 0.002250\nTraining Epoch: 12 [38784/50000]\tLoss: 0.2920\tLR: 0.002250\nTraining Epoch: 12 [38912/50000]\tLoss: 0.3484\tLR: 0.002250\nTraining Epoch: 12 [39040/50000]\tLoss: 0.2797\tLR: 0.002250\nTraining Epoch: 12 [39168/50000]\tLoss: 0.3713\tLR: 0.002250\nTraining Epoch: 12 [39296/50000]\tLoss: 0.3380\tLR: 0.002250\nTraining Epoch: 12 [39424/50000]\tLoss: 0.3121\tLR: 0.002250\nTraining Epoch: 12 [39552/50000]\tLoss: 0.2547\tLR: 0.002250\nTraining Epoch: 12 [39680/50000]\tLoss: 0.2740\tLR: 0.002250\nTraining Epoch: 12 [39808/50000]\tLoss: 0.3005\tLR: 0.002250\nTraining Epoch: 12 [39936/50000]\tLoss: 0.3411\tLR: 0.002250\nTraining Epoch: 12 [40064/50000]\tLoss: 0.3130\tLR: 0.002250\nTraining Epoch: 12 [40192/50000]\tLoss: 0.2833\tLR: 0.002250\nTraining Epoch: 12 [40320/50000]\tLoss: 0.3127\tLR: 0.002250\nTraining Epoch: 12 [40448/50000]\tLoss: 0.3267\tLR: 0.002250\nTraining Epoch: 12 [40576/50000]\tLoss: 0.2944\tLR: 0.002250\nTraining Epoch: 12 [40704/50000]\tLoss: 0.2609\tLR: 0.002250\nTraining Epoch: 12 [40832/50000]\tLoss: 0.3942\tLR: 0.002250\nTraining Epoch: 12 [40960/50000]\tLoss: 0.2877\tLR: 0.002250\nTraining Epoch: 12 [41088/50000]\tLoss: 0.3631\tLR: 0.002250\nTraining Epoch: 12 [41216/50000]\tLoss: 0.3129\tLR: 0.002250\nTraining Epoch: 12 [41344/50000]\tLoss: 0.2902\tLR: 0.002250\nTraining Epoch: 12 [41472/50000]\tLoss: 0.2555\tLR: 0.002250\nTraining Epoch: 12 [41600/50000]\tLoss: 0.3639\tLR: 0.002250\nTraining Epoch: 12 [41728/50000]\tLoss: 0.3717\tLR: 0.002250\nTraining Epoch: 12 [41856/50000]\tLoss: 0.2945\tLR: 0.002250\nTraining Epoch: 12 [41984/50000]\tLoss: 0.3434\tLR: 0.002250\nTraining Epoch: 12 [42112/50000]\tLoss: 0.3110\tLR: 0.002250\nTraining Epoch: 12 [42240/50000]\tLoss: 0.4192\tLR: 0.002250\nTraining Epoch: 12 [42368/50000]\tLoss: 0.2394\tLR: 0.002250\nTraining Epoch: 12 [42496/50000]\tLoss: 0.1968\tLR: 0.002250\nTraining Epoch: 12 [42624/50000]\tLoss: 0.2880\tLR: 0.002250\nTraining Epoch: 12 [42752/50000]\tLoss: 0.2580\tLR: 0.002250\nTraining Epoch: 12 [42880/50000]\tLoss: 0.3048\tLR: 0.002250\nTraining Epoch: 12 [43008/50000]\tLoss: 0.3478\tLR: 0.002250\nTraining Epoch: 12 [43136/50000]\tLoss: 0.3354\tLR: 0.002250\nTraining Epoch: 12 [43264/50000]\tLoss: 0.4077\tLR: 0.002250\nTraining Epoch: 12 [43392/50000]\tLoss: 0.3348\tLR: 0.002250\nTraining Epoch: 12 [43520/50000]\tLoss: 0.3343\tLR: 0.002250\nTraining Epoch: 12 [43648/50000]\tLoss: 0.4200\tLR: 0.002250\nTraining Epoch: 12 [43776/50000]\tLoss: 0.3070\tLR: 0.002250\nTraining Epoch: 12 [43904/50000]\tLoss: 0.4128\tLR: 0.002250\nTraining Epoch: 12 [44032/50000]\tLoss: 0.3591\tLR: 0.002250\nTraining Epoch: 12 [44160/50000]\tLoss: 0.2766\tLR: 0.002250\nTraining Epoch: 12 [44288/50000]\tLoss: 0.2633\tLR: 0.002250\nTraining Epoch: 12 [44416/50000]\tLoss: 0.2750\tLR: 0.002250\nTraining Epoch: 12 [44544/50000]\tLoss: 0.3878\tLR: 0.002250\nTraining Epoch: 12 [44672/50000]\tLoss: 0.2776\tLR: 0.002250\nTraining Epoch: 12 [44800/50000]\tLoss: 0.2774\tLR: 0.002250\nTraining Epoch: 12 [44928/50000]\tLoss: 0.3488\tLR: 0.002250\nTraining Epoch: 12 [45056/50000]\tLoss: 0.3512\tLR: 0.002250\nTraining Epoch: 12 [45184/50000]\tLoss: 0.3323\tLR: 0.002250\nTraining Epoch: 12 [45312/50000]\tLoss: 0.3450\tLR: 0.002250\nTraining Epoch: 12 [45440/50000]\tLoss: 0.1948\tLR: 0.002250\nTraining Epoch: 12 [45568/50000]\tLoss: 0.3842\tLR: 0.002250\nTraining Epoch: 12 [45696/50000]\tLoss: 0.3298\tLR: 0.002250\nTraining Epoch: 12 [45824/50000]\tLoss: 0.3202\tLR: 0.002250\nTraining Epoch: 12 [45952/50000]\tLoss: 0.3078\tLR: 0.002250\nTraining Epoch: 12 [46080/50000]\tLoss: 0.2619\tLR: 0.002250\nTraining Epoch: 12 [46208/50000]\tLoss: 0.3063\tLR: 0.002250\nTraining Epoch: 12 [46336/50000]\tLoss: 0.2185\tLR: 0.002250\nTraining Epoch: 12 [46464/50000]\tLoss: 0.3248\tLR: 0.002250\nTraining Epoch: 12 [46592/50000]\tLoss: 0.2112\tLR: 0.002250\nTraining Epoch: 12 [46720/50000]\tLoss: 0.3961\tLR: 0.002250\nTraining Epoch: 12 [46848/50000]\tLoss: 0.3758\tLR: 0.002250\nTraining Epoch: 12 [46976/50000]\tLoss: 0.3041\tLR: 0.002250\nTraining Epoch: 12 [47104/50000]\tLoss: 0.3363\tLR: 0.002250\nTraining Epoch: 12 [47232/50000]\tLoss: 0.4341\tLR: 0.002250\nTraining Epoch: 12 [47360/50000]\tLoss: 0.3353\tLR: 0.002250\nTraining Epoch: 12 [47488/50000]\tLoss: 0.2875\tLR: 0.002250\nTraining Epoch: 12 [47616/50000]\tLoss: 0.3044\tLR: 0.002250\nTraining Epoch: 12 [47744/50000]\tLoss: 0.3572\tLR: 0.002250\nTraining Epoch: 12 [47872/50000]\tLoss: 0.2245\tLR: 0.002250\nTraining Epoch: 12 [48000/50000]\tLoss: 0.2901\tLR: 0.002250\nTraining Epoch: 12 [48128/50000]\tLoss: 0.3613\tLR: 0.002250\nTraining Epoch: 12 [48256/50000]\tLoss: 0.2929\tLR: 0.002250\nTraining Epoch: 12 [48384/50000]\tLoss: 0.3837\tLR: 0.002250\nTraining Epoch: 12 [48512/50000]\tLoss: 0.4068\tLR: 0.002250\nTraining Epoch: 12 [48640/50000]\tLoss: 0.4157\tLR: 0.002250\nTraining Epoch: 12 [48768/50000]\tLoss: 0.3273\tLR: 0.002250\nTraining Epoch: 12 [48896/50000]\tLoss: 0.3815\tLR: 0.002250\nTraining Epoch: 12 [49024/50000]\tLoss: 0.2832\tLR: 0.002250\nTraining Epoch: 12 [49152/50000]\tLoss: 0.2403\tLR: 0.002250\nTraining Epoch: 12 [49280/50000]\tLoss: 0.3284\tLR: 0.002250\nTraining Epoch: 12 [49408/50000]\tLoss: 0.2175\tLR: 0.002250\nTraining Epoch: 12 [49536/50000]\tLoss: 0.2887\tLR: 0.002250\nTraining Epoch: 12 [49664/50000]\tLoss: 0.2803\tLR: 0.002250\nTraining Epoch: 12 [49792/50000]\tLoss: 0.4210\tLR: 0.002250\nTraining Epoch: 12 [49920/50000]\tLoss: 0.3275\tLR: 0.002250\nTraining Epoch: 12 [50000/50000]\tLoss: 0.2247\tLR: 0.002250\nTest set: Average loss: 0.0027, Accuracy: 0.8851\n\nTraining Epoch: 13 [128/50000]\tLoss: 0.2711\tLR: 0.002250\nTraining Epoch: 13 [256/50000]\tLoss: 0.2347\tLR: 0.002250\nTraining Epoch: 13 [384/50000]\tLoss: 0.2573\tLR: 0.002250\nTraining Epoch: 13 [512/50000]\tLoss: 0.2524\tLR: 0.002250\nTraining Epoch: 13 [640/50000]\tLoss: 0.2670\tLR: 0.002250\nTraining Epoch: 13 [768/50000]\tLoss: 0.3290\tLR: 0.002250\nTraining Epoch: 13 [896/50000]\tLoss: 0.2794\tLR: 0.002250\nTraining Epoch: 13 [1024/50000]\tLoss: 0.3455\tLR: 0.002250\nTraining Epoch: 13 [1152/50000]\tLoss: 0.2703\tLR: 0.002250\nTraining Epoch: 13 [1280/50000]\tLoss: 0.2864\tLR: 0.002250\nTraining Epoch: 13 [1408/50000]\tLoss: 0.2594\tLR: 0.002250\nTraining Epoch: 13 [1536/50000]\tLoss: 0.2661\tLR: 0.002250\nTraining Epoch: 13 [1664/50000]\tLoss: 0.2547\tLR: 0.002250\nTraining Epoch: 13 [1792/50000]\tLoss: 0.4456\tLR: 0.002250\nTraining Epoch: 13 [1920/50000]\tLoss: 0.3589\tLR: 0.002250\nTraining Epoch: 13 [2048/50000]\tLoss: 0.2254\tLR: 0.002250\nTraining Epoch: 13 [2176/50000]\tLoss: 0.3980\tLR: 0.002250\nTraining Epoch: 13 [2304/50000]\tLoss: 0.3655\tLR: 0.002250\nTraining Epoch: 13 [2432/50000]\tLoss: 0.2160\tLR: 0.002250\nTraining Epoch: 13 [2560/50000]\tLoss: 0.3862\tLR: 0.002250\nTraining Epoch: 13 [2688/50000]\tLoss: 0.3054\tLR: 0.002250\nTraining Epoch: 13 [2816/50000]\tLoss: 0.2842\tLR: 0.002250\nTraining Epoch: 13 [2944/50000]\tLoss: 0.2763\tLR: 0.002250\nTraining Epoch: 13 [3072/50000]\tLoss: 0.2422\tLR: 0.002250\nTraining Epoch: 13 [3200/50000]\tLoss: 0.3518\tLR: 0.002250\nTraining Epoch: 13 [3328/50000]\tLoss: 0.3499\tLR: 0.002250\nTraining Epoch: 13 [3456/50000]\tLoss: 0.3518\tLR: 0.002250\nTraining Epoch: 13 [3584/50000]\tLoss: 0.1991\tLR: 0.002250\nTraining Epoch: 13 [3712/50000]\tLoss: 0.2796\tLR: 0.002250\nTraining Epoch: 13 [3840/50000]\tLoss: 0.3395\tLR: 0.002250\nTraining Epoch: 13 [3968/50000]\tLoss: 0.3964\tLR: 0.002250\nTraining Epoch: 13 [4096/50000]\tLoss: 0.3695\tLR: 0.002250\nTraining Epoch: 13 [4224/50000]\tLoss: 0.2492\tLR: 0.002250\nTraining Epoch: 13 [4352/50000]\tLoss: 0.2580\tLR: 0.002250\nTraining Epoch: 13 [4480/50000]\tLoss: 0.2581\tLR: 0.002250\nTraining Epoch: 13 [4608/50000]\tLoss: 0.3350\tLR: 0.002250\nTraining Epoch: 13 [4736/50000]\tLoss: 0.3057\tLR: 0.002250\nTraining Epoch: 13 [4864/50000]\tLoss: 0.2788\tLR: 0.002250\nTraining Epoch: 13 [4992/50000]\tLoss: 0.2211\tLR: 0.002250\nTraining Epoch: 13 [5120/50000]\tLoss: 0.2920\tLR: 0.002250\nTraining Epoch: 13 [5248/50000]\tLoss: 0.2761\tLR: 0.002250\nTraining Epoch: 13 [5376/50000]\tLoss: 0.2177\tLR: 0.002250\nTraining Epoch: 13 [5504/50000]\tLoss: 0.2496\tLR: 0.002250\nTraining Epoch: 13 [5632/50000]\tLoss: 0.3490\tLR: 0.002250\nTraining Epoch: 13 [5760/50000]\tLoss: 0.3739\tLR: 0.002250\nTraining Epoch: 13 [5888/50000]\tLoss: 0.2907\tLR: 0.002250\nTraining Epoch: 13 [6016/50000]\tLoss: 0.3647\tLR: 0.002250\nTraining Epoch: 13 [6144/50000]\tLoss: 0.3318\tLR: 0.002250\nTraining Epoch: 13 [6272/50000]\tLoss: 0.3455\tLR: 0.002250\nTraining Epoch: 13 [6400/50000]\tLoss: 0.2839\tLR: 0.002250\nTraining Epoch: 13 [6528/50000]\tLoss: 0.3129\tLR: 0.002250\nTraining Epoch: 13 [6656/50000]\tLoss: 0.3031\tLR: 0.002250\nTraining Epoch: 13 [6784/50000]\tLoss: 0.3062\tLR: 0.002250\nTraining Epoch: 13 [6912/50000]\tLoss: 0.1884\tLR: 0.002250\nTraining Epoch: 13 [7040/50000]\tLoss: 0.2209\tLR: 0.002250\nTraining Epoch: 13 [7168/50000]\tLoss: 0.3555\tLR: 0.002250\nTraining Epoch: 13 [7296/50000]\tLoss: 0.3947\tLR: 0.002250\nTraining Epoch: 13 [7424/50000]\tLoss: 0.3566\tLR: 0.002250\nTraining Epoch: 13 [7552/50000]\tLoss: 0.1856\tLR: 0.002250\nTraining Epoch: 13 [7680/50000]\tLoss: 0.2722\tLR: 0.002250\nTraining Epoch: 13 [7808/50000]\tLoss: 0.3128\tLR: 0.002250\nTraining Epoch: 13 [7936/50000]\tLoss: 0.3253\tLR: 0.002250\nTraining Epoch: 13 [8064/50000]\tLoss: 0.3903\tLR: 0.002250\nTraining Epoch: 13 [8192/50000]\tLoss: 0.3651\tLR: 0.002250\nTraining Epoch: 13 [8320/50000]\tLoss: 0.3608\tLR: 0.002250\nTraining Epoch: 13 [8448/50000]\tLoss: 0.3385\tLR: 0.002250\nTraining Epoch: 13 [8576/50000]\tLoss: 0.3725\tLR: 0.002250\nTraining Epoch: 13 [8704/50000]\tLoss: 0.4110\tLR: 0.002250\nTraining Epoch: 13 [8832/50000]\tLoss: 0.3187\tLR: 0.002250\nTraining Epoch: 13 [8960/50000]\tLoss: 0.3383\tLR: 0.002250\nTraining Epoch: 13 [9088/50000]\tLoss: 0.3241\tLR: 0.002250\nTraining Epoch: 13 [9216/50000]\tLoss: 0.1465\tLR: 0.002250\nTraining Epoch: 13 [9344/50000]\tLoss: 0.2636\tLR: 0.002250\nTraining Epoch: 13 [9472/50000]\tLoss: 0.2141\tLR: 0.002250\nTraining Epoch: 13 [9600/50000]\tLoss: 0.3983\tLR: 0.002250\nTraining Epoch: 13 [9728/50000]\tLoss: 0.3639\tLR: 0.002250\nTraining Epoch: 13 [9856/50000]\tLoss: 0.3677\tLR: 0.002250\nTraining Epoch: 13 [9984/50000]\tLoss: 0.3305\tLR: 0.002250\nTraining Epoch: 13 [10112/50000]\tLoss: 0.3448\tLR: 0.002250\nTraining Epoch: 13 [10240/50000]\tLoss: 0.3035\tLR: 0.002250\nTraining Epoch: 13 [10368/50000]\tLoss: 0.3089\tLR: 0.002250\nTraining Epoch: 13 [10496/50000]\tLoss: 0.3299\tLR: 0.002250\nTraining Epoch: 13 [10624/50000]\tLoss: 0.4190\tLR: 0.002250\nTraining Epoch: 13 [10752/50000]\tLoss: 0.4113\tLR: 0.002250\nTraining Epoch: 13 [10880/50000]\tLoss: 0.2479\tLR: 0.002250\nTraining Epoch: 13 [11008/50000]\tLoss: 0.3857\tLR: 0.002250\nTraining Epoch: 13 [11136/50000]\tLoss: 0.2850\tLR: 0.002250\nTraining Epoch: 13 [11264/50000]\tLoss: 0.2694\tLR: 0.002250\nTraining Epoch: 13 [11392/50000]\tLoss: 0.3646\tLR: 0.002250\nTraining Epoch: 13 [11520/50000]\tLoss: 0.2729\tLR: 0.002250\nTraining Epoch: 13 [11648/50000]\tLoss: 0.3369\tLR: 0.002250\nTraining Epoch: 13 [11776/50000]\tLoss: 0.3438\tLR: 0.002250\nTraining Epoch: 13 [11904/50000]\tLoss: 0.3935\tLR: 0.002250\nTraining Epoch: 13 [12032/50000]\tLoss: 0.3543\tLR: 0.002250\nTraining Epoch: 13 [12160/50000]\tLoss: 0.2747\tLR: 0.002250\nTraining Epoch: 13 [12288/50000]\tLoss: 0.2661\tLR: 0.002250\nTraining Epoch: 13 [12416/50000]\tLoss: 0.3797\tLR: 0.002250\nTraining Epoch: 13 [12544/50000]\tLoss: 0.3222\tLR: 0.002250\nTraining Epoch: 13 [12672/50000]\tLoss: 0.2952\tLR: 0.002250\nTraining Epoch: 13 [12800/50000]\tLoss: 0.3564\tLR: 0.002250\nTraining Epoch: 13 [12928/50000]\tLoss: 0.3179\tLR: 0.002250\nTraining Epoch: 13 [13056/50000]\tLoss: 0.3793\tLR: 0.002250\nTraining Epoch: 13 [13184/50000]\tLoss: 0.3570\tLR: 0.002250\nTraining Epoch: 13 [13312/50000]\tLoss: 0.2545\tLR: 0.002250\nTraining Epoch: 13 [13440/50000]\tLoss: 0.3363\tLR: 0.002250\nTraining Epoch: 13 [13568/50000]\tLoss: 0.2507\tLR: 0.002250\nTraining Epoch: 13 [13696/50000]\tLoss: 0.3601\tLR: 0.002250\nTraining Epoch: 13 [13824/50000]\tLoss: 0.2139\tLR: 0.002250\nTraining Epoch: 13 [13952/50000]\tLoss: 0.3441\tLR: 0.002250\nTraining Epoch: 13 [14080/50000]\tLoss: 0.3224\tLR: 0.002250\nTraining Epoch: 13 [14208/50000]\tLoss: 0.3424\tLR: 0.002250\nTraining Epoch: 13 [14336/50000]\tLoss: 0.3659\tLR: 0.002250\nTraining Epoch: 13 [14464/50000]\tLoss: 0.2969\tLR: 0.002250\nTraining Epoch: 13 [14592/50000]\tLoss: 0.3994\tLR: 0.002250\nTraining Epoch: 13 [14720/50000]\tLoss: 0.2683\tLR: 0.002250\nTraining Epoch: 13 [14848/50000]\tLoss: 0.4315\tLR: 0.002250\nTraining Epoch: 13 [14976/50000]\tLoss: 0.3252\tLR: 0.002250\nTraining Epoch: 13 [15104/50000]\tLoss: 0.3260\tLR: 0.002250\nTraining Epoch: 13 [15232/50000]\tLoss: 0.4226\tLR: 0.002250\nTraining Epoch: 13 [15360/50000]\tLoss: 0.4883\tLR: 0.002250\nTraining Epoch: 13 [15488/50000]\tLoss: 0.2980\tLR: 0.002250\nTraining Epoch: 13 [15616/50000]\tLoss: 0.3159\tLR: 0.002250\nTraining Epoch: 13 [15744/50000]\tLoss: 0.2954\tLR: 0.002250\nTraining Epoch: 13 [15872/50000]\tLoss: 0.3919\tLR: 0.002250\nTraining Epoch: 13 [16000/50000]\tLoss: 0.3402\tLR: 0.002250\nTraining Epoch: 13 [16128/50000]\tLoss: 0.3718\tLR: 0.002250\nTraining Epoch: 13 [16256/50000]\tLoss: 0.3053\tLR: 0.002250\nTraining Epoch: 13 [16384/50000]\tLoss: 0.3482\tLR: 0.002250\nTraining Epoch: 13 [16512/50000]\tLoss: 0.4021\tLR: 0.002250\nTraining Epoch: 13 [16640/50000]\tLoss: 0.4794\tLR: 0.002250\nTraining Epoch: 13 [16768/50000]\tLoss: 0.2622\tLR: 0.002250\nTraining Epoch: 13 [16896/50000]\tLoss: 0.2939\tLR: 0.002250\nTraining Epoch: 13 [17024/50000]\tLoss: 0.3486\tLR: 0.002250\nTraining Epoch: 13 [17152/50000]\tLoss: 0.3085\tLR: 0.002250\nTraining Epoch: 13 [17280/50000]\tLoss: 0.2228\tLR: 0.002250\nTraining Epoch: 13 [17408/50000]\tLoss: 0.3070\tLR: 0.002250\nTraining Epoch: 13 [17536/50000]\tLoss: 0.2669\tLR: 0.002250\nTraining Epoch: 13 [17664/50000]\tLoss: 0.2938\tLR: 0.002250\nTraining Epoch: 13 [17792/50000]\tLoss: 0.3411\tLR: 0.002250\nTraining Epoch: 13 [17920/50000]\tLoss: 0.3054\tLR: 0.002250\nTraining Epoch: 13 [18048/50000]\tLoss: 0.4040\tLR: 0.002250\nTraining Epoch: 13 [18176/50000]\tLoss: 0.2964\tLR: 0.002250\nTraining Epoch: 13 [18304/50000]\tLoss: 0.3109\tLR: 0.002250\nTraining Epoch: 13 [18432/50000]\tLoss: 0.2270\tLR: 0.002250\nTraining Epoch: 13 [18560/50000]\tLoss: 0.3017\tLR: 0.002250\nTraining Epoch: 13 [18688/50000]\tLoss: 0.2735\tLR: 0.002250\nTraining Epoch: 13 [18816/50000]\tLoss: 0.3033\tLR: 0.002250\nTraining Epoch: 13 [18944/50000]\tLoss: 0.2250\tLR: 0.002250\nTraining Epoch: 13 [19072/50000]\tLoss: 0.2867\tLR: 0.002250\nTraining Epoch: 13 [19200/50000]\tLoss: 0.3084\tLR: 0.002250\nTraining Epoch: 13 [19328/50000]\tLoss: 0.3182\tLR: 0.002250\nTraining Epoch: 13 [19456/50000]\tLoss: 0.3064\tLR: 0.002250\nTraining Epoch: 13 [19584/50000]\tLoss: 0.2521\tLR: 0.002250\nTraining Epoch: 13 [19712/50000]\tLoss: 0.2621\tLR: 0.002250\nTraining Epoch: 13 [19840/50000]\tLoss: 0.2940\tLR: 0.002250\nTraining Epoch: 13 [19968/50000]\tLoss: 0.3023\tLR: 0.002250\nTraining Epoch: 13 [20096/50000]\tLoss: 0.3426\tLR: 0.002250\nTraining Epoch: 13 [20224/50000]\tLoss: 0.2178\tLR: 0.002250\nTraining Epoch: 13 [20352/50000]\tLoss: 0.2078\tLR: 0.002250\nTraining Epoch: 13 [20480/50000]\tLoss: 0.2853\tLR: 0.002250\nTraining Epoch: 13 [20608/50000]\tLoss: 0.2371\tLR: 0.002250\nTraining Epoch: 13 [20736/50000]\tLoss: 0.3267\tLR: 0.002250\nTraining Epoch: 13 [20864/50000]\tLoss: 0.3505\tLR: 0.002250\nTraining Epoch: 13 [20992/50000]\tLoss: 0.2402\tLR: 0.002250\nTraining Epoch: 13 [21120/50000]\tLoss: 0.2687\tLR: 0.002250\nTraining Epoch: 13 [21248/50000]\tLoss: 0.3852\tLR: 0.002250\nTraining Epoch: 13 [21376/50000]\tLoss: 0.2744\tLR: 0.002250\nTraining Epoch: 13 [21504/50000]\tLoss: 0.2404\tLR: 0.002250\nTraining Epoch: 13 [21632/50000]\tLoss: 0.3018\tLR: 0.002250\nTraining Epoch: 13 [21760/50000]\tLoss: 0.3533\tLR: 0.002250\nTraining Epoch: 13 [21888/50000]\tLoss: 0.3603\tLR: 0.002250\nTraining Epoch: 13 [22016/50000]\tLoss: 0.3045\tLR: 0.002250\nTraining Epoch: 13 [22144/50000]\tLoss: 0.3605\tLR: 0.002250\nTraining Epoch: 13 [22272/50000]\tLoss: 0.4104\tLR: 0.002250\nTraining Epoch: 13 [22400/50000]\tLoss: 0.2432\tLR: 0.002250\nTraining Epoch: 13 [22528/50000]\tLoss: 0.2559\tLR: 0.002250\nTraining Epoch: 13 [22656/50000]\tLoss: 0.4204\tLR: 0.002250\nTraining Epoch: 13 [22784/50000]\tLoss: 0.3053\tLR: 0.002250\nTraining Epoch: 13 [22912/50000]\tLoss: 0.2158\tLR: 0.002250\nTraining Epoch: 13 [23040/50000]\tLoss: 0.3027\tLR: 0.002250\nTraining Epoch: 13 [23168/50000]\tLoss: 0.2701\tLR: 0.002250\nTraining Epoch: 13 [23296/50000]\tLoss: 0.3157\tLR: 0.002250\nTraining Epoch: 13 [23424/50000]\tLoss: 0.2242\tLR: 0.002250\nTraining Epoch: 13 [23552/50000]\tLoss: 0.2594\tLR: 0.002250\nTraining Epoch: 13 [23680/50000]\tLoss: 0.3628\tLR: 0.002250\nTraining Epoch: 13 [23808/50000]\tLoss: 0.2722\tLR: 0.002250\nTraining Epoch: 13 [23936/50000]\tLoss: 0.2943\tLR: 0.002250\nTraining Epoch: 13 [24064/50000]\tLoss: 0.2961\tLR: 0.002250\nTraining Epoch: 13 [24192/50000]\tLoss: 0.2789\tLR: 0.002250\nTraining Epoch: 13 [24320/50000]\tLoss: 0.3884\tLR: 0.002250\nTraining Epoch: 13 [24448/50000]\tLoss: 0.4122\tLR: 0.002250\nTraining Epoch: 13 [24576/50000]\tLoss: 0.3763\tLR: 0.002250\nTraining Epoch: 13 [24704/50000]\tLoss: 0.2957\tLR: 0.002250\nTraining Epoch: 13 [24832/50000]\tLoss: 0.3128\tLR: 0.002250\nTraining Epoch: 13 [24960/50000]\tLoss: 0.3195\tLR: 0.002250\nTraining Epoch: 13 [25088/50000]\tLoss: 0.3207\tLR: 0.002250\nTraining Epoch: 13 [25216/50000]\tLoss: 0.2781\tLR: 0.002250\nTraining Epoch: 13 [25344/50000]\tLoss: 0.3092\tLR: 0.002250\nTraining Epoch: 13 [25472/50000]\tLoss: 0.2380\tLR: 0.002250\nTraining Epoch: 13 [25600/50000]\tLoss: 0.2899\tLR: 0.002250\nTraining Epoch: 13 [25728/50000]\tLoss: 0.4417\tLR: 0.002250\nTraining Epoch: 13 [25856/50000]\tLoss: 0.3824\tLR: 0.002250\nTraining Epoch: 13 [25984/50000]\tLoss: 0.2621\tLR: 0.002250\nTraining Epoch: 13 [26112/50000]\tLoss: 0.3759\tLR: 0.002250\nTraining Epoch: 13 [26240/50000]\tLoss: 0.2791\tLR: 0.002250\nTraining Epoch: 13 [26368/50000]\tLoss: 0.2809\tLR: 0.002250\nTraining Epoch: 13 [26496/50000]\tLoss: 0.2318\tLR: 0.002250\nTraining Epoch: 13 [26624/50000]\tLoss: 0.2249\tLR: 0.002250\nTraining Epoch: 13 [26752/50000]\tLoss: 0.3874\tLR: 0.002250\nTraining Epoch: 13 [26880/50000]\tLoss: 0.2769\tLR: 0.002250\nTraining Epoch: 13 [27008/50000]\tLoss: 0.1720\tLR: 0.002250\nTraining Epoch: 13 [27136/50000]\tLoss: 0.2904\tLR: 0.002250\nTraining Epoch: 13 [27264/50000]\tLoss: 0.2187\tLR: 0.002250\nTraining Epoch: 13 [27392/50000]\tLoss: 0.2981\tLR: 0.002250\nTraining Epoch: 13 [27520/50000]\tLoss: 0.3335\tLR: 0.002250\nTraining Epoch: 13 [27648/50000]\tLoss: 0.3221\tLR: 0.002250\nTraining Epoch: 13 [27776/50000]\tLoss: 0.3602\tLR: 0.002250\nTraining Epoch: 13 [27904/50000]\tLoss: 0.4162\tLR: 0.002250\nTraining Epoch: 13 [28032/50000]\tLoss: 0.2423\tLR: 0.002250\nTraining Epoch: 13 [28160/50000]\tLoss: 0.4142\tLR: 0.002250\nTraining Epoch: 13 [28288/50000]\tLoss: 0.2234\tLR: 0.002250\nTraining Epoch: 13 [28416/50000]\tLoss: 0.3239\tLR: 0.002250\nTraining Epoch: 13 [28544/50000]\tLoss: 0.3000\tLR: 0.002250\nTraining Epoch: 13 [28672/50000]\tLoss: 0.2031\tLR: 0.002250\nTraining Epoch: 13 [28800/50000]\tLoss: 0.2725\tLR: 0.002250\nTraining Epoch: 13 [28928/50000]\tLoss: 0.4143\tLR: 0.002250\nTraining Epoch: 13 [29056/50000]\tLoss: 0.3245\tLR: 0.002250\nTraining Epoch: 13 [29184/50000]\tLoss: 0.2500\tLR: 0.002250\nTraining Epoch: 13 [29312/50000]\tLoss: 0.3209\tLR: 0.002250\nTraining Epoch: 13 [29440/50000]\tLoss: 0.2276\tLR: 0.002250\nTraining Epoch: 13 [29568/50000]\tLoss: 0.2876\tLR: 0.002250\nTraining Epoch: 13 [29696/50000]\tLoss: 0.3080\tLR: 0.002250\nTraining Epoch: 13 [29824/50000]\tLoss: 0.3980\tLR: 0.002250\nTraining Epoch: 13 [29952/50000]\tLoss: 0.3851\tLR: 0.002250\nTraining Epoch: 13 [30080/50000]\tLoss: 0.4140\tLR: 0.002250\nTraining Epoch: 13 [30208/50000]\tLoss: 0.2371\tLR: 0.002250\nTraining Epoch: 13 [30336/50000]\tLoss: 0.2583\tLR: 0.002250\nTraining Epoch: 13 [30464/50000]\tLoss: 0.2926\tLR: 0.002250\nTraining Epoch: 13 [30592/50000]\tLoss: 0.3750\tLR: 0.002250\nTraining Epoch: 13 [30720/50000]\tLoss: 0.3880\tLR: 0.002250\nTraining Epoch: 13 [30848/50000]\tLoss: 0.3310\tLR: 0.002250\nTraining Epoch: 13 [30976/50000]\tLoss: 0.2549\tLR: 0.002250\nTraining Epoch: 13 [31104/50000]\tLoss: 0.2631\tLR: 0.002250\nTraining Epoch: 13 [31232/50000]\tLoss: 0.2898\tLR: 0.002250\nTraining Epoch: 13 [31360/50000]\tLoss: 0.3463\tLR: 0.002250\nTraining Epoch: 13 [31488/50000]\tLoss: 0.2751\tLR: 0.002250\nTraining Epoch: 13 [31616/50000]\tLoss: 0.2825\tLR: 0.002250\nTraining Epoch: 13 [31744/50000]\tLoss: 0.3865\tLR: 0.002250\nTraining Epoch: 13 [31872/50000]\tLoss: 0.3668\tLR: 0.002250\nTraining Epoch: 13 [32000/50000]\tLoss: 0.3609\tLR: 0.002250\nTraining Epoch: 13 [32128/50000]\tLoss: 0.1998\tLR: 0.002250\nTraining Epoch: 13 [32256/50000]\tLoss: 0.2991\tLR: 0.002250\nTraining Epoch: 13 [32384/50000]\tLoss: 0.2442\tLR: 0.002250\nTraining Epoch: 13 [32512/50000]\tLoss: 0.3670\tLR: 0.002250\nTraining Epoch: 13 [32640/50000]\tLoss: 0.3818\tLR: 0.002250\nTraining Epoch: 13 [32768/50000]\tLoss: 0.2466\tLR: 0.002250\nTraining Epoch: 13 [32896/50000]\tLoss: 0.2407\tLR: 0.002250\nTraining Epoch: 13 [33024/50000]\tLoss: 0.2678\tLR: 0.002250\nTraining Epoch: 13 [33152/50000]\tLoss: 0.5137\tLR: 0.002250\nTraining Epoch: 13 [33280/50000]\tLoss: 0.3024\tLR: 0.002250\nTraining Epoch: 13 [33408/50000]\tLoss: 0.2830\tLR: 0.002250\nTraining Epoch: 13 [33536/50000]\tLoss: 0.2468\tLR: 0.002250\nTraining Epoch: 13 [33664/50000]\tLoss: 0.4778\tLR: 0.002250\nTraining Epoch: 13 [33792/50000]\tLoss: 0.2190\tLR: 0.002250\nTraining Epoch: 13 [33920/50000]\tLoss: 0.3116\tLR: 0.002250\nTraining Epoch: 13 [34048/50000]\tLoss: 0.3167\tLR: 0.002250\nTraining Epoch: 13 [34176/50000]\tLoss: 0.4140\tLR: 0.002250\nTraining Epoch: 13 [34304/50000]\tLoss: 0.2251\tLR: 0.002250\nTraining Epoch: 13 [34432/50000]\tLoss: 0.2510\tLR: 0.002250\nTraining Epoch: 13 [34560/50000]\tLoss: 0.2760\tLR: 0.002250\nTraining Epoch: 13 [34688/50000]\tLoss: 0.2444\tLR: 0.002250\nTraining Epoch: 13 [34816/50000]\tLoss: 0.2844\tLR: 0.002250\nTraining Epoch: 13 [34944/50000]\tLoss: 0.3653\tLR: 0.002250\nTraining Epoch: 13 [35072/50000]\tLoss: 0.3514\tLR: 0.002250\nTraining Epoch: 13 [35200/50000]\tLoss: 0.2270\tLR: 0.002250\nTraining Epoch: 13 [35328/50000]\tLoss: 0.2289\tLR: 0.002250\nTraining Epoch: 13 [35456/50000]\tLoss: 0.2434\tLR: 0.002250\nTraining Epoch: 13 [35584/50000]\tLoss: 0.3645\tLR: 0.002250\nTraining Epoch: 13 [35712/50000]\tLoss: 0.2759\tLR: 0.002250\nTraining Epoch: 13 [35840/50000]\tLoss: 0.3321\tLR: 0.002250\nTraining Epoch: 13 [35968/50000]\tLoss: 0.3735\tLR: 0.002250\nTraining Epoch: 13 [36096/50000]\tLoss: 0.2472\tLR: 0.002250\nTraining Epoch: 13 [36224/50000]\tLoss: 0.4322\tLR: 0.002250\nTraining Epoch: 13 [36352/50000]\tLoss: 0.2754\tLR: 0.002250\nTraining Epoch: 13 [36480/50000]\tLoss: 0.2794\tLR: 0.002250\nTraining Epoch: 13 [36608/50000]\tLoss: 0.2499\tLR: 0.002250\nTraining Epoch: 13 [36736/50000]\tLoss: 0.3774\tLR: 0.002250\nTraining Epoch: 13 [36864/50000]\tLoss: 0.2304\tLR: 0.002250\nTraining Epoch: 13 [36992/50000]\tLoss: 0.2374\tLR: 0.002250\nTraining Epoch: 13 [37120/50000]\tLoss: 0.3085\tLR: 0.002250\nTraining Epoch: 13 [37248/50000]\tLoss: 0.3006\tLR: 0.002250\nTraining Epoch: 13 [37376/50000]\tLoss: 0.2640\tLR: 0.002250\nTraining Epoch: 13 [37504/50000]\tLoss: 0.3739\tLR: 0.002250\nTraining Epoch: 13 [37632/50000]\tLoss: 0.3687\tLR: 0.002250\nTraining Epoch: 13 [37760/50000]\tLoss: 0.2516\tLR: 0.002250\nTraining Epoch: 13 [37888/50000]\tLoss: 0.3159\tLR: 0.002250\nTraining Epoch: 13 [38016/50000]\tLoss: 0.3558\tLR: 0.002250\nTraining Epoch: 13 [38144/50000]\tLoss: 0.3324\tLR: 0.002250\nTraining Epoch: 13 [38272/50000]\tLoss: 0.3240\tLR: 0.002250\nTraining Epoch: 13 [38400/50000]\tLoss: 0.3882\tLR: 0.002250\nTraining Epoch: 13 [38528/50000]\tLoss: 0.2287\tLR: 0.002250\nTraining Epoch: 13 [38656/50000]\tLoss: 0.3226\tLR: 0.002250\nTraining Epoch: 13 [38784/50000]\tLoss: 0.3481\tLR: 0.002250\nTraining Epoch: 13 [38912/50000]\tLoss: 0.4005\tLR: 0.002250\nTraining Epoch: 13 [39040/50000]\tLoss: 0.3853\tLR: 0.002250\nTraining Epoch: 13 [39168/50000]\tLoss: 0.4090\tLR: 0.002250\nTraining Epoch: 13 [39296/50000]\tLoss: 0.3839\tLR: 0.002250\nTraining Epoch: 13 [39424/50000]\tLoss: 0.2682\tLR: 0.002250\nTraining Epoch: 13 [39552/50000]\tLoss: 0.3242\tLR: 0.002250\nTraining Epoch: 13 [39680/50000]\tLoss: 0.2919\tLR: 0.002250\nTraining Epoch: 13 [39808/50000]\tLoss: 0.2800\tLR: 0.002250\nTraining Epoch: 13 [39936/50000]\tLoss: 0.2970\tLR: 0.002250\nTraining Epoch: 13 [40064/50000]\tLoss: 0.3871\tLR: 0.002250\nTraining Epoch: 13 [40192/50000]\tLoss: 0.3026\tLR: 0.002250\nTraining Epoch: 13 [40320/50000]\tLoss: 0.2558\tLR: 0.002250\nTraining Epoch: 13 [40448/50000]\tLoss: 0.3111\tLR: 0.002250\nTraining Epoch: 13 [40576/50000]\tLoss: 0.1831\tLR: 0.002250\nTraining Epoch: 13 [40704/50000]\tLoss: 0.3193\tLR: 0.002250\nTraining Epoch: 13 [40832/50000]\tLoss: 0.4365\tLR: 0.002250\nTraining Epoch: 13 [40960/50000]\tLoss: 0.3340\tLR: 0.002250\nTraining Epoch: 13 [41088/50000]\tLoss: 0.1974\tLR: 0.002250\nTraining Epoch: 13 [41216/50000]\tLoss: 0.4024\tLR: 0.002250\nTraining Epoch: 13 [41344/50000]\tLoss: 0.3973\tLR: 0.002250\nTraining Epoch: 13 [41472/50000]\tLoss: 0.2086\tLR: 0.002250\nTraining Epoch: 13 [41600/50000]\tLoss: 0.3157\tLR: 0.002250\nTraining Epoch: 13 [41728/50000]\tLoss: 0.2523\tLR: 0.002250\nTraining Epoch: 13 [41856/50000]\tLoss: 0.4293\tLR: 0.002250\nTraining Epoch: 13 [41984/50000]\tLoss: 0.3805\tLR: 0.002250\nTraining Epoch: 13 [42112/50000]\tLoss: 0.4118\tLR: 0.002250\nTraining Epoch: 13 [42240/50000]\tLoss: 0.3929\tLR: 0.002250\nTraining Epoch: 13 [42368/50000]\tLoss: 0.3041\tLR: 0.002250\nTraining Epoch: 13 [42496/50000]\tLoss: 0.3357\tLR: 0.002250\nTraining Epoch: 13 [42624/50000]\tLoss: 0.3313\tLR: 0.002250\nTraining Epoch: 13 [42752/50000]\tLoss: 0.3334\tLR: 0.002250\nTraining Epoch: 13 [42880/50000]\tLoss: 0.2320\tLR: 0.002250\nTraining Epoch: 13 [43008/50000]\tLoss: 0.2598\tLR: 0.002250\nTraining Epoch: 13 [43136/50000]\tLoss: 0.2976\tLR: 0.002250\nTraining Epoch: 13 [43264/50000]\tLoss: 0.3993\tLR: 0.002250\nTraining Epoch: 13 [43392/50000]\tLoss: 0.3149\tLR: 0.002250\nTraining Epoch: 13 [43520/50000]\tLoss: 0.3151\tLR: 0.002250\nTraining Epoch: 13 [43648/50000]\tLoss: 0.3447\tLR: 0.002250\nTraining Epoch: 13 [43776/50000]\tLoss: 0.2598\tLR: 0.002250\nTraining Epoch: 13 [43904/50000]\tLoss: 0.2906\tLR: 0.002250\nTraining Epoch: 13 [44032/50000]\tLoss: 0.2810\tLR: 0.002250\nTraining Epoch: 13 [44160/50000]\tLoss: 0.2435\tLR: 0.002250\nTraining Epoch: 13 [44288/50000]\tLoss: 0.3040\tLR: 0.002250\nTraining Epoch: 13 [44416/50000]\tLoss: 0.2949\tLR: 0.002250\nTraining Epoch: 13 [44544/50000]\tLoss: 0.2826\tLR: 0.002250\nTraining Epoch: 13 [44672/50000]\tLoss: 0.2583\tLR: 0.002250\nTraining Epoch: 13 [44800/50000]\tLoss: 0.3569\tLR: 0.002250\nTraining Epoch: 13 [44928/50000]\tLoss: 0.2377\tLR: 0.002250\nTraining Epoch: 13 [45056/50000]\tLoss: 0.2253\tLR: 0.002250\nTraining Epoch: 13 [45184/50000]\tLoss: 0.3363\tLR: 0.002250\nTraining Epoch: 13 [45312/50000]\tLoss: 0.2611\tLR: 0.002250\nTraining Epoch: 13 [45440/50000]\tLoss: 0.2778\tLR: 0.002250\nTraining Epoch: 13 [45568/50000]\tLoss: 0.2717\tLR: 0.002250\nTraining Epoch: 13 [45696/50000]\tLoss: 0.1998\tLR: 0.002250\nTraining Epoch: 13 [45824/50000]\tLoss: 0.3954\tLR: 0.002250\nTraining Epoch: 13 [45952/50000]\tLoss: 0.3170\tLR: 0.002250\nTraining Epoch: 13 [46080/50000]\tLoss: 0.3120\tLR: 0.002250\nTraining Epoch: 13 [46208/50000]\tLoss: 0.3139\tLR: 0.002250\nTraining Epoch: 13 [46336/50000]\tLoss: 0.3065\tLR: 0.002250\nTraining Epoch: 13 [46464/50000]\tLoss: 0.4272\tLR: 0.002250\nTraining Epoch: 13 [46592/50000]\tLoss: 0.2505\tLR: 0.002250\nTraining Epoch: 13 [46720/50000]\tLoss: 0.3274\tLR: 0.002250\nTraining Epoch: 13 [46848/50000]\tLoss: 0.3102\tLR: 0.002250\nTraining Epoch: 13 [46976/50000]\tLoss: 0.2348\tLR: 0.002250\nTraining Epoch: 13 [47104/50000]\tLoss: 0.4120\tLR: 0.002250\nTraining Epoch: 13 [47232/50000]\tLoss: 0.2953\tLR: 0.002250\nTraining Epoch: 13 [47360/50000]\tLoss: 0.2817\tLR: 0.002250\nTraining Epoch: 13 [47488/50000]\tLoss: 0.2635\tLR: 0.002250\nTraining Epoch: 13 [47616/50000]\tLoss: 0.2580\tLR: 0.002250\nTraining Epoch: 13 [47744/50000]\tLoss: 0.3220\tLR: 0.002250\nTraining Epoch: 13 [47872/50000]\tLoss: 0.2411\tLR: 0.002250\nTraining Epoch: 13 [48000/50000]\tLoss: 0.2855\tLR: 0.002250\nTraining Epoch: 13 [48128/50000]\tLoss: 0.2457\tLR: 0.002250\nTraining Epoch: 13 [48256/50000]\tLoss: 0.2995\tLR: 0.002250\nTraining Epoch: 13 [48384/50000]\tLoss: 0.3198\tLR: 0.002250\nTraining Epoch: 13 [48512/50000]\tLoss: 0.2703\tLR: 0.002250\nTraining Epoch: 13 [48640/50000]\tLoss: 0.2448\tLR: 0.002250\nTraining Epoch: 13 [48768/50000]\tLoss: 0.2714\tLR: 0.002250\nTraining Epoch: 13 [48896/50000]\tLoss: 0.3543\tLR: 0.002250\nTraining Epoch: 13 [49024/50000]\tLoss: 0.2884\tLR: 0.002250\nTraining Epoch: 13 [49152/50000]\tLoss: 0.3686\tLR: 0.002250\nTraining Epoch: 13 [49280/50000]\tLoss: 0.3564\tLR: 0.002250\nTraining Epoch: 13 [49408/50000]\tLoss: 0.1776\tLR: 0.002250\nTraining Epoch: 13 [49536/50000]\tLoss: 0.3951\tLR: 0.002250\nTraining Epoch: 13 [49664/50000]\tLoss: 0.2752\tLR: 0.002250\nTraining Epoch: 13 [49792/50000]\tLoss: 0.3682\tLR: 0.002250\nTraining Epoch: 13 [49920/50000]\tLoss: 0.3893\tLR: 0.002250\nTraining Epoch: 13 [50000/50000]\tLoss: 0.3559\tLR: 0.002250\nTest set: Average loss: 0.0027, Accuracy: 0.8860\n\nTraining Epoch: 14 [128/50000]\tLoss: 0.3982\tLR: 0.002250\nTraining Epoch: 14 [256/50000]\tLoss: 0.2832\tLR: 0.002250\nTraining Epoch: 14 [384/50000]\tLoss: 0.3222\tLR: 0.002250\nTraining Epoch: 14 [512/50000]\tLoss: 0.2512\tLR: 0.002250\nTraining Epoch: 14 [640/50000]\tLoss: 0.3607\tLR: 0.002250\nTraining Epoch: 14 [768/50000]\tLoss: 0.2753\tLR: 0.002250\nTraining Epoch: 14 [896/50000]\tLoss: 0.2819\tLR: 0.002250\nTraining Epoch: 14 [1024/50000]\tLoss: 0.2379\tLR: 0.002250\nTraining Epoch: 14 [1152/50000]\tLoss: 0.2893\tLR: 0.002250\nTraining Epoch: 14 [1280/50000]\tLoss: 0.3176\tLR: 0.002250\nTraining Epoch: 14 [1408/50000]\tLoss: 0.2584\tLR: 0.002250\nTraining Epoch: 14 [1536/50000]\tLoss: 0.2200\tLR: 0.002250\nTraining Epoch: 14 [1664/50000]\tLoss: 0.3701\tLR: 0.002250\nTraining Epoch: 14 [1792/50000]\tLoss: 0.2781\tLR: 0.002250\nTraining Epoch: 14 [1920/50000]\tLoss: 0.3144\tLR: 0.002250\nTraining Epoch: 14 [2048/50000]\tLoss: 0.3041\tLR: 0.002250\nTraining Epoch: 14 [2176/50000]\tLoss: 0.3408\tLR: 0.002250\nTraining Epoch: 14 [2304/50000]\tLoss: 0.2742\tLR: 0.002250\nTraining Epoch: 14 [2432/50000]\tLoss: 0.3443\tLR: 0.002250\nTraining Epoch: 14 [2560/50000]\tLoss: 0.2583\tLR: 0.002250\nTraining Epoch: 14 [2688/50000]\tLoss: 0.3281\tLR: 0.002250\nTraining Epoch: 14 [2816/50000]\tLoss: 0.3525\tLR: 0.002250\nTraining Epoch: 14 [2944/50000]\tLoss: 0.2627\tLR: 0.002250\nTraining Epoch: 14 [3072/50000]\tLoss: 0.3341\tLR: 0.002250\nTraining Epoch: 14 [3200/50000]\tLoss: 0.3756\tLR: 0.002250\nTraining Epoch: 14 [3328/50000]\tLoss: 0.1822\tLR: 0.002250\nTraining Epoch: 14 [3456/50000]\tLoss: 0.3831\tLR: 0.002250\nTraining Epoch: 14 [3584/50000]\tLoss: 0.3023\tLR: 0.002250\nTraining Epoch: 14 [3712/50000]\tLoss: 0.2703\tLR: 0.002250\nTraining Epoch: 14 [3840/50000]\tLoss: 0.2341\tLR: 0.002250\nTraining Epoch: 14 [3968/50000]\tLoss: 0.3930\tLR: 0.002250\nTraining Epoch: 14 [4096/50000]\tLoss: 0.3091\tLR: 0.002250\nTraining Epoch: 14 [4224/50000]\tLoss: 0.3477\tLR: 0.002250\nTraining Epoch: 14 [4352/50000]\tLoss: 0.3389\tLR: 0.002250\nTraining Epoch: 14 [4480/50000]\tLoss: 0.2915\tLR: 0.002250\nTraining Epoch: 14 [4608/50000]\tLoss: 0.2369\tLR: 0.002250\nTraining Epoch: 14 [4736/50000]\tLoss: 0.3148\tLR: 0.002250\nTraining Epoch: 14 [4864/50000]\tLoss: 0.4167\tLR: 0.002250\nTraining Epoch: 14 [4992/50000]\tLoss: 0.2113\tLR: 0.002250\nTraining Epoch: 14 [5120/50000]\tLoss: 0.2144\tLR: 0.002250\nTraining Epoch: 14 [5248/50000]\tLoss: 0.2937\tLR: 0.002250\nTraining Epoch: 14 [5376/50000]\tLoss: 0.2007\tLR: 0.002250\nTraining Epoch: 14 [5504/50000]\tLoss: 0.2954\tLR: 0.002250\nTraining Epoch: 14 [5632/50000]\tLoss: 0.3394\tLR: 0.002250\nTraining Epoch: 14 [5760/50000]\tLoss: 0.3096\tLR: 0.002250\nTraining Epoch: 14 [5888/50000]\tLoss: 0.3769\tLR: 0.002250\nTraining Epoch: 14 [6016/50000]\tLoss: 0.2880\tLR: 0.002250\nTraining Epoch: 14 [6144/50000]\tLoss: 0.2893\tLR: 0.002250\nTraining Epoch: 14 [6272/50000]\tLoss: 0.4118\tLR: 0.002250\nTraining Epoch: 14 [6400/50000]\tLoss: 0.3454\tLR: 0.002250\nTraining Epoch: 14 [6528/50000]\tLoss: 0.3400\tLR: 0.002250\nTraining Epoch: 14 [6656/50000]\tLoss: 0.2309\tLR: 0.002250\nTraining Epoch: 14 [6784/50000]\tLoss: 0.3042\tLR: 0.002250\nTraining Epoch: 14 [6912/50000]\tLoss: 0.3648\tLR: 0.002250\nTraining Epoch: 14 [7040/50000]\tLoss: 0.3900\tLR: 0.002250\nTraining Epoch: 14 [7168/50000]\tLoss: 0.2724\tLR: 0.002250\nTraining Epoch: 14 [7296/50000]\tLoss: 0.4601\tLR: 0.002250\nTraining Epoch: 14 [7424/50000]\tLoss: 0.2138\tLR: 0.002250\nTraining Epoch: 14 [7552/50000]\tLoss: 0.4237\tLR: 0.002250\nTraining Epoch: 14 [7680/50000]\tLoss: 0.3572\tLR: 0.002250\nTraining Epoch: 14 [7808/50000]\tLoss: 0.3000\tLR: 0.002250\nTraining Epoch: 14 [7936/50000]\tLoss: 0.2724\tLR: 0.002250\nTraining Epoch: 14 [8064/50000]\tLoss: 0.2879\tLR: 0.002250\nTraining Epoch: 14 [8192/50000]\tLoss: 0.2465\tLR: 0.002250\nTraining Epoch: 14 [8320/50000]\tLoss: 0.2394\tLR: 0.002250\nTraining Epoch: 14 [8448/50000]\tLoss: 0.3473\tLR: 0.002250\nTraining Epoch: 14 [8576/50000]\tLoss: 0.3022\tLR: 0.002250\nTraining Epoch: 14 [8704/50000]\tLoss: 0.2739\tLR: 0.002250\nTraining Epoch: 14 [8832/50000]\tLoss: 0.3843\tLR: 0.002250\nTraining Epoch: 14 [8960/50000]\tLoss: 0.2882\tLR: 0.002250\nTraining Epoch: 14 [9088/50000]\tLoss: 0.2650\tLR: 0.002250\nTraining Epoch: 14 [9216/50000]\tLoss: 0.3842\tLR: 0.002250\nTraining Epoch: 14 [9344/50000]\tLoss: 0.3267\tLR: 0.002250\nTraining Epoch: 14 [9472/50000]\tLoss: 0.3402\tLR: 0.002250\nTraining Epoch: 14 [9600/50000]\tLoss: 0.3169\tLR: 0.002250\nTraining Epoch: 14 [9728/50000]\tLoss: 0.2968\tLR: 0.002250\nTraining Epoch: 14 [9856/50000]\tLoss: 0.4597\tLR: 0.002250\nTraining Epoch: 14 [9984/50000]\tLoss: 0.2044\tLR: 0.002250\nTraining Epoch: 14 [10112/50000]\tLoss: 0.3692\tLR: 0.002250\nTraining Epoch: 14 [10240/50000]\tLoss: 0.2148\tLR: 0.002250\nTraining Epoch: 14 [10368/50000]\tLoss: 0.4622\tLR: 0.002250\nTraining Epoch: 14 [10496/50000]\tLoss: 0.3170\tLR: 0.002250\nTraining Epoch: 14 [10624/50000]\tLoss: 0.2747\tLR: 0.002250\nTraining Epoch: 14 [10752/50000]\tLoss: 0.2767\tLR: 0.002250\nTraining Epoch: 14 [10880/50000]\tLoss: 0.1873\tLR: 0.002250\nTraining Epoch: 14 [11008/50000]\tLoss: 0.2151\tLR: 0.002250\nTraining Epoch: 14 [11136/50000]\tLoss: 0.4282\tLR: 0.002250\nTraining Epoch: 14 [11264/50000]\tLoss: 0.2845\tLR: 0.002250\nTraining Epoch: 14 [11392/50000]\tLoss: 0.2511\tLR: 0.002250\nTraining Epoch: 14 [11520/50000]\tLoss: 0.3825\tLR: 0.002250\nTraining Epoch: 14 [11648/50000]\tLoss: 0.3206\tLR: 0.002250\nTraining Epoch: 14 [11776/50000]\tLoss: 0.2645\tLR: 0.002250\nTraining Epoch: 14 [11904/50000]\tLoss: 0.4553\tLR: 0.002250\nTraining Epoch: 14 [12032/50000]\tLoss: 0.2381\tLR: 0.002250\nTraining Epoch: 14 [12160/50000]\tLoss: 0.2635\tLR: 0.002250\nTraining Epoch: 14 [12288/50000]\tLoss: 0.2169\tLR: 0.002250\nTraining Epoch: 14 [12416/50000]\tLoss: 0.3315\tLR: 0.002250\nTraining Epoch: 14 [12544/50000]\tLoss: 0.2404\tLR: 0.002250\nTraining Epoch: 14 [12672/50000]\tLoss: 0.2133\tLR: 0.002250\nTraining Epoch: 14 [12800/50000]\tLoss: 0.3337\tLR: 0.002250\nTraining Epoch: 14 [12928/50000]\tLoss: 0.2866\tLR: 0.002250\nTraining Epoch: 14 [13056/50000]\tLoss: 0.3173\tLR: 0.002250\nTraining Epoch: 14 [13184/50000]\tLoss: 0.2622\tLR: 0.002250\nTraining Epoch: 14 [13312/50000]\tLoss: 0.2579\tLR: 0.002250\nTraining Epoch: 14 [13440/50000]\tLoss: 0.3320\tLR: 0.002250\nTraining Epoch: 14 [13568/50000]\tLoss: 0.3666\tLR: 0.002250\nTraining Epoch: 14 [13696/50000]\tLoss: 0.2708\tLR: 0.002250\nTraining Epoch: 14 [13824/50000]\tLoss: 0.3442\tLR: 0.002250\nTraining Epoch: 14 [13952/50000]\tLoss: 0.2742\tLR: 0.002250\nTraining Epoch: 14 [14080/50000]\tLoss: 0.2921\tLR: 0.002250\nTraining Epoch: 14 [14208/50000]\tLoss: 0.2925\tLR: 0.002250\nTraining Epoch: 14 [14336/50000]\tLoss: 0.2482\tLR: 0.002250\nTraining Epoch: 14 [14464/50000]\tLoss: 0.2941\tLR: 0.002250\nTraining Epoch: 14 [14592/50000]\tLoss: 0.3044\tLR: 0.002250\nTraining Epoch: 14 [14720/50000]\tLoss: 0.3289\tLR: 0.002250\nTraining Epoch: 14 [14848/50000]\tLoss: 0.3184\tLR: 0.002250\nTraining Epoch: 14 [14976/50000]\tLoss: 0.4047\tLR: 0.002250\nTraining Epoch: 14 [15104/50000]\tLoss: 0.3856\tLR: 0.002250\nTraining Epoch: 14 [15232/50000]\tLoss: 0.2992\tLR: 0.002250\nTraining Epoch: 14 [15360/50000]\tLoss: 0.2828\tLR: 0.002250\nTraining Epoch: 14 [15488/50000]\tLoss: 0.2377\tLR: 0.002250\nTraining Epoch: 14 [15616/50000]\tLoss: 0.1449\tLR: 0.002250\nTraining Epoch: 14 [15744/50000]\tLoss: 0.2081\tLR: 0.002250\nTraining Epoch: 14 [15872/50000]\tLoss: 0.2247\tLR: 0.002250\nTraining Epoch: 14 [16000/50000]\tLoss: 0.3936\tLR: 0.002250\nTraining Epoch: 14 [16128/50000]\tLoss: 0.2563\tLR: 0.002250\nTraining Epoch: 14 [16256/50000]\tLoss: 0.3070\tLR: 0.002250\nTraining Epoch: 14 [16384/50000]\tLoss: 0.3395\tLR: 0.002250\nTraining Epoch: 14 [16512/50000]\tLoss: 0.2954\tLR: 0.002250\nTraining Epoch: 14 [16640/50000]\tLoss: 0.3436\tLR: 0.002250\nTraining Epoch: 14 [16768/50000]\tLoss: 0.3440\tLR: 0.002250\nTraining Epoch: 14 [16896/50000]\tLoss: 0.3194\tLR: 0.002250\nTraining Epoch: 14 [17024/50000]\tLoss: 0.2601\tLR: 0.002250\nTraining Epoch: 14 [17152/50000]\tLoss: 0.3066\tLR: 0.002250\nTraining Epoch: 14 [17280/50000]\tLoss: 0.4774\tLR: 0.002250\nTraining Epoch: 14 [17408/50000]\tLoss: 0.2879\tLR: 0.002250\nTraining Epoch: 14 [17536/50000]\tLoss: 0.3012\tLR: 0.002250\nTraining Epoch: 14 [17664/50000]\tLoss: 0.3897\tLR: 0.002250\nTraining Epoch: 14 [17792/50000]\tLoss: 0.2703\tLR: 0.002250\nTraining Epoch: 14 [17920/50000]\tLoss: 0.3038\tLR: 0.002250\nTraining Epoch: 14 [18048/50000]\tLoss: 0.4151\tLR: 0.002250\nTraining Epoch: 14 [18176/50000]\tLoss: 0.2420\tLR: 0.002250\nTraining Epoch: 14 [18304/50000]\tLoss: 0.2614\tLR: 0.002250\nTraining Epoch: 14 [18432/50000]\tLoss: 0.2773\tLR: 0.002250\nTraining Epoch: 14 [18560/50000]\tLoss: 0.3329\tLR: 0.002250\nTraining Epoch: 14 [18688/50000]\tLoss: 0.2812\tLR: 0.002250\nTraining Epoch: 14 [18816/50000]\tLoss: 0.2310\tLR: 0.002250\nTraining Epoch: 14 [18944/50000]\tLoss: 0.3306\tLR: 0.002250\nTraining Epoch: 14 [19072/50000]\tLoss: 0.2466\tLR: 0.002250\nTraining Epoch: 14 [19200/50000]\tLoss: 0.2765\tLR: 0.002250\nTraining Epoch: 14 [19328/50000]\tLoss: 0.2682\tLR: 0.002250\nTraining Epoch: 14 [19456/50000]\tLoss: 0.3204\tLR: 0.002250\nTraining Epoch: 14 [19584/50000]\tLoss: 0.3542\tLR: 0.002250\nTraining Epoch: 14 [19712/50000]\tLoss: 0.4068\tLR: 0.002250\nTraining Epoch: 14 [19840/50000]\tLoss: 0.3387\tLR: 0.002250\nTraining Epoch: 14 [19968/50000]\tLoss: 0.2222\tLR: 0.002250\nTraining Epoch: 14 [20096/50000]\tLoss: 0.4260\tLR: 0.002250\nTraining Epoch: 14 [20224/50000]\tLoss: 0.2403\tLR: 0.002250\nTraining Epoch: 14 [20352/50000]\tLoss: 0.3045\tLR: 0.002250\nTraining Epoch: 14 [20480/50000]\tLoss: 0.3165\tLR: 0.002250\nTraining Epoch: 14 [20608/50000]\tLoss: 0.2942\tLR: 0.002250\nTraining Epoch: 14 [20736/50000]\tLoss: 0.2052\tLR: 0.002250\nTraining Epoch: 14 [20864/50000]\tLoss: 0.2378\tLR: 0.002250\nTraining Epoch: 14 [20992/50000]\tLoss: 0.2274\tLR: 0.002250\nTraining Epoch: 14 [21120/50000]\tLoss: 0.3281\tLR: 0.002250\nTraining Epoch: 14 [21248/50000]\tLoss: 0.3864\tLR: 0.002250\nTraining Epoch: 14 [21376/50000]\tLoss: 0.3224\tLR: 0.002250\nTraining Epoch: 14 [21504/50000]\tLoss: 0.3893\tLR: 0.002250\nTraining Epoch: 14 [21632/50000]\tLoss: 0.2441\tLR: 0.002250\nTraining Epoch: 14 [21760/50000]\tLoss: 0.2539\tLR: 0.002250\nTraining Epoch: 14 [21888/50000]\tLoss: 0.2785\tLR: 0.002250\nTraining Epoch: 14 [22016/50000]\tLoss: 0.3583\tLR: 0.002250\nTraining Epoch: 14 [22144/50000]\tLoss: 0.2671\tLR: 0.002250\nTraining Epoch: 14 [22272/50000]\tLoss: 0.3534\tLR: 0.002250\nTraining Epoch: 14 [22400/50000]\tLoss: 0.2721\tLR: 0.002250\nTraining Epoch: 14 [22528/50000]\tLoss: 0.4333\tLR: 0.002250\nTraining Epoch: 14 [22656/50000]\tLoss: 0.2943\tLR: 0.002250\nTraining Epoch: 14 [22784/50000]\tLoss: 0.3724\tLR: 0.002250\nTraining Epoch: 14 [22912/50000]\tLoss: 0.3552\tLR: 0.002250\nTraining Epoch: 14 [23040/50000]\tLoss: 0.2690\tLR: 0.002250\nTraining Epoch: 14 [23168/50000]\tLoss: 0.3792\tLR: 0.002250\nTraining Epoch: 14 [23296/50000]\tLoss: 0.3964\tLR: 0.002250\nTraining Epoch: 14 [23424/50000]\tLoss: 0.3426\tLR: 0.002250\nTraining Epoch: 14 [23552/50000]\tLoss: 0.1810\tLR: 0.002250\nTraining Epoch: 14 [23680/50000]\tLoss: 0.2496\tLR: 0.002250\nTraining Epoch: 14 [23808/50000]\tLoss: 0.2074\tLR: 0.002250\nTraining Epoch: 14 [23936/50000]\tLoss: 0.2215\tLR: 0.002250\nTraining Epoch: 14 [24064/50000]\tLoss: 0.2510\tLR: 0.002250\nTraining Epoch: 14 [24192/50000]\tLoss: 0.2464\tLR: 0.002250\nTraining Epoch: 14 [24320/50000]\tLoss: 0.3034\tLR: 0.002250\nTraining Epoch: 14 [24448/50000]\tLoss: 0.2609\tLR: 0.002250\nTraining Epoch: 14 [24576/50000]\tLoss: 0.4311\tLR: 0.002250\nTraining Epoch: 14 [24704/50000]\tLoss: 0.3193\tLR: 0.002250\nTraining Epoch: 14 [24832/50000]\tLoss: 0.3844\tLR: 0.002250\nTraining Epoch: 14 [24960/50000]\tLoss: 0.2467\tLR: 0.002250\nTraining Epoch: 14 [25088/50000]\tLoss: 0.3108\tLR: 0.002250\nTraining Epoch: 14 [25216/50000]\tLoss: 0.2903\tLR: 0.002250\nTraining Epoch: 14 [25344/50000]\tLoss: 0.2744\tLR: 0.002250\nTraining Epoch: 14 [25472/50000]\tLoss: 0.2232\tLR: 0.002250\nTraining Epoch: 14 [25600/50000]\tLoss: 0.2238\tLR: 0.002250\nTraining Epoch: 14 [25728/50000]\tLoss: 0.3326\tLR: 0.002250\nTraining Epoch: 14 [25856/50000]\tLoss: 0.3262\tLR: 0.002250\nTraining Epoch: 14 [25984/50000]\tLoss: 0.4209\tLR: 0.002250\nTraining Epoch: 14 [26112/50000]\tLoss: 0.3583\tLR: 0.002250\nTraining Epoch: 14 [26240/50000]\tLoss: 0.2508\tLR: 0.002250\nTraining Epoch: 14 [26368/50000]\tLoss: 0.2385\tLR: 0.002250\nTraining Epoch: 14 [26496/50000]\tLoss: 0.3912\tLR: 0.002250\nTraining Epoch: 14 [26624/50000]\tLoss: 0.2020\tLR: 0.002250\nTraining Epoch: 14 [26752/50000]\tLoss: 0.3803\tLR: 0.002250\nTraining Epoch: 14 [26880/50000]\tLoss: 0.3099\tLR: 0.002250\nTraining Epoch: 14 [27008/50000]\tLoss: 0.2065\tLR: 0.002250\nTraining Epoch: 14 [27136/50000]\tLoss: 0.3823\tLR: 0.002250\nTraining Epoch: 14 [27264/50000]\tLoss: 0.2227\tLR: 0.002250\nTraining Epoch: 14 [27392/50000]\tLoss: 0.2929\tLR: 0.002250\nTraining Epoch: 14 [27520/50000]\tLoss: 0.2988\tLR: 0.002250\nTraining Epoch: 14 [27648/50000]\tLoss: 0.1753\tLR: 0.002250\nTraining Epoch: 14 [27776/50000]\tLoss: 0.3198\tLR: 0.002250\nTraining Epoch: 14 [27904/50000]\tLoss: 0.3103\tLR: 0.002250\nTraining Epoch: 14 [28032/50000]\tLoss: 0.3861\tLR: 0.002250\nTraining Epoch: 14 [28160/50000]\tLoss: 0.2856\tLR: 0.002250\nTraining Epoch: 14 [28288/50000]\tLoss: 0.3054\tLR: 0.002250\nTraining Epoch: 14 [28416/50000]\tLoss: 0.2842\tLR: 0.002250\nTraining Epoch: 14 [28544/50000]\tLoss: 0.3177\tLR: 0.002250\nTraining Epoch: 14 [28672/50000]\tLoss: 0.3773\tLR: 0.002250\nTraining Epoch: 14 [28800/50000]\tLoss: 0.2369\tLR: 0.002250\nTraining Epoch: 14 [28928/50000]\tLoss: 0.2972\tLR: 0.002250\nTraining Epoch: 14 [29056/50000]\tLoss: 0.1869\tLR: 0.002250\nTraining Epoch: 14 [29184/50000]\tLoss: 0.1737\tLR: 0.002250\nTraining Epoch: 14 [29312/50000]\tLoss: 0.3206\tLR: 0.002250\nTraining Epoch: 14 [29440/50000]\tLoss: 0.3286\tLR: 0.002250\nTraining Epoch: 14 [29568/50000]\tLoss: 0.2802\tLR: 0.002250\nTraining Epoch: 14 [29696/50000]\tLoss: 0.1917\tLR: 0.002250\nTraining Epoch: 14 [29824/50000]\tLoss: 0.3171\tLR: 0.002250\nTraining Epoch: 14 [29952/50000]\tLoss: 0.2123\tLR: 0.002250\nTraining Epoch: 14 [30080/50000]\tLoss: 0.3167\tLR: 0.002250\nTraining Epoch: 14 [30208/50000]\tLoss: 0.3078\tLR: 0.002250\nTraining Epoch: 14 [30336/50000]\tLoss: 0.2238\tLR: 0.002250\nTraining Epoch: 14 [30464/50000]\tLoss: 0.2705\tLR: 0.002250\nTraining Epoch: 14 [30592/50000]\tLoss: 0.4604\tLR: 0.002250\nTraining Epoch: 14 [30720/50000]\tLoss: 0.3747\tLR: 0.002250\nTraining Epoch: 14 [30848/50000]\tLoss: 0.2340\tLR: 0.002250\nTraining Epoch: 14 [30976/50000]\tLoss: 0.2085\tLR: 0.002250\nTraining Epoch: 14 [31104/50000]\tLoss: 0.2792\tLR: 0.002250\nTraining Epoch: 14 [31232/50000]\tLoss: 0.3083\tLR: 0.002250\nTraining Epoch: 14 [31360/50000]\tLoss: 0.1963\tLR: 0.002250\nTraining Epoch: 14 [31488/50000]\tLoss: 0.2283\tLR: 0.002250\nTraining Epoch: 14 [31616/50000]\tLoss: 0.2055\tLR: 0.002250\nTraining Epoch: 14 [31744/50000]\tLoss: 0.4098\tLR: 0.002250\nTraining Epoch: 14 [31872/50000]\tLoss: 0.2101\tLR: 0.002250\nTraining Epoch: 14 [32000/50000]\tLoss: 0.3439\tLR: 0.002250\nTraining Epoch: 14 [32128/50000]\tLoss: 0.1917\tLR: 0.002250\nTraining Epoch: 14 [32256/50000]\tLoss: 0.3119\tLR: 0.002250\nTraining Epoch: 14 [32384/50000]\tLoss: 0.2711\tLR: 0.002250\nTraining Epoch: 14 [32512/50000]\tLoss: 0.2560\tLR: 0.002250\nTraining Epoch: 14 [32640/50000]\tLoss: 0.4142\tLR: 0.002250\nTraining Epoch: 14 [32768/50000]\tLoss: 0.2649\tLR: 0.002250\nTraining Epoch: 14 [32896/50000]\tLoss: 0.4321\tLR: 0.002250\nTraining Epoch: 14 [33024/50000]\tLoss: 0.2211\tLR: 0.002250\nTraining Epoch: 14 [33152/50000]\tLoss: 0.3178\tLR: 0.002250\nTraining Epoch: 14 [33280/50000]\tLoss: 0.3206\tLR: 0.002250\nTraining Epoch: 14 [33408/50000]\tLoss: 0.2520\tLR: 0.002250\nTraining Epoch: 14 [33536/50000]\tLoss: 0.1509\tLR: 0.002250\nTraining Epoch: 14 [33664/50000]\tLoss: 0.2736\tLR: 0.002250\nTraining Epoch: 14 [33792/50000]\tLoss: 0.2899\tLR: 0.002250\nTraining Epoch: 14 [33920/50000]\tLoss: 0.2482\tLR: 0.002250\nTraining Epoch: 14 [34048/50000]\tLoss: 0.3103\tLR: 0.002250\nTraining Epoch: 14 [34176/50000]\tLoss: 0.2808\tLR: 0.002250\nTraining Epoch: 14 [34304/50000]\tLoss: 0.2466\tLR: 0.002250\nTraining Epoch: 14 [34432/50000]\tLoss: 0.2910\tLR: 0.002250\nTraining Epoch: 14 [34560/50000]\tLoss: 0.2598\tLR: 0.002250\nTraining Epoch: 14 [34688/50000]\tLoss: 0.2440\tLR: 0.002250\nTraining Epoch: 14 [34816/50000]\tLoss: 0.2639\tLR: 0.002250\nTraining Epoch: 14 [34944/50000]\tLoss: 0.2809\tLR: 0.002250\nTraining Epoch: 14 [35072/50000]\tLoss: 0.2532\tLR: 0.002250\nTraining Epoch: 14 [35200/50000]\tLoss: 0.1743\tLR: 0.002250\nTraining Epoch: 14 [35328/50000]\tLoss: 0.2381\tLR: 0.002250\nTraining Epoch: 14 [35456/50000]\tLoss: 0.2629\tLR: 0.002250\nTraining Epoch: 14 [35584/50000]\tLoss: 0.3637\tLR: 0.002250\nTraining Epoch: 14 [35712/50000]\tLoss: 0.2752\tLR: 0.002250\nTraining Epoch: 14 [35840/50000]\tLoss: 0.4403\tLR: 0.002250\nTraining Epoch: 14 [35968/50000]\tLoss: 0.2191\tLR: 0.002250\nTraining Epoch: 14 [36096/50000]\tLoss: 0.2750\tLR: 0.002250\nTraining Epoch: 14 [36224/50000]\tLoss: 0.2566\tLR: 0.002250\nTraining Epoch: 14 [36352/50000]\tLoss: 0.2640\tLR: 0.002250\nTraining Epoch: 14 [36480/50000]\tLoss: 0.2027\tLR: 0.002250\nTraining Epoch: 14 [36608/50000]\tLoss: 0.3427\tLR: 0.002250\nTraining Epoch: 14 [36736/50000]\tLoss: 0.3773\tLR: 0.002250\nTraining Epoch: 14 [36864/50000]\tLoss: 0.3371\tLR: 0.002250\nTraining Epoch: 14 [36992/50000]\tLoss: 0.4139\tLR: 0.002250\nTraining Epoch: 14 [37120/50000]\tLoss: 0.2816\tLR: 0.002250\nTraining Epoch: 14 [37248/50000]\tLoss: 0.3283\tLR: 0.002250\nTraining Epoch: 14 [37376/50000]\tLoss: 0.4515\tLR: 0.002250\nTraining Epoch: 14 [37504/50000]\tLoss: 0.3568\tLR: 0.002250\nTraining Epoch: 14 [37632/50000]\tLoss: 0.2860\tLR: 0.002250\nTraining Epoch: 14 [37760/50000]\tLoss: 0.2498\tLR: 0.002250\nTraining Epoch: 14 [37888/50000]\tLoss: 0.3172\tLR: 0.002250\nTraining Epoch: 14 [38016/50000]\tLoss: 0.5377\tLR: 0.002250\nTraining Epoch: 14 [38144/50000]\tLoss: 0.4144\tLR: 0.002250\nTraining Epoch: 14 [38272/50000]\tLoss: 0.3441\tLR: 0.002250\nTraining Epoch: 14 [38400/50000]\tLoss: 0.3222\tLR: 0.002250\nTraining Epoch: 14 [38528/50000]\tLoss: 0.3303\tLR: 0.002250\nTraining Epoch: 14 [38656/50000]\tLoss: 0.4229\tLR: 0.002250\nTraining Epoch: 14 [38784/50000]\tLoss: 0.3056\tLR: 0.002250\nTraining Epoch: 14 [38912/50000]\tLoss: 0.2053\tLR: 0.002250\nTraining Epoch: 14 [39040/50000]\tLoss: 0.2809\tLR: 0.002250\nTraining Epoch: 14 [39168/50000]\tLoss: 0.2849\tLR: 0.002250\nTraining Epoch: 14 [39296/50000]\tLoss: 0.3584\tLR: 0.002250\nTraining Epoch: 14 [39424/50000]\tLoss: 0.2467\tLR: 0.002250\nTraining Epoch: 14 [39552/50000]\tLoss: 0.4267\tLR: 0.002250\nTraining Epoch: 14 [39680/50000]\tLoss: 0.2131\tLR: 0.002250\nTraining Epoch: 14 [39808/50000]\tLoss: 0.2258\tLR: 0.002250\nTraining Epoch: 14 [39936/50000]\tLoss: 0.3352\tLR: 0.002250\nTraining Epoch: 14 [40064/50000]\tLoss: 0.2735\tLR: 0.002250\nTraining Epoch: 14 [40192/50000]\tLoss: 0.1972\tLR: 0.002250\nTraining Epoch: 14 [40320/50000]\tLoss: 0.3013\tLR: 0.002250\nTraining Epoch: 14 [40448/50000]\tLoss: 0.3438\tLR: 0.002250\nTraining Epoch: 14 [40576/50000]\tLoss: 0.2357\tLR: 0.002250\nTraining Epoch: 14 [40704/50000]\tLoss: 0.1719\tLR: 0.002250\nTraining Epoch: 14 [40832/50000]\tLoss: 0.3206\tLR: 0.002250\nTraining Epoch: 14 [40960/50000]\tLoss: 0.2779\tLR: 0.002250\nTraining Epoch: 14 [41088/50000]\tLoss: 0.2692\tLR: 0.002250\nTraining Epoch: 14 [41216/50000]\tLoss: 0.3192\tLR: 0.002250\nTraining Epoch: 14 [41344/50000]\tLoss: 0.2238\tLR: 0.002250\nTraining Epoch: 14 [41472/50000]\tLoss: 0.2360\tLR: 0.002250\nTraining Epoch: 14 [41600/50000]\tLoss: 0.3675\tLR: 0.002250\nTraining Epoch: 14 [41728/50000]\tLoss: 0.2995\tLR: 0.002250\nTraining Epoch: 14 [41856/50000]\tLoss: 0.2575\tLR: 0.002250\nTraining Epoch: 14 [41984/50000]\tLoss: 0.2011\tLR: 0.002250\nTraining Epoch: 14 [42112/50000]\tLoss: 0.3265\tLR: 0.002250\nTraining Epoch: 14 [42240/50000]\tLoss: 0.2148\tLR: 0.002250\nTraining Epoch: 14 [42368/50000]\tLoss: 0.2252\tLR: 0.002250\nTraining Epoch: 14 [42496/50000]\tLoss: 0.3860\tLR: 0.002250\nTraining Epoch: 14 [42624/50000]\tLoss: 0.2331\tLR: 0.002250\nTraining Epoch: 14 [42752/50000]\tLoss: 0.3062\tLR: 0.002250\nTraining Epoch: 14 [42880/50000]\tLoss: 0.3053\tLR: 0.002250\nTraining Epoch: 14 [43008/50000]\tLoss: 0.2424\tLR: 0.002250\nTraining Epoch: 14 [43136/50000]\tLoss: 0.3687\tLR: 0.002250\nTraining Epoch: 14 [43264/50000]\tLoss: 0.3386\tLR: 0.002250\nTraining Epoch: 14 [43392/50000]\tLoss: 0.3325\tLR: 0.002250\nTraining Epoch: 14 [43520/50000]\tLoss: 0.2850\tLR: 0.002250\nTraining Epoch: 14 [43648/50000]\tLoss: 0.3123\tLR: 0.002250\nTraining Epoch: 14 [43776/50000]\tLoss: 0.2967\tLR: 0.002250\nTraining Epoch: 14 [43904/50000]\tLoss: 0.3307\tLR: 0.002250\nTraining Epoch: 14 [44032/50000]\tLoss: 0.2031\tLR: 0.002250\nTraining Epoch: 14 [44160/50000]\tLoss: 0.2413\tLR: 0.002250\nTraining Epoch: 14 [44288/50000]\tLoss: 0.2077\tLR: 0.002250\nTraining Epoch: 14 [44416/50000]\tLoss: 0.2304\tLR: 0.002250\nTraining Epoch: 14 [44544/50000]\tLoss: 0.3192\tLR: 0.002250\nTraining Epoch: 14 [44672/50000]\tLoss: 0.3131\tLR: 0.002250\nTraining Epoch: 14 [44800/50000]\tLoss: 0.2966\tLR: 0.002250\nTraining Epoch: 14 [44928/50000]\tLoss: 0.3503\tLR: 0.002250\nTraining Epoch: 14 [45056/50000]\tLoss: 0.3808\tLR: 0.002250\nTraining Epoch: 14 [45184/50000]\tLoss: 0.2632\tLR: 0.002250\nTraining Epoch: 14 [45312/50000]\tLoss: 0.2800\tLR: 0.002250\nTraining Epoch: 14 [45440/50000]\tLoss: 0.2982\tLR: 0.002250\nTraining Epoch: 14 [45568/50000]\tLoss: 0.2952\tLR: 0.002250\nTraining Epoch: 14 [45696/50000]\tLoss: 0.2015\tLR: 0.002250\nTraining Epoch: 14 [45824/50000]\tLoss: 0.3106\tLR: 0.002250\nTraining Epoch: 14 [45952/50000]\tLoss: 0.3573\tLR: 0.002250\nTraining Epoch: 14 [46080/50000]\tLoss: 0.3095\tLR: 0.002250\nTraining Epoch: 14 [46208/50000]\tLoss: 0.2955\tLR: 0.002250\nTraining Epoch: 14 [46336/50000]\tLoss: 0.3221\tLR: 0.002250\nTraining Epoch: 14 [46464/50000]\tLoss: 0.2848\tLR: 0.002250\nTraining Epoch: 14 [46592/50000]\tLoss: 0.2120\tLR: 0.002250\nTraining Epoch: 14 [46720/50000]\tLoss: 0.2709\tLR: 0.002250\nTraining Epoch: 14 [46848/50000]\tLoss: 0.2110\tLR: 0.002250\nTraining Epoch: 14 [46976/50000]\tLoss: 0.3490\tLR: 0.002250\nTraining Epoch: 14 [47104/50000]\tLoss: 0.3227\tLR: 0.002250\nTraining Epoch: 14 [47232/50000]\tLoss: 0.2835\tLR: 0.002250\nTraining Epoch: 14 [47360/50000]\tLoss: 0.3795\tLR: 0.002250\nTraining Epoch: 14 [47488/50000]\tLoss: 0.2501\tLR: 0.002250\nTraining Epoch: 14 [47616/50000]\tLoss: 0.2729\tLR: 0.002250\nTraining Epoch: 14 [47744/50000]\tLoss: 0.3462\tLR: 0.002250\nTraining Epoch: 14 [47872/50000]\tLoss: 0.2909\tLR: 0.002250\nTraining Epoch: 14 [48000/50000]\tLoss: 0.3124\tLR: 0.002250\nTraining Epoch: 14 [48128/50000]\tLoss: 0.2225\tLR: 0.002250\nTraining Epoch: 14 [48256/50000]\tLoss: 0.3140\tLR: 0.002250\nTraining Epoch: 14 [48384/50000]\tLoss: 0.3249\tLR: 0.002250\nTraining Epoch: 14 [48512/50000]\tLoss: 0.3334\tLR: 0.002250\nTraining Epoch: 14 [48640/50000]\tLoss: 0.1988\tLR: 0.002250\nTraining Epoch: 14 [48768/50000]\tLoss: 0.2851\tLR: 0.002250\nTraining Epoch: 14 [48896/50000]\tLoss: 0.3755\tLR: 0.002250\nTraining Epoch: 14 [49024/50000]\tLoss: 0.2825\tLR: 0.002250\nTraining Epoch: 14 [49152/50000]\tLoss: 0.3636\tLR: 0.002250\nTraining Epoch: 14 [49280/50000]\tLoss: 0.2954\tLR: 0.002250\nTraining Epoch: 14 [49408/50000]\tLoss: 0.3693\tLR: 0.002250\nTraining Epoch: 14 [49536/50000]\tLoss: 0.3996\tLR: 0.002250\nTraining Epoch: 14 [49664/50000]\tLoss: 0.2864\tLR: 0.002250\nTraining Epoch: 14 [49792/50000]\tLoss: 0.2474\tLR: 0.002250\nTraining Epoch: 14 [49920/50000]\tLoss: 0.2473\tLR: 0.002250\nTraining Epoch: 14 [50000/50000]\tLoss: 0.3170\tLR: 0.002250\nTest set: Average loss: 0.0026, Accuracy: 0.8892\n\nTraining Epoch: 15 [128/50000]\tLoss: 0.2244\tLR: 0.002250\nTraining Epoch: 15 [256/50000]\tLoss: 0.2913\tLR: 0.002250\nTraining Epoch: 15 [384/50000]\tLoss: 0.3094\tLR: 0.002250\nTraining Epoch: 15 [512/50000]\tLoss: 0.2571\tLR: 0.002250\nTraining Epoch: 15 [640/50000]\tLoss: 0.4194\tLR: 0.002250\nTraining Epoch: 15 [768/50000]\tLoss: 0.2655\tLR: 0.002250\nTraining Epoch: 15 [896/50000]\tLoss: 0.1985\tLR: 0.002250\nTraining Epoch: 15 [1024/50000]\tLoss: 0.2189\tLR: 0.002250\nTraining Epoch: 15 [1152/50000]\tLoss: 0.2866\tLR: 0.002250\nTraining Epoch: 15 [1280/50000]\tLoss: 0.2254\tLR: 0.002250\nTraining Epoch: 15 [1408/50000]\tLoss: 0.3316\tLR: 0.002250\nTraining Epoch: 15 [1536/50000]\tLoss: 0.3198\tLR: 0.002250\nTraining Epoch: 15 [1664/50000]\tLoss: 0.2719\tLR: 0.002250\nTraining Epoch: 15 [1792/50000]\tLoss: 0.2738\tLR: 0.002250\nTraining Epoch: 15 [1920/50000]\tLoss: 0.3618\tLR: 0.002250\nTraining Epoch: 15 [2048/50000]\tLoss: 0.2297\tLR: 0.002250\nTraining Epoch: 15 [2176/50000]\tLoss: 0.1636\tLR: 0.002250\nTraining Epoch: 15 [2304/50000]\tLoss: 0.3093\tLR: 0.002250\nTraining Epoch: 15 [2432/50000]\tLoss: 0.2659\tLR: 0.002250\nTraining Epoch: 15 [2560/50000]\tLoss: 0.2497\tLR: 0.002250\nTraining Epoch: 15 [2688/50000]\tLoss: 0.2826\tLR: 0.002250\nTraining Epoch: 15 [2816/50000]\tLoss: 0.2325\tLR: 0.002250\nTraining Epoch: 15 [2944/50000]\tLoss: 0.2374\tLR: 0.002250\nTraining Epoch: 15 [3072/50000]\tLoss: 0.2878\tLR: 0.002250\nTraining Epoch: 15 [3200/50000]\tLoss: 0.2798\tLR: 0.002250\nTraining Epoch: 15 [3328/50000]\tLoss: 0.2310\tLR: 0.002250\nTraining Epoch: 15 [3456/50000]\tLoss: 0.2725\tLR: 0.002250\nTraining Epoch: 15 [3584/50000]\tLoss: 0.1919\tLR: 0.002250\nTraining Epoch: 15 [3712/50000]\tLoss: 0.3564\tLR: 0.002250\nTraining Epoch: 15 [3840/50000]\tLoss: 0.2781\tLR: 0.002250\nTraining Epoch: 15 [3968/50000]\tLoss: 0.3917\tLR: 0.002250\nTraining Epoch: 15 [4096/50000]\tLoss: 0.3397\tLR: 0.002250\nTraining Epoch: 15 [4224/50000]\tLoss: 0.2711\tLR: 0.002250\nTraining Epoch: 15 [4352/50000]\tLoss: 0.2609\tLR: 0.002250\nTraining Epoch: 15 [4480/50000]\tLoss: 0.2868\tLR: 0.002250\nTraining Epoch: 15 [4608/50000]\tLoss: 0.4968\tLR: 0.002250\nTraining Epoch: 15 [4736/50000]\tLoss: 0.3265\tLR: 0.002250\nTraining Epoch: 15 [4864/50000]\tLoss: 0.2769\tLR: 0.002250\nTraining Epoch: 15 [4992/50000]\tLoss: 0.4102\tLR: 0.002250\nTraining Epoch: 15 [5120/50000]\tLoss: 0.4563\tLR: 0.002250\nTraining Epoch: 15 [5248/50000]\tLoss: 0.2257\tLR: 0.002250\nTraining Epoch: 15 [5376/50000]\tLoss: 0.3334\tLR: 0.002250\nTraining Epoch: 15 [5504/50000]\tLoss: 0.2123\tLR: 0.002250\nTraining Epoch: 15 [5632/50000]\tLoss: 0.2624\tLR: 0.002250\nTraining Epoch: 15 [5760/50000]\tLoss: 0.2684\tLR: 0.002250\nTraining Epoch: 15 [5888/50000]\tLoss: 0.3862\tLR: 0.002250\nTraining Epoch: 15 [6016/50000]\tLoss: 0.3430\tLR: 0.002250\nTraining Epoch: 15 [6144/50000]\tLoss: 0.3127\tLR: 0.002250\nTraining Epoch: 15 [6272/50000]\tLoss: 0.4246\tLR: 0.002250\nTraining Epoch: 15 [6400/50000]\tLoss: 0.3609\tLR: 0.002250\nTraining Epoch: 15 [6528/50000]\tLoss: 0.2525\tLR: 0.002250\nTraining Epoch: 15 [6656/50000]\tLoss: 0.3402\tLR: 0.002250\nTraining Epoch: 15 [6784/50000]\tLoss: 0.2859\tLR: 0.002250\nTraining Epoch: 15 [6912/50000]\tLoss: 0.3231\tLR: 0.002250\nTraining Epoch: 15 [7040/50000]\tLoss: 0.3102\tLR: 0.002250\nTraining Epoch: 15 [7168/50000]\tLoss: 0.3213\tLR: 0.002250\nTraining Epoch: 15 [7296/50000]\tLoss: 0.3139\tLR: 0.002250\nTraining Epoch: 15 [7424/50000]\tLoss: 0.1694\tLR: 0.002250\nTraining Epoch: 15 [7552/50000]\tLoss: 0.3374\tLR: 0.002250\nTraining Epoch: 15 [7680/50000]\tLoss: 0.2488\tLR: 0.002250\nTraining Epoch: 15 [7808/50000]\tLoss: 0.3731\tLR: 0.002250\nTraining Epoch: 15 [7936/50000]\tLoss: 0.4125\tLR: 0.002250\nTraining Epoch: 15 [8064/50000]\tLoss: 0.2476\tLR: 0.002250\nTraining Epoch: 15 [8192/50000]\tLoss: 0.3337\tLR: 0.002250\nTraining Epoch: 15 [8320/50000]\tLoss: 0.2826\tLR: 0.002250\nTraining Epoch: 15 [8448/50000]\tLoss: 0.3390\tLR: 0.002250\nTraining Epoch: 15 [8576/50000]\tLoss: 0.1789\tLR: 0.002250\nTraining Epoch: 15 [8704/50000]\tLoss: 0.1892\tLR: 0.002250\nTraining Epoch: 15 [8832/50000]\tLoss: 0.3614\tLR: 0.002250\nTraining Epoch: 15 [8960/50000]\tLoss: 0.3579\tLR: 0.002250\nTraining Epoch: 15 [9088/50000]\tLoss: 0.2976\tLR: 0.002250\nTraining Epoch: 15 [9216/50000]\tLoss: 0.3038\tLR: 0.002250\nTraining Epoch: 15 [9344/50000]\tLoss: 0.2438\tLR: 0.002250\nTraining Epoch: 15 [9472/50000]\tLoss: 0.3064\tLR: 0.002250\nTraining Epoch: 15 [9600/50000]\tLoss: 0.1899\tLR: 0.002250\nTraining Epoch: 15 [9728/50000]\tLoss: 0.2878\tLR: 0.002250\nTraining Epoch: 15 [9856/50000]\tLoss: 0.2500\tLR: 0.002250\nTraining Epoch: 15 [9984/50000]\tLoss: 0.3054\tLR: 0.002250\nTraining Epoch: 15 [10112/50000]\tLoss: 0.3367\tLR: 0.002250\nTraining Epoch: 15 [10240/50000]\tLoss: 0.2609\tLR: 0.002250\nTraining Epoch: 15 [10368/50000]\tLoss: 0.3128\tLR: 0.002250\nTraining Epoch: 15 [10496/50000]\tLoss: 0.3135\tLR: 0.002250\nTraining Epoch: 15 [10624/50000]\tLoss: 0.2864\tLR: 0.002250\nTraining Epoch: 15 [10752/50000]\tLoss: 0.2160\tLR: 0.002250\nTraining Epoch: 15 [10880/50000]\tLoss: 0.2934\tLR: 0.002250\nTraining Epoch: 15 [11008/50000]\tLoss: 0.3292\tLR: 0.002250\nTraining Epoch: 15 [11136/50000]\tLoss: 0.2273\tLR: 0.002250\nTraining Epoch: 15 [11264/50000]\tLoss: 0.3370\tLR: 0.002250\nTraining Epoch: 15 [11392/50000]\tLoss: 0.3440\tLR: 0.002250\nTraining Epoch: 15 [11520/50000]\tLoss: 0.2590\tLR: 0.002250\nTraining Epoch: 15 [11648/50000]\tLoss: 0.2511\tLR: 0.002250\nTraining Epoch: 15 [11776/50000]\tLoss: 0.2424\tLR: 0.002250\nTraining Epoch: 15 [11904/50000]\tLoss: 0.2231\tLR: 0.002250\nTraining Epoch: 15 [12032/50000]\tLoss: 0.2039\tLR: 0.002250\nTraining Epoch: 15 [12160/50000]\tLoss: 0.2414\tLR: 0.002250\nTraining Epoch: 15 [12288/50000]\tLoss: 0.2271\tLR: 0.002250\nTraining Epoch: 15 [12416/50000]\tLoss: 0.2631\tLR: 0.002250\nTraining Epoch: 15 [12544/50000]\tLoss: 0.3345\tLR: 0.002250\nTraining Epoch: 15 [12672/50000]\tLoss: 0.2333\tLR: 0.002250\nTraining Epoch: 15 [12800/50000]\tLoss: 0.2356\tLR: 0.002250\nTraining Epoch: 15 [12928/50000]\tLoss: 0.2475\tLR: 0.002250\nTraining Epoch: 15 [13056/50000]\tLoss: 0.3448\tLR: 0.002250\nTraining Epoch: 15 [13184/50000]\tLoss: 0.4465\tLR: 0.002250\nTraining Epoch: 15 [13312/50000]\tLoss: 0.3386\tLR: 0.002250\nTraining Epoch: 15 [13440/50000]\tLoss: 0.2612\tLR: 0.002250\nTraining Epoch: 15 [13568/50000]\tLoss: 0.3615\tLR: 0.002250\nTraining Epoch: 15 [13696/50000]\tLoss: 0.2603\tLR: 0.002250\nTraining Epoch: 15 [13824/50000]\tLoss: 0.3711\tLR: 0.002250\nTraining Epoch: 15 [13952/50000]\tLoss: 0.2926\tLR: 0.002250\nTraining Epoch: 15 [14080/50000]\tLoss: 0.3784\tLR: 0.002250\nTraining Epoch: 15 [14208/50000]\tLoss: 0.2405\tLR: 0.002250\nTraining Epoch: 15 [14336/50000]\tLoss: 0.3178\tLR: 0.002250\nTraining Epoch: 15 [14464/50000]\tLoss: 0.3067\tLR: 0.002250\nTraining Epoch: 15 [14592/50000]\tLoss: 0.2918\tLR: 0.002250\nTraining Epoch: 15 [14720/50000]\tLoss: 0.1906\tLR: 0.002250\nTraining Epoch: 15 [14848/50000]\tLoss: 0.2862\tLR: 0.002250\nTraining Epoch: 15 [14976/50000]\tLoss: 0.2393\tLR: 0.002250\nTraining Epoch: 15 [15104/50000]\tLoss: 0.3016\tLR: 0.002250\nTraining Epoch: 15 [15232/50000]\tLoss: 0.4145\tLR: 0.002250\nTraining Epoch: 15 [15360/50000]\tLoss: 0.3949\tLR: 0.002250\nTraining Epoch: 15 [15488/50000]\tLoss: 0.4339\tLR: 0.002250\nTraining Epoch: 15 [15616/50000]\tLoss: 0.2073\tLR: 0.002250\nTraining Epoch: 15 [15744/50000]\tLoss: 0.2206\tLR: 0.002250\nTraining Epoch: 15 [15872/50000]\tLoss: 0.2830\tLR: 0.002250\nTraining Epoch: 15 [16000/50000]\tLoss: 0.3247\tLR: 0.002250\nTraining Epoch: 15 [16128/50000]\tLoss: 0.2569\tLR: 0.002250\nTraining Epoch: 15 [16256/50000]\tLoss: 0.2397\tLR: 0.002250\nTraining Epoch: 15 [16384/50000]\tLoss: 0.2640\tLR: 0.002250\nTraining Epoch: 15 [16512/50000]\tLoss: 0.4470\tLR: 0.002250\nTraining Epoch: 15 [16640/50000]\tLoss: 0.3258\tLR: 0.002250\nTraining Epoch: 15 [16768/50000]\tLoss: 0.1796\tLR: 0.002250\nTraining Epoch: 15 [16896/50000]\tLoss: 0.2704\tLR: 0.002250\nTraining Epoch: 15 [17024/50000]\tLoss: 0.2937\tLR: 0.002250\nTraining Epoch: 15 [17152/50000]\tLoss: 0.2756\tLR: 0.002250\nTraining Epoch: 15 [17280/50000]\tLoss: 0.3284\tLR: 0.002250\nTraining Epoch: 15 [17408/50000]\tLoss: 0.2288\tLR: 0.002250\nTraining Epoch: 15 [17536/50000]\tLoss: 0.2916\tLR: 0.002250\nTraining Epoch: 15 [17664/50000]\tLoss: 0.2549\tLR: 0.002250\nTraining Epoch: 15 [17792/50000]\tLoss: 0.2340\tLR: 0.002250\nTraining Epoch: 15 [17920/50000]\tLoss: 0.2987\tLR: 0.002250\nTraining Epoch: 15 [18048/50000]\tLoss: 0.2655\tLR: 0.002250\nTraining Epoch: 15 [18176/50000]\tLoss: 0.2702\tLR: 0.002250\nTraining Epoch: 15 [18304/50000]\tLoss: 0.2136\tLR: 0.002250\nTraining Epoch: 15 [18432/50000]\tLoss: 0.2412\tLR: 0.002250\nTraining Epoch: 15 [18560/50000]\tLoss: 0.3367\tLR: 0.002250\nTraining Epoch: 15 [18688/50000]\tLoss: 0.2600\tLR: 0.002250\nTraining Epoch: 15 [18816/50000]\tLoss: 0.4322\tLR: 0.002250\nTraining Epoch: 15 [18944/50000]\tLoss: 0.3180\tLR: 0.002250\nTraining Epoch: 15 [19072/50000]\tLoss: 0.3981\tLR: 0.002250\nTraining Epoch: 15 [19200/50000]\tLoss: 0.3299\tLR: 0.002250\nTraining Epoch: 15 [19328/50000]\tLoss: 0.3273\tLR: 0.002250\nTraining Epoch: 15 [19456/50000]\tLoss: 0.3923\tLR: 0.002250\nTraining Epoch: 15 [19584/50000]\tLoss: 0.2698\tLR: 0.002250\nTraining Epoch: 15 [19712/50000]\tLoss: 0.3225\tLR: 0.002250\nTraining Epoch: 15 [19840/50000]\tLoss: 0.2392\tLR: 0.002250\nTraining Epoch: 15 [19968/50000]\tLoss: 0.3389\tLR: 0.002250\nTraining Epoch: 15 [20096/50000]\tLoss: 0.2944\tLR: 0.002250\nTraining Epoch: 15 [20224/50000]\tLoss: 0.2939\tLR: 0.002250\nTraining Epoch: 15 [20352/50000]\tLoss: 0.3431\tLR: 0.002250\nTraining Epoch: 15 [20480/50000]\tLoss: 0.3029\tLR: 0.002250\nTraining Epoch: 15 [20608/50000]\tLoss: 0.3184\tLR: 0.002250\nTraining Epoch: 15 [20736/50000]\tLoss: 0.1896\tLR: 0.002250\nTraining Epoch: 15 [20864/50000]\tLoss: 0.2561\tLR: 0.002250\nTraining Epoch: 15 [20992/50000]\tLoss: 0.3728\tLR: 0.002250\nTraining Epoch: 15 [21120/50000]\tLoss: 0.3725\tLR: 0.002250\nTraining Epoch: 15 [21248/50000]\tLoss: 0.3401\tLR: 0.002250\nTraining Epoch: 15 [21376/50000]\tLoss: 0.2741\tLR: 0.002250\nTraining Epoch: 15 [21504/50000]\tLoss: 0.3426\tLR: 0.002250\nTraining Epoch: 15 [21632/50000]\tLoss: 0.2196\tLR: 0.002250\nTraining Epoch: 15 [21760/50000]\tLoss: 0.2364\tLR: 0.002250\nTraining Epoch: 15 [21888/50000]\tLoss: 0.2915\tLR: 0.002250\nTraining Epoch: 15 [22016/50000]\tLoss: 0.2657\tLR: 0.002250\nTraining Epoch: 15 [22144/50000]\tLoss: 0.2872\tLR: 0.002250\nTraining Epoch: 15 [22272/50000]\tLoss: 0.3046\tLR: 0.002250\nTraining Epoch: 15 [22400/50000]\tLoss: 0.3362\tLR: 0.002250\nTraining Epoch: 15 [22528/50000]\tLoss: 0.3060\tLR: 0.002250\nTraining Epoch: 15 [22656/50000]\tLoss: 0.2787\tLR: 0.002250\nTraining Epoch: 15 [22784/50000]\tLoss: 0.3638\tLR: 0.002250\nTraining Epoch: 15 [22912/50000]\tLoss: 0.1837\tLR: 0.002250\nTraining Epoch: 15 [23040/50000]\tLoss: 0.3894\tLR: 0.002250\nTraining Epoch: 15 [23168/50000]\tLoss: 0.3250\tLR: 0.002250\nTraining Epoch: 15 [23296/50000]\tLoss: 0.2512\tLR: 0.002250\nTraining Epoch: 15 [23424/50000]\tLoss: 0.2545\tLR: 0.002250\nTraining Epoch: 15 [23552/50000]\tLoss: 0.3555\tLR: 0.002250\nTraining Epoch: 15 [23680/50000]\tLoss: 0.2022\tLR: 0.002250\nTraining Epoch: 15 [23808/50000]\tLoss: 0.2456\tLR: 0.002250\nTraining Epoch: 15 [23936/50000]\tLoss: 0.3674\tLR: 0.002250\nTraining Epoch: 15 [24064/50000]\tLoss: 0.2717\tLR: 0.002250\nTraining Epoch: 15 [24192/50000]\tLoss: 0.2854\tLR: 0.002250\nTraining Epoch: 15 [24320/50000]\tLoss: 0.2734\tLR: 0.002250\nTraining Epoch: 15 [24448/50000]\tLoss: 0.2912\tLR: 0.002250\nTraining Epoch: 15 [24576/50000]\tLoss: 0.3102\tLR: 0.002250\nTraining Epoch: 15 [24704/50000]\tLoss: 0.2464\tLR: 0.002250\nTraining Epoch: 15 [24832/50000]\tLoss: 0.2991\tLR: 0.002250\nTraining Epoch: 15 [24960/50000]\tLoss: 0.3678\tLR: 0.002250\nTraining Epoch: 15 [25088/50000]\tLoss: 0.3806\tLR: 0.002250\nTraining Epoch: 15 [25216/50000]\tLoss: 0.3169\tLR: 0.002250\nTraining Epoch: 15 [25344/50000]\tLoss: 0.3140\tLR: 0.002250\nTraining Epoch: 15 [25472/50000]\tLoss: 0.3165\tLR: 0.002250\nTraining Epoch: 15 [25600/50000]\tLoss: 0.2261\tLR: 0.002250\nTraining Epoch: 15 [25728/50000]\tLoss: 0.4237\tLR: 0.002250\nTraining Epoch: 15 [25856/50000]\tLoss: 0.3269\tLR: 0.002250\nTraining Epoch: 15 [25984/50000]\tLoss: 0.3304\tLR: 0.002250\nTraining Epoch: 15 [26112/50000]\tLoss: 0.2876\tLR: 0.002250\nTraining Epoch: 15 [26240/50000]\tLoss: 0.2856\tLR: 0.002250\nTraining Epoch: 15 [26368/50000]\tLoss: 0.3605\tLR: 0.002250\nTraining Epoch: 15 [26496/50000]\tLoss: 0.2421\tLR: 0.002250\nTraining Epoch: 15 [26624/50000]\tLoss: 0.2713\tLR: 0.002250\nTraining Epoch: 15 [26752/50000]\tLoss: 0.3373\tLR: 0.002250\nTraining Epoch: 15 [26880/50000]\tLoss: 0.4011\tLR: 0.002250\nTraining Epoch: 15 [27008/50000]\tLoss: 0.2705\tLR: 0.002250\nTraining Epoch: 15 [27136/50000]\tLoss: 0.2388\tLR: 0.002250\nTraining Epoch: 15 [27264/50000]\tLoss: 0.3268\tLR: 0.002250\nTraining Epoch: 15 [27392/50000]\tLoss: 0.2745\tLR: 0.002250\nTraining Epoch: 15 [27520/50000]\tLoss: 0.2346\tLR: 0.002250\nTraining Epoch: 15 [27648/50000]\tLoss: 0.3709\tLR: 0.002250\nTraining Epoch: 15 [27776/50000]\tLoss: 0.2922\tLR: 0.002250\nTraining Epoch: 15 [27904/50000]\tLoss: 0.2534\tLR: 0.002250\nTraining Epoch: 15 [28032/50000]\tLoss: 0.3037\tLR: 0.002250\nTraining Epoch: 15 [28160/50000]\tLoss: 0.2706\tLR: 0.002250\nTraining Epoch: 15 [28288/50000]\tLoss: 0.3428\tLR: 0.002250\nTraining Epoch: 15 [28416/50000]\tLoss: 0.4244\tLR: 0.002250\nTraining Epoch: 15 [28544/50000]\tLoss: 0.2762\tLR: 0.002250\nTraining Epoch: 15 [28672/50000]\tLoss: 0.2048\tLR: 0.002250\nTraining Epoch: 15 [28800/50000]\tLoss: 0.2399\tLR: 0.002250\nTraining Epoch: 15 [28928/50000]\tLoss: 0.2286\tLR: 0.002250\nTraining Epoch: 15 [29056/50000]\tLoss: 0.3798\tLR: 0.002250\nTraining Epoch: 15 [29184/50000]\tLoss: 0.3500\tLR: 0.002250\nTraining Epoch: 15 [29312/50000]\tLoss: 0.2999\tLR: 0.002250\nTraining Epoch: 15 [29440/50000]\tLoss: 0.2770\tLR: 0.002250\nTraining Epoch: 15 [29568/50000]\tLoss: 0.2972\tLR: 0.002250\nTraining Epoch: 15 [29696/50000]\tLoss: 0.3143\tLR: 0.002250\nTraining Epoch: 15 [29824/50000]\tLoss: 0.2906\tLR: 0.002250\nTraining Epoch: 15 [29952/50000]\tLoss: 0.2316\tLR: 0.002250\nTraining Epoch: 15 [30080/50000]\tLoss: 0.4079\tLR: 0.002250\nTraining Epoch: 15 [30208/50000]\tLoss: 0.2230\tLR: 0.002250\nTraining Epoch: 15 [30336/50000]\tLoss: 0.4162\tLR: 0.002250\nTraining Epoch: 15 [30464/50000]\tLoss: 0.2636\tLR: 0.002250\nTraining Epoch: 15 [30592/50000]\tLoss: 0.3685\tLR: 0.002250\nTraining Epoch: 15 [30720/50000]\tLoss: 0.3504\tLR: 0.002250\nTraining Epoch: 15 [30848/50000]\tLoss: 0.3580\tLR: 0.002250\nTraining Epoch: 15 [30976/50000]\tLoss: 0.4523\tLR: 0.002250\nTraining Epoch: 15 [31104/50000]\tLoss: 0.4386\tLR: 0.002250\nTraining Epoch: 15 [31232/50000]\tLoss: 0.3522\tLR: 0.002250\nTraining Epoch: 15 [31360/50000]\tLoss: 0.2377\tLR: 0.002250\nTraining Epoch: 15 [31488/50000]\tLoss: 0.2828\tLR: 0.002250\nTraining Epoch: 15 [31616/50000]\tLoss: 0.3511\tLR: 0.002250\nTraining Epoch: 15 [31744/50000]\tLoss: 0.2518\tLR: 0.002250\nTraining Epoch: 15 [31872/50000]\tLoss: 0.2308\tLR: 0.002250\nTraining Epoch: 15 [32000/50000]\tLoss: 0.3059\tLR: 0.002250\nTraining Epoch: 15 [32128/50000]\tLoss: 0.2150\tLR: 0.002250\nTraining Epoch: 15 [32256/50000]\tLoss: 0.3106\tLR: 0.002250\nTraining Epoch: 15 [32384/50000]\tLoss: 0.2060\tLR: 0.002250\nTraining Epoch: 15 [32512/50000]\tLoss: 0.2912\tLR: 0.002250\nTraining Epoch: 15 [32640/50000]\tLoss: 0.2585\tLR: 0.002250\nTraining Epoch: 15 [32768/50000]\tLoss: 0.3119\tLR: 0.002250\nTraining Epoch: 15 [32896/50000]\tLoss: 0.3438\tLR: 0.002250\nTraining Epoch: 15 [33024/50000]\tLoss: 0.2615\tLR: 0.002250\nTraining Epoch: 15 [33152/50000]\tLoss: 0.2469\tLR: 0.002250\nTraining Epoch: 15 [33280/50000]\tLoss: 0.3192\tLR: 0.002250\nTraining Epoch: 15 [33408/50000]\tLoss: 0.2399\tLR: 0.002250\nTraining Epoch: 15 [33536/50000]\tLoss: 0.2367\tLR: 0.002250\nTraining Epoch: 15 [33664/50000]\tLoss: 0.1764\tLR: 0.002250\nTraining Epoch: 15 [33792/50000]\tLoss: 0.3798\tLR: 0.002250\nTraining Epoch: 15 [33920/50000]\tLoss: 0.2286\tLR: 0.002250\nTraining Epoch: 15 [34048/50000]\tLoss: 0.3844\tLR: 0.002250\nTraining Epoch: 15 [34176/50000]\tLoss: 0.4712\tLR: 0.002250\nTraining Epoch: 15 [34304/50000]\tLoss: 0.3426\tLR: 0.002250\nTraining Epoch: 15 [34432/50000]\tLoss: 0.2670\tLR: 0.002250\nTraining Epoch: 15 [34560/50000]\tLoss: 0.3762\tLR: 0.002250\nTraining Epoch: 15 [34688/50000]\tLoss: 0.2894\tLR: 0.002250\nTraining Epoch: 15 [34816/50000]\tLoss: 0.2126\tLR: 0.002250\nTraining Epoch: 15 [34944/50000]\tLoss: 0.2457\tLR: 0.002250\nTraining Epoch: 15 [35072/50000]\tLoss: 0.2483\tLR: 0.002250\nTraining Epoch: 15 [35200/50000]\tLoss: 0.2264\tLR: 0.002250\nTraining Epoch: 15 [35328/50000]\tLoss: 0.3313\tLR: 0.002250\nTraining Epoch: 15 [35456/50000]\tLoss: 0.2310\tLR: 0.002250\nTraining Epoch: 15 [35584/50000]\tLoss: 0.2609\tLR: 0.002250\nTraining Epoch: 15 [35712/50000]\tLoss: 0.2874\tLR: 0.002250\nTraining Epoch: 15 [35840/50000]\tLoss: 0.2791\tLR: 0.002250\nTraining Epoch: 15 [35968/50000]\tLoss: 0.2917\tLR: 0.002250\nTraining Epoch: 15 [36096/50000]\tLoss: 0.1946\tLR: 0.002250\nTraining Epoch: 15 [36224/50000]\tLoss: 0.2773\tLR: 0.002250\nTraining Epoch: 15 [36352/50000]\tLoss: 0.3212\tLR: 0.002250\nTraining Epoch: 15 [36480/50000]\tLoss: 0.3715\tLR: 0.002250\nTraining Epoch: 15 [36608/50000]\tLoss: 0.3005\tLR: 0.002250\nTraining Epoch: 15 [36736/50000]\tLoss: 0.3274\tLR: 0.002250\nTraining Epoch: 15 [36864/50000]\tLoss: 0.2438\tLR: 0.002250\nTraining Epoch: 15 [36992/50000]\tLoss: 0.2499\tLR: 0.002250\nTraining Epoch: 15 [37120/50000]\tLoss: 0.2467\tLR: 0.002250\nTraining Epoch: 15 [37248/50000]\tLoss: 0.2522\tLR: 0.002250\nTraining Epoch: 15 [37376/50000]\tLoss: 0.2834\tLR: 0.002250\nTraining Epoch: 15 [37504/50000]\tLoss: 0.4073\tLR: 0.002250\nTraining Epoch: 15 [37632/50000]\tLoss: 0.2942\tLR: 0.002250\nTraining Epoch: 15 [37760/50000]\tLoss: 0.3363\tLR: 0.002250\nTraining Epoch: 15 [37888/50000]\tLoss: 0.2527\tLR: 0.002250\nTraining Epoch: 15 [38016/50000]\tLoss: 0.3263\tLR: 0.002250\nTraining Epoch: 15 [38144/50000]\tLoss: 0.3135\tLR: 0.002250\nTraining Epoch: 15 [38272/50000]\tLoss: 0.3089\tLR: 0.002250\nTraining Epoch: 15 [38400/50000]\tLoss: 0.4187\tLR: 0.002250\nTraining Epoch: 15 [38528/50000]\tLoss: 0.3309\tLR: 0.002250\nTraining Epoch: 15 [38656/50000]\tLoss: 0.3279\tLR: 0.002250\nTraining Epoch: 15 [38784/50000]\tLoss: 0.3161\tLR: 0.002250\nTraining Epoch: 15 [38912/50000]\tLoss: 0.2232\tLR: 0.002250\nTraining Epoch: 15 [39040/50000]\tLoss: 0.2717\tLR: 0.002250\nTraining Epoch: 15 [39168/50000]\tLoss: 0.4011\tLR: 0.002250\nTraining Epoch: 15 [39296/50000]\tLoss: 0.3635\tLR: 0.002250\nTraining Epoch: 15 [39424/50000]\tLoss: 0.2742\tLR: 0.002250\nTraining Epoch: 15 [39552/50000]\tLoss: 0.2692\tLR: 0.002250\nTraining Epoch: 15 [39680/50000]\tLoss: 0.3194\tLR: 0.002250\nTraining Epoch: 15 [39808/50000]\tLoss: 0.1837\tLR: 0.002250\nTraining Epoch: 15 [39936/50000]\tLoss: 0.2424\tLR: 0.002250\nTraining Epoch: 15 [40064/50000]\tLoss: 0.3536\tLR: 0.002250\nTraining Epoch: 15 [40192/50000]\tLoss: 0.2189\tLR: 0.002250\nTraining Epoch: 15 [40320/50000]\tLoss: 0.1890\tLR: 0.002250\nTraining Epoch: 15 [40448/50000]\tLoss: 0.2592\tLR: 0.002250\nTraining Epoch: 15 [40576/50000]\tLoss: 0.2982\tLR: 0.002250\nTraining Epoch: 15 [40704/50000]\tLoss: 0.3456\tLR: 0.002250\nTraining Epoch: 15 [40832/50000]\tLoss: 0.2377\tLR: 0.002250\nTraining Epoch: 15 [40960/50000]\tLoss: 0.4142\tLR: 0.002250\nTraining Epoch: 15 [41088/50000]\tLoss: 0.2450\tLR: 0.002250\nTraining Epoch: 15 [41216/50000]\tLoss: 0.3702\tLR: 0.002250\nTraining Epoch: 15 [41344/50000]\tLoss: 0.2347\tLR: 0.002250\nTraining Epoch: 15 [41472/50000]\tLoss: 0.2892\tLR: 0.002250\nTraining Epoch: 15 [41600/50000]\tLoss: 0.3140\tLR: 0.002250\nTraining Epoch: 15 [41728/50000]\tLoss: 0.2344\tLR: 0.002250\nTraining Epoch: 15 [41856/50000]\tLoss: 0.3026\tLR: 0.002250\nTraining Epoch: 15 [41984/50000]\tLoss: 0.2379\tLR: 0.002250\nTraining Epoch: 15 [42112/50000]\tLoss: 0.2234\tLR: 0.002250\nTraining Epoch: 15 [42240/50000]\tLoss: 0.3311\tLR: 0.002250\nTraining Epoch: 15 [42368/50000]\tLoss: 0.3262\tLR: 0.002250\nTraining Epoch: 15 [42496/50000]\tLoss: 0.2761\tLR: 0.002250\nTraining Epoch: 15 [42624/50000]\tLoss: 0.2935\tLR: 0.002250\nTraining Epoch: 15 [42752/50000]\tLoss: 0.3613\tLR: 0.002250\nTraining Epoch: 15 [42880/50000]\tLoss: 0.2315\tLR: 0.002250\nTraining Epoch: 15 [43008/50000]\tLoss: 0.3789\tLR: 0.002250\nTraining Epoch: 15 [43136/50000]\tLoss: 0.2865\tLR: 0.002250\nTraining Epoch: 15 [43264/50000]\tLoss: 0.2760\tLR: 0.002250\nTraining Epoch: 15 [43392/50000]\tLoss: 0.2759\tLR: 0.002250\nTraining Epoch: 15 [43520/50000]\tLoss: 0.3100\tLR: 0.002250\nTraining Epoch: 15 [43648/50000]\tLoss: 0.1937\tLR: 0.002250\nTraining Epoch: 15 [43776/50000]\tLoss: 0.3981\tLR: 0.002250\nTraining Epoch: 15 [43904/50000]\tLoss: 0.2494\tLR: 0.002250\nTraining Epoch: 15 [44032/50000]\tLoss: 0.2642\tLR: 0.002250\nTraining Epoch: 15 [44160/50000]\tLoss: 0.3518\tLR: 0.002250\nTraining Epoch: 15 [44288/50000]\tLoss: 0.3172\tLR: 0.002250\nTraining Epoch: 15 [44416/50000]\tLoss: 0.3011\tLR: 0.002250\nTraining Epoch: 15 [44544/50000]\tLoss: 0.3415\tLR: 0.002250\nTraining Epoch: 15 [44672/50000]\tLoss: 0.3336\tLR: 0.002250\nTraining Epoch: 15 [44800/50000]\tLoss: 0.2983\tLR: 0.002250\nTraining Epoch: 15 [44928/50000]\tLoss: 0.4573\tLR: 0.002250\nTraining Epoch: 15 [45056/50000]\tLoss: 0.2709\tLR: 0.002250\nTraining Epoch: 15 [45184/50000]\tLoss: 0.3583\tLR: 0.002250\nTraining Epoch: 15 [45312/50000]\tLoss: 0.3238\tLR: 0.002250\nTraining Epoch: 15 [45440/50000]\tLoss: 0.3903\tLR: 0.002250\nTraining Epoch: 15 [45568/50000]\tLoss: 0.2215\tLR: 0.002250\nTraining Epoch: 15 [45696/50000]\tLoss: 0.2555\tLR: 0.002250\nTraining Epoch: 15 [45824/50000]\tLoss: 0.2631\tLR: 0.002250\nTraining Epoch: 15 [45952/50000]\tLoss: 0.3568\tLR: 0.002250\nTraining Epoch: 15 [46080/50000]\tLoss: 0.3362\tLR: 0.002250\nTraining Epoch: 15 [46208/50000]\tLoss: 0.3270\tLR: 0.002250\nTraining Epoch: 15 [46336/50000]\tLoss: 0.2100\tLR: 0.002250\nTraining Epoch: 15 [46464/50000]\tLoss: 0.2628\tLR: 0.002250\nTraining Epoch: 15 [46592/50000]\tLoss: 0.2838\tLR: 0.002250\nTraining Epoch: 15 [46720/50000]\tLoss: 0.2273\tLR: 0.002250\nTraining Epoch: 15 [46848/50000]\tLoss: 0.2345\tLR: 0.002250\nTraining Epoch: 15 [46976/50000]\tLoss: 0.2182\tLR: 0.002250\nTraining Epoch: 15 [47104/50000]\tLoss: 0.3257\tLR: 0.002250\nTraining Epoch: 15 [47232/50000]\tLoss: 0.2012\tLR: 0.002250\nTraining Epoch: 15 [47360/50000]\tLoss: 0.1656\tLR: 0.002250\nTraining Epoch: 15 [47488/50000]\tLoss: 0.3393\tLR: 0.002250\nTraining Epoch: 15 [47616/50000]\tLoss: 0.2800\tLR: 0.002250\nTraining Epoch: 15 [47744/50000]\tLoss: 0.2984\tLR: 0.002250\nTraining Epoch: 15 [47872/50000]\tLoss: 0.2252\tLR: 0.002250\nTraining Epoch: 15 [48000/50000]\tLoss: 0.2352\tLR: 0.002250\nTraining Epoch: 15 [48128/50000]\tLoss: 0.3146\tLR: 0.002250\nTraining Epoch: 15 [48256/50000]\tLoss: 0.2320\tLR: 0.002250\nTraining Epoch: 15 [48384/50000]\tLoss: 0.2854\tLR: 0.002250\nTraining Epoch: 15 [48512/50000]\tLoss: 0.3018\tLR: 0.002250\nTraining Epoch: 15 [48640/50000]\tLoss: 0.3371\tLR: 0.002250\nTraining Epoch: 15 [48768/50000]\tLoss: 0.3149\tLR: 0.002250\nTraining Epoch: 15 [48896/50000]\tLoss: 0.2267\tLR: 0.002250\nTraining Epoch: 15 [49024/50000]\tLoss: 0.3901\tLR: 0.002250\nTraining Epoch: 15 [49152/50000]\tLoss: 0.4005\tLR: 0.002250\nTraining Epoch: 15 [49280/50000]\tLoss: 0.3735\tLR: 0.002250\nTraining Epoch: 15 [49408/50000]\tLoss: 0.3271\tLR: 0.002250\nTraining Epoch: 15 [49536/50000]\tLoss: 0.2909\tLR: 0.002250\nTraining Epoch: 15 [49664/50000]\tLoss: 0.2516\tLR: 0.002250\nTraining Epoch: 15 [49792/50000]\tLoss: 0.1832\tLR: 0.002250\nTraining Epoch: 15 [49920/50000]\tLoss: 0.2919\tLR: 0.002250\nTraining Epoch: 15 [50000/50000]\tLoss: 0.1806\tLR: 0.002250\nTest set: Average loss: 0.0026, Accuracy: 0.8892\n\nTraining Epoch: 16 [128/50000]\tLoss: 0.2924\tLR: 0.000337\nTraining Epoch: 16 [256/50000]\tLoss: 0.2951\tLR: 0.000337\nTraining Epoch: 16 [384/50000]\tLoss: 0.2123\tLR: 0.000337\nTraining Epoch: 16 [512/50000]\tLoss: 0.2568\tLR: 0.000337\nTraining Epoch: 16 [640/50000]\tLoss: 0.3349\tLR: 0.000337\nTraining Epoch: 16 [768/50000]\tLoss: 0.2326\tLR: 0.000337\nTraining Epoch: 16 [896/50000]\tLoss: 0.2671\tLR: 0.000337\nTraining Epoch: 16 [1024/50000]\tLoss: 0.2289\tLR: 0.000337\nTraining Epoch: 16 [1152/50000]\tLoss: 0.2994\tLR: 0.000337\nTraining Epoch: 16 [1280/50000]\tLoss: 0.1834\tLR: 0.000337\nTraining Epoch: 16 [1408/50000]\tLoss: 0.3209\tLR: 0.000337\nTraining Epoch: 16 [1536/50000]\tLoss: 0.2695\tLR: 0.000337\nTraining Epoch: 16 [1664/50000]\tLoss: 0.1821\tLR: 0.000337\nTraining Epoch: 16 [1792/50000]\tLoss: 0.1648\tLR: 0.000337\nTraining Epoch: 16 [1920/50000]\tLoss: 0.2778\tLR: 0.000337\nTraining Epoch: 16 [2048/50000]\tLoss: 0.3401\tLR: 0.000337\nTraining Epoch: 16 [2176/50000]\tLoss: 0.3410\tLR: 0.000337\nTraining Epoch: 16 [2304/50000]\tLoss: 0.2895\tLR: 0.000337\nTraining Epoch: 16 [2432/50000]\tLoss: 0.2998\tLR: 0.000337\nTraining Epoch: 16 [2560/50000]\tLoss: 0.3714\tLR: 0.000337\nTraining Epoch: 16 [2688/50000]\tLoss: 0.2821\tLR: 0.000337\nTraining Epoch: 16 [2816/50000]\tLoss: 0.3313\tLR: 0.000337\nTraining Epoch: 16 [2944/50000]\tLoss: 0.3490\tLR: 0.000337\nTraining Epoch: 16 [3072/50000]\tLoss: 0.3849\tLR: 0.000337\nTraining Epoch: 16 [3200/50000]\tLoss: 0.2368\tLR: 0.000337\nTraining Epoch: 16 [3328/50000]\tLoss: 0.3372\tLR: 0.000337\nTraining Epoch: 16 [3456/50000]\tLoss: 0.2412\tLR: 0.000337\nTraining Epoch: 16 [3584/50000]\tLoss: 0.2087\tLR: 0.000337\nTraining Epoch: 16 [3712/50000]\tLoss: 0.1938\tLR: 0.000337\nTraining Epoch: 16 [3840/50000]\tLoss: 0.2902\tLR: 0.000337\nTraining Epoch: 16 [3968/50000]\tLoss: 0.2572\tLR: 0.000337\nTraining Epoch: 16 [4096/50000]\tLoss: 0.2334\tLR: 0.000337\nTraining Epoch: 16 [4224/50000]\tLoss: 0.3311\tLR: 0.000337\nTraining Epoch: 16 [4352/50000]\tLoss: 0.2113\tLR: 0.000337\nTraining Epoch: 16 [4480/50000]\tLoss: 0.3265\tLR: 0.000337\nTraining Epoch: 16 [4608/50000]\tLoss: 0.2795\tLR: 0.000337\nTraining Epoch: 16 [4736/50000]\tLoss: 0.3902\tLR: 0.000337\nTraining Epoch: 16 [4864/50000]\tLoss: 0.3511\tLR: 0.000337\nTraining Epoch: 16 [4992/50000]\tLoss: 0.2047\tLR: 0.000337\nTraining Epoch: 16 [5120/50000]\tLoss: 0.2630\tLR: 0.000337\nTraining Epoch: 16 [5248/50000]\tLoss: 0.2209\tLR: 0.000337\nTraining Epoch: 16 [5376/50000]\tLoss: 0.2285\tLR: 0.000337\nTraining Epoch: 16 [5504/50000]\tLoss: 0.4462\tLR: 0.000337\nTraining Epoch: 16 [5632/50000]\tLoss: 0.3260\tLR: 0.000337\nTraining Epoch: 16 [5760/50000]\tLoss: 0.3480\tLR: 0.000337\nTraining Epoch: 16 [5888/50000]\tLoss: 0.2046\tLR: 0.000337\nTraining Epoch: 16 [6016/50000]\tLoss: 0.1846\tLR: 0.000337\nTraining Epoch: 16 [6144/50000]\tLoss: 0.3103\tLR: 0.000337\nTraining Epoch: 16 [6272/50000]\tLoss: 0.2611\tLR: 0.000337\nTraining Epoch: 16 [6400/50000]\tLoss: 0.2010\tLR: 0.000337\nTraining Epoch: 16 [6528/50000]\tLoss: 0.2748\tLR: 0.000337\nTraining Epoch: 16 [6656/50000]\tLoss: 0.2110\tLR: 0.000337\nTraining Epoch: 16 [6784/50000]\tLoss: 0.1918\tLR: 0.000337\nTraining Epoch: 16 [6912/50000]\tLoss: 0.2504\tLR: 0.000337\nTraining Epoch: 16 [7040/50000]\tLoss: 0.2493\tLR: 0.000337\nTraining Epoch: 16 [7168/50000]\tLoss: 0.2751\tLR: 0.000337\nTraining Epoch: 16 [7296/50000]\tLoss: 0.2977\tLR: 0.000337\nTraining Epoch: 16 [7424/50000]\tLoss: 0.3271\tLR: 0.000337\nTraining Epoch: 16 [7552/50000]\tLoss: 0.2977\tLR: 0.000337\nTraining Epoch: 16 [7680/50000]\tLoss: 0.2044\tLR: 0.000337\nTraining Epoch: 16 [7808/50000]\tLoss: 0.3999\tLR: 0.000337\nTraining Epoch: 16 [7936/50000]\tLoss: 0.3312\tLR: 0.000337\nTraining Epoch: 16 [8064/50000]\tLoss: 0.2624\tLR: 0.000337\nTraining Epoch: 16 [8192/50000]\tLoss: 0.2569\tLR: 0.000337\nTraining Epoch: 16 [8320/50000]\tLoss: 0.2610\tLR: 0.000337\nTraining Epoch: 16 [8448/50000]\tLoss: 0.1696\tLR: 0.000337\nTraining Epoch: 16 [8576/50000]\tLoss: 0.3540\tLR: 0.000337\nTraining Epoch: 16 [8704/50000]\tLoss: 0.2755\tLR: 0.000337\nTraining Epoch: 16 [8832/50000]\tLoss: 0.2549\tLR: 0.000337\nTraining Epoch: 16 [8960/50000]\tLoss: 0.2418\tLR: 0.000337\nTraining Epoch: 16 [9088/50000]\tLoss: 0.4080\tLR: 0.000337\nTraining Epoch: 16 [9216/50000]\tLoss: 0.3449\tLR: 0.000337\nTraining Epoch: 16 [9344/50000]\tLoss: 0.2715\tLR: 0.000337\nTraining Epoch: 16 [9472/50000]\tLoss: 0.2555\tLR: 0.000337\nTraining Epoch: 16 [9600/50000]\tLoss: 0.2743\tLR: 0.000337\nTraining Epoch: 16 [9728/50000]\tLoss: 0.3402\tLR: 0.000337\nTraining Epoch: 16 [9856/50000]\tLoss: 0.3403\tLR: 0.000337\nTraining Epoch: 16 [9984/50000]\tLoss: 0.1830\tLR: 0.000337\nTraining Epoch: 16 [10112/50000]\tLoss: 0.3028\tLR: 0.000337\nTraining Epoch: 16 [10240/50000]\tLoss: 0.2205\tLR: 0.000337\nTraining Epoch: 16 [10368/50000]\tLoss: 0.3009\tLR: 0.000337\nTraining Epoch: 16 [10496/50000]\tLoss: 0.2473\tLR: 0.000337\nTraining Epoch: 16 [10624/50000]\tLoss: 0.2199\tLR: 0.000337\nTraining Epoch: 16 [10752/50000]\tLoss: 0.3010\tLR: 0.000337\nTraining Epoch: 16 [10880/50000]\tLoss: 0.2471\tLR: 0.000337\nTraining Epoch: 16 [11008/50000]\tLoss: 0.2766\tLR: 0.000337\nTraining Epoch: 16 [11136/50000]\tLoss: 0.4572\tLR: 0.000337\nTraining Epoch: 16 [11264/50000]\tLoss: 0.3485\tLR: 0.000337\nTraining Epoch: 16 [11392/50000]\tLoss: 0.3440\tLR: 0.000337\nTraining Epoch: 16 [11520/50000]\tLoss: 0.2639\tLR: 0.000337\nTraining Epoch: 16 [11648/50000]\tLoss: 0.3964\tLR: 0.000337\nTraining Epoch: 16 [11776/50000]\tLoss: 0.1821\tLR: 0.000337\nTraining Epoch: 16 [11904/50000]\tLoss: 0.2810\tLR: 0.000337\nTraining Epoch: 16 [12032/50000]\tLoss: 0.3424\tLR: 0.000337\nTraining Epoch: 16 [12160/50000]\tLoss: 0.2650\tLR: 0.000337\nTraining Epoch: 16 [12288/50000]\tLoss: 0.3220\tLR: 0.000337\nTraining Epoch: 16 [12416/50000]\tLoss: 0.2443\tLR: 0.000337\nTraining Epoch: 16 [12544/50000]\tLoss: 0.2642\tLR: 0.000337\nTraining Epoch: 16 [12672/50000]\tLoss: 0.2622\tLR: 0.000337\nTraining Epoch: 16 [12800/50000]\tLoss: 0.2106\tLR: 0.000337\nTraining Epoch: 16 [12928/50000]\tLoss: 0.2915\tLR: 0.000337\nTraining Epoch: 16 [13056/50000]\tLoss: 0.2166\tLR: 0.000337\nTraining Epoch: 16 [13184/50000]\tLoss: 0.3556\tLR: 0.000337\nTraining Epoch: 16 [13312/50000]\tLoss: 0.2933\tLR: 0.000337\nTraining Epoch: 16 [13440/50000]\tLoss: 0.3065\tLR: 0.000337\nTraining Epoch: 16 [13568/50000]\tLoss: 0.3266\tLR: 0.000337\nTraining Epoch: 16 [13696/50000]\tLoss: 0.2701\tLR: 0.000337\nTraining Epoch: 16 [13824/50000]\tLoss: 0.2542\tLR: 0.000337\nTraining Epoch: 16 [13952/50000]\tLoss: 0.2885\tLR: 0.000337\nTraining Epoch: 16 [14080/50000]\tLoss: 0.2162\tLR: 0.000337\nTraining Epoch: 16 [14208/50000]\tLoss: 0.2616\tLR: 0.000337\nTraining Epoch: 16 [14336/50000]\tLoss: 0.2524\tLR: 0.000337\nTraining Epoch: 16 [14464/50000]\tLoss: 0.2035\tLR: 0.000337\nTraining Epoch: 16 [14592/50000]\tLoss: 0.3289\tLR: 0.000337\nTraining Epoch: 16 [14720/50000]\tLoss: 0.2789\tLR: 0.000337\nTraining Epoch: 16 [14848/50000]\tLoss: 0.2420\tLR: 0.000337\nTraining Epoch: 16 [14976/50000]\tLoss: 0.3428\tLR: 0.000337\nTraining Epoch: 16 [15104/50000]\tLoss: 0.1990\tLR: 0.000337\nTraining Epoch: 16 [15232/50000]\tLoss: 0.4811\tLR: 0.000337\nTraining Epoch: 16 [15360/50000]\tLoss: 0.2445\tLR: 0.000337\nTraining Epoch: 16 [15488/50000]\tLoss: 0.3903\tLR: 0.000337\nTraining Epoch: 16 [15616/50000]\tLoss: 0.2805\tLR: 0.000337\nTraining Epoch: 16 [15744/50000]\tLoss: 0.2258\tLR: 0.000337\nTraining Epoch: 16 [15872/50000]\tLoss: 0.2131\tLR: 0.000337\nTraining Epoch: 16 [16000/50000]\tLoss: 0.1881\tLR: 0.000337\nTraining Epoch: 16 [16128/50000]\tLoss: 0.2507\tLR: 0.000337\nTraining Epoch: 16 [16256/50000]\tLoss: 0.2861\tLR: 0.000337\nTraining Epoch: 16 [16384/50000]\tLoss: 0.2215\tLR: 0.000337\nTraining Epoch: 16 [16512/50000]\tLoss: 0.2872\tLR: 0.000337\nTraining Epoch: 16 [16640/50000]\tLoss: 0.1312\tLR: 0.000337\nTraining Epoch: 16 [16768/50000]\tLoss: 0.3851\tLR: 0.000337\nTraining Epoch: 16 [16896/50000]\tLoss: 0.3198\tLR: 0.000337\nTraining Epoch: 16 [17024/50000]\tLoss: 0.3092\tLR: 0.000337\nTraining Epoch: 16 [17152/50000]\tLoss: 0.4438\tLR: 0.000337\nTraining Epoch: 16 [17280/50000]\tLoss: 0.2515\tLR: 0.000337\nTraining Epoch: 16 [17408/50000]\tLoss: 0.2773\tLR: 0.000337\nTraining Epoch: 16 [17536/50000]\tLoss: 0.2372\tLR: 0.000337\nTraining Epoch: 16 [17664/50000]\tLoss: 0.2611\tLR: 0.000337\nTraining Epoch: 16 [17792/50000]\tLoss: 0.2240\tLR: 0.000337\nTraining Epoch: 16 [17920/50000]\tLoss: 0.3405\tLR: 0.000337\nTraining Epoch: 16 [18048/50000]\tLoss: 0.2324\tLR: 0.000337\nTraining Epoch: 16 [18176/50000]\tLoss: 0.3126\tLR: 0.000337\nTraining Epoch: 16 [18304/50000]\tLoss: 0.2750\tLR: 0.000337\nTraining Epoch: 16 [18432/50000]\tLoss: 0.3636\tLR: 0.000337\nTraining Epoch: 16 [18560/50000]\tLoss: 0.4175\tLR: 0.000337\nTraining Epoch: 16 [18688/50000]\tLoss: 0.2376\tLR: 0.000337\nTraining Epoch: 16 [18816/50000]\tLoss: 0.3487\tLR: 0.000337\nTraining Epoch: 16 [18944/50000]\tLoss: 0.2313\tLR: 0.000337\nTraining Epoch: 16 [19072/50000]\tLoss: 0.1875\tLR: 0.000337\nTraining Epoch: 16 [19200/50000]\tLoss: 0.2505\tLR: 0.000337\nTraining Epoch: 16 [19328/50000]\tLoss: 0.3366\tLR: 0.000337\nTraining Epoch: 16 [19456/50000]\tLoss: 0.2999\tLR: 0.000337\nTraining Epoch: 16 [19584/50000]\tLoss: 0.2779\tLR: 0.000337\nTraining Epoch: 16 [19712/50000]\tLoss: 0.2087\tLR: 0.000337\nTraining Epoch: 16 [19840/50000]\tLoss: 0.2790\tLR: 0.000337\nTraining Epoch: 16 [19968/50000]\tLoss: 0.2976\tLR: 0.000337\nTraining Epoch: 16 [20096/50000]\tLoss: 0.2681\tLR: 0.000337\nTraining Epoch: 16 [20224/50000]\tLoss: 0.2334\tLR: 0.000337\nTraining Epoch: 16 [20352/50000]\tLoss: 0.3554\tLR: 0.000337\nTraining Epoch: 16 [20480/50000]\tLoss: 0.2291\tLR: 0.000337\nTraining Epoch: 16 [20608/50000]\tLoss: 0.2405\tLR: 0.000337\nTraining Epoch: 16 [20736/50000]\tLoss: 0.3353\tLR: 0.000337\nTraining Epoch: 16 [20864/50000]\tLoss: 0.2200\tLR: 0.000337\nTraining Epoch: 16 [20992/50000]\tLoss: 0.2929\tLR: 0.000337\nTraining Epoch: 16 [21120/50000]\tLoss: 0.2259\tLR: 0.000337\nTraining Epoch: 16 [21248/50000]\tLoss: 0.2288\tLR: 0.000337\nTraining Epoch: 16 [21376/50000]\tLoss: 0.2650\tLR: 0.000337\nTraining Epoch: 16 [21504/50000]\tLoss: 0.3069\tLR: 0.000337\nTraining Epoch: 16 [21632/50000]\tLoss: 0.2642\tLR: 0.000337\nTraining Epoch: 16 [21760/50000]\tLoss: 0.3132\tLR: 0.000337\nTraining Epoch: 16 [21888/50000]\tLoss: 0.2539\tLR: 0.000337\nTraining Epoch: 16 [22016/50000]\tLoss: 0.3027\tLR: 0.000337\nTraining Epoch: 16 [22144/50000]\tLoss: 0.2511\tLR: 0.000337\nTraining Epoch: 16 [22272/50000]\tLoss: 0.2351\tLR: 0.000337\nTraining Epoch: 16 [22400/50000]\tLoss: 0.3256\tLR: 0.000337\nTraining Epoch: 16 [22528/50000]\tLoss: 0.2228\tLR: 0.000337\nTraining Epoch: 16 [22656/50000]\tLoss: 0.2604\tLR: 0.000337\nTraining Epoch: 16 [22784/50000]\tLoss: 0.2437\tLR: 0.000337\nTraining Epoch: 16 [22912/50000]\tLoss: 0.2878\tLR: 0.000337\nTraining Epoch: 16 [23040/50000]\tLoss: 0.3252\tLR: 0.000337\nTraining Epoch: 16 [23168/50000]\tLoss: 0.1957\tLR: 0.000337\nTraining Epoch: 16 [23296/50000]\tLoss: 0.2234\tLR: 0.000337\nTraining Epoch: 16 [23424/50000]\tLoss: 0.4102\tLR: 0.000337\nTraining Epoch: 16 [23552/50000]\tLoss: 0.2983\tLR: 0.000337\nTraining Epoch: 16 [23680/50000]\tLoss: 0.2223\tLR: 0.000337\nTraining Epoch: 16 [23808/50000]\tLoss: 0.4104\tLR: 0.000337\nTraining Epoch: 16 [23936/50000]\tLoss: 0.3289\tLR: 0.000337\nTraining Epoch: 16 [24064/50000]\tLoss: 0.2903\tLR: 0.000337\nTraining Epoch: 16 [24192/50000]\tLoss: 0.3947\tLR: 0.000337\nTraining Epoch: 16 [24320/50000]\tLoss: 0.2189\tLR: 0.000337\nTraining Epoch: 16 [24448/50000]\tLoss: 0.1948\tLR: 0.000337\nTraining Epoch: 16 [24576/50000]\tLoss: 0.2549\tLR: 0.000337\nTraining Epoch: 16 [24704/50000]\tLoss: 0.3332\tLR: 0.000337\nTraining Epoch: 16 [24832/50000]\tLoss: 0.3374\tLR: 0.000337\nTraining Epoch: 16 [24960/50000]\tLoss: 0.2259\tLR: 0.000337\nTraining Epoch: 16 [25088/50000]\tLoss: 0.2263\tLR: 0.000337\nTraining Epoch: 16 [25216/50000]\tLoss: 0.2919\tLR: 0.000337\nTraining Epoch: 16 [25344/50000]\tLoss: 0.3262\tLR: 0.000337\nTraining Epoch: 16 [25472/50000]\tLoss: 0.2531\tLR: 0.000337\nTraining Epoch: 16 [25600/50000]\tLoss: 0.2042\tLR: 0.000337\nTraining Epoch: 16 [25728/50000]\tLoss: 0.3234\tLR: 0.000337\nTraining Epoch: 16 [25856/50000]\tLoss: 0.2887\tLR: 0.000337\nTraining Epoch: 16 [25984/50000]\tLoss: 0.3968\tLR: 0.000337\nTraining Epoch: 16 [26112/50000]\tLoss: 0.2678\tLR: 0.000337\nTraining Epoch: 16 [26240/50000]\tLoss: 0.3063\tLR: 0.000337\nTraining Epoch: 16 [26368/50000]\tLoss: 0.2157\tLR: 0.000337\nTraining Epoch: 16 [26496/50000]\tLoss: 0.2016\tLR: 0.000337\nTraining Epoch: 16 [26624/50000]\tLoss: 0.2132\tLR: 0.000337\nTraining Epoch: 16 [26752/50000]\tLoss: 0.2554\tLR: 0.000337\nTraining Epoch: 16 [26880/50000]\tLoss: 0.2598\tLR: 0.000337\nTraining Epoch: 16 [27008/50000]\tLoss: 0.2211\tLR: 0.000337\nTraining Epoch: 16 [27136/50000]\tLoss: 0.3787\tLR: 0.000337\nTraining Epoch: 16 [27264/50000]\tLoss: 0.2188\tLR: 0.000337\nTraining Epoch: 16 [27392/50000]\tLoss: 0.2566\tLR: 0.000337\nTraining Epoch: 16 [27520/50000]\tLoss: 0.2060\tLR: 0.000337\nTraining Epoch: 16 [27648/50000]\tLoss: 0.2772\tLR: 0.000337\nTraining Epoch: 16 [27776/50000]\tLoss: 0.2827\tLR: 0.000337\nTraining Epoch: 16 [27904/50000]\tLoss: 0.3085\tLR: 0.000337\nTraining Epoch: 16 [28032/50000]\tLoss: 0.1917\tLR: 0.000337\nTraining Epoch: 16 [28160/50000]\tLoss: 0.2087\tLR: 0.000337\nTraining Epoch: 16 [28288/50000]\tLoss: 0.2027\tLR: 0.000337\nTraining Epoch: 16 [28416/50000]\tLoss: 0.2696\tLR: 0.000337\nTraining Epoch: 16 [28544/50000]\tLoss: 0.2554\tLR: 0.000337\nTraining Epoch: 16 [28672/50000]\tLoss: 0.2941\tLR: 0.000337\nTraining Epoch: 16 [28800/50000]\tLoss: 0.2968\tLR: 0.000337\nTraining Epoch: 16 [28928/50000]\tLoss: 0.3770\tLR: 0.000337\nTraining Epoch: 16 [29056/50000]\tLoss: 0.3376\tLR: 0.000337\nTraining Epoch: 16 [29184/50000]\tLoss: 0.2327\tLR: 0.000337\nTraining Epoch: 16 [29312/50000]\tLoss: 0.2855\tLR: 0.000337\nTraining Epoch: 16 [29440/50000]\tLoss: 0.3134\tLR: 0.000337\nTraining Epoch: 16 [29568/50000]\tLoss: 0.2790\tLR: 0.000337\nTraining Epoch: 16 [29696/50000]\tLoss: 0.2796\tLR: 0.000337\nTraining Epoch: 16 [29824/50000]\tLoss: 0.2667\tLR: 0.000337\nTraining Epoch: 16 [29952/50000]\tLoss: 0.3661\tLR: 0.000337\nTraining Epoch: 16 [30080/50000]\tLoss: 0.3990\tLR: 0.000337\nTraining Epoch: 16 [30208/50000]\tLoss: 0.2941\tLR: 0.000337\nTraining Epoch: 16 [30336/50000]\tLoss: 0.3141\tLR: 0.000337\nTraining Epoch: 16 [30464/50000]\tLoss: 0.2039\tLR: 0.000337\nTraining Epoch: 16 [30592/50000]\tLoss: 0.3111\tLR: 0.000337\nTraining Epoch: 16 [30720/50000]\tLoss: 0.2824\tLR: 0.000337\nTraining Epoch: 16 [30848/50000]\tLoss: 0.2944\tLR: 0.000337\nTraining Epoch: 16 [30976/50000]\tLoss: 0.2774\tLR: 0.000337\nTraining Epoch: 16 [31104/50000]\tLoss: 0.2115\tLR: 0.000337\nTraining Epoch: 16 [31232/50000]\tLoss: 0.3172\tLR: 0.000337\nTraining Epoch: 16 [31360/50000]\tLoss: 0.3398\tLR: 0.000337\nTraining Epoch: 16 [31488/50000]\tLoss: 0.2874\tLR: 0.000337\nTraining Epoch: 16 [31616/50000]\tLoss: 0.2544\tLR: 0.000337\nTraining Epoch: 16 [31744/50000]\tLoss: 0.3146\tLR: 0.000337\nTraining Epoch: 16 [31872/50000]\tLoss: 0.2299\tLR: 0.000337\nTraining Epoch: 16 [32000/50000]\tLoss: 0.2578\tLR: 0.000337\nTraining Epoch: 16 [32128/50000]\tLoss: 0.3339\tLR: 0.000337\nTraining Epoch: 16 [32256/50000]\tLoss: 0.2322\tLR: 0.000337\nTraining Epoch: 16 [32384/50000]\tLoss: 0.3581\tLR: 0.000337\nTraining Epoch: 16 [32512/50000]\tLoss: 0.3093\tLR: 0.000337\nTraining Epoch: 16 [32640/50000]\tLoss: 0.2550\tLR: 0.000337\nTraining Epoch: 16 [32768/50000]\tLoss: 0.3171\tLR: 0.000337\nTraining Epoch: 16 [32896/50000]\tLoss: 0.3589\tLR: 0.000337\nTraining Epoch: 16 [33024/50000]\tLoss: 0.1296\tLR: 0.000337\nTraining Epoch: 16 [33152/50000]\tLoss: 0.3044\tLR: 0.000337\nTraining Epoch: 16 [33280/50000]\tLoss: 0.2838\tLR: 0.000337\nTraining Epoch: 16 [33408/50000]\tLoss: 0.2420\tLR: 0.000337\nTraining Epoch: 16 [33536/50000]\tLoss: 0.2594\tLR: 0.000337\nTraining Epoch: 16 [33664/50000]\tLoss: 0.1971\tLR: 0.000337\nTraining Epoch: 16 [33792/50000]\tLoss: 0.3529\tLR: 0.000337\nTraining Epoch: 16 [33920/50000]\tLoss: 0.2353\tLR: 0.000337\nTraining Epoch: 16 [34048/50000]\tLoss: 0.2512\tLR: 0.000337\nTraining Epoch: 16 [34176/50000]\tLoss: 0.2746\tLR: 0.000337\nTraining Epoch: 16 [34304/50000]\tLoss: 0.2507\tLR: 0.000337\nTraining Epoch: 16 [34432/50000]\tLoss: 0.2246\tLR: 0.000337\nTraining Epoch: 16 [34560/50000]\tLoss: 0.2851\tLR: 0.000337\nTraining Epoch: 16 [34688/50000]\tLoss: 0.3228\tLR: 0.000337\nTraining Epoch: 16 [34816/50000]\tLoss: 0.4399\tLR: 0.000337\nTraining Epoch: 16 [34944/50000]\tLoss: 0.2510\tLR: 0.000337\nTraining Epoch: 16 [35072/50000]\tLoss: 0.2723\tLR: 0.000337\nTraining Epoch: 16 [35200/50000]\tLoss: 0.2413\tLR: 0.000337\nTraining Epoch: 16 [35328/50000]\tLoss: 0.3282\tLR: 0.000337\nTraining Epoch: 16 [35456/50000]\tLoss: 0.2978\tLR: 0.000337\nTraining Epoch: 16 [35584/50000]\tLoss: 0.2325\tLR: 0.000337\nTraining Epoch: 16 [35712/50000]\tLoss: 0.2873\tLR: 0.000337\nTraining Epoch: 16 [35840/50000]\tLoss: 0.1910\tLR: 0.000337\nTraining Epoch: 16 [35968/50000]\tLoss: 0.2774\tLR: 0.000337\nTraining Epoch: 16 [36096/50000]\tLoss: 0.2795\tLR: 0.000337\nTraining Epoch: 16 [36224/50000]\tLoss: 0.3760\tLR: 0.000337\nTraining Epoch: 16 [36352/50000]\tLoss: 0.2546\tLR: 0.000337\nTraining Epoch: 16 [36480/50000]\tLoss: 0.3254\tLR: 0.000337\nTraining Epoch: 16 [36608/50000]\tLoss: 0.3428\tLR: 0.000337\nTraining Epoch: 16 [36736/50000]\tLoss: 0.2519\tLR: 0.000337\nTraining Epoch: 16 [36864/50000]\tLoss: 0.3388\tLR: 0.000337\nTraining Epoch: 16 [36992/50000]\tLoss: 0.3170\tLR: 0.000337\nTraining Epoch: 16 [37120/50000]\tLoss: 0.2453\tLR: 0.000337\nTraining Epoch: 16 [37248/50000]\tLoss: 0.2456\tLR: 0.000337\nTraining Epoch: 16 [37376/50000]\tLoss: 0.2265\tLR: 0.000337\nTraining Epoch: 16 [37504/50000]\tLoss: 0.2558\tLR: 0.000337\nTraining Epoch: 16 [37632/50000]\tLoss: 0.2221\tLR: 0.000337\nTraining Epoch: 16 [37760/50000]\tLoss: 0.2142\tLR: 0.000337\nTraining Epoch: 16 [37888/50000]\tLoss: 0.1613\tLR: 0.000337\nTraining Epoch: 16 [38016/50000]\tLoss: 0.2125\tLR: 0.000337\nTraining Epoch: 16 [38144/50000]\tLoss: 0.3609\tLR: 0.000337\nTraining Epoch: 16 [38272/50000]\tLoss: 0.2340\tLR: 0.000337\nTraining Epoch: 16 [38400/50000]\tLoss: 0.3525\tLR: 0.000337\nTraining Epoch: 16 [38528/50000]\tLoss: 0.3306\tLR: 0.000337\nTraining Epoch: 16 [38656/50000]\tLoss: 0.1933\tLR: 0.000337\nTraining Epoch: 16 [38784/50000]\tLoss: 0.3213\tLR: 0.000337\nTraining Epoch: 16 [38912/50000]\tLoss: 0.2763\tLR: 0.000337\nTraining Epoch: 16 [39040/50000]\tLoss: 0.2257\tLR: 0.000337\nTraining Epoch: 16 [39168/50000]\tLoss: 0.3520\tLR: 0.000337\nTraining Epoch: 16 [39296/50000]\tLoss: 0.1923\tLR: 0.000337\nTraining Epoch: 16 [39424/50000]\tLoss: 0.3714\tLR: 0.000337\nTraining Epoch: 16 [39552/50000]\tLoss: 0.3552\tLR: 0.000337\nTraining Epoch: 16 [39680/50000]\tLoss: 0.2461\tLR: 0.000337\nTraining Epoch: 16 [39808/50000]\tLoss: 0.3163\tLR: 0.000337\nTraining Epoch: 16 [39936/50000]\tLoss: 0.3350\tLR: 0.000337\nTraining Epoch: 16 [40064/50000]\tLoss: 0.2395\tLR: 0.000337\nTraining Epoch: 16 [40192/50000]\tLoss: 0.2597\tLR: 0.000337\nTraining Epoch: 16 [40320/50000]\tLoss: 0.2471\tLR: 0.000337\nTraining Epoch: 16 [40448/50000]\tLoss: 0.2728\tLR: 0.000337\nTraining Epoch: 16 [40576/50000]\tLoss: 0.2562\tLR: 0.000337\nTraining Epoch: 16 [40704/50000]\tLoss: 0.2280\tLR: 0.000337\nTraining Epoch: 16 [40832/50000]\tLoss: 0.2389\tLR: 0.000337\nTraining Epoch: 16 [40960/50000]\tLoss: 0.2407\tLR: 0.000337\nTraining Epoch: 16 [41088/50000]\tLoss: 0.3857\tLR: 0.000337\nTraining Epoch: 16 [41216/50000]\tLoss: 0.2681\tLR: 0.000337\nTraining Epoch: 16 [41344/50000]\tLoss: 0.3548\tLR: 0.000337\nTraining Epoch: 16 [41472/50000]\tLoss: 0.2474\tLR: 0.000337\nTraining Epoch: 16 [41600/50000]\tLoss: 0.4286\tLR: 0.000337\nTraining Epoch: 16 [41728/50000]\tLoss: 0.3375\tLR: 0.000337\nTraining Epoch: 16 [41856/50000]\tLoss: 0.3482\tLR: 0.000337\nTraining Epoch: 16 [41984/50000]\tLoss: 0.2307\tLR: 0.000337\nTraining Epoch: 16 [42112/50000]\tLoss: 0.2453\tLR: 0.000337\nTraining Epoch: 16 [42240/50000]\tLoss: 0.2521\tLR: 0.000337\nTraining Epoch: 16 [42368/50000]\tLoss: 0.3005\tLR: 0.000337\nTraining Epoch: 16 [42496/50000]\tLoss: 0.3217\tLR: 0.000337\nTraining Epoch: 16 [42624/50000]\tLoss: 0.2436\tLR: 0.000337\nTraining Epoch: 16 [42752/50000]\tLoss: 0.3267\tLR: 0.000337\nTraining Epoch: 16 [42880/50000]\tLoss: 0.2942\tLR: 0.000337\nTraining Epoch: 16 [43008/50000]\tLoss: 0.2006\tLR: 0.000337\nTraining Epoch: 16 [43136/50000]\tLoss: 0.1740\tLR: 0.000337\nTraining Epoch: 16 [43264/50000]\tLoss: 0.2552\tLR: 0.000337\nTraining Epoch: 16 [43392/50000]\tLoss: 0.3020\tLR: 0.000337\nTraining Epoch: 16 [43520/50000]\tLoss: 0.3421\tLR: 0.000337\nTraining Epoch: 16 [43648/50000]\tLoss: 0.3420\tLR: 0.000337\nTraining Epoch: 16 [43776/50000]\tLoss: 0.2200\tLR: 0.000337\nTraining Epoch: 16 [43904/50000]\tLoss: 0.3580\tLR: 0.000337\nTraining Epoch: 16 [44032/50000]\tLoss: 0.1925\tLR: 0.000337\nTraining Epoch: 16 [44160/50000]\tLoss: 0.3675\tLR: 0.000337\nTraining Epoch: 16 [44288/50000]\tLoss: 0.2272\tLR: 0.000337\nTraining Epoch: 16 [44416/50000]\tLoss: 0.2795\tLR: 0.000337\nTraining Epoch: 16 [44544/50000]\tLoss: 0.2308\tLR: 0.000337\nTraining Epoch: 16 [44672/50000]\tLoss: 0.2376\tLR: 0.000337\nTraining Epoch: 16 [44800/50000]\tLoss: 0.1963\tLR: 0.000337\nTraining Epoch: 16 [44928/50000]\tLoss: 0.1860\tLR: 0.000337\nTraining Epoch: 16 [45056/50000]\tLoss: 0.3744\tLR: 0.000337\nTraining Epoch: 16 [45184/50000]\tLoss: 0.2305\tLR: 0.000337\nTraining Epoch: 16 [45312/50000]\tLoss: 0.3254\tLR: 0.000337\nTraining Epoch: 16 [45440/50000]\tLoss: 0.2658\tLR: 0.000337\nTraining Epoch: 16 [45568/50000]\tLoss: 0.3241\tLR: 0.000337\nTraining Epoch: 16 [45696/50000]\tLoss: 0.2720\tLR: 0.000337\nTraining Epoch: 16 [45824/50000]\tLoss: 0.3594\tLR: 0.000337\nTraining Epoch: 16 [45952/50000]\tLoss: 0.2821\tLR: 0.000337\nTraining Epoch: 16 [46080/50000]\tLoss: 0.2547\tLR: 0.000337\nTraining Epoch: 16 [46208/50000]\tLoss: 0.2939\tLR: 0.000337\nTraining Epoch: 16 [46336/50000]\tLoss: 0.2601\tLR: 0.000337\nTraining Epoch: 16 [46464/50000]\tLoss: 0.3444\tLR: 0.000337\nTraining Epoch: 16 [46592/50000]\tLoss: 0.2485\tLR: 0.000337\nTraining Epoch: 16 [46720/50000]\tLoss: 0.2916\tLR: 0.000337\nTraining Epoch: 16 [46848/50000]\tLoss: 0.3004\tLR: 0.000337\nTraining Epoch: 16 [46976/50000]\tLoss: 0.3442\tLR: 0.000337\nTraining Epoch: 16 [47104/50000]\tLoss: 0.3690\tLR: 0.000337\nTraining Epoch: 16 [47232/50000]\tLoss: 0.2971\tLR: 0.000337\nTraining Epoch: 16 [47360/50000]\tLoss: 0.3918\tLR: 0.000337\nTraining Epoch: 16 [47488/50000]\tLoss: 0.2811\tLR: 0.000337\nTraining Epoch: 16 [47616/50000]\tLoss: 0.2969\tLR: 0.000337\nTraining Epoch: 16 [47744/50000]\tLoss: 0.2445\tLR: 0.000337\nTraining Epoch: 16 [47872/50000]\tLoss: 0.2531\tLR: 0.000337\nTraining Epoch: 16 [48000/50000]\tLoss: 0.3056\tLR: 0.000337\nTraining Epoch: 16 [48128/50000]\tLoss: 0.2977\tLR: 0.000337\nTraining Epoch: 16 [48256/50000]\tLoss: 0.2345\tLR: 0.000337\nTraining Epoch: 16 [48384/50000]\tLoss: 0.2428\tLR: 0.000337\nTraining Epoch: 16 [48512/50000]\tLoss: 0.3136\tLR: 0.000337\nTraining Epoch: 16 [48640/50000]\tLoss: 0.2132\tLR: 0.000337\nTraining Epoch: 16 [48768/50000]\tLoss: 0.3247\tLR: 0.000337\nTraining Epoch: 16 [48896/50000]\tLoss: 0.3527\tLR: 0.000337\nTraining Epoch: 16 [49024/50000]\tLoss: 0.2312\tLR: 0.000337\nTraining Epoch: 16 [49152/50000]\tLoss: 0.3019\tLR: 0.000337\nTraining Epoch: 16 [49280/50000]\tLoss: 0.3190\tLR: 0.000337\nTraining Epoch: 16 [49408/50000]\tLoss: 0.3153\tLR: 0.000337\nTraining Epoch: 16 [49536/50000]\tLoss: 0.3937\tLR: 0.000337\nTraining Epoch: 16 [49664/50000]\tLoss: 0.3906\tLR: 0.000337\nTraining Epoch: 16 [49792/50000]\tLoss: 0.2328\tLR: 0.000337\nTraining Epoch: 16 [49920/50000]\tLoss: 0.2096\tLR: 0.000337\nTraining Epoch: 16 [50000/50000]\tLoss: 0.2691\tLR: 0.000337\nTest set: Average loss: 0.0026, Accuracy: 0.8918\n\nTraining Epoch: 17 [128/50000]\tLoss: 0.2544\tLR: 0.000337\nTraining Epoch: 17 [256/50000]\tLoss: 0.1862\tLR: 0.000337\nTraining Epoch: 17 [384/50000]\tLoss: 0.3612\tLR: 0.000337\nTraining Epoch: 17 [512/50000]\tLoss: 0.2894\tLR: 0.000337\nTraining Epoch: 17 [640/50000]\tLoss: 0.2149\tLR: 0.000337\nTraining Epoch: 17 [768/50000]\tLoss: 0.2006\tLR: 0.000337\nTraining Epoch: 17 [896/50000]\tLoss: 0.2824\tLR: 0.000337\nTraining Epoch: 17 [1024/50000]\tLoss: 0.2396\tLR: 0.000337\nTraining Epoch: 17 [1152/50000]\tLoss: 0.3743\tLR: 0.000337\nTraining Epoch: 17 [1280/50000]\tLoss: 0.3976\tLR: 0.000337\nTraining Epoch: 17 [1408/50000]\tLoss: 0.2162\tLR: 0.000337\nTraining Epoch: 17 [1536/50000]\tLoss: 0.2268\tLR: 0.000337\nTraining Epoch: 17 [1664/50000]\tLoss: 0.3482\tLR: 0.000337\nTraining Epoch: 17 [1792/50000]\tLoss: 0.2290\tLR: 0.000337\nTraining Epoch: 17 [1920/50000]\tLoss: 0.2990\tLR: 0.000337\nTraining Epoch: 17 [2048/50000]\tLoss: 0.2505\tLR: 0.000337\nTraining Epoch: 17 [2176/50000]\tLoss: 0.3508\tLR: 0.000337\nTraining Epoch: 17 [2304/50000]\tLoss: 0.2424\tLR: 0.000337\nTraining Epoch: 17 [2432/50000]\tLoss: 0.2772\tLR: 0.000337\nTraining Epoch: 17 [2560/50000]\tLoss: 0.1778\tLR: 0.000337\nTraining Epoch: 17 [2688/50000]\tLoss: 0.2108\tLR: 0.000337\nTraining Epoch: 17 [2816/50000]\tLoss: 0.2945\tLR: 0.000337\nTraining Epoch: 17 [2944/50000]\tLoss: 0.2560\tLR: 0.000337\nTraining Epoch: 17 [3072/50000]\tLoss: 0.2194\tLR: 0.000337\nTraining Epoch: 17 [3200/50000]\tLoss: 0.3206\tLR: 0.000337\nTraining Epoch: 17 [3328/50000]\tLoss: 0.5239\tLR: 0.000337\nTraining Epoch: 17 [3456/50000]\tLoss: 0.3331\tLR: 0.000337\nTraining Epoch: 17 [3584/50000]\tLoss: 0.1902\tLR: 0.000337\nTraining Epoch: 17 [3712/50000]\tLoss: 0.1896\tLR: 0.000337\nTraining Epoch: 17 [3840/50000]\tLoss: 0.2493\tLR: 0.000337\nTraining Epoch: 17 [3968/50000]\tLoss: 0.2578\tLR: 0.000337\nTraining Epoch: 17 [4096/50000]\tLoss: 0.3381\tLR: 0.000337\nTraining Epoch: 17 [4224/50000]\tLoss: 0.2350\tLR: 0.000337\nTraining Epoch: 17 [4352/50000]\tLoss: 0.2927\tLR: 0.000337\nTraining Epoch: 17 [4480/50000]\tLoss: 0.3150\tLR: 0.000337\nTraining Epoch: 17 [4608/50000]\tLoss: 0.3596\tLR: 0.000337\nTraining Epoch: 17 [4736/50000]\tLoss: 0.2691\tLR: 0.000337\nTraining Epoch: 17 [4864/50000]\tLoss: 0.3280\tLR: 0.000337\nTraining Epoch: 17 [4992/50000]\tLoss: 0.3277\tLR: 0.000337\nTraining Epoch: 17 [5120/50000]\tLoss: 0.2616\tLR: 0.000337\nTraining Epoch: 17 [5248/50000]\tLoss: 0.2653\tLR: 0.000337\nTraining Epoch: 17 [5376/50000]\tLoss: 0.3600\tLR: 0.000337\nTraining Epoch: 17 [5504/50000]\tLoss: 0.2798\tLR: 0.000337\nTraining Epoch: 17 [5632/50000]\tLoss: 0.2294\tLR: 0.000337\nTraining Epoch: 17 [5760/50000]\tLoss: 0.2199\tLR: 0.000337\nTraining Epoch: 17 [5888/50000]\tLoss: 0.2027\tLR: 0.000337\nTraining Epoch: 17 [6016/50000]\tLoss: 0.3027\tLR: 0.000337\nTraining Epoch: 17 [6144/50000]\tLoss: 0.3421\tLR: 0.000337\nTraining Epoch: 17 [6272/50000]\tLoss: 0.2566\tLR: 0.000337\nTraining Epoch: 17 [6400/50000]\tLoss: 0.2609\tLR: 0.000337\nTraining Epoch: 17 [6528/50000]\tLoss: 0.2529\tLR: 0.000337\nTraining Epoch: 17 [6656/50000]\tLoss: 0.3097\tLR: 0.000337\nTraining Epoch: 17 [6784/50000]\tLoss: 0.2283\tLR: 0.000337\nTraining Epoch: 17 [6912/50000]\tLoss: 0.3054\tLR: 0.000337\nTraining Epoch: 17 [7040/50000]\tLoss: 0.4056\tLR: 0.000337\nTraining Epoch: 17 [7168/50000]\tLoss: 0.2279\tLR: 0.000337\nTraining Epoch: 17 [7296/50000]\tLoss: 0.3300\tLR: 0.000337\nTraining Epoch: 17 [7424/50000]\tLoss: 0.3313\tLR: 0.000337\nTraining Epoch: 17 [7552/50000]\tLoss: 0.2880\tLR: 0.000337\nTraining Epoch: 17 [7680/50000]\tLoss: 0.2362\tLR: 0.000337\nTraining Epoch: 17 [7808/50000]\tLoss: 0.2987\tLR: 0.000337\nTraining Epoch: 17 [7936/50000]\tLoss: 0.2871\tLR: 0.000337\nTraining Epoch: 17 [8064/50000]\tLoss: 0.3336\tLR: 0.000337\nTraining Epoch: 17 [8192/50000]\tLoss: 0.2694\tLR: 0.000337\nTraining Epoch: 17 [8320/50000]\tLoss: 0.2892\tLR: 0.000337\nTraining Epoch: 17 [8448/50000]\tLoss: 0.3036\tLR: 0.000337\nTraining Epoch: 17 [8576/50000]\tLoss: 0.2396\tLR: 0.000337\nTraining Epoch: 17 [8704/50000]\tLoss: 0.3875\tLR: 0.000337\nTraining Epoch: 17 [8832/50000]\tLoss: 0.2905\tLR: 0.000337\nTraining Epoch: 17 [8960/50000]\tLoss: 0.2516\tLR: 0.000337\nTraining Epoch: 17 [9088/50000]\tLoss: 0.2905\tLR: 0.000337\nTraining Epoch: 17 [9216/50000]\tLoss: 0.3333\tLR: 0.000337\nTraining Epoch: 17 [9344/50000]\tLoss: 0.3560\tLR: 0.000337\nTraining Epoch: 17 [9472/50000]\tLoss: 0.1887\tLR: 0.000337\nTraining Epoch: 17 [9600/50000]\tLoss: 0.2741\tLR: 0.000337\nTraining Epoch: 17 [9728/50000]\tLoss: 0.2914\tLR: 0.000337\nTraining Epoch: 17 [9856/50000]\tLoss: 0.3178\tLR: 0.000337\nTraining Epoch: 17 [9984/50000]\tLoss: 0.2117\tLR: 0.000337\nTraining Epoch: 17 [10112/50000]\tLoss: 0.3728\tLR: 0.000337\nTraining Epoch: 17 [10240/50000]\tLoss: 0.3129\tLR: 0.000337\nTraining Epoch: 17 [10368/50000]\tLoss: 0.4017\tLR: 0.000337\nTraining Epoch: 17 [10496/50000]\tLoss: 0.3267\tLR: 0.000337\nTraining Epoch: 17 [10624/50000]\tLoss: 0.3374\tLR: 0.000337\nTraining Epoch: 17 [10752/50000]\tLoss: 0.3236\tLR: 0.000337\nTraining Epoch: 17 [10880/50000]\tLoss: 0.1822\tLR: 0.000337\nTraining Epoch: 17 [11008/50000]\tLoss: 0.2148\tLR: 0.000337\nTraining Epoch: 17 [11136/50000]\tLoss: 0.2777\tLR: 0.000337\nTraining Epoch: 17 [11264/50000]\tLoss: 0.2599\tLR: 0.000337\nTraining Epoch: 17 [11392/50000]\tLoss: 0.2746\tLR: 0.000337\nTraining Epoch: 17 [11520/50000]\tLoss: 0.2861\tLR: 0.000337\nTraining Epoch: 17 [11648/50000]\tLoss: 0.2785\tLR: 0.000337\nTraining Epoch: 17 [11776/50000]\tLoss: 0.3387\tLR: 0.000337\nTraining Epoch: 17 [11904/50000]\tLoss: 0.3089\tLR: 0.000337\nTraining Epoch: 17 [12032/50000]\tLoss: 0.2484\tLR: 0.000337\nTraining Epoch: 17 [12160/50000]\tLoss: 0.2611\tLR: 0.000337\nTraining Epoch: 17 [12288/50000]\tLoss: 0.2738\tLR: 0.000337\nTraining Epoch: 17 [12416/50000]\tLoss: 0.2495\tLR: 0.000337\nTraining Epoch: 17 [12544/50000]\tLoss: 0.2401\tLR: 0.000337\nTraining Epoch: 17 [12672/50000]\tLoss: 0.3264\tLR: 0.000337\nTraining Epoch: 17 [12800/50000]\tLoss: 0.2613\tLR: 0.000337\nTraining Epoch: 17 [12928/50000]\tLoss: 0.2720\tLR: 0.000337\nTraining Epoch: 17 [13056/50000]\tLoss: 0.2503\tLR: 0.000337\nTraining Epoch: 17 [13184/50000]\tLoss: 0.3034\tLR: 0.000337\nTraining Epoch: 17 [13312/50000]\tLoss: 0.2223\tLR: 0.000337\nTraining Epoch: 17 [13440/50000]\tLoss: 0.3457\tLR: 0.000337\nTraining Epoch: 17 [13568/50000]\tLoss: 0.3731\tLR: 0.000337\nTraining Epoch: 17 [13696/50000]\tLoss: 0.2241\tLR: 0.000337\nTraining Epoch: 17 [13824/50000]\tLoss: 0.2738\tLR: 0.000337\nTraining Epoch: 17 [13952/50000]\tLoss: 0.2303\tLR: 0.000337\nTraining Epoch: 17 [14080/50000]\tLoss: 0.2193\tLR: 0.000337\nTraining Epoch: 17 [14208/50000]\tLoss: 0.2846\tLR: 0.000337\nTraining Epoch: 17 [14336/50000]\tLoss: 0.2407\tLR: 0.000337\nTraining Epoch: 17 [14464/50000]\tLoss: 0.2764\tLR: 0.000337\nTraining Epoch: 17 [14592/50000]\tLoss: 0.2133\tLR: 0.000337\nTraining Epoch: 17 [14720/50000]\tLoss: 0.2795\tLR: 0.000337\nTraining Epoch: 17 [14848/50000]\tLoss: 0.2452\tLR: 0.000337\nTraining Epoch: 17 [14976/50000]\tLoss: 0.2872\tLR: 0.000337\nTraining Epoch: 17 [15104/50000]\tLoss: 0.2113\tLR: 0.000337\nTraining Epoch: 17 [15232/50000]\tLoss: 0.4097\tLR: 0.000337\nTraining Epoch: 17 [15360/50000]\tLoss: 0.3670\tLR: 0.000337\nTraining Epoch: 17 [15488/50000]\tLoss: 0.2556\tLR: 0.000337\nTraining Epoch: 17 [15616/50000]\tLoss: 0.3302\tLR: 0.000337\nTraining Epoch: 17 [15744/50000]\tLoss: 0.2445\tLR: 0.000337\nTraining Epoch: 17 [15872/50000]\tLoss: 0.3461\tLR: 0.000337\nTraining Epoch: 17 [16000/50000]\tLoss: 0.3754\tLR: 0.000337\nTraining Epoch: 17 [16128/50000]\tLoss: 0.1598\tLR: 0.000337\nTraining Epoch: 17 [16256/50000]\tLoss: 0.2843\tLR: 0.000337\nTraining Epoch: 17 [16384/50000]\tLoss: 0.3405\tLR: 0.000337\nTraining Epoch: 17 [16512/50000]\tLoss: 0.3137\tLR: 0.000337\nTraining Epoch: 17 [16640/50000]\tLoss: 0.2086\tLR: 0.000337\nTraining Epoch: 17 [16768/50000]\tLoss: 0.3788\tLR: 0.000337\nTraining Epoch: 17 [16896/50000]\tLoss: 0.2864\tLR: 0.000337\nTraining Epoch: 17 [17024/50000]\tLoss: 0.2318\tLR: 0.000337\nTraining Epoch: 17 [17152/50000]\tLoss: 0.3243\tLR: 0.000337\nTraining Epoch: 17 [17280/50000]\tLoss: 0.2837\tLR: 0.000337\nTraining Epoch: 17 [17408/50000]\tLoss: 0.2396\tLR: 0.000337\nTraining Epoch: 17 [17536/50000]\tLoss: 0.2573\tLR: 0.000337\nTraining Epoch: 17 [17664/50000]\tLoss: 0.3398\tLR: 0.000337\nTraining Epoch: 17 [17792/50000]\tLoss: 0.2048\tLR: 0.000337\nTraining Epoch: 17 [17920/50000]\tLoss: 0.2384\tLR: 0.000337\nTraining Epoch: 17 [18048/50000]\tLoss: 0.2912\tLR: 0.000337\nTraining Epoch: 17 [18176/50000]\tLoss: 0.1970\tLR: 0.000337\nTraining Epoch: 17 [18304/50000]\tLoss: 0.4028\tLR: 0.000337\nTraining Epoch: 17 [18432/50000]\tLoss: 0.1961\tLR: 0.000337\nTraining Epoch: 17 [18560/50000]\tLoss: 0.2325\tLR: 0.000337\nTraining Epoch: 17 [18688/50000]\tLoss: 0.3365\tLR: 0.000337\nTraining Epoch: 17 [18816/50000]\tLoss: 0.2570\tLR: 0.000337\nTraining Epoch: 17 [18944/50000]\tLoss: 0.3192\tLR: 0.000337\nTraining Epoch: 17 [19072/50000]\tLoss: 0.1646\tLR: 0.000337\nTraining Epoch: 17 [19200/50000]\tLoss: 0.3089\tLR: 0.000337\nTraining Epoch: 17 [19328/50000]\tLoss: 0.2233\tLR: 0.000337\nTraining Epoch: 17 [19456/50000]\tLoss: 0.3374\tLR: 0.000337\nTraining Epoch: 17 [19584/50000]\tLoss: 0.2250\tLR: 0.000337\nTraining Epoch: 17 [19712/50000]\tLoss: 0.2370\tLR: 0.000337\nTraining Epoch: 17 [19840/50000]\tLoss: 0.2520\tLR: 0.000337\nTraining Epoch: 17 [19968/50000]\tLoss: 0.2220\tLR: 0.000337\nTraining Epoch: 17 [20096/50000]\tLoss: 0.2550\tLR: 0.000337\nTraining Epoch: 17 [20224/50000]\tLoss: 0.2125\tLR: 0.000337\nTraining Epoch: 17 [20352/50000]\tLoss: 0.4245\tLR: 0.000337\nTraining Epoch: 17 [20480/50000]\tLoss: 0.2192\tLR: 0.000337\nTraining Epoch: 17 [20608/50000]\tLoss: 0.3042\tLR: 0.000337\nTraining Epoch: 17 [20736/50000]\tLoss: 0.1774\tLR: 0.000337\nTraining Epoch: 17 [20864/50000]\tLoss: 0.2527\tLR: 0.000337\nTraining Epoch: 17 [20992/50000]\tLoss: 0.1696\tLR: 0.000337\nTraining Epoch: 17 [21120/50000]\tLoss: 0.2435\tLR: 0.000337\nTraining Epoch: 17 [21248/50000]\tLoss: 0.2483\tLR: 0.000337\nTraining Epoch: 17 [21376/50000]\tLoss: 0.2312\tLR: 0.000337\nTraining Epoch: 17 [21504/50000]\tLoss: 0.3242\tLR: 0.000337\nTraining Epoch: 17 [21632/50000]\tLoss: 0.3121\tLR: 0.000337\nTraining Epoch: 17 [21760/50000]\tLoss: 0.3147\tLR: 0.000337\nTraining Epoch: 17 [21888/50000]\tLoss: 0.3180\tLR: 0.000337\nTraining Epoch: 17 [22016/50000]\tLoss: 0.2816\tLR: 0.000337\nTraining Epoch: 17 [22144/50000]\tLoss: 0.2447\tLR: 0.000337\nTraining Epoch: 17 [22272/50000]\tLoss: 0.3172\tLR: 0.000337\nTraining Epoch: 17 [22400/50000]\tLoss: 0.5027\tLR: 0.000337\nTraining Epoch: 17 [22528/50000]\tLoss: 0.3596\tLR: 0.000337\nTraining Epoch: 17 [22656/50000]\tLoss: 0.2531\tLR: 0.000337\nTraining Epoch: 17 [22784/50000]\tLoss: 0.2153\tLR: 0.000337\nTraining Epoch: 17 [22912/50000]\tLoss: 0.2767\tLR: 0.000337\nTraining Epoch: 17 [23040/50000]\tLoss: 0.3138\tLR: 0.000337\nTraining Epoch: 17 [23168/50000]\tLoss: 0.2188\tLR: 0.000337\nTraining Epoch: 17 [23296/50000]\tLoss: 0.2981\tLR: 0.000337\nTraining Epoch: 17 [23424/50000]\tLoss: 0.3330\tLR: 0.000337\nTraining Epoch: 17 [23552/50000]\tLoss: 0.2724\tLR: 0.000337\nTraining Epoch: 17 [23680/50000]\tLoss: 0.2669\tLR: 0.000337\nTraining Epoch: 17 [23808/50000]\tLoss: 0.3269\tLR: 0.000337\nTraining Epoch: 17 [23936/50000]\tLoss: 0.3284\tLR: 0.000337\nTraining Epoch: 17 [24064/50000]\tLoss: 0.3377\tLR: 0.000337\nTraining Epoch: 17 [24192/50000]\tLoss: 0.2070\tLR: 0.000337\nTraining Epoch: 17 [24320/50000]\tLoss: 0.2823\tLR: 0.000337\nTraining Epoch: 17 [24448/50000]\tLoss: 0.2449\tLR: 0.000337\nTraining Epoch: 17 [24576/50000]\tLoss: 0.2180\tLR: 0.000337\nTraining Epoch: 17 [24704/50000]\tLoss: 0.3134\tLR: 0.000337\nTraining Epoch: 17 [24832/50000]\tLoss: 0.2848\tLR: 0.000337\nTraining Epoch: 17 [24960/50000]\tLoss: 0.3759\tLR: 0.000337\nTraining Epoch: 17 [25088/50000]\tLoss: 0.2315\tLR: 0.000337\nTraining Epoch: 17 [25216/50000]\tLoss: 0.2570\tLR: 0.000337\nTraining Epoch: 17 [25344/50000]\tLoss: 0.1685\tLR: 0.000337\nTraining Epoch: 17 [25472/50000]\tLoss: 0.2601\tLR: 0.000337\nTraining Epoch: 17 [25600/50000]\tLoss: 0.2388\tLR: 0.000337\nTraining Epoch: 17 [25728/50000]\tLoss: 0.2840\tLR: 0.000337\nTraining Epoch: 17 [25856/50000]\tLoss: 0.2201\tLR: 0.000337\nTraining Epoch: 17 [25984/50000]\tLoss: 0.3391\tLR: 0.000337\nTraining Epoch: 17 [26112/50000]\tLoss: 0.3404\tLR: 0.000337\nTraining Epoch: 17 [26240/50000]\tLoss: 0.2553\tLR: 0.000337\nTraining Epoch: 17 [26368/50000]\tLoss: 0.3402\tLR: 0.000337\nTraining Epoch: 17 [26496/50000]\tLoss: 0.2212\tLR: 0.000337\nTraining Epoch: 17 [26624/50000]\tLoss: 0.3042\tLR: 0.000337\nTraining Epoch: 17 [26752/50000]\tLoss: 0.3622\tLR: 0.000337\nTraining Epoch: 17 [26880/50000]\tLoss: 0.2444\tLR: 0.000337\nTraining Epoch: 17 [27008/50000]\tLoss: 0.2858\tLR: 0.000337\nTraining Epoch: 17 [27136/50000]\tLoss: 0.2259\tLR: 0.000337\nTraining Epoch: 17 [27264/50000]\tLoss: 0.2991\tLR: 0.000337\nTraining Epoch: 17 [27392/50000]\tLoss: 0.2859\tLR: 0.000337\nTraining Epoch: 17 [27520/50000]\tLoss: 0.1942\tLR: 0.000337\nTraining Epoch: 17 [27648/50000]\tLoss: 0.2846\tLR: 0.000337\nTraining Epoch: 17 [27776/50000]\tLoss: 0.1661\tLR: 0.000337\nTraining Epoch: 17 [27904/50000]\tLoss: 0.3525\tLR: 0.000337\nTraining Epoch: 17 [28032/50000]\tLoss: 0.3240\tLR: 0.000337\nTraining Epoch: 17 [28160/50000]\tLoss: 0.2050\tLR: 0.000337\nTraining Epoch: 17 [28288/50000]\tLoss: 0.2825\tLR: 0.000337\nTraining Epoch: 17 [28416/50000]\tLoss: 0.2752\tLR: 0.000337\nTraining Epoch: 17 [28544/50000]\tLoss: 0.2184\tLR: 0.000337\nTraining Epoch: 17 [28672/50000]\tLoss: 0.3244\tLR: 0.000337\nTraining Epoch: 17 [28800/50000]\tLoss: 0.3076\tLR: 0.000337\nTraining Epoch: 17 [28928/50000]\tLoss: 0.3545\tLR: 0.000337\nTraining Epoch: 17 [29056/50000]\tLoss: 0.2053\tLR: 0.000337\nTraining Epoch: 17 [29184/50000]\tLoss: 0.3852\tLR: 0.000337\nTraining Epoch: 17 [29312/50000]\tLoss: 0.2907\tLR: 0.000337\nTraining Epoch: 17 [29440/50000]\tLoss: 0.2172\tLR: 0.000337\nTraining Epoch: 17 [29568/50000]\tLoss: 0.2798\tLR: 0.000337\nTraining Epoch: 17 [29696/50000]\tLoss: 0.2257\tLR: 0.000337\nTraining Epoch: 17 [29824/50000]\tLoss: 0.2088\tLR: 0.000337\nTraining Epoch: 17 [29952/50000]\tLoss: 0.2617\tLR: 0.000337\nTraining Epoch: 17 [30080/50000]\tLoss: 0.1969\tLR: 0.000337\nTraining Epoch: 17 [30208/50000]\tLoss: 0.2882\tLR: 0.000337\nTraining Epoch: 17 [30336/50000]\tLoss: 0.3437\tLR: 0.000337\nTraining Epoch: 17 [30464/50000]\tLoss: 0.2037\tLR: 0.000337\nTraining Epoch: 17 [30592/50000]\tLoss: 0.3090\tLR: 0.000337\nTraining Epoch: 17 [30720/50000]\tLoss: 0.2383\tLR: 0.000337\nTraining Epoch: 17 [30848/50000]\tLoss: 0.3267\tLR: 0.000337\nTraining Epoch: 17 [30976/50000]\tLoss: 0.3467\tLR: 0.000337\nTraining Epoch: 17 [31104/50000]\tLoss: 0.3371\tLR: 0.000337\nTraining Epoch: 17 [31232/50000]\tLoss: 0.1691\tLR: 0.000337\nTraining Epoch: 17 [31360/50000]\tLoss: 0.3023\tLR: 0.000337\nTraining Epoch: 17 [31488/50000]\tLoss: 0.3148\tLR: 0.000337\nTraining Epoch: 17 [31616/50000]\tLoss: 0.3421\tLR: 0.000337\nTraining Epoch: 17 [31744/50000]\tLoss: 0.2138\tLR: 0.000337\nTraining Epoch: 17 [31872/50000]\tLoss: 0.1695\tLR: 0.000337\nTraining Epoch: 17 [32000/50000]\tLoss: 0.1952\tLR: 0.000337\nTraining Epoch: 17 [32128/50000]\tLoss: 0.2570\tLR: 0.000337\nTraining Epoch: 17 [32256/50000]\tLoss: 0.2741\tLR: 0.000337\nTraining Epoch: 17 [32384/50000]\tLoss: 0.1802\tLR: 0.000337\nTraining Epoch: 17 [32512/50000]\tLoss: 0.2883\tLR: 0.000337\nTraining Epoch: 17 [32640/50000]\tLoss: 0.1744\tLR: 0.000337\nTraining Epoch: 17 [32768/50000]\tLoss: 0.1876\tLR: 0.000337\nTraining Epoch: 17 [32896/50000]\tLoss: 0.1836\tLR: 0.000337\nTraining Epoch: 17 [33024/50000]\tLoss: 0.2507\tLR: 0.000337\nTraining Epoch: 17 [33152/50000]\tLoss: 0.2019\tLR: 0.000337\nTraining Epoch: 17 [33280/50000]\tLoss: 0.2457\tLR: 0.000337\nTraining Epoch: 17 [33408/50000]\tLoss: 0.1882\tLR: 0.000337\nTraining Epoch: 17 [33536/50000]\tLoss: 0.3136\tLR: 0.000337\nTraining Epoch: 17 [33664/50000]\tLoss: 0.2832\tLR: 0.000337\nTraining Epoch: 17 [33792/50000]\tLoss: 0.2858\tLR: 0.000337\nTraining Epoch: 17 [33920/50000]\tLoss: 0.2954\tLR: 0.000337\nTraining Epoch: 17 [34048/50000]\tLoss: 0.3299\tLR: 0.000337\nTraining Epoch: 17 [34176/50000]\tLoss: 0.2199\tLR: 0.000337\nTraining Epoch: 17 [34304/50000]\tLoss: 0.2731\tLR: 0.000337\nTraining Epoch: 17 [34432/50000]\tLoss: 0.3697\tLR: 0.000337\nTraining Epoch: 17 [34560/50000]\tLoss: 0.2625\tLR: 0.000337\nTraining Epoch: 17 [34688/50000]\tLoss: 0.3680\tLR: 0.000337\nTraining Epoch: 17 [34816/50000]\tLoss: 0.3078\tLR: 0.000337\nTraining Epoch: 17 [34944/50000]\tLoss: 0.2893\tLR: 0.000337\nTraining Epoch: 17 [35072/50000]\tLoss: 0.2455\tLR: 0.000337\nTraining Epoch: 17 [35200/50000]\tLoss: 0.2211\tLR: 0.000337\nTraining Epoch: 17 [35328/50000]\tLoss: 0.1804\tLR: 0.000337\nTraining Epoch: 17 [35456/50000]\tLoss: 0.3572\tLR: 0.000337\nTraining Epoch: 17 [35584/50000]\tLoss: 0.2974\tLR: 0.000337\nTraining Epoch: 17 [35712/50000]\tLoss: 0.3287\tLR: 0.000337\nTraining Epoch: 17 [35840/50000]\tLoss: 0.2462\tLR: 0.000337\nTraining Epoch: 17 [35968/50000]\tLoss: 0.2311\tLR: 0.000337\nTraining Epoch: 17 [36096/50000]\tLoss: 0.2545\tLR: 0.000337\nTraining Epoch: 17 [36224/50000]\tLoss: 0.2774\tLR: 0.000337\nTraining Epoch: 17 [36352/50000]\tLoss: 0.2399\tLR: 0.000337\nTraining Epoch: 17 [36480/50000]\tLoss: 0.3541\tLR: 0.000337\nTraining Epoch: 17 [36608/50000]\tLoss: 0.2307\tLR: 0.000337\nTraining Epoch: 17 [36736/50000]\tLoss: 0.2665\tLR: 0.000337\nTraining Epoch: 17 [36864/50000]\tLoss: 0.2510\tLR: 0.000337\nTraining Epoch: 17 [36992/50000]\tLoss: 0.2561\tLR: 0.000337\nTraining Epoch: 17 [37120/50000]\tLoss: 0.1913\tLR: 0.000337\nTraining Epoch: 17 [37248/50000]\tLoss: 0.3861\tLR: 0.000337\nTraining Epoch: 17 [37376/50000]\tLoss: 0.2894\tLR: 0.000337\nTraining Epoch: 17 [37504/50000]\tLoss: 0.3372\tLR: 0.000337\nTraining Epoch: 17 [37632/50000]\tLoss: 0.1691\tLR: 0.000337\nTraining Epoch: 17 [37760/50000]\tLoss: 0.1928\tLR: 0.000337\nTraining Epoch: 17 [37888/50000]\tLoss: 0.3125\tLR: 0.000337\nTraining Epoch: 17 [38016/50000]\tLoss: 0.3447\tLR: 0.000337\nTraining Epoch: 17 [38144/50000]\tLoss: 0.3395\tLR: 0.000337\nTraining Epoch: 17 [38272/50000]\tLoss: 0.3563\tLR: 0.000337\nTraining Epoch: 17 [38400/50000]\tLoss: 0.2455\tLR: 0.000337\nTraining Epoch: 17 [38528/50000]\tLoss: 0.3121\tLR: 0.000337\nTraining Epoch: 17 [38656/50000]\tLoss: 0.2992\tLR: 0.000337\nTraining Epoch: 17 [38784/50000]\tLoss: 0.3004\tLR: 0.000337\nTraining Epoch: 17 [38912/50000]\tLoss: 0.2766\tLR: 0.000337\nTraining Epoch: 17 [39040/50000]\tLoss: 0.2535\tLR: 0.000337\nTraining Epoch: 17 [39168/50000]\tLoss: 0.2150\tLR: 0.000337\nTraining Epoch: 17 [39296/50000]\tLoss: 0.3203\tLR: 0.000337\nTraining Epoch: 17 [39424/50000]\tLoss: 0.2651\tLR: 0.000337\nTraining Epoch: 17 [39552/50000]\tLoss: 0.2409\tLR: 0.000337\nTraining Epoch: 17 [39680/50000]\tLoss: 0.2622\tLR: 0.000337\nTraining Epoch: 17 [39808/50000]\tLoss: 0.2834\tLR: 0.000337\nTraining Epoch: 17 [39936/50000]\tLoss: 0.2733\tLR: 0.000337\nTraining Epoch: 17 [40064/50000]\tLoss: 0.3203\tLR: 0.000337\nTraining Epoch: 17 [40192/50000]\tLoss: 0.2709\tLR: 0.000337\nTraining Epoch: 17 [40320/50000]\tLoss: 0.3072\tLR: 0.000337\nTraining Epoch: 17 [40448/50000]\tLoss: 0.3041\tLR: 0.000337\nTraining Epoch: 17 [40576/50000]\tLoss: 0.2247\tLR: 0.000337\nTraining Epoch: 17 [40704/50000]\tLoss: 0.1972\tLR: 0.000337\nTraining Epoch: 17 [40832/50000]\tLoss: 0.2155\tLR: 0.000337\nTraining Epoch: 17 [40960/50000]\tLoss: 0.2663\tLR: 0.000337\nTraining Epoch: 17 [41088/50000]\tLoss: 0.2877\tLR: 0.000337\nTraining Epoch: 17 [41216/50000]\tLoss: 0.2697\tLR: 0.000337\nTraining Epoch: 17 [41344/50000]\tLoss: 0.3187\tLR: 0.000337\nTraining Epoch: 17 [41472/50000]\tLoss: 0.4003\tLR: 0.000337\nTraining Epoch: 17 [41600/50000]\tLoss: 0.4146\tLR: 0.000337\nTraining Epoch: 17 [41728/50000]\tLoss: 0.2184\tLR: 0.000337\nTraining Epoch: 17 [41856/50000]\tLoss: 0.3236\tLR: 0.000337\nTraining Epoch: 17 [41984/50000]\tLoss: 0.2533\tLR: 0.000337\nTraining Epoch: 17 [42112/50000]\tLoss: 0.4610\tLR: 0.000337\nTraining Epoch: 17 [42240/50000]\tLoss: 0.2481\tLR: 0.000337\nTraining Epoch: 17 [42368/50000]\tLoss: 0.2535\tLR: 0.000337\nTraining Epoch: 17 [42496/50000]\tLoss: 0.2868\tLR: 0.000337\nTraining Epoch: 17 [42624/50000]\tLoss: 0.2705\tLR: 0.000337\nTraining Epoch: 17 [42752/50000]\tLoss: 0.1849\tLR: 0.000337\nTraining Epoch: 17 [42880/50000]\tLoss: 0.2643\tLR: 0.000337\nTraining Epoch: 17 [43008/50000]\tLoss: 0.2868\tLR: 0.000337\nTraining Epoch: 17 [43136/50000]\tLoss: 0.2479\tLR: 0.000337\nTraining Epoch: 17 [43264/50000]\tLoss: 0.2111\tLR: 0.000337\nTraining Epoch: 17 [43392/50000]\tLoss: 0.2748\tLR: 0.000337\nTraining Epoch: 17 [43520/50000]\tLoss: 0.2891\tLR: 0.000337\nTraining Epoch: 17 [43648/50000]\tLoss: 0.3366\tLR: 0.000337\nTraining Epoch: 17 [43776/50000]\tLoss: 0.2496\tLR: 0.000337\nTraining Epoch: 17 [43904/50000]\tLoss: 0.2592\tLR: 0.000337\nTraining Epoch: 17 [44032/50000]\tLoss: 0.2767\tLR: 0.000337\nTraining Epoch: 17 [44160/50000]\tLoss: 0.2826\tLR: 0.000337\nTraining Epoch: 17 [44288/50000]\tLoss: 0.3213\tLR: 0.000337\nTraining Epoch: 17 [44416/50000]\tLoss: 0.2637\tLR: 0.000337\nTraining Epoch: 17 [44544/50000]\tLoss: 0.2457\tLR: 0.000337\nTraining Epoch: 17 [44672/50000]\tLoss: 0.2338\tLR: 0.000337\nTraining Epoch: 17 [44800/50000]\tLoss: 0.3044\tLR: 0.000337\nTraining Epoch: 17 [44928/50000]\tLoss: 0.3360\tLR: 0.000337\nTraining Epoch: 17 [45056/50000]\tLoss: 0.2680\tLR: 0.000337\nTraining Epoch: 17 [45184/50000]\tLoss: 0.2962\tLR: 0.000337\nTraining Epoch: 17 [45312/50000]\tLoss: 0.3055\tLR: 0.000337\nTraining Epoch: 17 [45440/50000]\tLoss: 0.2561\tLR: 0.000337\nTraining Epoch: 17 [45568/50000]\tLoss: 0.2278\tLR: 0.000337\nTraining Epoch: 17 [45696/50000]\tLoss: 0.2774\tLR: 0.000337\nTraining Epoch: 17 [45824/50000]\tLoss: 0.1941\tLR: 0.000337\nTraining Epoch: 17 [45952/50000]\tLoss: 0.1535\tLR: 0.000337\nTraining Epoch: 17 [46080/50000]\tLoss: 0.2453\tLR: 0.000337\nTraining Epoch: 17 [46208/50000]\tLoss: 0.2367\tLR: 0.000337\nTraining Epoch: 17 [46336/50000]\tLoss: 0.3276\tLR: 0.000337\nTraining Epoch: 17 [46464/50000]\tLoss: 0.2631\tLR: 0.000337\nTraining Epoch: 17 [46592/50000]\tLoss: 0.2510\tLR: 0.000337\nTraining Epoch: 17 [46720/50000]\tLoss: 0.3111\tLR: 0.000337\nTraining Epoch: 17 [46848/50000]\tLoss: 0.3229\tLR: 0.000337\nTraining Epoch: 17 [46976/50000]\tLoss: 0.3099\tLR: 0.000337\nTraining Epoch: 17 [47104/50000]\tLoss: 0.2198\tLR: 0.000337\nTraining Epoch: 17 [47232/50000]\tLoss: 0.3329\tLR: 0.000337\nTraining Epoch: 17 [47360/50000]\tLoss: 0.4009\tLR: 0.000337\nTraining Epoch: 17 [47488/50000]\tLoss: 0.2130\tLR: 0.000337\nTraining Epoch: 17 [47616/50000]\tLoss: 0.3249\tLR: 0.000337\nTraining Epoch: 17 [47744/50000]\tLoss: 0.3624\tLR: 0.000337\nTraining Epoch: 17 [47872/50000]\tLoss: 0.3204\tLR: 0.000337\nTraining Epoch: 17 [48000/50000]\tLoss: 0.2429\tLR: 0.000337\nTraining Epoch: 17 [48128/50000]\tLoss: 0.3589\tLR: 0.000337\nTraining Epoch: 17 [48256/50000]\tLoss: 0.2100\tLR: 0.000337\nTraining Epoch: 17 [48384/50000]\tLoss: 0.2398\tLR: 0.000337\nTraining Epoch: 17 [48512/50000]\tLoss: 0.2276\tLR: 0.000337\nTraining Epoch: 17 [48640/50000]\tLoss: 0.2240\tLR: 0.000337\nTraining Epoch: 17 [48768/50000]\tLoss: 0.1748\tLR: 0.000337\nTraining Epoch: 17 [48896/50000]\tLoss: 0.2811\tLR: 0.000337\nTraining Epoch: 17 [49024/50000]\tLoss: 0.3147\tLR: 0.000337\nTraining Epoch: 17 [49152/50000]\tLoss: 0.1941\tLR: 0.000337\nTraining Epoch: 17 [49280/50000]\tLoss: 0.2039\tLR: 0.000337\nTraining Epoch: 17 [49408/50000]\tLoss: 0.2471\tLR: 0.000337\nTraining Epoch: 17 [49536/50000]\tLoss: 0.2131\tLR: 0.000337\nTraining Epoch: 17 [49664/50000]\tLoss: 0.1838\tLR: 0.000337\nTraining Epoch: 17 [49792/50000]\tLoss: 0.3514\tLR: 0.000337\nTraining Epoch: 17 [49920/50000]\tLoss: 0.2206\tLR: 0.000337\nTraining Epoch: 17 [50000/50000]\tLoss: 0.2725\tLR: 0.000337\nTest set: Average loss: 0.0025, Accuracy: 0.8917\n\nTraining Epoch: 18 [128/50000]\tLoss: 0.2560\tLR: 0.000337\nTraining Epoch: 18 [256/50000]\tLoss: 0.2824\tLR: 0.000337\nTraining Epoch: 18 [384/50000]\tLoss: 0.3053\tLR: 0.000337\nTraining Epoch: 18 [512/50000]\tLoss: 0.1783\tLR: 0.000337\nTraining Epoch: 18 [640/50000]\tLoss: 0.1797\tLR: 0.000337\nTraining Epoch: 18 [768/50000]\tLoss: 0.2431\tLR: 0.000337\nTraining Epoch: 18 [896/50000]\tLoss: 0.2170\tLR: 0.000337\nTraining Epoch: 18 [1024/50000]\tLoss: 0.3650\tLR: 0.000337\nTraining Epoch: 18 [1152/50000]\tLoss: 0.3939\tLR: 0.000337\nTraining Epoch: 18 [1280/50000]\tLoss: 0.2455\tLR: 0.000337\nTraining Epoch: 18 [1408/50000]\tLoss: 0.2713\tLR: 0.000337\nTraining Epoch: 18 [1536/50000]\tLoss: 0.2411\tLR: 0.000337\nTraining Epoch: 18 [1664/50000]\tLoss: 0.2982\tLR: 0.000337\nTraining Epoch: 18 [1792/50000]\tLoss: 0.1871\tLR: 0.000337\nTraining Epoch: 18 [1920/50000]\tLoss: 0.2986\tLR: 0.000337\nTraining Epoch: 18 [2048/50000]\tLoss: 0.2189\tLR: 0.000337\nTraining Epoch: 18 [2176/50000]\tLoss: 0.2655\tLR: 0.000337\nTraining Epoch: 18 [2304/50000]\tLoss: 0.3447\tLR: 0.000337\nTraining Epoch: 18 [2432/50000]\tLoss: 0.4347\tLR: 0.000337\nTraining Epoch: 18 [2560/50000]\tLoss: 0.2462\tLR: 0.000337\nTraining Epoch: 18 [2688/50000]\tLoss: 0.2623\tLR: 0.000337\nTraining Epoch: 18 [2816/50000]\tLoss: 0.2799\tLR: 0.000337\nTraining Epoch: 18 [2944/50000]\tLoss: 0.1577\tLR: 0.000337\nTraining Epoch: 18 [3072/50000]\tLoss: 0.3342\tLR: 0.000337\nTraining Epoch: 18 [3200/50000]\tLoss: 0.2719\tLR: 0.000337\nTraining Epoch: 18 [3328/50000]\tLoss: 0.3394\tLR: 0.000337\nTraining Epoch: 18 [3456/50000]\tLoss: 0.3148\tLR: 0.000337\nTraining Epoch: 18 [3584/50000]\tLoss: 0.2436\tLR: 0.000337\nTraining Epoch: 18 [3712/50000]\tLoss: 0.2070\tLR: 0.000337\nTraining Epoch: 18 [3840/50000]\tLoss: 0.1962\tLR: 0.000337\nTraining Epoch: 18 [3968/50000]\tLoss: 0.3713\tLR: 0.000337\nTraining Epoch: 18 [4096/50000]\tLoss: 0.2154\tLR: 0.000337\nTraining Epoch: 18 [4224/50000]\tLoss: 0.2670\tLR: 0.000337\nTraining Epoch: 18 [4352/50000]\tLoss: 0.2375\tLR: 0.000337\nTraining Epoch: 18 [4480/50000]\tLoss: 0.3433\tLR: 0.000337\nTraining Epoch: 18 [4608/50000]\tLoss: 0.2776\tLR: 0.000337\nTraining Epoch: 18 [4736/50000]\tLoss: 0.3038\tLR: 0.000337\nTraining Epoch: 18 [4864/50000]\tLoss: 0.2826\tLR: 0.000337\nTraining Epoch: 18 [4992/50000]\tLoss: 0.2910\tLR: 0.000337\nTraining Epoch: 18 [5120/50000]\tLoss: 0.2836\tLR: 0.000337\nTraining Epoch: 18 [5248/50000]\tLoss: 0.2577\tLR: 0.000337\nTraining Epoch: 18 [5376/50000]\tLoss: 0.3103\tLR: 0.000337\nTraining Epoch: 18 [5504/50000]\tLoss: 0.2607\tLR: 0.000337\nTraining Epoch: 18 [5632/50000]\tLoss: 0.2647\tLR: 0.000337\nTraining Epoch: 18 [5760/50000]\tLoss: 0.2245\tLR: 0.000337\nTraining Epoch: 18 [5888/50000]\tLoss: 0.2880\tLR: 0.000337\nTraining Epoch: 18 [6016/50000]\tLoss: 0.2023\tLR: 0.000337\nTraining Epoch: 18 [6144/50000]\tLoss: 0.2227\tLR: 0.000337\nTraining Epoch: 18 [6272/50000]\tLoss: 0.1921\tLR: 0.000337\nTraining Epoch: 18 [6400/50000]\tLoss: 0.2797\tLR: 0.000337\nTraining Epoch: 18 [6528/50000]\tLoss: 0.2528\tLR: 0.000337\nTraining Epoch: 18 [6656/50000]\tLoss: 0.2984\tLR: 0.000337\nTraining Epoch: 18 [6784/50000]\tLoss: 0.3528\tLR: 0.000337\nTraining Epoch: 18 [6912/50000]\tLoss: 0.3903\tLR: 0.000337\nTraining Epoch: 18 [7040/50000]\tLoss: 0.2411\tLR: 0.000337\nTraining Epoch: 18 [7168/50000]\tLoss: 0.3130\tLR: 0.000337\nTraining Epoch: 18 [7296/50000]\tLoss: 0.2363\tLR: 0.000337\nTraining Epoch: 18 [7424/50000]\tLoss: 0.2834\tLR: 0.000337\nTraining Epoch: 18 [7552/50000]\tLoss: 0.3833\tLR: 0.000337\nTraining Epoch: 18 [7680/50000]\tLoss: 0.3418\tLR: 0.000337\nTraining Epoch: 18 [7808/50000]\tLoss: 0.2779\tLR: 0.000337\nTraining Epoch: 18 [7936/50000]\tLoss: 0.3844\tLR: 0.000337\nTraining Epoch: 18 [8064/50000]\tLoss: 0.3206\tLR: 0.000337\nTraining Epoch: 18 [8192/50000]\tLoss: 0.3164\tLR: 0.000337\nTraining Epoch: 18 [8320/50000]\tLoss: 0.3235\tLR: 0.000337\nTraining Epoch: 18 [8448/50000]\tLoss: 0.3163\tLR: 0.000337\nTraining Epoch: 18 [8576/50000]\tLoss: 0.2943\tLR: 0.000337\nTraining Epoch: 18 [8704/50000]\tLoss: 0.1992\tLR: 0.000337\nTraining Epoch: 18 [8832/50000]\tLoss: 0.2598\tLR: 0.000337\nTraining Epoch: 18 [8960/50000]\tLoss: 0.3900\tLR: 0.000337\nTraining Epoch: 18 [9088/50000]\tLoss: 0.1982\tLR: 0.000337\nTraining Epoch: 18 [9216/50000]\tLoss: 0.2855\tLR: 0.000337\nTraining Epoch: 18 [9344/50000]\tLoss: 0.3289\tLR: 0.000337\nTraining Epoch: 18 [9472/50000]\tLoss: 0.2531\tLR: 0.000337\nTraining Epoch: 18 [9600/50000]\tLoss: 0.1929\tLR: 0.000337\nTraining Epoch: 18 [9728/50000]\tLoss: 0.1961\tLR: 0.000337\nTraining Epoch: 18 [9856/50000]\tLoss: 0.2766\tLR: 0.000337\nTraining Epoch: 18 [9984/50000]\tLoss: 0.3290\tLR: 0.000337\nTraining Epoch: 18 [10112/50000]\tLoss: 0.2812\tLR: 0.000337\nTraining Epoch: 18 [10240/50000]\tLoss: 0.2825\tLR: 0.000337\nTraining Epoch: 18 [10368/50000]\tLoss: 0.2295\tLR: 0.000337\nTraining Epoch: 18 [10496/50000]\tLoss: 0.3370\tLR: 0.000337\nTraining Epoch: 18 [10624/50000]\tLoss: 0.2617\tLR: 0.000337\nTraining Epoch: 18 [10752/50000]\tLoss: 0.1865\tLR: 0.000337\nTraining Epoch: 18 [10880/50000]\tLoss: 0.2624\tLR: 0.000337\nTraining Epoch: 18 [11008/50000]\tLoss: 0.2506\tLR: 0.000337\nTraining Epoch: 18 [11136/50000]\tLoss: 0.2010\tLR: 0.000337\nTraining Epoch: 18 [11264/50000]\tLoss: 0.2572\tLR: 0.000337\nTraining Epoch: 18 [11392/50000]\tLoss: 0.3335\tLR: 0.000337\nTraining Epoch: 18 [11520/50000]\tLoss: 0.2058\tLR: 0.000337\nTraining Epoch: 18 [11648/50000]\tLoss: 0.2248\tLR: 0.000337\nTraining Epoch: 18 [11776/50000]\tLoss: 0.2139\tLR: 0.000337\nTraining Epoch: 18 [11904/50000]\tLoss: 0.2594\tLR: 0.000337\nTraining Epoch: 18 [12032/50000]\tLoss: 0.3577\tLR: 0.000337\nTraining Epoch: 18 [12160/50000]\tLoss: 0.1461\tLR: 0.000337\nTraining Epoch: 18 [12288/50000]\tLoss: 0.2707\tLR: 0.000337\nTraining Epoch: 18 [12416/50000]\tLoss: 0.2928\tLR: 0.000337\nTraining Epoch: 18 [12544/50000]\tLoss: 0.2867\tLR: 0.000337\nTraining Epoch: 18 [12672/50000]\tLoss: 0.3250\tLR: 0.000337\nTraining Epoch: 18 [12800/50000]\tLoss: 0.2771\tLR: 0.000337\nTraining Epoch: 18 [12928/50000]\tLoss: 0.2568\tLR: 0.000337\nTraining Epoch: 18 [13056/50000]\tLoss: 0.2683\tLR: 0.000337\nTraining Epoch: 18 [13184/50000]\tLoss: 0.3953\tLR: 0.000337\nTraining Epoch: 18 [13312/50000]\tLoss: 0.2432\tLR: 0.000337\nTraining Epoch: 18 [13440/50000]\tLoss: 0.2254\tLR: 0.000337\nTraining Epoch: 18 [13568/50000]\tLoss: 0.3994\tLR: 0.000337\nTraining Epoch: 18 [13696/50000]\tLoss: 0.1821\tLR: 0.000337\nTraining Epoch: 18 [13824/50000]\tLoss: 0.2310\tLR: 0.000337\nTraining Epoch: 18 [13952/50000]\tLoss: 0.2216\tLR: 0.000337\nTraining Epoch: 18 [14080/50000]\tLoss: 0.2565\tLR: 0.000337\nTraining Epoch: 18 [14208/50000]\tLoss: 0.3037\tLR: 0.000337\nTraining Epoch: 18 [14336/50000]\tLoss: 0.2706\tLR: 0.000337\nTraining Epoch: 18 [14464/50000]\tLoss: 0.3883\tLR: 0.000337\nTraining Epoch: 18 [14592/50000]\tLoss: 0.3212\tLR: 0.000337\nTraining Epoch: 18 [14720/50000]\tLoss: 0.1585\tLR: 0.000337\nTraining Epoch: 18 [14848/50000]\tLoss: 0.3215\tLR: 0.000337\nTraining Epoch: 18 [14976/50000]\tLoss: 0.2800\tLR: 0.000337\nTraining Epoch: 18 [15104/50000]\tLoss: 0.2707\tLR: 0.000337\nTraining Epoch: 18 [15232/50000]\tLoss: 0.2112\tLR: 0.000337\nTraining Epoch: 18 [15360/50000]\tLoss: 0.2627\tLR: 0.000337\nTraining Epoch: 18 [15488/50000]\tLoss: 0.2342\tLR: 0.000337\nTraining Epoch: 18 [15616/50000]\tLoss: 0.2508\tLR: 0.000337\nTraining Epoch: 18 [15744/50000]\tLoss: 0.2718\tLR: 0.000337\nTraining Epoch: 18 [15872/50000]\tLoss: 0.2838\tLR: 0.000337\nTraining Epoch: 18 [16000/50000]\tLoss: 0.1833\tLR: 0.000337\nTraining Epoch: 18 [16128/50000]\tLoss: 0.2236\tLR: 0.000337\nTraining Epoch: 18 [16256/50000]\tLoss: 0.2764\tLR: 0.000337\nTraining Epoch: 18 [16384/50000]\tLoss: 0.1971\tLR: 0.000337\nTraining Epoch: 18 [16512/50000]\tLoss: 0.2742\tLR: 0.000337\nTraining Epoch: 18 [16640/50000]\tLoss: 0.2529\tLR: 0.000337\nTraining Epoch: 18 [16768/50000]\tLoss: 0.2393\tLR: 0.000337\nTraining Epoch: 18 [16896/50000]\tLoss: 0.3474\tLR: 0.000337\nTraining Epoch: 18 [17024/50000]\tLoss: 0.2964\tLR: 0.000337\nTraining Epoch: 18 [17152/50000]\tLoss: 0.3560\tLR: 0.000337\nTraining Epoch: 18 [17280/50000]\tLoss: 0.2711\tLR: 0.000337\nTraining Epoch: 18 [17408/50000]\tLoss: 0.2569\tLR: 0.000337\nTraining Epoch: 18 [17536/50000]\tLoss: 0.2594\tLR: 0.000337\nTraining Epoch: 18 [17664/50000]\tLoss: 0.2523\tLR: 0.000337\nTraining Epoch: 18 [17792/50000]\tLoss: 0.3261\tLR: 0.000337\nTraining Epoch: 18 [17920/50000]\tLoss: 0.3499\tLR: 0.000337\nTraining Epoch: 18 [18048/50000]\tLoss: 0.2259\tLR: 0.000337\nTraining Epoch: 18 [18176/50000]\tLoss: 0.2578\tLR: 0.000337\nTraining Epoch: 18 [18304/50000]\tLoss: 0.2357\tLR: 0.000337\nTraining Epoch: 18 [18432/50000]\tLoss: 0.2623\tLR: 0.000337\nTraining Epoch: 18 [18560/50000]\tLoss: 0.2204\tLR: 0.000337\nTraining Epoch: 18 [18688/50000]\tLoss: 0.2487\tLR: 0.000337\nTraining Epoch: 18 [18816/50000]\tLoss: 0.3375\tLR: 0.000337\nTraining Epoch: 18 [18944/50000]\tLoss: 0.1992\tLR: 0.000337\nTraining Epoch: 18 [19072/50000]\tLoss: 0.3305\tLR: 0.000337\nTraining Epoch: 18 [19200/50000]\tLoss: 0.3002\tLR: 0.000337\nTraining Epoch: 18 [19328/50000]\tLoss: 0.3258\tLR: 0.000337\nTraining Epoch: 18 [19456/50000]\tLoss: 0.2672\tLR: 0.000337\nTraining Epoch: 18 [19584/50000]\tLoss: 0.1899\tLR: 0.000337\nTraining Epoch: 18 [19712/50000]\tLoss: 0.1867\tLR: 0.000337\nTraining Epoch: 18 [19840/50000]\tLoss: 0.3758\tLR: 0.000337\nTraining Epoch: 18 [19968/50000]\tLoss: 0.1588\tLR: 0.000337\nTraining Epoch: 18 [20096/50000]\tLoss: 0.3232\tLR: 0.000337\nTraining Epoch: 18 [20224/50000]\tLoss: 0.2597\tLR: 0.000337\nTraining Epoch: 18 [20352/50000]\tLoss: 0.2490\tLR: 0.000337\nTraining Epoch: 18 [20480/50000]\tLoss: 0.3727\tLR: 0.000337\nTraining Epoch: 18 [20608/50000]\tLoss: 0.2977\tLR: 0.000337\nTraining Epoch: 18 [20736/50000]\tLoss: 0.1931\tLR: 0.000337\nTraining Epoch: 18 [20864/50000]\tLoss: 0.2751\tLR: 0.000337\nTraining Epoch: 18 [20992/50000]\tLoss: 0.3518\tLR: 0.000337\nTraining Epoch: 18 [21120/50000]\tLoss: 0.2360\tLR: 0.000337\nTraining Epoch: 18 [21248/50000]\tLoss: 0.2519\tLR: 0.000337\nTraining Epoch: 18 [21376/50000]\tLoss: 0.2491\tLR: 0.000337\nTraining Epoch: 18 [21504/50000]\tLoss: 0.2714\tLR: 0.000337\nTraining Epoch: 18 [21632/50000]\tLoss: 0.1930\tLR: 0.000337\nTraining Epoch: 18 [21760/50000]\tLoss: 0.2488\tLR: 0.000337\nTraining Epoch: 18 [21888/50000]\tLoss: 0.2169\tLR: 0.000337\nTraining Epoch: 18 [22016/50000]\tLoss: 0.2878\tLR: 0.000337\nTraining Epoch: 18 [22144/50000]\tLoss: 0.4261\tLR: 0.000337\nTraining Epoch: 18 [22272/50000]\tLoss: 0.2303\tLR: 0.000337\nTraining Epoch: 18 [22400/50000]\tLoss: 0.2264\tLR: 0.000337\nTraining Epoch: 18 [22528/50000]\tLoss: 0.3840\tLR: 0.000337\nTraining Epoch: 18 [22656/50000]\tLoss: 0.3422\tLR: 0.000337\nTraining Epoch: 18 [22784/50000]\tLoss: 0.3434\tLR: 0.000337\nTraining Epoch: 18 [22912/50000]\tLoss: 0.3396\tLR: 0.000337\nTraining Epoch: 18 [23040/50000]\tLoss: 0.3453\tLR: 0.000337\nTraining Epoch: 18 [23168/50000]\tLoss: 0.4226\tLR: 0.000337\nTraining Epoch: 18 [23296/50000]\tLoss: 0.2033\tLR: 0.000337\nTraining Epoch: 18 [23424/50000]\tLoss: 0.3649\tLR: 0.000337\nTraining Epoch: 18 [23552/50000]\tLoss: 0.2296\tLR: 0.000337\nTraining Epoch: 18 [23680/50000]\tLoss: 0.2607\tLR: 0.000337\nTraining Epoch: 18 [23808/50000]\tLoss: 0.2979\tLR: 0.000337\nTraining Epoch: 18 [23936/50000]\tLoss: 0.3018\tLR: 0.000337\nTraining Epoch: 18 [24064/50000]\tLoss: 0.2244\tLR: 0.000337\nTraining Epoch: 18 [24192/50000]\tLoss: 0.1520\tLR: 0.000337\nTraining Epoch: 18 [24320/50000]\tLoss: 0.3200\tLR: 0.000337\nTraining Epoch: 18 [24448/50000]\tLoss: 0.2604\tLR: 0.000337\nTraining Epoch: 18 [24576/50000]\tLoss: 0.2756\tLR: 0.000337\nTraining Epoch: 18 [24704/50000]\tLoss: 0.2982\tLR: 0.000337\nTraining Epoch: 18 [24832/50000]\tLoss: 0.3042\tLR: 0.000337\nTraining Epoch: 18 [24960/50000]\tLoss: 0.2216\tLR: 0.000337\nTraining Epoch: 18 [25088/50000]\tLoss: 0.2204\tLR: 0.000337\nTraining Epoch: 18 [25216/50000]\tLoss: 0.2117\tLR: 0.000337\nTraining Epoch: 18 [25344/50000]\tLoss: 0.2213\tLR: 0.000337\nTraining Epoch: 18 [25472/50000]\tLoss: 0.3415\tLR: 0.000337\nTraining Epoch: 18 [25600/50000]\tLoss: 0.2933\tLR: 0.000337\nTraining Epoch: 18 [25728/50000]\tLoss: 0.2529\tLR: 0.000337\nTraining Epoch: 18 [25856/50000]\tLoss: 0.2548\tLR: 0.000337\nTraining Epoch: 18 [25984/50000]\tLoss: 0.3274\tLR: 0.000337\nTraining Epoch: 18 [26112/50000]\tLoss: 0.2847\tLR: 0.000337\nTraining Epoch: 18 [26240/50000]\tLoss: 0.2085\tLR: 0.000337\nTraining Epoch: 18 [26368/50000]\tLoss: 0.3144\tLR: 0.000337\nTraining Epoch: 18 [26496/50000]\tLoss: 0.1842\tLR: 0.000337\nTraining Epoch: 18 [26624/50000]\tLoss: 0.3611\tLR: 0.000337\nTraining Epoch: 18 [26752/50000]\tLoss: 0.2648\tLR: 0.000337\nTraining Epoch: 18 [26880/50000]\tLoss: 0.2584\tLR: 0.000337\nTraining Epoch: 18 [27008/50000]\tLoss: 0.2220\tLR: 0.000337\nTraining Epoch: 18 [27136/50000]\tLoss: 0.3238\tLR: 0.000337\nTraining Epoch: 18 [27264/50000]\tLoss: 0.2655\tLR: 0.000337\nTraining Epoch: 18 [27392/50000]\tLoss: 0.2062\tLR: 0.000337\nTraining Epoch: 18 [27520/50000]\tLoss: 0.1868\tLR: 0.000337\nTraining Epoch: 18 [27648/50000]\tLoss: 0.2667\tLR: 0.000337\nTraining Epoch: 18 [27776/50000]\tLoss: 0.2650\tLR: 0.000337\nTraining Epoch: 18 [27904/50000]\tLoss: 0.2459\tLR: 0.000337\nTraining Epoch: 18 [28032/50000]\tLoss: 0.2946\tLR: 0.000337\nTraining Epoch: 18 [28160/50000]\tLoss: 0.2600\tLR: 0.000337\nTraining Epoch: 18 [28288/50000]\tLoss: 0.2592\tLR: 0.000337\nTraining Epoch: 18 [28416/50000]\tLoss: 0.2142\tLR: 0.000337\nTraining Epoch: 18 [28544/50000]\tLoss: 0.2870\tLR: 0.000337\nTraining Epoch: 18 [28672/50000]\tLoss: 0.2389\tLR: 0.000337\nTraining Epoch: 18 [28800/50000]\tLoss: 0.2188\tLR: 0.000337\nTraining Epoch: 18 [28928/50000]\tLoss: 0.2993\tLR: 0.000337\nTraining Epoch: 18 [29056/50000]\tLoss: 0.3178\tLR: 0.000337\nTraining Epoch: 18 [29184/50000]\tLoss: 0.2670\tLR: 0.000337\nTraining Epoch: 18 [29312/50000]\tLoss: 0.2133\tLR: 0.000337\nTraining Epoch: 18 [29440/50000]\tLoss: 0.2717\tLR: 0.000337\nTraining Epoch: 18 [29568/50000]\tLoss: 0.3251\tLR: 0.000337\nTraining Epoch: 18 [29696/50000]\tLoss: 0.2227\tLR: 0.000337\nTraining Epoch: 18 [29824/50000]\tLoss: 0.1904\tLR: 0.000337\nTraining Epoch: 18 [29952/50000]\tLoss: 0.3043\tLR: 0.000337\nTraining Epoch: 18 [30080/50000]\tLoss: 0.3141\tLR: 0.000337\nTraining Epoch: 18 [30208/50000]\tLoss: 0.3187\tLR: 0.000337\nTraining Epoch: 18 [30336/50000]\tLoss: 0.3127\tLR: 0.000337\nTraining Epoch: 18 [30464/50000]\tLoss: 0.2817\tLR: 0.000337\nTraining Epoch: 18 [30592/50000]\tLoss: 0.3635\tLR: 0.000337\nTraining Epoch: 18 [30720/50000]\tLoss: 0.3031\tLR: 0.000337\nTraining Epoch: 18 [30848/50000]\tLoss: 0.2946\tLR: 0.000337\nTraining Epoch: 18 [30976/50000]\tLoss: 0.2837\tLR: 0.000337\nTraining Epoch: 18 [31104/50000]\tLoss: 0.3315\tLR: 0.000337\nTraining Epoch: 18 [31232/50000]\tLoss: 0.2534\tLR: 0.000337\nTraining Epoch: 18 [31360/50000]\tLoss: 0.2245\tLR: 0.000337\nTraining Epoch: 18 [31488/50000]\tLoss: 0.2447\tLR: 0.000337\nTraining Epoch: 18 [31616/50000]\tLoss: 0.2375\tLR: 0.000337\nTraining Epoch: 18 [31744/50000]\tLoss: 0.2473\tLR: 0.000337\nTraining Epoch: 18 [31872/50000]\tLoss: 0.2950\tLR: 0.000337\nTraining Epoch: 18 [32000/50000]\tLoss: 0.1948\tLR: 0.000337\nTraining Epoch: 18 [32128/50000]\tLoss: 0.2236\tLR: 0.000337\nTraining Epoch: 18 [32256/50000]\tLoss: 0.3421\tLR: 0.000337\nTraining Epoch: 18 [32384/50000]\tLoss: 0.2210\tLR: 0.000337\nTraining Epoch: 18 [32512/50000]\tLoss: 0.1801\tLR: 0.000337\nTraining Epoch: 18 [32640/50000]\tLoss: 0.3478\tLR: 0.000337\nTraining Epoch: 18 [32768/50000]\tLoss: 0.3976\tLR: 0.000337\nTraining Epoch: 18 [32896/50000]\tLoss: 0.3165\tLR: 0.000337\nTraining Epoch: 18 [33024/50000]\tLoss: 0.3237\tLR: 0.000337\nTraining Epoch: 18 [33152/50000]\tLoss: 0.2409\tLR: 0.000337\nTraining Epoch: 18 [33280/50000]\tLoss: 0.2859\tLR: 0.000337\nTraining Epoch: 18 [33408/50000]\tLoss: 0.2939\tLR: 0.000337\nTraining Epoch: 18 [33536/50000]\tLoss: 0.2366\tLR: 0.000337\nTraining Epoch: 18 [33664/50000]\tLoss: 0.3058\tLR: 0.000337\nTraining Epoch: 18 [33792/50000]\tLoss: 0.2956\tLR: 0.000337\nTraining Epoch: 18 [33920/50000]\tLoss: 0.5039\tLR: 0.000337\nTraining Epoch: 18 [34048/50000]\tLoss: 0.2974\tLR: 0.000337\nTraining Epoch: 18 [34176/50000]\tLoss: 0.2193\tLR: 0.000337\nTraining Epoch: 18 [34304/50000]\tLoss: 0.2897\tLR: 0.000337\nTraining Epoch: 18 [34432/50000]\tLoss: 0.2845\tLR: 0.000337\nTraining Epoch: 18 [34560/50000]\tLoss: 0.4054\tLR: 0.000337\nTraining Epoch: 18 [34688/50000]\tLoss: 0.3070\tLR: 0.000337\nTraining Epoch: 18 [34816/50000]\tLoss: 0.3387\tLR: 0.000337\nTraining Epoch: 18 [34944/50000]\tLoss: 0.1890\tLR: 0.000337\nTraining Epoch: 18 [35072/50000]\tLoss: 0.2474\tLR: 0.000337\nTraining Epoch: 18 [35200/50000]\tLoss: 0.2719\tLR: 0.000337\nTraining Epoch: 18 [35328/50000]\tLoss: 0.3604\tLR: 0.000337\nTraining Epoch: 18 [35456/50000]\tLoss: 0.2819\tLR: 0.000337\nTraining Epoch: 18 [35584/50000]\tLoss: 0.2959\tLR: 0.000337\nTraining Epoch: 18 [35712/50000]\tLoss: 0.2859\tLR: 0.000337\nTraining Epoch: 18 [35840/50000]\tLoss: 0.3115\tLR: 0.000337\nTraining Epoch: 18 [35968/50000]\tLoss: 0.1588\tLR: 0.000337\nTraining Epoch: 18 [36096/50000]\tLoss: 0.1970\tLR: 0.000337\nTraining Epoch: 18 [36224/50000]\tLoss: 0.2468\tLR: 0.000337\nTraining Epoch: 18 [36352/50000]\tLoss: 0.3185\tLR: 0.000337\nTraining Epoch: 18 [36480/50000]\tLoss: 0.3821\tLR: 0.000337\nTraining Epoch: 18 [36608/50000]\tLoss: 0.2618\tLR: 0.000337\nTraining Epoch: 18 [36736/50000]\tLoss: 0.3863\tLR: 0.000337\nTraining Epoch: 18 [36864/50000]\tLoss: 0.2445\tLR: 0.000337\nTraining Epoch: 18 [36992/50000]\tLoss: 0.2781\tLR: 0.000337\nTraining Epoch: 18 [37120/50000]\tLoss: 0.2340\tLR: 0.000337\nTraining Epoch: 18 [37248/50000]\tLoss: 0.3430\tLR: 0.000337\nTraining Epoch: 18 [37376/50000]\tLoss: 0.2964\tLR: 0.000337\nTraining Epoch: 18 [37504/50000]\tLoss: 0.1775\tLR: 0.000337\nTraining Epoch: 18 [37632/50000]\tLoss: 0.3027\tLR: 0.000337\nTraining Epoch: 18 [37760/50000]\tLoss: 0.3438\tLR: 0.000337\nTraining Epoch: 18 [37888/50000]\tLoss: 0.2879\tLR: 0.000337\nTraining Epoch: 18 [38016/50000]\tLoss: 0.2765\tLR: 0.000337\nTraining Epoch: 18 [38144/50000]\tLoss: 0.3189\tLR: 0.000337\nTraining Epoch: 18 [38272/50000]\tLoss: 0.3277\tLR: 0.000337\nTraining Epoch: 18 [38400/50000]\tLoss: 0.2185\tLR: 0.000337\nTraining Epoch: 18 [38528/50000]\tLoss: 0.2125\tLR: 0.000337\nTraining Epoch: 18 [38656/50000]\tLoss: 0.2012\tLR: 0.000337\nTraining Epoch: 18 [38784/50000]\tLoss: 0.2275\tLR: 0.000337\nTraining Epoch: 18 [38912/50000]\tLoss: 0.2588\tLR: 0.000337\nTraining Epoch: 18 [39040/50000]\tLoss: 0.2986\tLR: 0.000337\nTraining Epoch: 18 [39168/50000]\tLoss: 0.2147\tLR: 0.000337\nTraining Epoch: 18 [39296/50000]\tLoss: 0.2789\tLR: 0.000337\nTraining Epoch: 18 [39424/50000]\tLoss: 0.3362\tLR: 0.000337\nTraining Epoch: 18 [39552/50000]\tLoss: 0.2662\tLR: 0.000337\nTraining Epoch: 18 [39680/50000]\tLoss: 0.2696\tLR: 0.000337\nTraining Epoch: 18 [39808/50000]\tLoss: 0.2687\tLR: 0.000337\nTraining Epoch: 18 [39936/50000]\tLoss: 0.2665\tLR: 0.000337\nTraining Epoch: 18 [40064/50000]\tLoss: 0.3087\tLR: 0.000337\nTraining Epoch: 18 [40192/50000]\tLoss: 0.3564\tLR: 0.000337\nTraining Epoch: 18 [40320/50000]\tLoss: 0.3438\tLR: 0.000337\nTraining Epoch: 18 [40448/50000]\tLoss: 0.3531\tLR: 0.000337\nTraining Epoch: 18 [40576/50000]\tLoss: 0.2638\tLR: 0.000337\nTraining Epoch: 18 [40704/50000]\tLoss: 0.2059\tLR: 0.000337\nTraining Epoch: 18 [40832/50000]\tLoss: 0.2761\tLR: 0.000337\nTraining Epoch: 18 [40960/50000]\tLoss: 0.2230\tLR: 0.000337\nTraining Epoch: 18 [41088/50000]\tLoss: 0.3662\tLR: 0.000337\nTraining Epoch: 18 [41216/50000]\tLoss: 0.3604\tLR: 0.000337\nTraining Epoch: 18 [41344/50000]\tLoss: 0.3766\tLR: 0.000337\nTraining Epoch: 18 [41472/50000]\tLoss: 0.1789\tLR: 0.000337\nTraining Epoch: 18 [41600/50000]\tLoss: 0.2815\tLR: 0.000337\nTraining Epoch: 18 [41728/50000]\tLoss: 0.2169\tLR: 0.000337\nTraining Epoch: 18 [41856/50000]\tLoss: 0.2606\tLR: 0.000337\nTraining Epoch: 18 [41984/50000]\tLoss: 0.3231\tLR: 0.000337\nTraining Epoch: 18 [42112/50000]\tLoss: 0.3574\tLR: 0.000337\nTraining Epoch: 18 [42240/50000]\tLoss: 0.2163\tLR: 0.000337\nTraining Epoch: 18 [42368/50000]\tLoss: 0.3491\tLR: 0.000337\nTraining Epoch: 18 [42496/50000]\tLoss: 0.3307\tLR: 0.000337\nTraining Epoch: 18 [42624/50000]\tLoss: 0.3027\tLR: 0.000337\nTraining Epoch: 18 [42752/50000]\tLoss: 0.1850\tLR: 0.000337\nTraining Epoch: 18 [42880/50000]\tLoss: 0.1680\tLR: 0.000337\nTraining Epoch: 18 [43008/50000]\tLoss: 0.2450\tLR: 0.000337\nTraining Epoch: 18 [43136/50000]\tLoss: 0.3144\tLR: 0.000337\nTraining Epoch: 18 [43264/50000]\tLoss: 0.2311\tLR: 0.000337\nTraining Epoch: 18 [43392/50000]\tLoss: 0.2381\tLR: 0.000337\nTraining Epoch: 18 [43520/50000]\tLoss: 0.3468\tLR: 0.000337\nTraining Epoch: 18 [43648/50000]\tLoss: 0.2507\tLR: 0.000337\nTraining Epoch: 18 [43776/50000]\tLoss: 0.3647\tLR: 0.000337\nTraining Epoch: 18 [43904/50000]\tLoss: 0.3662\tLR: 0.000337\nTraining Epoch: 18 [44032/50000]\tLoss: 0.3140\tLR: 0.000337\nTraining Epoch: 18 [44160/50000]\tLoss: 0.1554\tLR: 0.000337\nTraining Epoch: 18 [44288/50000]\tLoss: 0.3537\tLR: 0.000337\nTraining Epoch: 18 [44416/50000]\tLoss: 0.2305\tLR: 0.000337\nTraining Epoch: 18 [44544/50000]\tLoss: 0.2537\tLR: 0.000337\nTraining Epoch: 18 [44672/50000]\tLoss: 0.2869\tLR: 0.000337\nTraining Epoch: 18 [44800/50000]\tLoss: 0.2473\tLR: 0.000337\nTraining Epoch: 18 [44928/50000]\tLoss: 0.2799\tLR: 0.000337\nTraining Epoch: 18 [45056/50000]\tLoss: 0.2531\tLR: 0.000337\nTraining Epoch: 18 [45184/50000]\tLoss: 0.3127\tLR: 0.000337\nTraining Epoch: 18 [45312/50000]\tLoss: 0.2094\tLR: 0.000337\nTraining Epoch: 18 [45440/50000]\tLoss: 0.2637\tLR: 0.000337\nTraining Epoch: 18 [45568/50000]\tLoss: 0.3091\tLR: 0.000337\nTraining Epoch: 18 [45696/50000]\tLoss: 0.2122\tLR: 0.000337\nTraining Epoch: 18 [45824/50000]\tLoss: 0.3004\tLR: 0.000337\nTraining Epoch: 18 [45952/50000]\tLoss: 0.3887\tLR: 0.000337\nTraining Epoch: 18 [46080/50000]\tLoss: 0.2487\tLR: 0.000337\nTraining Epoch: 18 [46208/50000]\tLoss: 0.1834\tLR: 0.000337\nTraining Epoch: 18 [46336/50000]\tLoss: 0.3455\tLR: 0.000337\nTraining Epoch: 18 [46464/50000]\tLoss: 0.3176\tLR: 0.000337\nTraining Epoch: 18 [46592/50000]\tLoss: 0.2537\tLR: 0.000337\nTraining Epoch: 18 [46720/50000]\tLoss: 0.2430\tLR: 0.000337\nTraining Epoch: 18 [46848/50000]\tLoss: 0.2289\tLR: 0.000337\nTraining Epoch: 18 [46976/50000]\tLoss: 0.2927\tLR: 0.000337\nTraining Epoch: 18 [47104/50000]\tLoss: 0.2987\tLR: 0.000337\nTraining Epoch: 18 [47232/50000]\tLoss: 0.2517\tLR: 0.000337\nTraining Epoch: 18 [47360/50000]\tLoss: 0.2065\tLR: 0.000337\nTraining Epoch: 18 [47488/50000]\tLoss: 0.2891\tLR: 0.000337\nTraining Epoch: 18 [47616/50000]\tLoss: 0.2358\tLR: 0.000337\nTraining Epoch: 18 [47744/50000]\tLoss: 0.2655\tLR: 0.000337\nTraining Epoch: 18 [47872/50000]\tLoss: 0.3012\tLR: 0.000337\nTraining Epoch: 18 [48000/50000]\tLoss: 0.3270\tLR: 0.000337\nTraining Epoch: 18 [48128/50000]\tLoss: 0.2784\tLR: 0.000337\nTraining Epoch: 18 [48256/50000]\tLoss: 0.2772\tLR: 0.000337\nTraining Epoch: 18 [48384/50000]\tLoss: 0.4234\tLR: 0.000337\nTraining Epoch: 18 [48512/50000]\tLoss: 0.2881\tLR: 0.000337\nTraining Epoch: 18 [48640/50000]\tLoss: 0.2296\tLR: 0.000337\nTraining Epoch: 18 [48768/50000]\tLoss: 0.3247\tLR: 0.000337\nTraining Epoch: 18 [48896/50000]\tLoss: 0.3010\tLR: 0.000337\nTraining Epoch: 18 [49024/50000]\tLoss: 0.3460\tLR: 0.000337\nTraining Epoch: 18 [49152/50000]\tLoss: 0.2640\tLR: 0.000337\nTraining Epoch: 18 [49280/50000]\tLoss: 0.1935\tLR: 0.000337\nTraining Epoch: 18 [49408/50000]\tLoss: 0.2631\tLR: 0.000337\nTraining Epoch: 18 [49536/50000]\tLoss: 0.2886\tLR: 0.000337\nTraining Epoch: 18 [49664/50000]\tLoss: 0.3200\tLR: 0.000337\nTraining Epoch: 18 [49792/50000]\tLoss: 0.2346\tLR: 0.000337\nTraining Epoch: 18 [49920/50000]\tLoss: 0.2284\tLR: 0.000337\nTraining Epoch: 18 [50000/50000]\tLoss: 0.3664\tLR: 0.000337\nTest set: Average loss: 0.0025, Accuracy: 0.8912\n\nTraining Epoch: 19 [128/50000]\tLoss: 0.2317\tLR: 0.000337\nTraining Epoch: 19 [256/50000]\tLoss: 0.1830\tLR: 0.000337\nTraining Epoch: 19 [384/50000]\tLoss: 0.2456\tLR: 0.000337\nTraining Epoch: 19 [512/50000]\tLoss: 0.4542\tLR: 0.000337\nTraining Epoch: 19 [640/50000]\tLoss: 0.2484\tLR: 0.000337\nTraining Epoch: 19 [768/50000]\tLoss: 0.2305\tLR: 0.000337\nTraining Epoch: 19 [896/50000]\tLoss: 0.2909\tLR: 0.000337\nTraining Epoch: 19 [1024/50000]\tLoss: 0.3101\tLR: 0.000337\nTraining Epoch: 19 [1152/50000]\tLoss: 0.1503\tLR: 0.000337\nTraining Epoch: 19 [1280/50000]\tLoss: 0.2648\tLR: 0.000337\nTraining Epoch: 19 [1408/50000]\tLoss: 0.3213\tLR: 0.000337\nTraining Epoch: 19 [1536/50000]\tLoss: 0.2098\tLR: 0.000337\nTraining Epoch: 19 [1664/50000]\tLoss: 0.1959\tLR: 0.000337\nTraining Epoch: 19 [1792/50000]\tLoss: 0.2713\tLR: 0.000337\nTraining Epoch: 19 [1920/50000]\tLoss: 0.2311\tLR: 0.000337\nTraining Epoch: 19 [2048/50000]\tLoss: 0.3207\tLR: 0.000337\nTraining Epoch: 19 [2176/50000]\tLoss: 0.2835\tLR: 0.000337\nTraining Epoch: 19 [2304/50000]\tLoss: 0.2472\tLR: 0.000337\nTraining Epoch: 19 [2432/50000]\tLoss: 0.4328\tLR: 0.000337\nTraining Epoch: 19 [2560/50000]\tLoss: 0.3280\tLR: 0.000337\nTraining Epoch: 19 [2688/50000]\tLoss: 0.3050\tLR: 0.000337\nTraining Epoch: 19 [2816/50000]\tLoss: 0.2008\tLR: 0.000337\nTraining Epoch: 19 [2944/50000]\tLoss: 0.3184\tLR: 0.000337\nTraining Epoch: 19 [3072/50000]\tLoss: 0.2928\tLR: 0.000337\nTraining Epoch: 19 [3200/50000]\tLoss: 0.2865\tLR: 0.000337\nTraining Epoch: 19 [3328/50000]\tLoss: 0.2764\tLR: 0.000337\nTraining Epoch: 19 [3456/50000]\tLoss: 0.2629\tLR: 0.000337\nTraining Epoch: 19 [3584/50000]\tLoss: 0.2345\tLR: 0.000337\nTraining Epoch: 19 [3712/50000]\tLoss: 0.3063\tLR: 0.000337\nTraining Epoch: 19 [3840/50000]\tLoss: 0.2411\tLR: 0.000337\nTraining Epoch: 19 [3968/50000]\tLoss: 0.2374\tLR: 0.000337\nTraining Epoch: 19 [4096/50000]\tLoss: 0.2488\tLR: 0.000337\nTraining Epoch: 19 [4224/50000]\tLoss: 0.1710\tLR: 0.000337\nTraining Epoch: 19 [4352/50000]\tLoss: 0.2965\tLR: 0.000337\nTraining Epoch: 19 [4480/50000]\tLoss: 0.2069\tLR: 0.000337\nTraining Epoch: 19 [4608/50000]\tLoss: 0.2430\tLR: 0.000337\nTraining Epoch: 19 [4736/50000]\tLoss: 0.2820\tLR: 0.000337\nTraining Epoch: 19 [4864/50000]\tLoss: 0.3196\tLR: 0.000337\nTraining Epoch: 19 [4992/50000]\tLoss: 0.2910\tLR: 0.000337\nTraining Epoch: 19 [5120/50000]\tLoss: 0.2475\tLR: 0.000337\nTraining Epoch: 19 [5248/50000]\tLoss: 0.2853\tLR: 0.000337\nTraining Epoch: 19 [5376/50000]\tLoss: 0.3372\tLR: 0.000337\nTraining Epoch: 19 [5504/50000]\tLoss: 0.3300\tLR: 0.000337\nTraining Epoch: 19 [5632/50000]\tLoss: 0.2441\tLR: 0.000337\nTraining Epoch: 19 [5760/50000]\tLoss: 0.3563\tLR: 0.000337\nTraining Epoch: 19 [5888/50000]\tLoss: 0.3295\tLR: 0.000337\nTraining Epoch: 19 [6016/50000]\tLoss: 0.2605\tLR: 0.000337\nTraining Epoch: 19 [6144/50000]\tLoss: 0.2593\tLR: 0.000337\nTraining Epoch: 19 [6272/50000]\tLoss: 0.3172\tLR: 0.000337\nTraining Epoch: 19 [6400/50000]\tLoss: 0.2759\tLR: 0.000337\nTraining Epoch: 19 [6528/50000]\tLoss: 0.3887\tLR: 0.000337\nTraining Epoch: 19 [6656/50000]\tLoss: 0.2479\tLR: 0.000337\nTraining Epoch: 19 [6784/50000]\tLoss: 0.2770\tLR: 0.000337\nTraining Epoch: 19 [6912/50000]\tLoss: 0.2033\tLR: 0.000337\nTraining Epoch: 19 [7040/50000]\tLoss: 0.2847\tLR: 0.000337\nTraining Epoch: 19 [7168/50000]\tLoss: 0.2579\tLR: 0.000337\nTraining Epoch: 19 [7296/50000]\tLoss: 0.4280\tLR: 0.000337\nTraining Epoch: 19 [7424/50000]\tLoss: 0.1912\tLR: 0.000337\nTraining Epoch: 19 [7552/50000]\tLoss: 0.4163\tLR: 0.000337\nTraining Epoch: 19 [7680/50000]\tLoss: 0.2906\tLR: 0.000337\nTraining Epoch: 19 [7808/50000]\tLoss: 0.3283\tLR: 0.000337\nTraining Epoch: 19 [7936/50000]\tLoss: 0.2949\tLR: 0.000337\nTraining Epoch: 19 [8064/50000]\tLoss: 0.2676\tLR: 0.000337\nTraining Epoch: 19 [8192/50000]\tLoss: 0.2444\tLR: 0.000337\nTraining Epoch: 19 [8320/50000]\tLoss: 0.3435\tLR: 0.000337\nTraining Epoch: 19 [8448/50000]\tLoss: 0.2786\tLR: 0.000337\nTraining Epoch: 19 [8576/50000]\tLoss: 0.1776\tLR: 0.000337\nTraining Epoch: 19 [8704/50000]\tLoss: 0.1462\tLR: 0.000337\nTraining Epoch: 19 [8832/50000]\tLoss: 0.3466\tLR: 0.000337\nTraining Epoch: 19 [8960/50000]\tLoss: 0.2264\tLR: 0.000337\nTraining Epoch: 19 [9088/50000]\tLoss: 0.2036\tLR: 0.000337\nTraining Epoch: 19 [9216/50000]\tLoss: 0.2639\tLR: 0.000337\nTraining Epoch: 19 [9344/50000]\tLoss: 0.1734\tLR: 0.000337\nTraining Epoch: 19 [9472/50000]\tLoss: 0.3460\tLR: 0.000337\nTraining Epoch: 19 [9600/50000]\tLoss: 0.2391\tLR: 0.000337\nTraining Epoch: 19 [9728/50000]\tLoss: 0.3296\tLR: 0.000337\nTraining Epoch: 19 [9856/50000]\tLoss: 0.2290\tLR: 0.000337\nTraining Epoch: 19 [9984/50000]\tLoss: 0.3438\tLR: 0.000337\nTraining Epoch: 19 [10112/50000]\tLoss: 0.2406\tLR: 0.000337\nTraining Epoch: 19 [10240/50000]\tLoss: 0.3073\tLR: 0.000337\nTraining Epoch: 19 [10368/50000]\tLoss: 0.2241\tLR: 0.000337\nTraining Epoch: 19 [10496/50000]\tLoss: 0.2307\tLR: 0.000337\nTraining Epoch: 19 [10624/50000]\tLoss: 0.2143\tLR: 0.000337\nTraining Epoch: 19 [10752/50000]\tLoss: 0.2436\tLR: 0.000337\nTraining Epoch: 19 [10880/50000]\tLoss: 0.3574\tLR: 0.000337\nTraining Epoch: 19 [11008/50000]\tLoss: 0.2562\tLR: 0.000337\nTraining Epoch: 19 [11136/50000]\tLoss: 0.2065\tLR: 0.000337\nTraining Epoch: 19 [11264/50000]\tLoss: 0.3183\tLR: 0.000337\nTraining Epoch: 19 [11392/50000]\tLoss: 0.2732\tLR: 0.000337\nTraining Epoch: 19 [11520/50000]\tLoss: 0.2217\tLR: 0.000337\nTraining Epoch: 19 [11648/50000]\tLoss: 0.2662\tLR: 0.000337\nTraining Epoch: 19 [11776/50000]\tLoss: 0.2885\tLR: 0.000337\nTraining Epoch: 19 [11904/50000]\tLoss: 0.3309\tLR: 0.000337\nTraining Epoch: 19 [12032/50000]\tLoss: 0.2739\tLR: 0.000337\nTraining Epoch: 19 [12160/50000]\tLoss: 0.3515\tLR: 0.000337\nTraining Epoch: 19 [12288/50000]\tLoss: 0.3466\tLR: 0.000337\nTraining Epoch: 19 [12416/50000]\tLoss: 0.1955\tLR: 0.000337\nTraining Epoch: 19 [12544/50000]\tLoss: 0.2629\tLR: 0.000337\nTraining Epoch: 19 [12672/50000]\tLoss: 0.2763\tLR: 0.000337\nTraining Epoch: 19 [12800/50000]\tLoss: 0.2905\tLR: 0.000337\nTraining Epoch: 19 [12928/50000]\tLoss: 0.2509\tLR: 0.000337\nTraining Epoch: 19 [13056/50000]\tLoss: 0.2601\tLR: 0.000337\nTraining Epoch: 19 [13184/50000]\tLoss: 0.2936\tLR: 0.000337\nTraining Epoch: 19 [13312/50000]\tLoss: 0.3674\tLR: 0.000337\nTraining Epoch: 19 [13440/50000]\tLoss: 0.2452\tLR: 0.000337\nTraining Epoch: 19 [13568/50000]\tLoss: 0.2295\tLR: 0.000337\nTraining Epoch: 19 [13696/50000]\tLoss: 0.2684\tLR: 0.000337\nTraining Epoch: 19 [13824/50000]\tLoss: 0.3306\tLR: 0.000337\nTraining Epoch: 19 [13952/50000]\tLoss: 0.2927\tLR: 0.000337\nTraining Epoch: 19 [14080/50000]\tLoss: 0.3214\tLR: 0.000337\nTraining Epoch: 19 [14208/50000]\tLoss: 0.3438\tLR: 0.000337\nTraining Epoch: 19 [14336/50000]\tLoss: 0.1468\tLR: 0.000337\nTraining Epoch: 19 [14464/50000]\tLoss: 0.2907\tLR: 0.000337\nTraining Epoch: 19 [14592/50000]\tLoss: 0.1935\tLR: 0.000337\nTraining Epoch: 19 [14720/50000]\tLoss: 0.2856\tLR: 0.000337\nTraining Epoch: 19 [14848/50000]\tLoss: 0.2474\tLR: 0.000337\nTraining Epoch: 19 [14976/50000]\tLoss: 0.3310\tLR: 0.000337\nTraining Epoch: 19 [15104/50000]\tLoss: 0.1817\tLR: 0.000337\nTraining Epoch: 19 [15232/50000]\tLoss: 0.3947\tLR: 0.000337\nTraining Epoch: 19 [15360/50000]\tLoss: 0.2517\tLR: 0.000337\nTraining Epoch: 19 [15488/50000]\tLoss: 0.2211\tLR: 0.000337\nTraining Epoch: 19 [15616/50000]\tLoss: 0.1969\tLR: 0.000337\nTraining Epoch: 19 [15744/50000]\tLoss: 0.2831\tLR: 0.000337\nTraining Epoch: 19 [15872/50000]\tLoss: 0.2027\tLR: 0.000337\nTraining Epoch: 19 [16000/50000]\tLoss: 0.2064\tLR: 0.000337\nTraining Epoch: 19 [16128/50000]\tLoss: 0.2835\tLR: 0.000337\nTraining Epoch: 19 [16256/50000]\tLoss: 0.2322\tLR: 0.000337\nTraining Epoch: 19 [16384/50000]\tLoss: 0.2686\tLR: 0.000337\nTraining Epoch: 19 [16512/50000]\tLoss: 0.2669\tLR: 0.000337\nTraining Epoch: 19 [16640/50000]\tLoss: 0.2443\tLR: 0.000337\nTraining Epoch: 19 [16768/50000]\tLoss: 0.2088\tLR: 0.000337\nTraining Epoch: 19 [16896/50000]\tLoss: 0.1746\tLR: 0.000337\nTraining Epoch: 19 [17024/50000]\tLoss: 0.3068\tLR: 0.000337\nTraining Epoch: 19 [17152/50000]\tLoss: 0.3045\tLR: 0.000337\nTraining Epoch: 19 [17280/50000]\tLoss: 0.3072\tLR: 0.000337\nTraining Epoch: 19 [17408/50000]\tLoss: 0.2372\tLR: 0.000337\nTraining Epoch: 19 [17536/50000]\tLoss: 0.2789\tLR: 0.000337\nTraining Epoch: 19 [17664/50000]\tLoss: 0.3452\tLR: 0.000337\nTraining Epoch: 19 [17792/50000]\tLoss: 0.3506\tLR: 0.000337\nTraining Epoch: 19 [17920/50000]\tLoss: 0.2496\tLR: 0.000337\nTraining Epoch: 19 [18048/50000]\tLoss: 0.2633\tLR: 0.000337\nTraining Epoch: 19 [18176/50000]\tLoss: 0.2069\tLR: 0.000337\nTraining Epoch: 19 [18304/50000]\tLoss: 0.2523\tLR: 0.000337\nTraining Epoch: 19 [18432/50000]\tLoss: 0.2324\tLR: 0.000337\nTraining Epoch: 19 [18560/50000]\tLoss: 0.3322\tLR: 0.000337\nTraining Epoch: 19 [18688/50000]\tLoss: 0.1923\tLR: 0.000337\nTraining Epoch: 19 [18816/50000]\tLoss: 0.2967\tLR: 0.000337\nTraining Epoch: 19 [18944/50000]\tLoss: 0.2624\tLR: 0.000337\nTraining Epoch: 19 [19072/50000]\tLoss: 0.2318\tLR: 0.000337\nTraining Epoch: 19 [19200/50000]\tLoss: 0.2911\tLR: 0.000337\nTraining Epoch: 19 [19328/50000]\tLoss: 0.2013\tLR: 0.000337\nTraining Epoch: 19 [19456/50000]\tLoss: 0.2129\tLR: 0.000337\nTraining Epoch: 19 [19584/50000]\tLoss: 0.1869\tLR: 0.000337\nTraining Epoch: 19 [19712/50000]\tLoss: 0.3536\tLR: 0.000337\nTraining Epoch: 19 [19840/50000]\tLoss: 0.2093\tLR: 0.000337\nTraining Epoch: 19 [19968/50000]\tLoss: 0.2802\tLR: 0.000337\nTraining Epoch: 19 [20096/50000]\tLoss: 0.2255\tLR: 0.000337\nTraining Epoch: 19 [20224/50000]\tLoss: 0.3498\tLR: 0.000337\nTraining Epoch: 19 [20352/50000]\tLoss: 0.3343\tLR: 0.000337\nTraining Epoch: 19 [20480/50000]\tLoss: 0.3147\tLR: 0.000337\nTraining Epoch: 19 [20608/50000]\tLoss: 0.2911\tLR: 0.000337\nTraining Epoch: 19 [20736/50000]\tLoss: 0.1391\tLR: 0.000337\nTraining Epoch: 19 [20864/50000]\tLoss: 0.3371\tLR: 0.000337\nTraining Epoch: 19 [20992/50000]\tLoss: 0.2385\tLR: 0.000337\nTraining Epoch: 19 [21120/50000]\tLoss: 0.2923\tLR: 0.000337\nTraining Epoch: 19 [21248/50000]\tLoss: 0.2376\tLR: 0.000337\nTraining Epoch: 19 [21376/50000]\tLoss: 0.2050\tLR: 0.000337\nTraining Epoch: 19 [21504/50000]\tLoss: 0.3671\tLR: 0.000337\nTraining Epoch: 19 [21632/50000]\tLoss: 0.2543\tLR: 0.000337\nTraining Epoch: 19 [21760/50000]\tLoss: 0.2868\tLR: 0.000337\nTraining Epoch: 19 [21888/50000]\tLoss: 0.1914\tLR: 0.000337\nTraining Epoch: 19 [22016/50000]\tLoss: 0.2529\tLR: 0.000337\nTraining Epoch: 19 [22144/50000]\tLoss: 0.2793\tLR: 0.000337\nTraining Epoch: 19 [22272/50000]\tLoss: 0.1749\tLR: 0.000337\nTraining Epoch: 19 [22400/50000]\tLoss: 0.2502\tLR: 0.000337\nTraining Epoch: 19 [22528/50000]\tLoss: 0.2536\tLR: 0.000337\nTraining Epoch: 19 [22656/50000]\tLoss: 0.2158\tLR: 0.000337\nTraining Epoch: 19 [22784/50000]\tLoss: 0.2091\tLR: 0.000337\nTraining Epoch: 19 [22912/50000]\tLoss: 0.3560\tLR: 0.000337\nTraining Epoch: 19 [23040/50000]\tLoss: 0.3172\tLR: 0.000337\nTraining Epoch: 19 [23168/50000]\tLoss: 0.3574\tLR: 0.000337\nTraining Epoch: 19 [23296/50000]\tLoss: 0.3830\tLR: 0.000337\nTraining Epoch: 19 [23424/50000]\tLoss: 0.1422\tLR: 0.000337\nTraining Epoch: 19 [23552/50000]\tLoss: 0.2176\tLR: 0.000337\nTraining Epoch: 19 [23680/50000]\tLoss: 0.2402\tLR: 0.000337\nTraining Epoch: 19 [23808/50000]\tLoss: 0.2753\tLR: 0.000337\nTraining Epoch: 19 [23936/50000]\tLoss: 0.3640\tLR: 0.000337\nTraining Epoch: 19 [24064/50000]\tLoss: 0.2898\tLR: 0.000337\nTraining Epoch: 19 [24192/50000]\tLoss: 0.2676\tLR: 0.000337\nTraining Epoch: 19 [24320/50000]\tLoss: 0.2999\tLR: 0.000337\nTraining Epoch: 19 [24448/50000]\tLoss: 0.1749\tLR: 0.000337\nTraining Epoch: 19 [24576/50000]\tLoss: 0.3355\tLR: 0.000337\nTraining Epoch: 19 [24704/50000]\tLoss: 0.2710\tLR: 0.000337\nTraining Epoch: 19 [24832/50000]\tLoss: 0.3441\tLR: 0.000337\nTraining Epoch: 19 [24960/50000]\tLoss: 0.2557\tLR: 0.000337\nTraining Epoch: 19 [25088/50000]\tLoss: 0.2825\tLR: 0.000337\nTraining Epoch: 19 [25216/50000]\tLoss: 0.2918\tLR: 0.000337\nTraining Epoch: 19 [25344/50000]\tLoss: 0.3069\tLR: 0.000337\nTraining Epoch: 19 [25472/50000]\tLoss: 0.2642\tLR: 0.000337\nTraining Epoch: 19 [25600/50000]\tLoss: 0.1678\tLR: 0.000337\nTraining Epoch: 19 [25728/50000]\tLoss: 0.3162\tLR: 0.000337\nTraining Epoch: 19 [25856/50000]\tLoss: 0.3388\tLR: 0.000337\nTraining Epoch: 19 [25984/50000]\tLoss: 0.3001\tLR: 0.000337\nTraining Epoch: 19 [26112/50000]\tLoss: 0.3072\tLR: 0.000337\nTraining Epoch: 19 [26240/50000]\tLoss: 0.3059\tLR: 0.000337\nTraining Epoch: 19 [26368/50000]\tLoss: 0.2403\tLR: 0.000337\nTraining Epoch: 19 [26496/50000]\tLoss: 0.2831\tLR: 0.000337\nTraining Epoch: 19 [26624/50000]\tLoss: 0.3154\tLR: 0.000337\nTraining Epoch: 19 [26752/50000]\tLoss: 0.3336\tLR: 0.000337\nTraining Epoch: 19 [26880/50000]\tLoss: 0.2269\tLR: 0.000337\nTraining Epoch: 19 [27008/50000]\tLoss: 0.3219\tLR: 0.000337\nTraining Epoch: 19 [27136/50000]\tLoss: 0.1981\tLR: 0.000337\nTraining Epoch: 19 [27264/50000]\tLoss: 0.2829\tLR: 0.000337\nTraining Epoch: 19 [27392/50000]\tLoss: 0.2372\tLR: 0.000337\nTraining Epoch: 19 [27520/50000]\tLoss: 0.2417\tLR: 0.000337\nTraining Epoch: 19 [27648/50000]\tLoss: 0.4133\tLR: 0.000337\nTraining Epoch: 19 [27776/50000]\tLoss: 0.3280\tLR: 0.000337\nTraining Epoch: 19 [27904/50000]\tLoss: 0.4122\tLR: 0.000337\nTraining Epoch: 19 [28032/50000]\tLoss: 0.3285\tLR: 0.000337\nTraining Epoch: 19 [28160/50000]\tLoss: 0.2680\tLR: 0.000337\nTraining Epoch: 19 [28288/50000]\tLoss: 0.2233\tLR: 0.000337\nTraining Epoch: 19 [28416/50000]\tLoss: 0.3489\tLR: 0.000337\nTraining Epoch: 19 [28544/50000]\tLoss: 0.1514\tLR: 0.000337\nTraining Epoch: 19 [28672/50000]\tLoss: 0.3186\tLR: 0.000337\nTraining Epoch: 19 [28800/50000]\tLoss: 0.2800\tLR: 0.000337\nTraining Epoch: 19 [28928/50000]\tLoss: 0.2709\tLR: 0.000337\nTraining Epoch: 19 [29056/50000]\tLoss: 0.2647\tLR: 0.000337\nTraining Epoch: 19 [29184/50000]\tLoss: 0.3077\tLR: 0.000337\nTraining Epoch: 19 [29312/50000]\tLoss: 0.3521\tLR: 0.000337\nTraining Epoch: 19 [29440/50000]\tLoss: 0.4019\tLR: 0.000337\nTraining Epoch: 19 [29568/50000]\tLoss: 0.2367\tLR: 0.000337\nTraining Epoch: 19 [29696/50000]\tLoss: 0.4932\tLR: 0.000337\nTraining Epoch: 19 [29824/50000]\tLoss: 0.2375\tLR: 0.000337\nTraining Epoch: 19 [29952/50000]\tLoss: 0.3325\tLR: 0.000337\nTraining Epoch: 19 [30080/50000]\tLoss: 0.3457\tLR: 0.000337\nTraining Epoch: 19 [30208/50000]\tLoss: 0.2091\tLR: 0.000337\nTraining Epoch: 19 [30336/50000]\tLoss: 0.2597\tLR: 0.000337\nTraining Epoch: 19 [30464/50000]\tLoss: 0.3191\tLR: 0.000337\nTraining Epoch: 19 [30592/50000]\tLoss: 0.2323\tLR: 0.000337\nTraining Epoch: 19 [30720/50000]\tLoss: 0.3279\tLR: 0.000337\nTraining Epoch: 19 [30848/50000]\tLoss: 0.2321\tLR: 0.000337\nTraining Epoch: 19 [30976/50000]\tLoss: 0.3011\tLR: 0.000337\nTraining Epoch: 19 [31104/50000]\tLoss: 0.2388\tLR: 0.000337\nTraining Epoch: 19 [31232/50000]\tLoss: 0.2797\tLR: 0.000337\nTraining Epoch: 19 [31360/50000]\tLoss: 0.2112\tLR: 0.000337\nTraining Epoch: 19 [31488/50000]\tLoss: 0.2650\tLR: 0.000337\nTraining Epoch: 19 [31616/50000]\tLoss: 0.2716\tLR: 0.000337\nTraining Epoch: 19 [31744/50000]\tLoss: 0.2684\tLR: 0.000337\nTraining Epoch: 19 [31872/50000]\tLoss: 0.2471\tLR: 0.000337\nTraining Epoch: 19 [32000/50000]\tLoss: 0.2540\tLR: 0.000337\nTraining Epoch: 19 [32128/50000]\tLoss: 0.3089\tLR: 0.000337\nTraining Epoch: 19 [32256/50000]\tLoss: 0.2883\tLR: 0.000337\nTraining Epoch: 19 [32384/50000]\tLoss: 0.2439\tLR: 0.000337\nTraining Epoch: 19 [32512/50000]\tLoss: 0.3039\tLR: 0.000337\nTraining Epoch: 19 [32640/50000]\tLoss: 0.2161\tLR: 0.000337\nTraining Epoch: 19 [32768/50000]\tLoss: 0.2497\tLR: 0.000337\nTraining Epoch: 19 [32896/50000]\tLoss: 0.1639\tLR: 0.000337\nTraining Epoch: 19 [33024/50000]\tLoss: 0.3014\tLR: 0.000337\nTraining Epoch: 19 [33152/50000]\tLoss: 0.1752\tLR: 0.000337\nTraining Epoch: 19 [33280/50000]\tLoss: 0.2806\tLR: 0.000337\nTraining Epoch: 19 [33408/50000]\tLoss: 0.2558\tLR: 0.000337\nTraining Epoch: 19 [33536/50000]\tLoss: 0.3670\tLR: 0.000337\nTraining Epoch: 19 [33664/50000]\tLoss: 0.1951\tLR: 0.000337\nTraining Epoch: 19 [33792/50000]\tLoss: 0.1761\tLR: 0.000337\nTraining Epoch: 19 [33920/50000]\tLoss: 0.2665\tLR: 0.000337\nTraining Epoch: 19 [34048/50000]\tLoss: 0.3127\tLR: 0.000337\nTraining Epoch: 19 [34176/50000]\tLoss: 0.3170\tLR: 0.000337\nTraining Epoch: 19 [34304/50000]\tLoss: 0.2408\tLR: 0.000337\nTraining Epoch: 19 [34432/50000]\tLoss: 0.1659\tLR: 0.000337\nTraining Epoch: 19 [34560/50000]\tLoss: 0.1798\tLR: 0.000337\nTraining Epoch: 19 [34688/50000]\tLoss: 0.3315\tLR: 0.000337\nTraining Epoch: 19 [34816/50000]\tLoss: 0.3833\tLR: 0.000337\nTraining Epoch: 19 [34944/50000]\tLoss: 0.3132\tLR: 0.000337\nTraining Epoch: 19 [35072/50000]\tLoss: 0.2780\tLR: 0.000337\nTraining Epoch: 19 [35200/50000]\tLoss: 0.2813\tLR: 0.000337\nTraining Epoch: 19 [35328/50000]\tLoss: 0.2242\tLR: 0.000337\nTraining Epoch: 19 [35456/50000]\tLoss: 0.3384\tLR: 0.000337\nTraining Epoch: 19 [35584/50000]\tLoss: 0.3568\tLR: 0.000337\nTraining Epoch: 19 [35712/50000]\tLoss: 0.1905\tLR: 0.000337\nTraining Epoch: 19 [35840/50000]\tLoss: 0.1715\tLR: 0.000337\nTraining Epoch: 19 [35968/50000]\tLoss: 0.2083\tLR: 0.000337\nTraining Epoch: 19 [36096/50000]\tLoss: 0.2675\tLR: 0.000337\nTraining Epoch: 19 [36224/50000]\tLoss: 0.3415\tLR: 0.000337\nTraining Epoch: 19 [36352/50000]\tLoss: 0.2453\tLR: 0.000337\nTraining Epoch: 19 [36480/50000]\tLoss: 0.2815\tLR: 0.000337\nTraining Epoch: 19 [36608/50000]\tLoss: 0.2839\tLR: 0.000337\nTraining Epoch: 19 [36736/50000]\tLoss: 0.2329\tLR: 0.000337\nTraining Epoch: 19 [36864/50000]\tLoss: 0.3810\tLR: 0.000337\nTraining Epoch: 19 [36992/50000]\tLoss: 0.3016\tLR: 0.000337\nTraining Epoch: 19 [37120/50000]\tLoss: 0.2390\tLR: 0.000337\nTraining Epoch: 19 [37248/50000]\tLoss: 0.2726\tLR: 0.000337\nTraining Epoch: 19 [37376/50000]\tLoss: 0.2857\tLR: 0.000337\nTraining Epoch: 19 [37504/50000]\tLoss: 0.3739\tLR: 0.000337\nTraining Epoch: 19 [37632/50000]\tLoss: 0.2557\tLR: 0.000337\nTraining Epoch: 19 [37760/50000]\tLoss: 0.3028\tLR: 0.000337\nTraining Epoch: 19 [37888/50000]\tLoss: 0.2706\tLR: 0.000337\nTraining Epoch: 19 [38016/50000]\tLoss: 0.3239\tLR: 0.000337\nTraining Epoch: 19 [38144/50000]\tLoss: 0.3559\tLR: 0.000337\nTraining Epoch: 19 [38272/50000]\tLoss: 0.3043\tLR: 0.000337\nTraining Epoch: 19 [38400/50000]\tLoss: 0.3744\tLR: 0.000337\nTraining Epoch: 19 [38528/50000]\tLoss: 0.2892\tLR: 0.000337\nTraining Epoch: 19 [38656/50000]\tLoss: 0.1995\tLR: 0.000337\nTraining Epoch: 19 [38784/50000]\tLoss: 0.2581\tLR: 0.000337\nTraining Epoch: 19 [38912/50000]\tLoss: 0.3258\tLR: 0.000337\nTraining Epoch: 19 [39040/50000]\tLoss: 0.2939\tLR: 0.000337\nTraining Epoch: 19 [39168/50000]\tLoss: 0.2227\tLR: 0.000337\nTraining Epoch: 19 [39296/50000]\tLoss: 0.2803\tLR: 0.000337\nTraining Epoch: 19 [39424/50000]\tLoss: 0.3132\tLR: 0.000337\nTraining Epoch: 19 [39552/50000]\tLoss: 0.2078\tLR: 0.000337\nTraining Epoch: 19 [39680/50000]\tLoss: 0.4072\tLR: 0.000337\nTraining Epoch: 19 [39808/50000]\tLoss: 0.3276\tLR: 0.000337\nTraining Epoch: 19 [39936/50000]\tLoss: 0.2935\tLR: 0.000337\nTraining Epoch: 19 [40064/50000]\tLoss: 0.2441\tLR: 0.000337\nTraining Epoch: 19 [40192/50000]\tLoss: 0.2462\tLR: 0.000337\nTraining Epoch: 19 [40320/50000]\tLoss: 0.4208\tLR: 0.000337\nTraining Epoch: 19 [40448/50000]\tLoss: 0.2695\tLR: 0.000337\nTraining Epoch: 19 [40576/50000]\tLoss: 0.1986\tLR: 0.000337\nTraining Epoch: 19 [40704/50000]\tLoss: 0.3343\tLR: 0.000337\nTraining Epoch: 19 [40832/50000]\tLoss: 0.2808\tLR: 0.000337\nTraining Epoch: 19 [40960/50000]\tLoss: 0.4291\tLR: 0.000337\nTraining Epoch: 19 [41088/50000]\tLoss: 0.2242\tLR: 0.000337\nTraining Epoch: 19 [41216/50000]\tLoss: 0.2483\tLR: 0.000337\nTraining Epoch: 19 [41344/50000]\tLoss: 0.2456\tLR: 0.000337\nTraining Epoch: 19 [41472/50000]\tLoss: 0.2561\tLR: 0.000337\nTraining Epoch: 19 [41600/50000]\tLoss: 0.1609\tLR: 0.000337\nTraining Epoch: 19 [41728/50000]\tLoss: 0.2788\tLR: 0.000337\nTraining Epoch: 19 [41856/50000]\tLoss: 0.2615\tLR: 0.000337\nTraining Epoch: 19 [41984/50000]\tLoss: 0.3140\tLR: 0.000337\nTraining Epoch: 19 [42112/50000]\tLoss: 0.2720\tLR: 0.000337\nTraining Epoch: 19 [42240/50000]\tLoss: 0.2463\tLR: 0.000337\nTraining Epoch: 19 [42368/50000]\tLoss: 0.2488\tLR: 0.000337\nTraining Epoch: 19 [42496/50000]\tLoss: 0.3490\tLR: 0.000337\nTraining Epoch: 19 [42624/50000]\tLoss: 0.2094\tLR: 0.000337\nTraining Epoch: 19 [42752/50000]\tLoss: 0.1599\tLR: 0.000337\nTraining Epoch: 19 [42880/50000]\tLoss: 0.3048\tLR: 0.000337\nTraining Epoch: 19 [43008/50000]\tLoss: 0.2062\tLR: 0.000337\nTraining Epoch: 19 [43136/50000]\tLoss: 0.2866\tLR: 0.000337\nTraining Epoch: 19 [43264/50000]\tLoss: 0.2940\tLR: 0.000337\nTraining Epoch: 19 [43392/50000]\tLoss: 0.2894\tLR: 0.000337\nTraining Epoch: 19 [43520/50000]\tLoss: 0.3593\tLR: 0.000337\nTraining Epoch: 19 [43648/50000]\tLoss: 0.3026\tLR: 0.000337\nTraining Epoch: 19 [43776/50000]\tLoss: 0.2961\tLR: 0.000337\nTraining Epoch: 19 [43904/50000]\tLoss: 0.2316\tLR: 0.000337\nTraining Epoch: 19 [44032/50000]\tLoss: 0.2975\tLR: 0.000337\nTraining Epoch: 19 [44160/50000]\tLoss: 0.3079\tLR: 0.000337\nTraining Epoch: 19 [44288/50000]\tLoss: 0.1903\tLR: 0.000337\nTraining Epoch: 19 [44416/50000]\tLoss: 0.2056\tLR: 0.000337\nTraining Epoch: 19 [44544/50000]\tLoss: 0.2274\tLR: 0.000337\nTraining Epoch: 19 [44672/50000]\tLoss: 0.1970\tLR: 0.000337\nTraining Epoch: 19 [44800/50000]\tLoss: 0.2580\tLR: 0.000337\nTraining Epoch: 19 [44928/50000]\tLoss: 0.2978\tLR: 0.000337\nTraining Epoch: 19 [45056/50000]\tLoss: 0.2619\tLR: 0.000337\nTraining Epoch: 19 [45184/50000]\tLoss: 0.3413\tLR: 0.000337\nTraining Epoch: 19 [45312/50000]\tLoss: 0.3595\tLR: 0.000337\nTraining Epoch: 19 [45440/50000]\tLoss: 0.2670\tLR: 0.000337\nTraining Epoch: 19 [45568/50000]\tLoss: 0.1882\tLR: 0.000337\nTraining Epoch: 19 [45696/50000]\tLoss: 0.3008\tLR: 0.000337\nTraining Epoch: 19 [45824/50000]\tLoss: 0.3339\tLR: 0.000337\nTraining Epoch: 19 [45952/50000]\tLoss: 0.1994\tLR: 0.000337\nTraining Epoch: 19 [46080/50000]\tLoss: 0.2665\tLR: 0.000337\nTraining Epoch: 19 [46208/50000]\tLoss: 0.2648\tLR: 0.000337\nTraining Epoch: 19 [46336/50000]\tLoss: 0.3361\tLR: 0.000337\nTraining Epoch: 19 [46464/50000]\tLoss: 0.2680\tLR: 0.000337\nTraining Epoch: 19 [46592/50000]\tLoss: 0.2516\tLR: 0.000337\nTraining Epoch: 19 [46720/50000]\tLoss: 0.2297\tLR: 0.000337\nTraining Epoch: 19 [46848/50000]\tLoss: 0.1715\tLR: 0.000337\nTraining Epoch: 19 [46976/50000]\tLoss: 0.3018\tLR: 0.000337\nTraining Epoch: 19 [47104/50000]\tLoss: 0.3866\tLR: 0.000337\nTraining Epoch: 19 [47232/50000]\tLoss: 0.2481\tLR: 0.000337\nTraining Epoch: 19 [47360/50000]\tLoss: 0.3381\tLR: 0.000337\nTraining Epoch: 19 [47488/50000]\tLoss: 0.3251\tLR: 0.000337\nTraining Epoch: 19 [47616/50000]\tLoss: 0.3518\tLR: 0.000337\nTraining Epoch: 19 [47744/50000]\tLoss: 0.3529\tLR: 0.000337\nTraining Epoch: 19 [47872/50000]\tLoss: 0.2937\tLR: 0.000337\nTraining Epoch: 19 [48000/50000]\tLoss: 0.3655\tLR: 0.000337\nTraining Epoch: 19 [48128/50000]\tLoss: 0.3326\tLR: 0.000337\nTraining Epoch: 19 [48256/50000]\tLoss: 0.3242\tLR: 0.000337\nTraining Epoch: 19 [48384/50000]\tLoss: 0.3048\tLR: 0.000337\nTraining Epoch: 19 [48512/50000]\tLoss: 0.2474\tLR: 0.000337\nTraining Epoch: 19 [48640/50000]\tLoss: 0.3221\tLR: 0.000337\nTraining Epoch: 19 [48768/50000]\tLoss: 0.2952\tLR: 0.000337\nTraining Epoch: 19 [48896/50000]\tLoss: 0.1999\tLR: 0.000337\nTraining Epoch: 19 [49024/50000]\tLoss: 0.2602\tLR: 0.000337\nTraining Epoch: 19 [49152/50000]\tLoss: 0.2475\tLR: 0.000337\nTraining Epoch: 19 [49280/50000]\tLoss: 0.2324\tLR: 0.000337\nTraining Epoch: 19 [49408/50000]\tLoss: 0.2007\tLR: 0.000337\nTraining Epoch: 19 [49536/50000]\tLoss: 0.3155\tLR: 0.000337\nTraining Epoch: 19 [49664/50000]\tLoss: 0.3084\tLR: 0.000337\nTraining Epoch: 19 [49792/50000]\tLoss: 0.2588\tLR: 0.000337\nTraining Epoch: 19 [49920/50000]\tLoss: 0.2486\tLR: 0.000337\nTraining Epoch: 19 [50000/50000]\tLoss: 0.2646\tLR: 0.000337\nTest set: Average loss: 0.0025, Accuracy: 0.8928\n\nTraining Epoch: 20 [128/50000]\tLoss: 0.3082\tLR: 0.000337\nTraining Epoch: 20 [256/50000]\tLoss: 0.2579\tLR: 0.000337\nTraining Epoch: 20 [384/50000]\tLoss: 0.2860\tLR: 0.000337\nTraining Epoch: 20 [512/50000]\tLoss: 0.1633\tLR: 0.000337\nTraining Epoch: 20 [640/50000]\tLoss: 0.2249\tLR: 0.000337\nTraining Epoch: 20 [768/50000]\tLoss: 0.3622\tLR: 0.000337\nTraining Epoch: 20 [896/50000]\tLoss: 0.2407\tLR: 0.000337\nTraining Epoch: 20 [1024/50000]\tLoss: 0.3076\tLR: 0.000337\nTraining Epoch: 20 [1152/50000]\tLoss: 0.2580\tLR: 0.000337\nTraining Epoch: 20 [1280/50000]\tLoss: 0.2634\tLR: 0.000337\nTraining Epoch: 20 [1408/50000]\tLoss: 0.2184\tLR: 0.000337\nTraining Epoch: 20 [1536/50000]\tLoss: 0.2635\tLR: 0.000337\nTraining Epoch: 20 [1664/50000]\tLoss: 0.2692\tLR: 0.000337\nTraining Epoch: 20 [1792/50000]\tLoss: 0.3016\tLR: 0.000337\nTraining Epoch: 20 [1920/50000]\tLoss: 0.2672\tLR: 0.000337\nTraining Epoch: 20 [2048/50000]\tLoss: 0.1838\tLR: 0.000337\nTraining Epoch: 20 [2176/50000]\tLoss: 0.2514\tLR: 0.000337\nTraining Epoch: 20 [2304/50000]\tLoss: 0.3098\tLR: 0.000337\nTraining Epoch: 20 [2432/50000]\tLoss: 0.2131\tLR: 0.000337\nTraining Epoch: 20 [2560/50000]\tLoss: 0.2419\tLR: 0.000337\nTraining Epoch: 20 [2688/50000]\tLoss: 0.2755\tLR: 0.000337\nTraining Epoch: 20 [2816/50000]\tLoss: 0.2402\tLR: 0.000337\nTraining Epoch: 20 [2944/50000]\tLoss: 0.2638\tLR: 0.000337\nTraining Epoch: 20 [3072/50000]\tLoss: 0.2291\tLR: 0.000337\nTraining Epoch: 20 [3200/50000]\tLoss: 0.3932\tLR: 0.000337\nTraining Epoch: 20 [3328/50000]\tLoss: 0.2537\tLR: 0.000337\nTraining Epoch: 20 [3456/50000]\tLoss: 0.2256\tLR: 0.000337\nTraining Epoch: 20 [3584/50000]\tLoss: 0.2791\tLR: 0.000337\nTraining Epoch: 20 [3712/50000]\tLoss: 0.2861\tLR: 0.000337\nTraining Epoch: 20 [3840/50000]\tLoss: 0.2795\tLR: 0.000337\nTraining Epoch: 20 [3968/50000]\tLoss: 0.2604\tLR: 0.000337\nTraining Epoch: 20 [4096/50000]\tLoss: 0.3150\tLR: 0.000337\nTraining Epoch: 20 [4224/50000]\tLoss: 0.2534\tLR: 0.000337\nTraining Epoch: 20 [4352/50000]\tLoss: 0.2172\tLR: 0.000337\nTraining Epoch: 20 [4480/50000]\tLoss: 0.3044\tLR: 0.000337\nTraining Epoch: 20 [4608/50000]\tLoss: 0.2317\tLR: 0.000337\nTraining Epoch: 20 [4736/50000]\tLoss: 0.2692\tLR: 0.000337\nTraining Epoch: 20 [4864/50000]\tLoss: 0.2456\tLR: 0.000337\nTraining Epoch: 20 [4992/50000]\tLoss: 0.4233\tLR: 0.000337\nTraining Epoch: 20 [5120/50000]\tLoss: 0.2621\tLR: 0.000337\nTraining Epoch: 20 [5248/50000]\tLoss: 0.3637\tLR: 0.000337\nTraining Epoch: 20 [5376/50000]\tLoss: 0.2780\tLR: 0.000337\nTraining Epoch: 20 [5504/50000]\tLoss: 0.1780\tLR: 0.000337\nTraining Epoch: 20 [5632/50000]\tLoss: 0.2313\tLR: 0.000337\nTraining Epoch: 20 [5760/50000]\tLoss: 0.2094\tLR: 0.000337\nTraining Epoch: 20 [5888/50000]\tLoss: 0.3783\tLR: 0.000337\nTraining Epoch: 20 [6016/50000]\tLoss: 0.3569\tLR: 0.000337\nTraining Epoch: 20 [6144/50000]\tLoss: 0.2574\tLR: 0.000337\nTraining Epoch: 20 [6272/50000]\tLoss: 0.3124\tLR: 0.000337\nTraining Epoch: 20 [6400/50000]\tLoss: 0.2269\tLR: 0.000337\nTraining Epoch: 20 [6528/50000]\tLoss: 0.2905\tLR: 0.000337\nTraining Epoch: 20 [6656/50000]\tLoss: 0.1851\tLR: 0.000337\nTraining Epoch: 20 [6784/50000]\tLoss: 0.2094\tLR: 0.000337\nTraining Epoch: 20 [6912/50000]\tLoss: 0.3828\tLR: 0.000337\nTraining Epoch: 20 [7040/50000]\tLoss: 0.2844\tLR: 0.000337\nTraining Epoch: 20 [7168/50000]\tLoss: 0.3310\tLR: 0.000337\nTraining Epoch: 20 [7296/50000]\tLoss: 0.2444\tLR: 0.000337\nTraining Epoch: 20 [7424/50000]\tLoss: 0.3334\tLR: 0.000337\nTraining Epoch: 20 [7552/50000]\tLoss: 0.3433\tLR: 0.000337\nTraining Epoch: 20 [7680/50000]\tLoss: 0.2877\tLR: 0.000337\nTraining Epoch: 20 [7808/50000]\tLoss: 0.2527\tLR: 0.000337\nTraining Epoch: 20 [7936/50000]\tLoss: 0.3028\tLR: 0.000337\nTraining Epoch: 20 [8064/50000]\tLoss: 0.3747\tLR: 0.000337\nTraining Epoch: 20 [8192/50000]\tLoss: 0.1611\tLR: 0.000337\nTraining Epoch: 20 [8320/50000]\tLoss: 0.2942\tLR: 0.000337\nTraining Epoch: 20 [8448/50000]\tLoss: 0.2545\tLR: 0.000337\nTraining Epoch: 20 [8576/50000]\tLoss: 0.2940\tLR: 0.000337\nTraining Epoch: 20 [8704/50000]\tLoss: 0.2507\tLR: 0.000337\nTraining Epoch: 20 [8832/50000]\tLoss: 0.2968\tLR: 0.000337\nTraining Epoch: 20 [8960/50000]\tLoss: 0.3576\tLR: 0.000337\nTraining Epoch: 20 [9088/50000]\tLoss: 0.2620\tLR: 0.000337\nTraining Epoch: 20 [9216/50000]\tLoss: 0.3927\tLR: 0.000337\nTraining Epoch: 20 [9344/50000]\tLoss: 0.2283\tLR: 0.000337\nTraining Epoch: 20 [9472/50000]\tLoss: 0.4016\tLR: 0.000337\nTraining Epoch: 20 [9600/50000]\tLoss: 0.3223\tLR: 0.000337\nTraining Epoch: 20 [9728/50000]\tLoss: 0.3684\tLR: 0.000337\nTraining Epoch: 20 [9856/50000]\tLoss: 0.3496\tLR: 0.000337\nTraining Epoch: 20 [9984/50000]\tLoss: 0.2677\tLR: 0.000337\nTraining Epoch: 20 [10112/50000]\tLoss: 0.3486\tLR: 0.000337\nTraining Epoch: 20 [10240/50000]\tLoss: 0.3084\tLR: 0.000337\nTraining Epoch: 20 [10368/50000]\tLoss: 0.2490\tLR: 0.000337\nTraining Epoch: 20 [10496/50000]\tLoss: 0.2115\tLR: 0.000337\nTraining Epoch: 20 [10624/50000]\tLoss: 0.2901\tLR: 0.000337\nTraining Epoch: 20 [10752/50000]\tLoss: 0.2667\tLR: 0.000337\nTraining Epoch: 20 [10880/50000]\tLoss: 0.2722\tLR: 0.000337\nTraining Epoch: 20 [11008/50000]\tLoss: 0.3453\tLR: 0.000337\nTraining Epoch: 20 [11136/50000]\tLoss: 0.2123\tLR: 0.000337\nTraining Epoch: 20 [11264/50000]\tLoss: 0.2927\tLR: 0.000337\nTraining Epoch: 20 [11392/50000]\tLoss: 0.3425\tLR: 0.000337\nTraining Epoch: 20 [11520/50000]\tLoss: 0.2790\tLR: 0.000337\nTraining Epoch: 20 [11648/50000]\tLoss: 0.2607\tLR: 0.000337\nTraining Epoch: 20 [11776/50000]\tLoss: 0.2525\tLR: 0.000337\nTraining Epoch: 20 [11904/50000]\tLoss: 0.3152\tLR: 0.000337\nTraining Epoch: 20 [12032/50000]\tLoss: 0.2474\tLR: 0.000337\nTraining Epoch: 20 [12160/50000]\tLoss: 0.4156\tLR: 0.000337\nTraining Epoch: 20 [12288/50000]\tLoss: 0.2300\tLR: 0.000337\nTraining Epoch: 20 [12416/50000]\tLoss: 0.2682\tLR: 0.000337\nTraining Epoch: 20 [12544/50000]\tLoss: 0.2599\tLR: 0.000337\nTraining Epoch: 20 [12672/50000]\tLoss: 0.2934\tLR: 0.000337\nTraining Epoch: 20 [12800/50000]\tLoss: 0.2269\tLR: 0.000337\nTraining Epoch: 20 [12928/50000]\tLoss: 0.2145\tLR: 0.000337\nTraining Epoch: 20 [13056/50000]\tLoss: 0.2354\tLR: 0.000337\nTraining Epoch: 20 [13184/50000]\tLoss: 0.2510\tLR: 0.000337\nTraining Epoch: 20 [13312/50000]\tLoss: 0.2946\tLR: 0.000337\nTraining Epoch: 20 [13440/50000]\tLoss: 0.2970\tLR: 0.000337\nTraining Epoch: 20 [13568/50000]\tLoss: 0.2838\tLR: 0.000337\nTraining Epoch: 20 [13696/50000]\tLoss: 0.2916\tLR: 0.000337\nTraining Epoch: 20 [13824/50000]\tLoss: 0.2665\tLR: 0.000337\nTraining Epoch: 20 [13952/50000]\tLoss: 0.3838\tLR: 0.000337\nTraining Epoch: 20 [14080/50000]\tLoss: 0.3173\tLR: 0.000337\nTraining Epoch: 20 [14208/50000]\tLoss: 0.2898\tLR: 0.000337\nTraining Epoch: 20 [14336/50000]\tLoss: 0.4171\tLR: 0.000337\nTraining Epoch: 20 [14464/50000]\tLoss: 0.2344\tLR: 0.000337\nTraining Epoch: 20 [14592/50000]\tLoss: 0.2729\tLR: 0.000337\nTraining Epoch: 20 [14720/50000]\tLoss: 0.2327\tLR: 0.000337\nTraining Epoch: 20 [14848/50000]\tLoss: 0.2529\tLR: 0.000337\nTraining Epoch: 20 [14976/50000]\tLoss: 0.2817\tLR: 0.000337\nTraining Epoch: 20 [15104/50000]\tLoss: 0.2079\tLR: 0.000337\nTraining Epoch: 20 [15232/50000]\tLoss: 0.3789\tLR: 0.000337\nTraining Epoch: 20 [15360/50000]\tLoss: 0.2875\tLR: 0.000337\nTraining Epoch: 20 [15488/50000]\tLoss: 0.3381\tLR: 0.000337\nTraining Epoch: 20 [15616/50000]\tLoss: 0.2668\tLR: 0.000337\nTraining Epoch: 20 [15744/50000]\tLoss: 0.1818\tLR: 0.000337\nTraining Epoch: 20 [15872/50000]\tLoss: 0.2342\tLR: 0.000337\nTraining Epoch: 20 [16000/50000]\tLoss: 0.2477\tLR: 0.000337\nTraining Epoch: 20 [16128/50000]\tLoss: 0.3208\tLR: 0.000337\nTraining Epoch: 20 [16256/50000]\tLoss: 0.2380\tLR: 0.000337\nTraining Epoch: 20 [16384/50000]\tLoss: 0.1667\tLR: 0.000337\nTraining Epoch: 20 [16512/50000]\tLoss: 0.3204\tLR: 0.000337\nTraining Epoch: 20 [16640/50000]\tLoss: 0.2312\tLR: 0.000337\nTraining Epoch: 20 [16768/50000]\tLoss: 0.2824\tLR: 0.000337\nTraining Epoch: 20 [16896/50000]\tLoss: 0.2577\tLR: 0.000337\nTraining Epoch: 20 [17024/50000]\tLoss: 0.2553\tLR: 0.000337\nTraining Epoch: 20 [17152/50000]\tLoss: 0.3443\tLR: 0.000337\nTraining Epoch: 20 [17280/50000]\tLoss: 0.3112\tLR: 0.000337\nTraining Epoch: 20 [17408/50000]\tLoss: 0.2053\tLR: 0.000337\nTraining Epoch: 20 [17536/50000]\tLoss: 0.2678\tLR: 0.000337\nTraining Epoch: 20 [17664/50000]\tLoss: 0.3330\tLR: 0.000337\nTraining Epoch: 20 [17792/50000]\tLoss: 0.2031\tLR: 0.000337\nTraining Epoch: 20 [17920/50000]\tLoss: 0.2554\tLR: 0.000337\nTraining Epoch: 20 [18048/50000]\tLoss: 0.3105\tLR: 0.000337\nTraining Epoch: 20 [18176/50000]\tLoss: 0.2225\tLR: 0.000337\nTraining Epoch: 20 [18304/50000]\tLoss: 0.2179\tLR: 0.000337\nTraining Epoch: 20 [18432/50000]\tLoss: 0.3673\tLR: 0.000337\nTraining Epoch: 20 [18560/50000]\tLoss: 0.2832\tLR: 0.000337\nTraining Epoch: 20 [18688/50000]\tLoss: 0.1948\tLR: 0.000337\nTraining Epoch: 20 [18816/50000]\tLoss: 0.2702\tLR: 0.000337\nTraining Epoch: 20 [18944/50000]\tLoss: 0.2604\tLR: 0.000337\nTraining Epoch: 20 [19072/50000]\tLoss: 0.2380\tLR: 0.000337\nTraining Epoch: 20 [19200/50000]\tLoss: 0.2679\tLR: 0.000337\nTraining Epoch: 20 [19328/50000]\tLoss: 0.3428\tLR: 0.000337\nTraining Epoch: 20 [19456/50000]\tLoss: 0.3368\tLR: 0.000337\nTraining Epoch: 20 [19584/50000]\tLoss: 0.2194\tLR: 0.000337\nTraining Epoch: 20 [19712/50000]\tLoss: 0.2651\tLR: 0.000337\nTraining Epoch: 20 [19840/50000]\tLoss: 0.2986\tLR: 0.000337\nTraining Epoch: 20 [19968/50000]\tLoss: 0.2933\tLR: 0.000337\nTraining Epoch: 20 [20096/50000]\tLoss: 0.2262\tLR: 0.000337\nTraining Epoch: 20 [20224/50000]\tLoss: 0.2165\tLR: 0.000337\nTraining Epoch: 20 [20352/50000]\tLoss: 0.2265\tLR: 0.000337\nTraining Epoch: 20 [20480/50000]\tLoss: 0.3142\tLR: 0.000337\nTraining Epoch: 20 [20608/50000]\tLoss: 0.2586\tLR: 0.000337\nTraining Epoch: 20 [20736/50000]\tLoss: 0.3287\tLR: 0.000337\nTraining Epoch: 20 [20864/50000]\tLoss: 0.3199\tLR: 0.000337\nTraining Epoch: 20 [20992/50000]\tLoss: 0.2382\tLR: 0.000337\nTraining Epoch: 20 [21120/50000]\tLoss: 0.3038\tLR: 0.000337\nTraining Epoch: 20 [21248/50000]\tLoss: 0.2681\tLR: 0.000337\nTraining Epoch: 20 [21376/50000]\tLoss: 0.3061\tLR: 0.000337\nTraining Epoch: 20 [21504/50000]\tLoss: 0.2319\tLR: 0.000337\nTraining Epoch: 20 [21632/50000]\tLoss: 0.2846\tLR: 0.000337\nTraining Epoch: 20 [21760/50000]\tLoss: 0.2728\tLR: 0.000337\nTraining Epoch: 20 [21888/50000]\tLoss: 0.4524\tLR: 0.000337\nTraining Epoch: 20 [22016/50000]\tLoss: 0.2487\tLR: 0.000337\nTraining Epoch: 20 [22144/50000]\tLoss: 0.2821\tLR: 0.000337\nTraining Epoch: 20 [22272/50000]\tLoss: 0.2928\tLR: 0.000337\nTraining Epoch: 20 [22400/50000]\tLoss: 0.2523\tLR: 0.000337\nTraining Epoch: 20 [22528/50000]\tLoss: 0.2985\tLR: 0.000337\nTraining Epoch: 20 [22656/50000]\tLoss: 0.2468\tLR: 0.000337\nTraining Epoch: 20 [22784/50000]\tLoss: 0.3144\tLR: 0.000337\nTraining Epoch: 20 [22912/50000]\tLoss: 0.3032\tLR: 0.000337\nTraining Epoch: 20 [23040/50000]\tLoss: 0.2586\tLR: 0.000337\nTraining Epoch: 20 [23168/50000]\tLoss: 0.3066\tLR: 0.000337\nTraining Epoch: 20 [23296/50000]\tLoss: 0.1792\tLR: 0.000337\nTraining Epoch: 20 [23424/50000]\tLoss: 0.2492\tLR: 0.000337\nTraining Epoch: 20 [23552/50000]\tLoss: 0.2568\tLR: 0.000337\nTraining Epoch: 20 [23680/50000]\tLoss: 0.2504\tLR: 0.000337\nTraining Epoch: 20 [23808/50000]\tLoss: 0.2822\tLR: 0.000337\nTraining Epoch: 20 [23936/50000]\tLoss: 0.4033\tLR: 0.000337\nTraining Epoch: 20 [24064/50000]\tLoss: 0.2607\tLR: 0.000337\nTraining Epoch: 20 [24192/50000]\tLoss: 0.1661\tLR: 0.000337\nTraining Epoch: 20 [24320/50000]\tLoss: 0.2635\tLR: 0.000337\nTraining Epoch: 20 [24448/50000]\tLoss: 0.3394\tLR: 0.000337\nTraining Epoch: 20 [24576/50000]\tLoss: 0.2667\tLR: 0.000337\nTraining Epoch: 20 [24704/50000]\tLoss: 0.2506\tLR: 0.000337\nTraining Epoch: 20 [24832/50000]\tLoss: 0.3263\tLR: 0.000337\nTraining Epoch: 20 [24960/50000]\tLoss: 0.2546\tLR: 0.000337\nTraining Epoch: 20 [25088/50000]\tLoss: 0.2488\tLR: 0.000337\nTraining Epoch: 20 [25216/50000]\tLoss: 0.4057\tLR: 0.000337\nTraining Epoch: 20 [25344/50000]\tLoss: 0.2556\tLR: 0.000337\nTraining Epoch: 20 [25472/50000]\tLoss: 0.3066\tLR: 0.000337\nTraining Epoch: 20 [25600/50000]\tLoss: 0.3053\tLR: 0.000337\nTraining Epoch: 20 [25728/50000]\tLoss: 0.3035\tLR: 0.000337\nTraining Epoch: 20 [25856/50000]\tLoss: 0.2492\tLR: 0.000337\nTraining Epoch: 20 [25984/50000]\tLoss: 0.2391\tLR: 0.000337\nTraining Epoch: 20 [26112/50000]\tLoss: 0.3295\tLR: 0.000337\nTraining Epoch: 20 [26240/50000]\tLoss: 0.2174\tLR: 0.000337\nTraining Epoch: 20 [26368/50000]\tLoss: 0.1787\tLR: 0.000337\nTraining Epoch: 20 [26496/50000]\tLoss: 0.2870\tLR: 0.000337\nTraining Epoch: 20 [26624/50000]\tLoss: 0.3471\tLR: 0.000337\nTraining Epoch: 20 [26752/50000]\tLoss: 0.2674\tLR: 0.000337\nTraining Epoch: 20 [26880/50000]\tLoss: 0.2457\tLR: 0.000337\nTraining Epoch: 20 [27008/50000]\tLoss: 0.2575\tLR: 0.000337\nTraining Epoch: 20 [27136/50000]\tLoss: 0.3125\tLR: 0.000337\nTraining Epoch: 20 [27264/50000]\tLoss: 0.2603\tLR: 0.000337\nTraining Epoch: 20 [27392/50000]\tLoss: 0.3756\tLR: 0.000337\nTraining Epoch: 20 [27520/50000]\tLoss: 0.2598\tLR: 0.000337\nTraining Epoch: 20 [27648/50000]\tLoss: 0.1624\tLR: 0.000337\nTraining Epoch: 20 [27776/50000]\tLoss: 0.2872\tLR: 0.000337\nTraining Epoch: 20 [27904/50000]\tLoss: 0.2832\tLR: 0.000337\nTraining Epoch: 20 [28032/50000]\tLoss: 0.2758\tLR: 0.000337\nTraining Epoch: 20 [28160/50000]\tLoss: 0.2405\tLR: 0.000337\nTraining Epoch: 20 [28288/50000]\tLoss: 0.1944\tLR: 0.000337\nTraining Epoch: 20 [28416/50000]\tLoss: 0.1835\tLR: 0.000337\nTraining Epoch: 20 [28544/50000]\tLoss: 0.4561\tLR: 0.000337\nTraining Epoch: 20 [28672/50000]\tLoss: 0.2810\tLR: 0.000337\nTraining Epoch: 20 [28800/50000]\tLoss: 0.2230\tLR: 0.000337\nTraining Epoch: 20 [28928/50000]\tLoss: 0.2252\tLR: 0.000337\nTraining Epoch: 20 [29056/50000]\tLoss: 0.2638\tLR: 0.000337\nTraining Epoch: 20 [29184/50000]\tLoss: 0.2633\tLR: 0.000337\nTraining Epoch: 20 [29312/50000]\tLoss: 0.1322\tLR: 0.000337\nTraining Epoch: 20 [29440/50000]\tLoss: 0.3198\tLR: 0.000337\nTraining Epoch: 20 [29568/50000]\tLoss: 0.3254\tLR: 0.000337\nTraining Epoch: 20 [29696/50000]\tLoss: 0.2111\tLR: 0.000337\nTraining Epoch: 20 [29824/50000]\tLoss: 0.3496\tLR: 0.000337\nTraining Epoch: 20 [29952/50000]\tLoss: 0.2744\tLR: 0.000337\nTraining Epoch: 20 [30080/50000]\tLoss: 0.3254\tLR: 0.000337\nTraining Epoch: 20 [30208/50000]\tLoss: 0.1849\tLR: 0.000337\nTraining Epoch: 20 [30336/50000]\tLoss: 0.2862\tLR: 0.000337\nTraining Epoch: 20 [30464/50000]\tLoss: 0.2565\tLR: 0.000337\nTraining Epoch: 20 [30592/50000]\tLoss: 0.2527\tLR: 0.000337\nTraining Epoch: 20 [30720/50000]\tLoss: 0.2967\tLR: 0.000337\nTraining Epoch: 20 [30848/50000]\tLoss: 0.2567\tLR: 0.000337\nTraining Epoch: 20 [30976/50000]\tLoss: 0.2977\tLR: 0.000337\nTraining Epoch: 20 [31104/50000]\tLoss: 0.1601\tLR: 0.000337\nTraining Epoch: 20 [31232/50000]\tLoss: 0.3446\tLR: 0.000337\nTraining Epoch: 20 [31360/50000]\tLoss: 0.3366\tLR: 0.000337\nTraining Epoch: 20 [31488/50000]\tLoss: 0.3772\tLR: 0.000337\nTraining Epoch: 20 [31616/50000]\tLoss: 0.2405\tLR: 0.000337\nTraining Epoch: 20 [31744/50000]\tLoss: 0.2638\tLR: 0.000337\nTraining Epoch: 20 [31872/50000]\tLoss: 0.1930\tLR: 0.000337\nTraining Epoch: 20 [32000/50000]\tLoss: 0.2332\tLR: 0.000337\nTraining Epoch: 20 [32128/50000]\tLoss: 0.3071\tLR: 0.000337\nTraining Epoch: 20 [32256/50000]\tLoss: 0.2770\tLR: 0.000337\nTraining Epoch: 20 [32384/50000]\tLoss: 0.2560\tLR: 0.000337\nTraining Epoch: 20 [32512/50000]\tLoss: 0.3646\tLR: 0.000337\nTraining Epoch: 20 [32640/50000]\tLoss: 0.2330\tLR: 0.000337\nTraining Epoch: 20 [32768/50000]\tLoss: 0.2784\tLR: 0.000337\nTraining Epoch: 20 [32896/50000]\tLoss: 0.3002\tLR: 0.000337\nTraining Epoch: 20 [33024/50000]\tLoss: 0.2750\tLR: 0.000337\nTraining Epoch: 20 [33152/50000]\tLoss: 0.2372\tLR: 0.000337\nTraining Epoch: 20 [33280/50000]\tLoss: 0.3107\tLR: 0.000337\nTraining Epoch: 20 [33408/50000]\tLoss: 0.1968\tLR: 0.000337\nTraining Epoch: 20 [33536/50000]\tLoss: 0.2192\tLR: 0.000337\nTraining Epoch: 20 [33664/50000]\tLoss: 0.2835\tLR: 0.000337\nTraining Epoch: 20 [33792/50000]\tLoss: 0.2605\tLR: 0.000337\nTraining Epoch: 20 [33920/50000]\tLoss: 0.2448\tLR: 0.000337\nTraining Epoch: 20 [34048/50000]\tLoss: 0.2695\tLR: 0.000337\nTraining Epoch: 20 [34176/50000]\tLoss: 0.3946\tLR: 0.000337\nTraining Epoch: 20 [34304/50000]\tLoss: 0.3540\tLR: 0.000337\nTraining Epoch: 20 [34432/50000]\tLoss: 0.2699\tLR: 0.000337\nTraining Epoch: 20 [34560/50000]\tLoss: 0.2478\tLR: 0.000337\nTraining Epoch: 20 [34688/50000]\tLoss: 0.2211\tLR: 0.000337\nTraining Epoch: 20 [34816/50000]\tLoss: 0.3360\tLR: 0.000337\nTraining Epoch: 20 [34944/50000]\tLoss: 0.1915\tLR: 0.000337\nTraining Epoch: 20 [35072/50000]\tLoss: 0.2692\tLR: 0.000337\nTraining Epoch: 20 [35200/50000]\tLoss: 0.2309\tLR: 0.000337\nTraining Epoch: 20 [35328/50000]\tLoss: 0.2543\tLR: 0.000337\nTraining Epoch: 20 [35456/50000]\tLoss: 0.2407\tLR: 0.000337\nTraining Epoch: 20 [35584/50000]\tLoss: 0.2440\tLR: 0.000337\nTraining Epoch: 20 [35712/50000]\tLoss: 0.1600\tLR: 0.000337\nTraining Epoch: 20 [35840/50000]\tLoss: 0.2119\tLR: 0.000337\nTraining Epoch: 20 [35968/50000]\tLoss: 0.3412\tLR: 0.000337\nTraining Epoch: 20 [36096/50000]\tLoss: 0.2600\tLR: 0.000337\nTraining Epoch: 20 [36224/50000]\tLoss: 0.2508\tLR: 0.000337\nTraining Epoch: 20 [36352/50000]\tLoss: 0.3495\tLR: 0.000337\nTraining Epoch: 20 [36480/50000]\tLoss: 0.2575\tLR: 0.000337\nTraining Epoch: 20 [36608/50000]\tLoss: 0.2563\tLR: 0.000337\nTraining Epoch: 20 [36736/50000]\tLoss: 0.1974\tLR: 0.000337\nTraining Epoch: 20 [36864/50000]\tLoss: 0.2468\tLR: 0.000337\nTraining Epoch: 20 [36992/50000]\tLoss: 0.2476\tLR: 0.000337\nTraining Epoch: 20 [37120/50000]\tLoss: 0.2258\tLR: 0.000337\nTraining Epoch: 20 [37248/50000]\tLoss: 0.2704\tLR: 0.000337\nTraining Epoch: 20 [37376/50000]\tLoss: 0.1992\tLR: 0.000337\nTraining Epoch: 20 [37504/50000]\tLoss: 0.2155\tLR: 0.000337\nTraining Epoch: 20 [37632/50000]\tLoss: 0.2727\tLR: 0.000337\nTraining Epoch: 20 [37760/50000]\tLoss: 0.1914\tLR: 0.000337\nTraining Epoch: 20 [37888/50000]\tLoss: 0.2549\tLR: 0.000337\nTraining Epoch: 20 [38016/50000]\tLoss: 0.2443\tLR: 0.000337\nTraining Epoch: 20 [38144/50000]\tLoss: 0.2859\tLR: 0.000337\nTraining Epoch: 20 [38272/50000]\tLoss: 0.3416\tLR: 0.000337\nTraining Epoch: 20 [38400/50000]\tLoss: 0.3387\tLR: 0.000337\nTraining Epoch: 20 [38528/50000]\tLoss: 0.2510\tLR: 0.000337\nTraining Epoch: 20 [38656/50000]\tLoss: 0.2667\tLR: 0.000337\nTraining Epoch: 20 [38784/50000]\tLoss: 0.3263\tLR: 0.000337\nTraining Epoch: 20 [38912/50000]\tLoss: 0.2467\tLR: 0.000337\nTraining Epoch: 20 [39040/50000]\tLoss: 0.3325\tLR: 0.000337\nTraining Epoch: 20 [39168/50000]\tLoss: 0.2943\tLR: 0.000337\nTraining Epoch: 20 [39296/50000]\tLoss: 0.3023\tLR: 0.000337\nTraining Epoch: 20 [39424/50000]\tLoss: 0.3121\tLR: 0.000337\nTraining Epoch: 20 [39552/50000]\tLoss: 0.2263\tLR: 0.000337\nTraining Epoch: 20 [39680/50000]\tLoss: 0.2903\tLR: 0.000337\nTraining Epoch: 20 [39808/50000]\tLoss: 0.1348\tLR: 0.000337\nTraining Epoch: 20 [39936/50000]\tLoss: 0.3150\tLR: 0.000337\nTraining Epoch: 20 [40064/50000]\tLoss: 0.3333\tLR: 0.000337\nTraining Epoch: 20 [40192/50000]\tLoss: 0.3362\tLR: 0.000337\nTraining Epoch: 20 [40320/50000]\tLoss: 0.2418\tLR: 0.000337\nTraining Epoch: 20 [40448/50000]\tLoss: 0.3688\tLR: 0.000337\nTraining Epoch: 20 [40576/50000]\tLoss: 0.3581\tLR: 0.000337\nTraining Epoch: 20 [40704/50000]\tLoss: 0.3327\tLR: 0.000337\nTraining Epoch: 20 [40832/50000]\tLoss: 0.2570\tLR: 0.000337\nTraining Epoch: 20 [40960/50000]\tLoss: 0.2473\tLR: 0.000337\nTraining Epoch: 20 [41088/50000]\tLoss: 0.3287\tLR: 0.000337\nTraining Epoch: 20 [41216/50000]\tLoss: 0.3399\tLR: 0.000337\nTraining Epoch: 20 [41344/50000]\tLoss: 0.2768\tLR: 0.000337\nTraining Epoch: 20 [41472/50000]\tLoss: 0.2714\tLR: 0.000337\nTraining Epoch: 20 [41600/50000]\tLoss: 0.2426\tLR: 0.000337\nTraining Epoch: 20 [41728/50000]\tLoss: 0.1678\tLR: 0.000337\nTraining Epoch: 20 [41856/50000]\tLoss: 0.3300\tLR: 0.000337\nTraining Epoch: 20 [41984/50000]\tLoss: 0.1645\tLR: 0.000337\nTraining Epoch: 20 [42112/50000]\tLoss: 0.2836\tLR: 0.000337\nTraining Epoch: 20 [42240/50000]\tLoss: 0.2330\tLR: 0.000337\nTraining Epoch: 20 [42368/50000]\tLoss: 0.2306\tLR: 0.000337\nTraining Epoch: 20 [42496/50000]\tLoss: 0.1787\tLR: 0.000337\nTraining Epoch: 20 [42624/50000]\tLoss: 0.3172\tLR: 0.000337\nTraining Epoch: 20 [42752/50000]\tLoss: 0.1973\tLR: 0.000337\nTraining Epoch: 20 [42880/50000]\tLoss: 0.2938\tLR: 0.000337\nTraining Epoch: 20 [43008/50000]\tLoss: 0.2594\tLR: 0.000337\nTraining Epoch: 20 [43136/50000]\tLoss: 0.2760\tLR: 0.000337\nTraining Epoch: 20 [43264/50000]\tLoss: 0.3500\tLR: 0.000337\nTraining Epoch: 20 [43392/50000]\tLoss: 0.1628\tLR: 0.000337\nTraining Epoch: 20 [43520/50000]\tLoss: 0.2254\tLR: 0.000337\nTraining Epoch: 20 [43648/50000]\tLoss: 0.2913\tLR: 0.000337\nTraining Epoch: 20 [43776/50000]\tLoss: 0.3022\tLR: 0.000337\nTraining Epoch: 20 [43904/50000]\tLoss: 0.1792\tLR: 0.000337\nTraining Epoch: 20 [44032/50000]\tLoss: 0.2933\tLR: 0.000337\nTraining Epoch: 20 [44160/50000]\tLoss: 0.2330\tLR: 0.000337\nTraining Epoch: 20 [44288/50000]\tLoss: 0.2928\tLR: 0.000337\nTraining Epoch: 20 [44416/50000]\tLoss: 0.3104\tLR: 0.000337\nTraining Epoch: 20 [44544/50000]\tLoss: 0.2079\tLR: 0.000337\nTraining Epoch: 20 [44672/50000]\tLoss: 0.1728\tLR: 0.000337\nTraining Epoch: 20 [44800/50000]\tLoss: 0.2599\tLR: 0.000337\nTraining Epoch: 20 [44928/50000]\tLoss: 0.2741\tLR: 0.000337\nTraining Epoch: 20 [45056/50000]\tLoss: 0.1778\tLR: 0.000337\nTraining Epoch: 20 [45184/50000]\tLoss: 0.3021\tLR: 0.000337\nTraining Epoch: 20 [45312/50000]\tLoss: 0.2171\tLR: 0.000337\nTraining Epoch: 20 [45440/50000]\tLoss: 0.2883\tLR: 0.000337\nTraining Epoch: 20 [45568/50000]\tLoss: 0.2824\tLR: 0.000337\nTraining Epoch: 20 [45696/50000]\tLoss: 0.2923\tLR: 0.000337\nTraining Epoch: 20 [45824/50000]\tLoss: 0.2665\tLR: 0.000337\nTraining Epoch: 20 [45952/50000]\tLoss: 0.1924\tLR: 0.000337\nTraining Epoch: 20 [46080/50000]\tLoss: 0.2647\tLR: 0.000337\nTraining Epoch: 20 [46208/50000]\tLoss: 0.2567\tLR: 0.000337\nTraining Epoch: 20 [46336/50000]\tLoss: 0.3085\tLR: 0.000337\nTraining Epoch: 20 [46464/50000]\tLoss: 0.2345\tLR: 0.000337\nTraining Epoch: 20 [46592/50000]\tLoss: 0.2163\tLR: 0.000337\nTraining Epoch: 20 [46720/50000]\tLoss: 0.2229\tLR: 0.000337\nTraining Epoch: 20 [46848/50000]\tLoss: 0.1780\tLR: 0.000337\nTraining Epoch: 20 [46976/50000]\tLoss: 0.2291\tLR: 0.000337\nTraining Epoch: 20 [47104/50000]\tLoss: 0.2322\tLR: 0.000337\nTraining Epoch: 20 [47232/50000]\tLoss: 0.2799\tLR: 0.000337\nTraining Epoch: 20 [47360/50000]\tLoss: 0.3311\tLR: 0.000337\nTraining Epoch: 20 [47488/50000]\tLoss: 0.2749\tLR: 0.000337\nTraining Epoch: 20 [47616/50000]\tLoss: 0.2941\tLR: 0.000337\nTraining Epoch: 20 [47744/50000]\tLoss: 0.2980\tLR: 0.000337\nTraining Epoch: 20 [47872/50000]\tLoss: 0.2175\tLR: 0.000337\nTraining Epoch: 20 [48000/50000]\tLoss: 0.2611\tLR: 0.000337\nTraining Epoch: 20 [48128/50000]\tLoss: 0.2045\tLR: 0.000337\nTraining Epoch: 20 [48256/50000]\tLoss: 0.2280\tLR: 0.000337\nTraining Epoch: 20 [48384/50000]\tLoss: 0.2857\tLR: 0.000337\nTraining Epoch: 20 [48512/50000]\tLoss: 0.3284\tLR: 0.000337\nTraining Epoch: 20 [48640/50000]\tLoss: 0.2810\tLR: 0.000337\nTraining Epoch: 20 [48768/50000]\tLoss: 0.2055\tLR: 0.000337\nTraining Epoch: 20 [48896/50000]\tLoss: 0.2995\tLR: 0.000337\nTraining Epoch: 20 [49024/50000]\tLoss: 0.1954\tLR: 0.000337\nTraining Epoch: 20 [49152/50000]\tLoss: 0.2632\tLR: 0.000337\nTraining Epoch: 20 [49280/50000]\tLoss: 0.2828\tLR: 0.000337\nTraining Epoch: 20 [49408/50000]\tLoss: 0.2119\tLR: 0.000337\nTraining Epoch: 20 [49536/50000]\tLoss: 0.3277\tLR: 0.000337\nTraining Epoch: 20 [49664/50000]\tLoss: 0.2732\tLR: 0.000337\nTraining Epoch: 20 [49792/50000]\tLoss: 0.2494\tLR: 0.000337\nTraining Epoch: 20 [49920/50000]\tLoss: 0.3233\tLR: 0.000337\nTraining Epoch: 20 [50000/50000]\tLoss: 0.1923\tLR: 0.000337\nTest set: Average loss: 0.0025, Accuracy: 0.8917\n\nTraining Epoch: 21 [128/50000]\tLoss: 0.2595\tLR: 0.000337\nTraining Epoch: 21 [256/50000]\tLoss: 0.3895\tLR: 0.000337\nTraining Epoch: 21 [384/50000]\tLoss: 0.2981\tLR: 0.000337\nTraining Epoch: 21 [512/50000]\tLoss: 0.2680\tLR: 0.000337\nTraining Epoch: 21 [640/50000]\tLoss: 0.2944\tLR: 0.000337\nTraining Epoch: 21 [768/50000]\tLoss: 0.2174\tLR: 0.000337\nTraining Epoch: 21 [896/50000]\tLoss: 0.1660\tLR: 0.000337\nTraining Epoch: 21 [1024/50000]\tLoss: 0.2094\tLR: 0.000337\nTraining Epoch: 21 [1152/50000]\tLoss: 0.1302\tLR: 0.000337\nTraining Epoch: 21 [1280/50000]\tLoss: 0.1838\tLR: 0.000337\nTraining Epoch: 21 [1408/50000]\tLoss: 0.1783\tLR: 0.000337\nTraining Epoch: 21 [1536/50000]\tLoss: 0.2325\tLR: 0.000337\nTraining Epoch: 21 [1664/50000]\tLoss: 0.2128\tLR: 0.000337\nTraining Epoch: 21 [1792/50000]\tLoss: 0.3510\tLR: 0.000337\nTraining Epoch: 21 [1920/50000]\tLoss: 0.2693\tLR: 0.000337\nTraining Epoch: 21 [2048/50000]\tLoss: 0.1223\tLR: 0.000337\nTraining Epoch: 21 [2176/50000]\tLoss: 0.3400\tLR: 0.000337\nTraining Epoch: 21 [2304/50000]\tLoss: 0.2894\tLR: 0.000337\nTraining Epoch: 21 [2432/50000]\tLoss: 0.2086\tLR: 0.000337\nTraining Epoch: 21 [2560/50000]\tLoss: 0.2900\tLR: 0.000337\nTraining Epoch: 21 [2688/50000]\tLoss: 0.1580\tLR: 0.000337\nTraining Epoch: 21 [2816/50000]\tLoss: 0.2432\tLR: 0.000337\nTraining Epoch: 21 [2944/50000]\tLoss: 0.2092\tLR: 0.000337\nTraining Epoch: 21 [3072/50000]\tLoss: 0.2376\tLR: 0.000337\nTraining Epoch: 21 [3200/50000]\tLoss: 0.2640\tLR: 0.000337\nTraining Epoch: 21 [3328/50000]\tLoss: 0.2819\tLR: 0.000337\nTraining Epoch: 21 [3456/50000]\tLoss: 0.1998\tLR: 0.000337\nTraining Epoch: 21 [3584/50000]\tLoss: 0.2380\tLR: 0.000337\nTraining Epoch: 21 [3712/50000]\tLoss: 0.3021\tLR: 0.000337\nTraining Epoch: 21 [3840/50000]\tLoss: 0.2415\tLR: 0.000337\nTraining Epoch: 21 [3968/50000]\tLoss: 0.2659\tLR: 0.000337\nTraining Epoch: 21 [4096/50000]\tLoss: 0.3617\tLR: 0.000337\nTraining Epoch: 21 [4224/50000]\tLoss: 0.2825\tLR: 0.000337\nTraining Epoch: 21 [4352/50000]\tLoss: 0.3430\tLR: 0.000337\nTraining Epoch: 21 [4480/50000]\tLoss: 0.2585\tLR: 0.000337\nTraining Epoch: 21 [4608/50000]\tLoss: 0.2335\tLR: 0.000337\nTraining Epoch: 21 [4736/50000]\tLoss: 0.2565\tLR: 0.000337\nTraining Epoch: 21 [4864/50000]\tLoss: 0.2464\tLR: 0.000337\nTraining Epoch: 21 [4992/50000]\tLoss: 0.2353\tLR: 0.000337\nTraining Epoch: 21 [5120/50000]\tLoss: 0.2502\tLR: 0.000337\nTraining Epoch: 21 [5248/50000]\tLoss: 0.2321\tLR: 0.000337\nTraining Epoch: 21 [5376/50000]\tLoss: 0.2108\tLR: 0.000337\nTraining Epoch: 21 [5504/50000]\tLoss: 0.2716\tLR: 0.000337\nTraining Epoch: 21 [5632/50000]\tLoss: 0.3409\tLR: 0.000337\nTraining Epoch: 21 [5760/50000]\tLoss: 0.2730\tLR: 0.000337\nTraining Epoch: 21 [5888/50000]\tLoss: 0.2716\tLR: 0.000337\nTraining Epoch: 21 [6016/50000]\tLoss: 0.3205\tLR: 0.000337\nTraining Epoch: 21 [6144/50000]\tLoss: 0.1640\tLR: 0.000337\nTraining Epoch: 21 [6272/50000]\tLoss: 0.3777\tLR: 0.000337\nTraining Epoch: 21 [6400/50000]\tLoss: 0.3968\tLR: 0.000337\nTraining Epoch: 21 [6528/50000]\tLoss: 0.2551\tLR: 0.000337\nTraining Epoch: 21 [6656/50000]\tLoss: 0.3042\tLR: 0.000337\nTraining Epoch: 21 [6784/50000]\tLoss: 0.3932\tLR: 0.000337\nTraining Epoch: 21 [6912/50000]\tLoss: 0.2510\tLR: 0.000337\nTraining Epoch: 21 [7040/50000]\tLoss: 0.3158\tLR: 0.000337\nTraining Epoch: 21 [7168/50000]\tLoss: 0.2552\tLR: 0.000337\nTraining Epoch: 21 [7296/50000]\tLoss: 0.1785\tLR: 0.000337\nTraining Epoch: 21 [7424/50000]\tLoss: 0.3851\tLR: 0.000337\nTraining Epoch: 21 [7552/50000]\tLoss: 0.2803\tLR: 0.000337\nTraining Epoch: 21 [7680/50000]\tLoss: 0.3364\tLR: 0.000337\nTraining Epoch: 21 [7808/50000]\tLoss: 0.3017\tLR: 0.000337\nTraining Epoch: 21 [7936/50000]\tLoss: 0.3141\tLR: 0.000337\nTraining Epoch: 21 [8064/50000]\tLoss: 0.2971\tLR: 0.000337\nTraining Epoch: 21 [8192/50000]\tLoss: 0.3703\tLR: 0.000337\nTraining Epoch: 21 [8320/50000]\tLoss: 0.2446\tLR: 0.000337\nTraining Epoch: 21 [8448/50000]\tLoss: 0.2767\tLR: 0.000337\nTraining Epoch: 21 [8576/50000]\tLoss: 0.2066\tLR: 0.000337\nTraining Epoch: 21 [8704/50000]\tLoss: 0.2754\tLR: 0.000337\nTraining Epoch: 21 [8832/50000]\tLoss: 0.2342\tLR: 0.000337\nTraining Epoch: 21 [8960/50000]\tLoss: 0.2681\tLR: 0.000337\nTraining Epoch: 21 [9088/50000]\tLoss: 0.2301\tLR: 0.000337\nTraining Epoch: 21 [9216/50000]\tLoss: 0.2357\tLR: 0.000337\nTraining Epoch: 21 [9344/50000]\tLoss: 0.2415\tLR: 0.000337\nTraining Epoch: 21 [9472/50000]\tLoss: 0.3984\tLR: 0.000337\nTraining Epoch: 21 [9600/50000]\tLoss: 0.2494\tLR: 0.000337\nTraining Epoch: 21 [9728/50000]\tLoss: 0.2956\tLR: 0.000337\nTraining Epoch: 21 [9856/50000]\tLoss: 0.2733\tLR: 0.000337\nTraining Epoch: 21 [9984/50000]\tLoss: 0.2398\tLR: 0.000337\nTraining Epoch: 21 [10112/50000]\tLoss: 0.2184\tLR: 0.000337\nTraining Epoch: 21 [10240/50000]\tLoss: 0.2160\tLR: 0.000337\nTraining Epoch: 21 [10368/50000]\tLoss: 0.2191\tLR: 0.000337\nTraining Epoch: 21 [10496/50000]\tLoss: 0.2807\tLR: 0.000337\nTraining Epoch: 21 [10624/50000]\tLoss: 0.2679\tLR: 0.000337\nTraining Epoch: 21 [10752/50000]\tLoss: 0.2016\tLR: 0.000337\nTraining Epoch: 21 [10880/50000]\tLoss: 0.1750\tLR: 0.000337\nTraining Epoch: 21 [11008/50000]\tLoss: 0.2552\tLR: 0.000337\nTraining Epoch: 21 [11136/50000]\tLoss: 0.2589\tLR: 0.000337\nTraining Epoch: 21 [11264/50000]\tLoss: 0.2862\tLR: 0.000337\nTraining Epoch: 21 [11392/50000]\tLoss: 0.2361\tLR: 0.000337\nTraining Epoch: 21 [11520/50000]\tLoss: 0.2761\tLR: 0.000337\nTraining Epoch: 21 [11648/50000]\tLoss: 0.2844\tLR: 0.000337\nTraining Epoch: 21 [11776/50000]\tLoss: 0.3320\tLR: 0.000337\nTraining Epoch: 21 [11904/50000]\tLoss: 0.1686\tLR: 0.000337\nTraining Epoch: 21 [12032/50000]\tLoss: 0.3022\tLR: 0.000337\nTraining Epoch: 21 [12160/50000]\tLoss: 0.2502\tLR: 0.000337\nTraining Epoch: 21 [12288/50000]\tLoss: 0.2286\tLR: 0.000337\nTraining Epoch: 21 [12416/50000]\tLoss: 0.3990\tLR: 0.000337\nTraining Epoch: 21 [12544/50000]\tLoss: 0.1982\tLR: 0.000337\nTraining Epoch: 21 [12672/50000]\tLoss: 0.2896\tLR: 0.000337\nTraining Epoch: 21 [12800/50000]\tLoss: 0.2850\tLR: 0.000337\nTraining Epoch: 21 [12928/50000]\tLoss: 0.1848\tLR: 0.000337\nTraining Epoch: 21 [13056/50000]\tLoss: 0.2137\tLR: 0.000337\nTraining Epoch: 21 [13184/50000]\tLoss: 0.2893\tLR: 0.000337\nTraining Epoch: 21 [13312/50000]\tLoss: 0.2669\tLR: 0.000337\nTraining Epoch: 21 [13440/50000]\tLoss: 0.2680\tLR: 0.000337\nTraining Epoch: 21 [13568/50000]\tLoss: 0.2912\tLR: 0.000337\nTraining Epoch: 21 [13696/50000]\tLoss: 0.2516\tLR: 0.000337\nTraining Epoch: 21 [13824/50000]\tLoss: 0.1993\tLR: 0.000337\nTraining Epoch: 21 [13952/50000]\tLoss: 0.3665\tLR: 0.000337\nTraining Epoch: 21 [14080/50000]\tLoss: 0.3974\tLR: 0.000337\nTraining Epoch: 21 [14208/50000]\tLoss: 0.3834\tLR: 0.000337\nTraining Epoch: 21 [14336/50000]\tLoss: 0.2545\tLR: 0.000337\nTraining Epoch: 21 [14464/50000]\tLoss: 0.3599\tLR: 0.000337\nTraining Epoch: 21 [14592/50000]\tLoss: 0.1692\tLR: 0.000337\nTraining Epoch: 21 [14720/50000]\tLoss: 0.2527\tLR: 0.000337\nTraining Epoch: 21 [14848/50000]\tLoss: 0.2648\tLR: 0.000337\nTraining Epoch: 21 [14976/50000]\tLoss: 0.3857\tLR: 0.000337\nTraining Epoch: 21 [15104/50000]\tLoss: 0.2528\tLR: 0.000337\nTraining Epoch: 21 [15232/50000]\tLoss: 0.2257\tLR: 0.000337\nTraining Epoch: 21 [15360/50000]\tLoss: 0.3592\tLR: 0.000337\nTraining Epoch: 21 [15488/50000]\tLoss: 0.2972\tLR: 0.000337\nTraining Epoch: 21 [15616/50000]\tLoss: 0.2030\tLR: 0.000337\nTraining Epoch: 21 [15744/50000]\tLoss: 0.4268\tLR: 0.000337\nTraining Epoch: 21 [15872/50000]\tLoss: 0.2928\tLR: 0.000337\nTraining Epoch: 21 [16000/50000]\tLoss: 0.2437\tLR: 0.000337\nTraining Epoch: 21 [16128/50000]\tLoss: 0.3163\tLR: 0.000337\nTraining Epoch: 21 [16256/50000]\tLoss: 0.2634\tLR: 0.000337\nTraining Epoch: 21 [16384/50000]\tLoss: 0.2141\tLR: 0.000337\nTraining Epoch: 21 [16512/50000]\tLoss: 0.2856\tLR: 0.000337\nTraining Epoch: 21 [16640/50000]\tLoss: 0.3091\tLR: 0.000337\nTraining Epoch: 21 [16768/50000]\tLoss: 0.2297\tLR: 0.000337\nTraining Epoch: 21 [16896/50000]\tLoss: 0.2613\tLR: 0.000337\nTraining Epoch: 21 [17024/50000]\tLoss: 0.2842\tLR: 0.000337\nTraining Epoch: 21 [17152/50000]\tLoss: 0.2068\tLR: 0.000337\nTraining Epoch: 21 [17280/50000]\tLoss: 0.2195\tLR: 0.000337\nTraining Epoch: 21 [17408/50000]\tLoss: 0.3200\tLR: 0.000337\nTraining Epoch: 21 [17536/50000]\tLoss: 0.2399\tLR: 0.000337\nTraining Epoch: 21 [17664/50000]\tLoss: 0.2373\tLR: 0.000337\nTraining Epoch: 21 [17792/50000]\tLoss: 0.2321\tLR: 0.000337\nTraining Epoch: 21 [17920/50000]\tLoss: 0.3474\tLR: 0.000337\nTraining Epoch: 21 [18048/50000]\tLoss: 0.2949\tLR: 0.000337\nTraining Epoch: 21 [18176/50000]\tLoss: 0.2660\tLR: 0.000337\nTraining Epoch: 21 [18304/50000]\tLoss: 0.3400\tLR: 0.000337\nTraining Epoch: 21 [18432/50000]\tLoss: 0.2385\tLR: 0.000337\nTraining Epoch: 21 [18560/50000]\tLoss: 0.2696\tLR: 0.000337\nTraining Epoch: 21 [18688/50000]\tLoss: 0.3782\tLR: 0.000337\nTraining Epoch: 21 [18816/50000]\tLoss: 0.4248\tLR: 0.000337\nTraining Epoch: 21 [18944/50000]\tLoss: 0.2446\tLR: 0.000337\nTraining Epoch: 21 [19072/50000]\tLoss: 0.3778\tLR: 0.000337\nTraining Epoch: 21 [19200/50000]\tLoss: 0.3442\tLR: 0.000337\nTraining Epoch: 21 [19328/50000]\tLoss: 0.1730\tLR: 0.000337\nTraining Epoch: 21 [19456/50000]\tLoss: 0.2957\tLR: 0.000337\nTraining Epoch: 21 [19584/50000]\tLoss: 0.2022\tLR: 0.000337\nTraining Epoch: 21 [19712/50000]\tLoss: 0.2979\tLR: 0.000337\nTraining Epoch: 21 [19840/50000]\tLoss: 0.3624\tLR: 0.000337\nTraining Epoch: 21 [19968/50000]\tLoss: 0.1501\tLR: 0.000337\nTraining Epoch: 21 [20096/50000]\tLoss: 0.3800\tLR: 0.000337\nTraining Epoch: 21 [20224/50000]\tLoss: 0.3259\tLR: 0.000337\nTraining Epoch: 21 [20352/50000]\tLoss: 0.2644\tLR: 0.000337\nTraining Epoch: 21 [20480/50000]\tLoss: 0.2236\tLR: 0.000337\nTraining Epoch: 21 [20608/50000]\tLoss: 0.3013\tLR: 0.000337\nTraining Epoch: 21 [20736/50000]\tLoss: 0.2312\tLR: 0.000337\nTraining Epoch: 21 [20864/50000]\tLoss: 0.2467\tLR: 0.000337\nTraining Epoch: 21 [20992/50000]\tLoss: 0.2701\tLR: 0.000337\nTraining Epoch: 21 [21120/50000]\tLoss: 0.3622\tLR: 0.000337\nTraining Epoch: 21 [21248/50000]\tLoss: 0.3039\tLR: 0.000337\nTraining Epoch: 21 [21376/50000]\tLoss: 0.2628\tLR: 0.000337\nTraining Epoch: 21 [21504/50000]\tLoss: 0.2081\tLR: 0.000337\nTraining Epoch: 21 [21632/50000]\tLoss: 0.3307\tLR: 0.000337\nTraining Epoch: 21 [21760/50000]\tLoss: 0.2485\tLR: 0.000337\nTraining Epoch: 21 [21888/50000]\tLoss: 0.2097\tLR: 0.000337\nTraining Epoch: 21 [22016/50000]\tLoss: 0.2867\tLR: 0.000337\nTraining Epoch: 21 [22144/50000]\tLoss: 0.3484\tLR: 0.000337\nTraining Epoch: 21 [22272/50000]\tLoss: 0.1990\tLR: 0.000337\nTraining Epoch: 21 [22400/50000]\tLoss: 0.2251\tLR: 0.000337\nTraining Epoch: 21 [22528/50000]\tLoss: 0.2520\tLR: 0.000337\nTraining Epoch: 21 [22656/50000]\tLoss: 0.2350\tLR: 0.000337\nTraining Epoch: 21 [22784/50000]\tLoss: 0.4100\tLR: 0.000337\nTraining Epoch: 21 [22912/50000]\tLoss: 0.2711\tLR: 0.000337\nTraining Epoch: 21 [23040/50000]\tLoss: 0.2774\tLR: 0.000337\nTraining Epoch: 21 [23168/50000]\tLoss: 0.1950\tLR: 0.000337\nTraining Epoch: 21 [23296/50000]\tLoss: 0.2487\tLR: 0.000337\nTraining Epoch: 21 [23424/50000]\tLoss: 0.1774\tLR: 0.000337\nTraining Epoch: 21 [23552/50000]\tLoss: 0.3113\tLR: 0.000337\nTraining Epoch: 21 [23680/50000]\tLoss: 0.2079\tLR: 0.000337\nTraining Epoch: 21 [23808/50000]\tLoss: 0.2037\tLR: 0.000337\nTraining Epoch: 21 [23936/50000]\tLoss: 0.2318\tLR: 0.000337\nTraining Epoch: 21 [24064/50000]\tLoss: 0.1879\tLR: 0.000337\nTraining Epoch: 21 [24192/50000]\tLoss: 0.3285\tLR: 0.000337\nTraining Epoch: 21 [24320/50000]\tLoss: 0.4428\tLR: 0.000337\nTraining Epoch: 21 [24448/50000]\tLoss: 0.2023\tLR: 0.000337\nTraining Epoch: 21 [24576/50000]\tLoss: 0.4043\tLR: 0.000337\nTraining Epoch: 21 [24704/50000]\tLoss: 0.2956\tLR: 0.000337\nTraining Epoch: 21 [24832/50000]\tLoss: 0.2144\tLR: 0.000337\nTraining Epoch: 21 [24960/50000]\tLoss: 0.2331\tLR: 0.000337\nTraining Epoch: 21 [25088/50000]\tLoss: 0.3580\tLR: 0.000337\nTraining Epoch: 21 [25216/50000]\tLoss: 0.2595\tLR: 0.000337\nTraining Epoch: 21 [25344/50000]\tLoss: 0.2231\tLR: 0.000337\nTraining Epoch: 21 [25472/50000]\tLoss: 0.2821\tLR: 0.000337\nTraining Epoch: 21 [25600/50000]\tLoss: 0.3060\tLR: 0.000337\nTraining Epoch: 21 [25728/50000]\tLoss: 0.3077\tLR: 0.000337\nTraining Epoch: 21 [25856/50000]\tLoss: 0.2577\tLR: 0.000337\nTraining Epoch: 21 [25984/50000]\tLoss: 0.3570\tLR: 0.000337\nTraining Epoch: 21 [26112/50000]\tLoss: 0.2726\tLR: 0.000337\nTraining Epoch: 21 [26240/50000]\tLoss: 0.3278\tLR: 0.000337\nTraining Epoch: 21 [26368/50000]\tLoss: 0.2662\tLR: 0.000337\nTraining Epoch: 21 [26496/50000]\tLoss: 0.1790\tLR: 0.000337\nTraining Epoch: 21 [26624/50000]\tLoss: 0.3883\tLR: 0.000337\nTraining Epoch: 21 [26752/50000]\tLoss: 0.2212\tLR: 0.000337\nTraining Epoch: 21 [26880/50000]\tLoss: 0.2034\tLR: 0.000337\nTraining Epoch: 21 [27008/50000]\tLoss: 0.2338\tLR: 0.000337\nTraining Epoch: 21 [27136/50000]\tLoss: 0.2381\tLR: 0.000337\nTraining Epoch: 21 [27264/50000]\tLoss: 0.2498\tLR: 0.000337\nTraining Epoch: 21 [27392/50000]\tLoss: 0.2427\tLR: 0.000337\nTraining Epoch: 21 [27520/50000]\tLoss: 0.2577\tLR: 0.000337\nTraining Epoch: 21 [27648/50000]\tLoss: 0.2178\tLR: 0.000337\nTraining Epoch: 21 [27776/50000]\tLoss: 0.2248\tLR: 0.000337\nTraining Epoch: 21 [27904/50000]\tLoss: 0.2207\tLR: 0.000337\nTraining Epoch: 21 [28032/50000]\tLoss: 0.2113\tLR: 0.000337\nTraining Epoch: 21 [28160/50000]\tLoss: 0.2542\tLR: 0.000337\nTraining Epoch: 21 [28288/50000]\tLoss: 0.2813\tLR: 0.000337\nTraining Epoch: 21 [28416/50000]\tLoss: 0.2854\tLR: 0.000337\nTraining Epoch: 21 [28544/50000]\tLoss: 0.3352\tLR: 0.000337\nTraining Epoch: 21 [28672/50000]\tLoss: 0.3835\tLR: 0.000337\nTraining Epoch: 21 [28800/50000]\tLoss: 0.2800\tLR: 0.000337\nTraining Epoch: 21 [28928/50000]\tLoss: 0.3214\tLR: 0.000337\nTraining Epoch: 21 [29056/50000]\tLoss: 0.4120\tLR: 0.000337\nTraining Epoch: 21 [29184/50000]\tLoss: 0.3119\tLR: 0.000337\nTraining Epoch: 21 [29312/50000]\tLoss: 0.2554\tLR: 0.000337\nTraining Epoch: 21 [29440/50000]\tLoss: 0.2153\tLR: 0.000337\nTraining Epoch: 21 [29568/50000]\tLoss: 0.3225\tLR: 0.000337\nTraining Epoch: 21 [29696/50000]\tLoss: 0.2280\tLR: 0.000337\nTraining Epoch: 21 [29824/50000]\tLoss: 0.3170\tLR: 0.000337\nTraining Epoch: 21 [29952/50000]\tLoss: 0.3268\tLR: 0.000337\nTraining Epoch: 21 [30080/50000]\tLoss: 0.2908\tLR: 0.000337\nTraining Epoch: 21 [30208/50000]\tLoss: 0.3236\tLR: 0.000337\nTraining Epoch: 21 [30336/50000]\tLoss: 0.1304\tLR: 0.000337\nTraining Epoch: 21 [30464/50000]\tLoss: 0.3234\tLR: 0.000337\nTraining Epoch: 21 [30592/50000]\tLoss: 0.2739\tLR: 0.000337\nTraining Epoch: 21 [30720/50000]\tLoss: 0.2710\tLR: 0.000337\nTraining Epoch: 21 [30848/50000]\tLoss: 0.2712\tLR: 0.000337\nTraining Epoch: 21 [30976/50000]\tLoss: 0.2047\tLR: 0.000337\nTraining Epoch: 21 [31104/50000]\tLoss: 0.3172\tLR: 0.000337\nTraining Epoch: 21 [31232/50000]\tLoss: 0.1859\tLR: 0.000337\nTraining Epoch: 21 [31360/50000]\tLoss: 0.2473\tLR: 0.000337\nTraining Epoch: 21 [31488/50000]\tLoss: 0.3207\tLR: 0.000337\nTraining Epoch: 21 [31616/50000]\tLoss: 0.2127\tLR: 0.000337\nTraining Epoch: 21 [31744/50000]\tLoss: 0.2130\tLR: 0.000337\nTraining Epoch: 21 [31872/50000]\tLoss: 0.2943\tLR: 0.000337\nTraining Epoch: 21 [32000/50000]\tLoss: 0.2689\tLR: 0.000337\nTraining Epoch: 21 [32128/50000]\tLoss: 0.3634\tLR: 0.000337\nTraining Epoch: 21 [32256/50000]\tLoss: 0.1864\tLR: 0.000337\nTraining Epoch: 21 [32384/50000]\tLoss: 0.3004\tLR: 0.000337\nTraining Epoch: 21 [32512/50000]\tLoss: 0.2962\tLR: 0.000337\nTraining Epoch: 21 [32640/50000]\tLoss: 0.3166\tLR: 0.000337\nTraining Epoch: 21 [32768/50000]\tLoss: 0.2752\tLR: 0.000337\nTraining Epoch: 21 [32896/50000]\tLoss: 0.2542\tLR: 0.000337\nTraining Epoch: 21 [33024/50000]\tLoss: 0.2278\tLR: 0.000337\nTraining Epoch: 21 [33152/50000]\tLoss: 0.1914\tLR: 0.000337\nTraining Epoch: 21 [33280/50000]\tLoss: 0.1913\tLR: 0.000337\nTraining Epoch: 21 [33408/50000]\tLoss: 0.2424\tLR: 0.000337\nTraining Epoch: 21 [33536/50000]\tLoss: 0.2307\tLR: 0.000337\nTraining Epoch: 21 [33664/50000]\tLoss: 0.2921\tLR: 0.000337\nTraining Epoch: 21 [33792/50000]\tLoss: 0.1867\tLR: 0.000337\nTraining Epoch: 21 [33920/50000]\tLoss: 0.2433\tLR: 0.000337\nTraining Epoch: 21 [34048/50000]\tLoss: 0.2301\tLR: 0.000337\nTraining Epoch: 21 [34176/50000]\tLoss: 0.3608\tLR: 0.000337\nTraining Epoch: 21 [34304/50000]\tLoss: 0.2850\tLR: 0.000337\nTraining Epoch: 21 [34432/50000]\tLoss: 0.1893\tLR: 0.000337\nTraining Epoch: 21 [34560/50000]\tLoss: 0.3024\tLR: 0.000337\nTraining Epoch: 21 [34688/50000]\tLoss: 0.2186\tLR: 0.000337\nTraining Epoch: 21 [34816/50000]\tLoss: 0.1826\tLR: 0.000337\nTraining Epoch: 21 [34944/50000]\tLoss: 0.2122\tLR: 0.000337\nTraining Epoch: 21 [35072/50000]\tLoss: 0.2211\tLR: 0.000337\nTraining Epoch: 21 [35200/50000]\tLoss: 0.2181\tLR: 0.000337\nTraining Epoch: 21 [35328/50000]\tLoss: 0.3385\tLR: 0.000337\nTraining Epoch: 21 [35456/50000]\tLoss: 0.2205\tLR: 0.000337\nTraining Epoch: 21 [35584/50000]\tLoss: 0.3424\tLR: 0.000337\nTraining Epoch: 21 [35712/50000]\tLoss: 0.3012\tLR: 0.000337\nTraining Epoch: 21 [35840/50000]\tLoss: 0.1940\tLR: 0.000337\nTraining Epoch: 21 [35968/50000]\tLoss: 0.2718\tLR: 0.000337\nTraining Epoch: 21 [36096/50000]\tLoss: 0.2738\tLR: 0.000337\nTraining Epoch: 21 [36224/50000]\tLoss: 0.3882\tLR: 0.000337\nTraining Epoch: 21 [36352/50000]\tLoss: 0.2084\tLR: 0.000337\nTraining Epoch: 21 [36480/50000]\tLoss: 0.2495\tLR: 0.000337\nTraining Epoch: 21 [36608/50000]\tLoss: 0.3290\tLR: 0.000337\nTraining Epoch: 21 [36736/50000]\tLoss: 0.2934\tLR: 0.000337\nTraining Epoch: 21 [36864/50000]\tLoss: 0.2727\tLR: 0.000337\nTraining Epoch: 21 [36992/50000]\tLoss: 0.3239\tLR: 0.000337\nTraining Epoch: 21 [37120/50000]\tLoss: 0.2558\tLR: 0.000337\nTraining Epoch: 21 [37248/50000]\tLoss: 0.2557\tLR: 0.000337\nTraining Epoch: 21 [37376/50000]\tLoss: 0.3188\tLR: 0.000337\nTraining Epoch: 21 [37504/50000]\tLoss: 0.1759\tLR: 0.000337\nTraining Epoch: 21 [37632/50000]\tLoss: 0.2903\tLR: 0.000337\nTraining Epoch: 21 [37760/50000]\tLoss: 0.2867\tLR: 0.000337\nTraining Epoch: 21 [37888/50000]\tLoss: 0.2502\tLR: 0.000337\nTraining Epoch: 21 [38016/50000]\tLoss: 0.2562\tLR: 0.000337\nTraining Epoch: 21 [38144/50000]\tLoss: 0.2508\tLR: 0.000337\nTraining Epoch: 21 [38272/50000]\tLoss: 0.2973\tLR: 0.000337\nTraining Epoch: 21 [38400/50000]\tLoss: 0.2156\tLR: 0.000337\nTraining Epoch: 21 [38528/50000]\tLoss: 0.3411\tLR: 0.000337\nTraining Epoch: 21 [38656/50000]\tLoss: 0.3095\tLR: 0.000337\nTraining Epoch: 21 [38784/50000]\tLoss: 0.2749\tLR: 0.000337\nTraining Epoch: 21 [38912/50000]\tLoss: 0.2469\tLR: 0.000337\nTraining Epoch: 21 [39040/50000]\tLoss: 0.2994\tLR: 0.000337\nTraining Epoch: 21 [39168/50000]\tLoss: 0.2959\tLR: 0.000337\nTraining Epoch: 21 [39296/50000]\tLoss: 0.2134\tLR: 0.000337\nTraining Epoch: 21 [39424/50000]\tLoss: 0.2057\tLR: 0.000337\nTraining Epoch: 21 [39552/50000]\tLoss: 0.2624\tLR: 0.000337\nTraining Epoch: 21 [39680/50000]\tLoss: 0.1554\tLR: 0.000337\nTraining Epoch: 21 [39808/50000]\tLoss: 0.2314\tLR: 0.000337\nTraining Epoch: 21 [39936/50000]\tLoss: 0.2194\tLR: 0.000337\nTraining Epoch: 21 [40064/50000]\tLoss: 0.3544\tLR: 0.000337\nTraining Epoch: 21 [40192/50000]\tLoss: 0.3121\tLR: 0.000337\nTraining Epoch: 21 [40320/50000]\tLoss: 0.2272\tLR: 0.000337\nTraining Epoch: 21 [40448/50000]\tLoss: 0.2729\tLR: 0.000337\nTraining Epoch: 21 [40576/50000]\tLoss: 0.1807\tLR: 0.000337\nTraining Epoch: 21 [40704/50000]\tLoss: 0.2428\tLR: 0.000337\nTraining Epoch: 21 [40832/50000]\tLoss: 0.2351\tLR: 0.000337\nTraining Epoch: 21 [40960/50000]\tLoss: 0.3843\tLR: 0.000337\nTraining Epoch: 21 [41088/50000]\tLoss: 0.3519\tLR: 0.000337\nTraining Epoch: 21 [41216/50000]\tLoss: 0.2396\tLR: 0.000337\nTraining Epoch: 21 [41344/50000]\tLoss: 0.3478\tLR: 0.000337\nTraining Epoch: 21 [41472/50000]\tLoss: 0.2878\tLR: 0.000337\nTraining Epoch: 21 [41600/50000]\tLoss: 0.3376\tLR: 0.000337\nTraining Epoch: 21 [41728/50000]\tLoss: 0.3489\tLR: 0.000337\nTraining Epoch: 21 [41856/50000]\tLoss: 0.2158\tLR: 0.000337\nTraining Epoch: 21 [41984/50000]\tLoss: 0.2178\tLR: 0.000337\nTraining Epoch: 21 [42112/50000]\tLoss: 0.3050\tLR: 0.000337\nTraining Epoch: 21 [42240/50000]\tLoss: 0.3788\tLR: 0.000337\nTraining Epoch: 21 [42368/50000]\tLoss: 0.3671\tLR: 0.000337\nTraining Epoch: 21 [42496/50000]\tLoss: 0.2388\tLR: 0.000337\nTraining Epoch: 21 [42624/50000]\tLoss: 0.2123\tLR: 0.000337\nTraining Epoch: 21 [42752/50000]\tLoss: 0.2493\tLR: 0.000337\nTraining Epoch: 21 [42880/50000]\tLoss: 0.2959\tLR: 0.000337\nTraining Epoch: 21 [43008/50000]\tLoss: 0.2357\tLR: 0.000337\nTraining Epoch: 21 [43136/50000]\tLoss: 0.2301\tLR: 0.000337\nTraining Epoch: 21 [43264/50000]\tLoss: 0.2670\tLR: 0.000337\nTraining Epoch: 21 [43392/50000]\tLoss: 0.3033\tLR: 0.000337\nTraining Epoch: 21 [43520/50000]\tLoss: 0.2658\tLR: 0.000337\nTraining Epoch: 21 [43648/50000]\tLoss: 0.2763\tLR: 0.000337\nTraining Epoch: 21 [43776/50000]\tLoss: 0.3895\tLR: 0.000337\nTraining Epoch: 21 [43904/50000]\tLoss: 0.2312\tLR: 0.000337\nTraining Epoch: 21 [44032/50000]\tLoss: 0.2563\tLR: 0.000337\nTraining Epoch: 21 [44160/50000]\tLoss: 0.2733\tLR: 0.000337\nTraining Epoch: 21 [44288/50000]\tLoss: 0.2604\tLR: 0.000337\nTraining Epoch: 21 [44416/50000]\tLoss: 0.2713\tLR: 0.000337\nTraining Epoch: 21 [44544/50000]\tLoss: 0.2226\tLR: 0.000337\nTraining Epoch: 21 [44672/50000]\tLoss: 0.2076\tLR: 0.000337\nTraining Epoch: 21 [44800/50000]\tLoss: 0.2286\tLR: 0.000337\nTraining Epoch: 21 [44928/50000]\tLoss: 0.1531\tLR: 0.000337\nTraining Epoch: 21 [45056/50000]\tLoss: 0.2045\tLR: 0.000337\nTraining Epoch: 21 [45184/50000]\tLoss: 0.4025\tLR: 0.000337\nTraining Epoch: 21 [45312/50000]\tLoss: 0.1963\tLR: 0.000337\nTraining Epoch: 21 [45440/50000]\tLoss: 0.2402\tLR: 0.000337\nTraining Epoch: 21 [45568/50000]\tLoss: 0.2810\tLR: 0.000337\nTraining Epoch: 21 [45696/50000]\tLoss: 0.2532\tLR: 0.000337\nTraining Epoch: 21 [45824/50000]\tLoss: 0.1217\tLR: 0.000337\nTraining Epoch: 21 [45952/50000]\tLoss: 0.2846\tLR: 0.000337\nTraining Epoch: 21 [46080/50000]\tLoss: 0.2953\tLR: 0.000337\nTraining Epoch: 21 [46208/50000]\tLoss: 0.2441\tLR: 0.000337\nTraining Epoch: 21 [46336/50000]\tLoss: 0.1963\tLR: 0.000337\nTraining Epoch: 21 [46464/50000]\tLoss: 0.2290\tLR: 0.000337\nTraining Epoch: 21 [46592/50000]\tLoss: 0.2971\tLR: 0.000337\nTraining Epoch: 21 [46720/50000]\tLoss: 0.3168\tLR: 0.000337\nTraining Epoch: 21 [46848/50000]\tLoss: 0.3437\tLR: 0.000337\nTraining Epoch: 21 [46976/50000]\tLoss: 0.2251\tLR: 0.000337\nTraining Epoch: 21 [47104/50000]\tLoss: 0.2868\tLR: 0.000337\nTraining Epoch: 21 [47232/50000]\tLoss: 0.2444\tLR: 0.000337\nTraining Epoch: 21 [47360/50000]\tLoss: 0.1987\tLR: 0.000337\nTraining Epoch: 21 [47488/50000]\tLoss: 0.2011\tLR: 0.000337\nTraining Epoch: 21 [47616/50000]\tLoss: 0.3116\tLR: 0.000337\nTraining Epoch: 21 [47744/50000]\tLoss: 0.3151\tLR: 0.000337\nTraining Epoch: 21 [47872/50000]\tLoss: 0.1953\tLR: 0.000337\nTraining Epoch: 21 [48000/50000]\tLoss: 0.3028\tLR: 0.000337\nTraining Epoch: 21 [48128/50000]\tLoss: 0.3250\tLR: 0.000337\nTraining Epoch: 21 [48256/50000]\tLoss: 0.2821\tLR: 0.000337\nTraining Epoch: 21 [48384/50000]\tLoss: 0.2797\tLR: 0.000337\nTraining Epoch: 21 [48512/50000]\tLoss: 0.3236\tLR: 0.000337\nTraining Epoch: 21 [48640/50000]\tLoss: 0.3041\tLR: 0.000337\nTraining Epoch: 21 [48768/50000]\tLoss: 0.3173\tLR: 0.000337\nTraining Epoch: 21 [48896/50000]\tLoss: 0.1813\tLR: 0.000337\nTraining Epoch: 21 [49024/50000]\tLoss: 0.3754\tLR: 0.000337\nTraining Epoch: 21 [49152/50000]\tLoss: 0.2360\tLR: 0.000337\nTraining Epoch: 21 [49280/50000]\tLoss: 0.3495\tLR: 0.000337\nTraining Epoch: 21 [49408/50000]\tLoss: 0.3789\tLR: 0.000337\nTraining Epoch: 21 [49536/50000]\tLoss: 0.2385\tLR: 0.000337\nTraining Epoch: 21 [49664/50000]\tLoss: 0.2177\tLR: 0.000337\nTraining Epoch: 21 [49792/50000]\tLoss: 0.2690\tLR: 0.000337\nTraining Epoch: 21 [49920/50000]\tLoss: 0.3070\tLR: 0.000337\nTraining Epoch: 21 [50000/50000]\tLoss: 0.3834\tLR: 0.000337\nTest set: Average loss: 0.0026, Accuracy: 0.8921\n\nTraining Epoch: 22 [128/50000]\tLoss: 0.2856\tLR: 0.000337\nTraining Epoch: 22 [256/50000]\tLoss: 0.1843\tLR: 0.000337\nTraining Epoch: 22 [384/50000]\tLoss: 0.2881\tLR: 0.000337\nTraining Epoch: 22 [512/50000]\tLoss: 0.3036\tLR: 0.000337\nTraining Epoch: 22 [640/50000]\tLoss: 0.2811\tLR: 0.000337\nTraining Epoch: 22 [768/50000]\tLoss: 0.3024\tLR: 0.000337\nTraining Epoch: 22 [896/50000]\tLoss: 0.2242\tLR: 0.000337\nTraining Epoch: 22 [1024/50000]\tLoss: 0.2822\tLR: 0.000337\nTraining Epoch: 22 [1152/50000]\tLoss: 0.1684\tLR: 0.000337\nTraining Epoch: 22 [1280/50000]\tLoss: 0.3295\tLR: 0.000337\nTraining Epoch: 22 [1408/50000]\tLoss: 0.1753\tLR: 0.000337\nTraining Epoch: 22 [1536/50000]\tLoss: 0.2451\tLR: 0.000337\nTraining Epoch: 22 [1664/50000]\tLoss: 0.3428\tLR: 0.000337\nTraining Epoch: 22 [1792/50000]\tLoss: 0.2806\tLR: 0.000337\nTraining Epoch: 22 [1920/50000]\tLoss: 0.3068\tLR: 0.000337\nTraining Epoch: 22 [2048/50000]\tLoss: 0.2704\tLR: 0.000337\nTraining Epoch: 22 [2176/50000]\tLoss: 0.1665\tLR: 0.000337\nTraining Epoch: 22 [2304/50000]\tLoss: 0.2513\tLR: 0.000337\nTraining Epoch: 22 [2432/50000]\tLoss: 0.2318\tLR: 0.000337\nTraining Epoch: 22 [2560/50000]\tLoss: 0.2443\tLR: 0.000337\nTraining Epoch: 22 [2688/50000]\tLoss: 0.1626\tLR: 0.000337\nTraining Epoch: 22 [2816/50000]\tLoss: 0.1697\tLR: 0.000337\nTraining Epoch: 22 [2944/50000]\tLoss: 0.2496\tLR: 0.000337\nTraining Epoch: 22 [3072/50000]\tLoss: 0.4360\tLR: 0.000337\nTraining Epoch: 22 [3200/50000]\tLoss: 0.1925\tLR: 0.000337\nTraining Epoch: 22 [3328/50000]\tLoss: 0.2853\tLR: 0.000337\nTraining Epoch: 22 [3456/50000]\tLoss: 0.2212\tLR: 0.000337\nTraining Epoch: 22 [3584/50000]\tLoss: 0.2096\tLR: 0.000337\nTraining Epoch: 22 [3712/50000]\tLoss: 0.2327\tLR: 0.000337\nTraining Epoch: 22 [3840/50000]\tLoss: 0.2525\tLR: 0.000337\nTraining Epoch: 22 [3968/50000]\tLoss: 0.3066\tLR: 0.000337\nTraining Epoch: 22 [4096/50000]\tLoss: 0.3272\tLR: 0.000337\nTraining Epoch: 22 [4224/50000]\tLoss: 0.1890\tLR: 0.000337\nTraining Epoch: 22 [4352/50000]\tLoss: 0.2297\tLR: 0.000337\nTraining Epoch: 22 [4480/50000]\tLoss: 0.3029\tLR: 0.000337\nTraining Epoch: 22 [4608/50000]\tLoss: 0.2303\tLR: 0.000337\nTraining Epoch: 22 [4736/50000]\tLoss: 0.3469\tLR: 0.000337\nTraining Epoch: 22 [4864/50000]\tLoss: 0.2882\tLR: 0.000337\nTraining Epoch: 22 [4992/50000]\tLoss: 0.2085\tLR: 0.000337\nTraining Epoch: 22 [5120/50000]\tLoss: 0.1955\tLR: 0.000337\nTraining Epoch: 22 [5248/50000]\tLoss: 0.2138\tLR: 0.000337\nTraining Epoch: 22 [5376/50000]\tLoss: 0.3809\tLR: 0.000337\nTraining Epoch: 22 [5504/50000]\tLoss: 0.3077\tLR: 0.000337\nTraining Epoch: 22 [5632/50000]\tLoss: 0.2471\tLR: 0.000337\nTraining Epoch: 22 [5760/50000]\tLoss: 0.2165\tLR: 0.000337\nTraining Epoch: 22 [5888/50000]\tLoss: 0.3936\tLR: 0.000337\nTraining Epoch: 22 [6016/50000]\tLoss: 0.2251\tLR: 0.000337\nTraining Epoch: 22 [6144/50000]\tLoss: 0.1998\tLR: 0.000337\nTraining Epoch: 22 [6272/50000]\tLoss: 0.2446\tLR: 0.000337\nTraining Epoch: 22 [6400/50000]\tLoss: 0.1900\tLR: 0.000337\nTraining Epoch: 22 [6528/50000]\tLoss: 0.2309\tLR: 0.000337\nTraining Epoch: 22 [6656/50000]\tLoss: 0.2596\tLR: 0.000337\nTraining Epoch: 22 [6784/50000]\tLoss: 0.2978\tLR: 0.000337\nTraining Epoch: 22 [6912/50000]\tLoss: 0.2227\tLR: 0.000337\nTraining Epoch: 22 [7040/50000]\tLoss: 0.2909\tLR: 0.000337\nTraining Epoch: 22 [7168/50000]\tLoss: 0.1857\tLR: 0.000337\nTraining Epoch: 22 [7296/50000]\tLoss: 0.2131\tLR: 0.000337\nTraining Epoch: 22 [7424/50000]\tLoss: 0.2662\tLR: 0.000337\nTraining Epoch: 22 [7552/50000]\tLoss: 0.3981\tLR: 0.000337\nTraining Epoch: 22 [7680/50000]\tLoss: 0.1861\tLR: 0.000337\nTraining Epoch: 22 [7808/50000]\tLoss: 0.2489\tLR: 0.000337\nTraining Epoch: 22 [7936/50000]\tLoss: 0.2100\tLR: 0.000337\nTraining Epoch: 22 [8064/50000]\tLoss: 0.1944\tLR: 0.000337\nTraining Epoch: 22 [8192/50000]\tLoss: 0.3147\tLR: 0.000337\nTraining Epoch: 22 [8320/50000]\tLoss: 0.2839\tLR: 0.000337\nTraining Epoch: 22 [8448/50000]\tLoss: 0.2087\tLR: 0.000337\nTraining Epoch: 22 [8576/50000]\tLoss: 0.3585\tLR: 0.000337\nTraining Epoch: 22 [8704/50000]\tLoss: 0.2722\tLR: 0.000337\nTraining Epoch: 22 [8832/50000]\tLoss: 0.3226\tLR: 0.000337\nTraining Epoch: 22 [8960/50000]\tLoss: 0.2769\tLR: 0.000337\nTraining Epoch: 22 [9088/50000]\tLoss: 0.2534\tLR: 0.000337\nTraining Epoch: 22 [9216/50000]\tLoss: 0.2119\tLR: 0.000337\nTraining Epoch: 22 [9344/50000]\tLoss: 0.2306\tLR: 0.000337\nTraining Epoch: 22 [9472/50000]\tLoss: 0.1652\tLR: 0.000337\nTraining Epoch: 22 [9600/50000]\tLoss: 0.2376\tLR: 0.000337\nTraining Epoch: 22 [9728/50000]\tLoss: 0.3446\tLR: 0.000337\nTraining Epoch: 22 [9856/50000]\tLoss: 0.2883\tLR: 0.000337\nTraining Epoch: 22 [9984/50000]\tLoss: 0.2597\tLR: 0.000337\nTraining Epoch: 22 [10112/50000]\tLoss: 0.2425\tLR: 0.000337\nTraining Epoch: 22 [10240/50000]\tLoss: 0.1940\tLR: 0.000337\nTraining Epoch: 22 [10368/50000]\tLoss: 0.2511\tLR: 0.000337\nTraining Epoch: 22 [10496/50000]\tLoss: 0.2845\tLR: 0.000337\nTraining Epoch: 22 [10624/50000]\tLoss: 0.2554\tLR: 0.000337\nTraining Epoch: 22 [10752/50000]\tLoss: 0.3364\tLR: 0.000337\nTraining Epoch: 22 [10880/50000]\tLoss: 0.2983\tLR: 0.000337\nTraining Epoch: 22 [11008/50000]\tLoss: 0.3220\tLR: 0.000337\nTraining Epoch: 22 [11136/50000]\tLoss: 0.3571\tLR: 0.000337\nTraining Epoch: 22 [11264/50000]\tLoss: 0.2044\tLR: 0.000337\nTraining Epoch: 22 [11392/50000]\tLoss: 0.2420\tLR: 0.000337\nTraining Epoch: 22 [11520/50000]\tLoss: 0.3415\tLR: 0.000337\nTraining Epoch: 22 [11648/50000]\tLoss: 0.2220\tLR: 0.000337\nTraining Epoch: 22 [11776/50000]\tLoss: 0.2043\tLR: 0.000337\nTraining Epoch: 22 [11904/50000]\tLoss: 0.2381\tLR: 0.000337\nTraining Epoch: 22 [12032/50000]\tLoss: 0.2197\tLR: 0.000337\nTraining Epoch: 22 [12160/50000]\tLoss: 0.2573\tLR: 0.000337\nTraining Epoch: 22 [12288/50000]\tLoss: 0.2886\tLR: 0.000337\nTraining Epoch: 22 [12416/50000]\tLoss: 0.2936\tLR: 0.000337\nTraining Epoch: 22 [12544/50000]\tLoss: 0.3464\tLR: 0.000337\nTraining Epoch: 22 [12672/50000]\tLoss: 0.2279\tLR: 0.000337\nTraining Epoch: 22 [12800/50000]\tLoss: 0.3759\tLR: 0.000337\nTraining Epoch: 22 [12928/50000]\tLoss: 0.2920\tLR: 0.000337\nTraining Epoch: 22 [13056/50000]\tLoss: 0.3007\tLR: 0.000337\nTraining Epoch: 22 [13184/50000]\tLoss: 0.1745\tLR: 0.000337\nTraining Epoch: 22 [13312/50000]\tLoss: 0.2760\tLR: 0.000337\nTraining Epoch: 22 [13440/50000]\tLoss: 0.4217\tLR: 0.000337\nTraining Epoch: 22 [13568/50000]\tLoss: 0.1721\tLR: 0.000337\nTraining Epoch: 22 [13696/50000]\tLoss: 0.3989\tLR: 0.000337\nTraining Epoch: 22 [13824/50000]\tLoss: 0.2657\tLR: 0.000337\nTraining Epoch: 22 [13952/50000]\tLoss: 0.3616\tLR: 0.000337\nTraining Epoch: 22 [14080/50000]\tLoss: 0.3191\tLR: 0.000337\nTraining Epoch: 22 [14208/50000]\tLoss: 0.1964\tLR: 0.000337\nTraining Epoch: 22 [14336/50000]\tLoss: 0.1626\tLR: 0.000337\nTraining Epoch: 22 [14464/50000]\tLoss: 0.2659\tLR: 0.000337\nTraining Epoch: 22 [14592/50000]\tLoss: 0.3011\tLR: 0.000337\nTraining Epoch: 22 [14720/50000]\tLoss: 0.2775\tLR: 0.000337\nTraining Epoch: 22 [14848/50000]\tLoss: 0.2483\tLR: 0.000337\nTraining Epoch: 22 [14976/50000]\tLoss: 0.3079\tLR: 0.000337\nTraining Epoch: 22 [15104/50000]\tLoss: 0.3043\tLR: 0.000337\nTraining Epoch: 22 [15232/50000]\tLoss: 0.2893\tLR: 0.000337\nTraining Epoch: 22 [15360/50000]\tLoss: 0.2843\tLR: 0.000337\nTraining Epoch: 22 [15488/50000]\tLoss: 0.3047\tLR: 0.000337\nTraining Epoch: 22 [15616/50000]\tLoss: 0.3097\tLR: 0.000337\nTraining Epoch: 22 [15744/50000]\tLoss: 0.2217\tLR: 0.000337\nTraining Epoch: 22 [15872/50000]\tLoss: 0.3124\tLR: 0.000337\nTraining Epoch: 22 [16000/50000]\tLoss: 0.1997\tLR: 0.000337\nTraining Epoch: 22 [16128/50000]\tLoss: 0.2267\tLR: 0.000337\nTraining Epoch: 22 [16256/50000]\tLoss: 0.3055\tLR: 0.000337\nTraining Epoch: 22 [16384/50000]\tLoss: 0.3395\tLR: 0.000337\nTraining Epoch: 22 [16512/50000]\tLoss: 0.3687\tLR: 0.000337\nTraining Epoch: 22 [16640/50000]\tLoss: 0.2637\tLR: 0.000337\nTraining Epoch: 22 [16768/50000]\tLoss: 0.2727\tLR: 0.000337\nTraining Epoch: 22 [16896/50000]\tLoss: 0.1603\tLR: 0.000337\nTraining Epoch: 22 [17024/50000]\tLoss: 0.3212\tLR: 0.000337\nTraining Epoch: 22 [17152/50000]\tLoss: 0.2494\tLR: 0.000337\nTraining Epoch: 22 [17280/50000]\tLoss: 0.1937\tLR: 0.000337\nTraining Epoch: 22 [17408/50000]\tLoss: 0.2719\tLR: 0.000337\nTraining Epoch: 22 [17536/50000]\tLoss: 0.2820\tLR: 0.000337\nTraining Epoch: 22 [17664/50000]\tLoss: 0.1895\tLR: 0.000337\nTraining Epoch: 22 [17792/50000]\tLoss: 0.2884\tLR: 0.000337\nTraining Epoch: 22 [17920/50000]\tLoss: 0.2176\tLR: 0.000337\nTraining Epoch: 22 [18048/50000]\tLoss: 0.2309\tLR: 0.000337\nTraining Epoch: 22 [18176/50000]\tLoss: 0.2310\tLR: 0.000337\nTraining Epoch: 22 [18304/50000]\tLoss: 0.2974\tLR: 0.000337\nTraining Epoch: 22 [18432/50000]\tLoss: 0.1795\tLR: 0.000337\nTraining Epoch: 22 [18560/50000]\tLoss: 0.2995\tLR: 0.000337\nTraining Epoch: 22 [18688/50000]\tLoss: 0.2278\tLR: 0.000337\nTraining Epoch: 22 [18816/50000]\tLoss: 0.2845\tLR: 0.000337\nTraining Epoch: 22 [18944/50000]\tLoss: 0.2323\tLR: 0.000337\nTraining Epoch: 22 [19072/50000]\tLoss: 0.3421\tLR: 0.000337\nTraining Epoch: 22 [19200/50000]\tLoss: 0.2100\tLR: 0.000337\nTraining Epoch: 22 [19328/50000]\tLoss: 0.2077\tLR: 0.000337\nTraining Epoch: 22 [19456/50000]\tLoss: 0.2510\tLR: 0.000337\nTraining Epoch: 22 [19584/50000]\tLoss: 0.2984\tLR: 0.000337\nTraining Epoch: 22 [19712/50000]\tLoss: 0.2676\tLR: 0.000337\nTraining Epoch: 22 [19840/50000]\tLoss: 0.2093\tLR: 0.000337\nTraining Epoch: 22 [19968/50000]\tLoss: 0.2728\tLR: 0.000337\nTraining Epoch: 22 [20096/50000]\tLoss: 0.3144\tLR: 0.000337\nTraining Epoch: 22 [20224/50000]\tLoss: 0.3125\tLR: 0.000337\nTraining Epoch: 22 [20352/50000]\tLoss: 0.2357\tLR: 0.000337\nTraining Epoch: 22 [20480/50000]\tLoss: 0.2279\tLR: 0.000337\nTraining Epoch: 22 [20608/50000]\tLoss: 0.3299\tLR: 0.000337\nTraining Epoch: 22 [20736/50000]\tLoss: 0.2957\tLR: 0.000337\nTraining Epoch: 22 [20864/50000]\tLoss: 0.2113\tLR: 0.000337\nTraining Epoch: 22 [20992/50000]\tLoss: 0.2222\tLR: 0.000337\nTraining Epoch: 22 [21120/50000]\tLoss: 0.3059\tLR: 0.000337\nTraining Epoch: 22 [21248/50000]\tLoss: 0.3466\tLR: 0.000337\nTraining Epoch: 22 [21376/50000]\tLoss: 0.1840\tLR: 0.000337\nTraining Epoch: 22 [21504/50000]\tLoss: 0.2493\tLR: 0.000337\nTraining Epoch: 22 [21632/50000]\tLoss: 0.3029\tLR: 0.000337\nTraining Epoch: 22 [21760/50000]\tLoss: 0.2687\tLR: 0.000337\nTraining Epoch: 22 [21888/50000]\tLoss: 0.1809\tLR: 0.000337\nTraining Epoch: 22 [22016/50000]\tLoss: 0.3914\tLR: 0.000337\nTraining Epoch: 22 [22144/50000]\tLoss: 0.2602\tLR: 0.000337\nTraining Epoch: 22 [22272/50000]\tLoss: 0.2767\tLR: 0.000337\nTraining Epoch: 22 [22400/50000]\tLoss: 0.3742\tLR: 0.000337\nTraining Epoch: 22 [22528/50000]\tLoss: 0.2272\tLR: 0.000337\nTraining Epoch: 22 [22656/50000]\tLoss: 0.2615\tLR: 0.000337\nTraining Epoch: 22 [22784/50000]\tLoss: 0.2767\tLR: 0.000337\nTraining Epoch: 22 [22912/50000]\tLoss: 0.2552\tLR: 0.000337\nTraining Epoch: 22 [23040/50000]\tLoss: 0.3785\tLR: 0.000337\nTraining Epoch: 22 [23168/50000]\tLoss: 0.3037\tLR: 0.000337\nTraining Epoch: 22 [23296/50000]\tLoss: 0.3206\tLR: 0.000337\nTraining Epoch: 22 [23424/50000]\tLoss: 0.3468\tLR: 0.000337\nTraining Epoch: 22 [23552/50000]\tLoss: 0.3180\tLR: 0.000337\nTraining Epoch: 22 [23680/50000]\tLoss: 0.2088\tLR: 0.000337\nTraining Epoch: 22 [23808/50000]\tLoss: 0.2768\tLR: 0.000337\nTraining Epoch: 22 [23936/50000]\tLoss: 0.1549\tLR: 0.000337\nTraining Epoch: 22 [24064/50000]\tLoss: 0.3721\tLR: 0.000337\nTraining Epoch: 22 [24192/50000]\tLoss: 0.2355\tLR: 0.000337\nTraining Epoch: 22 [24320/50000]\tLoss: 0.4628\tLR: 0.000337\nTraining Epoch: 22 [24448/50000]\tLoss: 0.2185\tLR: 0.000337\nTraining Epoch: 22 [24576/50000]\tLoss: 0.3145\tLR: 0.000337\nTraining Epoch: 22 [24704/50000]\tLoss: 0.2081\tLR: 0.000337\nTraining Epoch: 22 [24832/50000]\tLoss: 0.3372\tLR: 0.000337\nTraining Epoch: 22 [24960/50000]\tLoss: 0.3589\tLR: 0.000337\nTraining Epoch: 22 [25088/50000]\tLoss: 0.3206\tLR: 0.000337\nTraining Epoch: 22 [25216/50000]\tLoss: 0.3663\tLR: 0.000337\nTraining Epoch: 22 [25344/50000]\tLoss: 0.4116\tLR: 0.000337\nTraining Epoch: 22 [25472/50000]\tLoss: 0.2862\tLR: 0.000337\nTraining Epoch: 22 [25600/50000]\tLoss: 0.2762\tLR: 0.000337\nTraining Epoch: 22 [25728/50000]\tLoss: 0.2388\tLR: 0.000337\nTraining Epoch: 22 [25856/50000]\tLoss: 0.2841\tLR: 0.000337\nTraining Epoch: 22 [25984/50000]\tLoss: 0.2615\tLR: 0.000337\nTraining Epoch: 22 [26112/50000]\tLoss: 0.1782\tLR: 0.000337\nTraining Epoch: 22 [26240/50000]\tLoss: 0.3194\tLR: 0.000337\nTraining Epoch: 22 [26368/50000]\tLoss: 0.3759\tLR: 0.000337\nTraining Epoch: 22 [26496/50000]\tLoss: 0.3218\tLR: 0.000337\nTraining Epoch: 22 [26624/50000]\tLoss: 0.3555\tLR: 0.000337\nTraining Epoch: 22 [26752/50000]\tLoss: 0.2159\tLR: 0.000337\nTraining Epoch: 22 [26880/50000]\tLoss: 0.2539\tLR: 0.000337\nTraining Epoch: 22 [27008/50000]\tLoss: 0.1742\tLR: 0.000337\nTraining Epoch: 22 [27136/50000]\tLoss: 0.2874\tLR: 0.000337\nTraining Epoch: 22 [27264/50000]\tLoss: 0.3365\tLR: 0.000337\nTraining Epoch: 22 [27392/50000]\tLoss: 0.2901\tLR: 0.000337\nTraining Epoch: 22 [27520/50000]\tLoss: 0.3368\tLR: 0.000337\nTraining Epoch: 22 [27648/50000]\tLoss: 0.2489\tLR: 0.000337\nTraining Epoch: 22 [27776/50000]\tLoss: 0.3477\tLR: 0.000337\nTraining Epoch: 22 [27904/50000]\tLoss: 0.3068\tLR: 0.000337\nTraining Epoch: 22 [28032/50000]\tLoss: 0.2917\tLR: 0.000337\nTraining Epoch: 22 [28160/50000]\tLoss: 0.2787\tLR: 0.000337\nTraining Epoch: 22 [28288/50000]\tLoss: 0.2989\tLR: 0.000337\nTraining Epoch: 22 [28416/50000]\tLoss: 0.2936\tLR: 0.000337\nTraining Epoch: 22 [28544/50000]\tLoss: 0.2334\tLR: 0.000337\nTraining Epoch: 22 [28672/50000]\tLoss: 0.2548\tLR: 0.000337\nTraining Epoch: 22 [28800/50000]\tLoss: 0.2175\tLR: 0.000337\nTraining Epoch: 22 [28928/50000]\tLoss: 0.2079\tLR: 0.000337\nTraining Epoch: 22 [29056/50000]\tLoss: 0.3874\tLR: 0.000337\nTraining Epoch: 22 [29184/50000]\tLoss: 0.2972\tLR: 0.000337\nTraining Epoch: 22 [29312/50000]\tLoss: 0.2788\tLR: 0.000337\nTraining Epoch: 22 [29440/50000]\tLoss: 0.2430\tLR: 0.000337\nTraining Epoch: 22 [29568/50000]\tLoss: 0.2308\tLR: 0.000337\nTraining Epoch: 22 [29696/50000]\tLoss: 0.2777\tLR: 0.000337\nTraining Epoch: 22 [29824/50000]\tLoss: 0.2711\tLR: 0.000337\nTraining Epoch: 22 [29952/50000]\tLoss: 0.1545\tLR: 0.000337\nTraining Epoch: 22 [30080/50000]\tLoss: 0.2739\tLR: 0.000337\nTraining Epoch: 22 [30208/50000]\tLoss: 0.4142\tLR: 0.000337\nTraining Epoch: 22 [30336/50000]\tLoss: 0.2715\tLR: 0.000337\nTraining Epoch: 22 [30464/50000]\tLoss: 0.2869\tLR: 0.000337\nTraining Epoch: 22 [30592/50000]\tLoss: 0.3039\tLR: 0.000337\nTraining Epoch: 22 [30720/50000]\tLoss: 0.3327\tLR: 0.000337\nTraining Epoch: 22 [30848/50000]\tLoss: 0.2306\tLR: 0.000337\nTraining Epoch: 22 [30976/50000]\tLoss: 0.2447\tLR: 0.000337\nTraining Epoch: 22 [31104/50000]\tLoss: 0.2730\tLR: 0.000337\nTraining Epoch: 22 [31232/50000]\tLoss: 0.2554\tLR: 0.000337\nTraining Epoch: 22 [31360/50000]\tLoss: 0.2024\tLR: 0.000337\nTraining Epoch: 22 [31488/50000]\tLoss: 0.2645\tLR: 0.000337\nTraining Epoch: 22 [31616/50000]\tLoss: 0.3610\tLR: 0.000337\nTraining Epoch: 22 [31744/50000]\tLoss: 0.3024\tLR: 0.000337\nTraining Epoch: 22 [31872/50000]\tLoss: 0.3433\tLR: 0.000337\nTraining Epoch: 22 [32000/50000]\tLoss: 0.3308\tLR: 0.000337\nTraining Epoch: 22 [32128/50000]\tLoss: 0.2445\tLR: 0.000337\nTraining Epoch: 22 [32256/50000]\tLoss: 0.2884\tLR: 0.000337\nTraining Epoch: 22 [32384/50000]\tLoss: 0.2381\tLR: 0.000337\nTraining Epoch: 22 [32512/50000]\tLoss: 0.3556\tLR: 0.000337\nTraining Epoch: 22 [32640/50000]\tLoss: 0.3372\tLR: 0.000337\nTraining Epoch: 22 [32768/50000]\tLoss: 0.2473\tLR: 0.000337\nTraining Epoch: 22 [32896/50000]\tLoss: 0.2704\tLR: 0.000337\nTraining Epoch: 22 [33024/50000]\tLoss: 0.5023\tLR: 0.000337\nTraining Epoch: 22 [33152/50000]\tLoss: 0.3638\tLR: 0.000337\nTraining Epoch: 22 [33280/50000]\tLoss: 0.2418\tLR: 0.000337\nTraining Epoch: 22 [33408/50000]\tLoss: 0.3366\tLR: 0.000337\nTraining Epoch: 22 [33536/50000]\tLoss: 0.2467\tLR: 0.000337\nTraining Epoch: 22 [33664/50000]\tLoss: 0.2566\tLR: 0.000337\nTraining Epoch: 22 [33792/50000]\tLoss: 0.2746\tLR: 0.000337\nTraining Epoch: 22 [33920/50000]\tLoss: 0.2716\tLR: 0.000337\nTraining Epoch: 22 [34048/50000]\tLoss: 0.2982\tLR: 0.000337\nTraining Epoch: 22 [34176/50000]\tLoss: 0.3199\tLR: 0.000337\nTraining Epoch: 22 [34304/50000]\tLoss: 0.2959\tLR: 0.000337\nTraining Epoch: 22 [34432/50000]\tLoss: 0.1903\tLR: 0.000337\nTraining Epoch: 22 [34560/50000]\tLoss: 0.2849\tLR: 0.000337\nTraining Epoch: 22 [34688/50000]\tLoss: 0.2741\tLR: 0.000337\nTraining Epoch: 22 [34816/50000]\tLoss: 0.2375\tLR: 0.000337\nTraining Epoch: 22 [34944/50000]\tLoss: 0.2664\tLR: 0.000337\nTraining Epoch: 22 [35072/50000]\tLoss: 0.2266\tLR: 0.000337\nTraining Epoch: 22 [35200/50000]\tLoss: 0.2658\tLR: 0.000337\nTraining Epoch: 22 [35328/50000]\tLoss: 0.1957\tLR: 0.000337\nTraining Epoch: 22 [35456/50000]\tLoss: 0.2510\tLR: 0.000337\nTraining Epoch: 22 [35584/50000]\tLoss: 0.2842\tLR: 0.000337\nTraining Epoch: 22 [35712/50000]\tLoss: 0.2489\tLR: 0.000337\nTraining Epoch: 22 [35840/50000]\tLoss: 0.2691\tLR: 0.000337\nTraining Epoch: 22 [35968/50000]\tLoss: 0.1524\tLR: 0.000337\nTraining Epoch: 22 [36096/50000]\tLoss: 0.2565\tLR: 0.000337\nTraining Epoch: 22 [36224/50000]\tLoss: 0.1892\tLR: 0.000337\nTraining Epoch: 22 [36352/50000]\tLoss: 0.3445\tLR: 0.000337\nTraining Epoch: 22 [36480/50000]\tLoss: 0.2099\tLR: 0.000337\nTraining Epoch: 22 [36608/50000]\tLoss: 0.3406\tLR: 0.000337\nTraining Epoch: 22 [36736/50000]\tLoss: 0.2804\tLR: 0.000337\nTraining Epoch: 22 [36864/50000]\tLoss: 0.1663\tLR: 0.000337\nTraining Epoch: 22 [36992/50000]\tLoss: 0.2997\tLR: 0.000337\nTraining Epoch: 22 [37120/50000]\tLoss: 0.2632\tLR: 0.000337\nTraining Epoch: 22 [37248/50000]\tLoss: 0.2597\tLR: 0.000337\nTraining Epoch: 22 [37376/50000]\tLoss: 0.2743\tLR: 0.000337\nTraining Epoch: 22 [37504/50000]\tLoss: 0.2524\tLR: 0.000337\nTraining Epoch: 22 [37632/50000]\tLoss: 0.3513\tLR: 0.000337\nTraining Epoch: 22 [37760/50000]\tLoss: 0.1339\tLR: 0.000337\nTraining Epoch: 22 [37888/50000]\tLoss: 0.2199\tLR: 0.000337\nTraining Epoch: 22 [38016/50000]\tLoss: 0.3677\tLR: 0.000337\nTraining Epoch: 22 [38144/50000]\tLoss: 0.1712\tLR: 0.000337\nTraining Epoch: 22 [38272/50000]\tLoss: 0.2545\tLR: 0.000337\nTraining Epoch: 22 [38400/50000]\tLoss: 0.2328\tLR: 0.000337\nTraining Epoch: 22 [38528/50000]\tLoss: 0.3210\tLR: 0.000337\nTraining Epoch: 22 [38656/50000]\tLoss: 0.1211\tLR: 0.000337\nTraining Epoch: 22 [38784/50000]\tLoss: 0.2407\tLR: 0.000337\nTraining Epoch: 22 [38912/50000]\tLoss: 0.2114\tLR: 0.000337\nTraining Epoch: 22 [39040/50000]\tLoss: 0.2241\tLR: 0.000337\nTraining Epoch: 22 [39168/50000]\tLoss: 0.2947\tLR: 0.000337\nTraining Epoch: 22 [39296/50000]\tLoss: 0.3168\tLR: 0.000337\nTraining Epoch: 22 [39424/50000]\tLoss: 0.2339\tLR: 0.000337\nTraining Epoch: 22 [39552/50000]\tLoss: 0.2622\tLR: 0.000337\nTraining Epoch: 22 [39680/50000]\tLoss: 0.1789\tLR: 0.000337\nTraining Epoch: 22 [39808/50000]\tLoss: 0.2197\tLR: 0.000337\nTraining Epoch: 22 [39936/50000]\tLoss: 0.2625\tLR: 0.000337\nTraining Epoch: 22 [40064/50000]\tLoss: 0.2604\tLR: 0.000337\nTraining Epoch: 22 [40192/50000]\tLoss: 0.2452\tLR: 0.000337\nTraining Epoch: 22 [40320/50000]\tLoss: 0.2014\tLR: 0.000337\nTraining Epoch: 22 [40448/50000]\tLoss: 0.2299\tLR: 0.000337\nTraining Epoch: 22 [40576/50000]\tLoss: 0.2309\tLR: 0.000337\nTraining Epoch: 22 [40704/50000]\tLoss: 0.2662\tLR: 0.000337\nTraining Epoch: 22 [40832/50000]\tLoss: 0.2697\tLR: 0.000337\nTraining Epoch: 22 [40960/50000]\tLoss: 0.2974\tLR: 0.000337\nTraining Epoch: 22 [41088/50000]\tLoss: 0.2581\tLR: 0.000337\nTraining Epoch: 22 [41216/50000]\tLoss: 0.2471\tLR: 0.000337\nTraining Epoch: 22 [41344/50000]\tLoss: 0.2409\tLR: 0.000337\nTraining Epoch: 22 [41472/50000]\tLoss: 0.3008\tLR: 0.000337\nTraining Epoch: 22 [41600/50000]\tLoss: 0.2392\tLR: 0.000337\nTraining Epoch: 22 [41728/50000]\tLoss: 0.2429\tLR: 0.000337\nTraining Epoch: 22 [41856/50000]\tLoss: 0.2667\tLR: 0.000337\nTraining Epoch: 22 [41984/50000]\tLoss: 0.2596\tLR: 0.000337\nTraining Epoch: 22 [42112/50000]\tLoss: 0.3277\tLR: 0.000337\nTraining Epoch: 22 [42240/50000]\tLoss: 0.1584\tLR: 0.000337\nTraining Epoch: 22 [42368/50000]\tLoss: 0.2217\tLR: 0.000337\nTraining Epoch: 22 [42496/50000]\tLoss: 0.2482\tLR: 0.000337\nTraining Epoch: 22 [42624/50000]\tLoss: 0.2996\tLR: 0.000337\nTraining Epoch: 22 [42752/50000]\tLoss: 0.1965\tLR: 0.000337\nTraining Epoch: 22 [42880/50000]\tLoss: 0.2256\tLR: 0.000337\nTraining Epoch: 22 [43008/50000]\tLoss: 0.2287\tLR: 0.000337\nTraining Epoch: 22 [43136/50000]\tLoss: 0.2292\tLR: 0.000337\nTraining Epoch: 22 [43264/50000]\tLoss: 0.3290\tLR: 0.000337\nTraining Epoch: 22 [43392/50000]\tLoss: 0.2768\tLR: 0.000337\nTraining Epoch: 22 [43520/50000]\tLoss: 0.3543\tLR: 0.000337\nTraining Epoch: 22 [43648/50000]\tLoss: 0.1164\tLR: 0.000337\nTraining Epoch: 22 [43776/50000]\tLoss: 0.2998\tLR: 0.000337\nTraining Epoch: 22 [43904/50000]\tLoss: 0.1434\tLR: 0.000337\nTraining Epoch: 22 [44032/50000]\tLoss: 0.2420\tLR: 0.000337\nTraining Epoch: 22 [44160/50000]\tLoss: 0.3006\tLR: 0.000337\nTraining Epoch: 22 [44288/50000]\tLoss: 0.1516\tLR: 0.000337\nTraining Epoch: 22 [44416/50000]\tLoss: 0.2571\tLR: 0.000337\nTraining Epoch: 22 [44544/50000]\tLoss: 0.2337\tLR: 0.000337\nTraining Epoch: 22 [44672/50000]\tLoss: 0.3109\tLR: 0.000337\nTraining Epoch: 22 [44800/50000]\tLoss: 0.2788\tLR: 0.000337\nTraining Epoch: 22 [44928/50000]\tLoss: 0.1890\tLR: 0.000337\nTraining Epoch: 22 [45056/50000]\tLoss: 0.3416\tLR: 0.000337\nTraining Epoch: 22 [45184/50000]\tLoss: 0.2415\tLR: 0.000337\nTraining Epoch: 22 [45312/50000]\tLoss: 0.3872\tLR: 0.000337\nTraining Epoch: 22 [45440/50000]\tLoss: 0.3861\tLR: 0.000337\nTraining Epoch: 22 [45568/50000]\tLoss: 0.2546\tLR: 0.000337\nTraining Epoch: 22 [45696/50000]\tLoss: 0.2739\tLR: 0.000337\nTraining Epoch: 22 [45824/50000]\tLoss: 0.3121\tLR: 0.000337\nTraining Epoch: 22 [45952/50000]\tLoss: 0.2167\tLR: 0.000337\nTraining Epoch: 22 [46080/50000]\tLoss: 0.1716\tLR: 0.000337\nTraining Epoch: 22 [46208/50000]\tLoss: 0.2865\tLR: 0.000337\nTraining Epoch: 22 [46336/50000]\tLoss: 0.2622\tLR: 0.000337\nTraining Epoch: 22 [46464/50000]\tLoss: 0.1527\tLR: 0.000337\nTraining Epoch: 22 [46592/50000]\tLoss: 0.3045\tLR: 0.000337\nTraining Epoch: 22 [46720/50000]\tLoss: 0.3171\tLR: 0.000337\nTraining Epoch: 22 [46848/50000]\tLoss: 0.2212\tLR: 0.000337\nTraining Epoch: 22 [46976/50000]\tLoss: 0.2873\tLR: 0.000337\nTraining Epoch: 22 [47104/50000]\tLoss: 0.2253\tLR: 0.000337\nTraining Epoch: 22 [47232/50000]\tLoss: 0.4082\tLR: 0.000337\nTraining Epoch: 22 [47360/50000]\tLoss: 0.3231\tLR: 0.000337\nTraining Epoch: 22 [47488/50000]\tLoss: 0.1637\tLR: 0.000337\nTraining Epoch: 22 [47616/50000]\tLoss: 0.2876\tLR: 0.000337\nTraining Epoch: 22 [47744/50000]\tLoss: 0.2783\tLR: 0.000337\nTraining Epoch: 22 [47872/50000]\tLoss: 0.2716\tLR: 0.000337\nTraining Epoch: 22 [48000/50000]\tLoss: 0.2471\tLR: 0.000337\nTraining Epoch: 22 [48128/50000]\tLoss: 0.1735\tLR: 0.000337\nTraining Epoch: 22 [48256/50000]\tLoss: 0.2258\tLR: 0.000337\nTraining Epoch: 22 [48384/50000]\tLoss: 0.3627\tLR: 0.000337\nTraining Epoch: 22 [48512/50000]\tLoss: 0.1804\tLR: 0.000337\nTraining Epoch: 22 [48640/50000]\tLoss: 0.2889\tLR: 0.000337\nTraining Epoch: 22 [48768/50000]\tLoss: 0.4037\tLR: 0.000337\nTraining Epoch: 22 [48896/50000]\tLoss: 0.2921\tLR: 0.000337\nTraining Epoch: 22 [49024/50000]\tLoss: 0.2450\tLR: 0.000337\nTraining Epoch: 22 [49152/50000]\tLoss: 0.3429\tLR: 0.000337\nTraining Epoch: 22 [49280/50000]\tLoss: 0.3703\tLR: 0.000337\nTraining Epoch: 22 [49408/50000]\tLoss: 0.2614\tLR: 0.000337\nTraining Epoch: 22 [49536/50000]\tLoss: 0.3112\tLR: 0.000337\nTraining Epoch: 22 [49664/50000]\tLoss: 0.2746\tLR: 0.000337\nTraining Epoch: 22 [49792/50000]\tLoss: 0.2941\tLR: 0.000337\nTraining Epoch: 22 [49920/50000]\tLoss: 0.2695\tLR: 0.000337\nTraining Epoch: 22 [50000/50000]\tLoss: 0.2363\tLR: 0.000337\nTest set: Average loss: 0.0025, Accuracy: 0.8942\n\nTraining Epoch: 23 [128/50000]\tLoss: 0.4046\tLR: 0.000337\nTraining Epoch: 23 [256/50000]\tLoss: 0.2141\tLR: 0.000337\nTraining Epoch: 23 [384/50000]\tLoss: 0.3036\tLR: 0.000337\nTraining Epoch: 23 [512/50000]\tLoss: 0.2314\tLR: 0.000337\nTraining Epoch: 23 [640/50000]\tLoss: 0.2640\tLR: 0.000337\nTraining Epoch: 23 [768/50000]\tLoss: 0.2119\tLR: 0.000337\nTraining Epoch: 23 [896/50000]\tLoss: 0.3062\tLR: 0.000337\nTraining Epoch: 23 [1024/50000]\tLoss: 0.2276\tLR: 0.000337\nTraining Epoch: 23 [1152/50000]\tLoss: 0.3932\tLR: 0.000337\nTraining Epoch: 23 [1280/50000]\tLoss: 0.2286\tLR: 0.000337\nTraining Epoch: 23 [1408/50000]\tLoss: 0.2717\tLR: 0.000337\nTraining Epoch: 23 [1536/50000]\tLoss: 0.2422\tLR: 0.000337\nTraining Epoch: 23 [1664/50000]\tLoss: 0.2706\tLR: 0.000337\nTraining Epoch: 23 [1792/50000]\tLoss: 0.3037\tLR: 0.000337\nTraining Epoch: 23 [1920/50000]\tLoss: 0.3503\tLR: 0.000337\nTraining Epoch: 23 [2048/50000]\tLoss: 0.2834\tLR: 0.000337\nTraining Epoch: 23 [2176/50000]\tLoss: 0.2653\tLR: 0.000337\nTraining Epoch: 23 [2304/50000]\tLoss: 0.3106\tLR: 0.000337\nTraining Epoch: 23 [2432/50000]\tLoss: 0.2734\tLR: 0.000337\nTraining Epoch: 23 [2560/50000]\tLoss: 0.3029\tLR: 0.000337\nTraining Epoch: 23 [2688/50000]\tLoss: 0.2848\tLR: 0.000337\nTraining Epoch: 23 [2816/50000]\tLoss: 0.2887\tLR: 0.000337\nTraining Epoch: 23 [2944/50000]\tLoss: 0.2046\tLR: 0.000337\nTraining Epoch: 23 [3072/50000]\tLoss: 0.2545\tLR: 0.000337\nTraining Epoch: 23 [3200/50000]\tLoss: 0.2619\tLR: 0.000337\nTraining Epoch: 23 [3328/50000]\tLoss: 0.2662\tLR: 0.000337\nTraining Epoch: 23 [3456/50000]\tLoss: 0.1932\tLR: 0.000337\nTraining Epoch: 23 [3584/50000]\tLoss: 0.2849\tLR: 0.000337\nTraining Epoch: 23 [3712/50000]\tLoss: 0.2595\tLR: 0.000337\nTraining Epoch: 23 [3840/50000]\tLoss: 0.1973\tLR: 0.000337\nTraining Epoch: 23 [3968/50000]\tLoss: 0.2188\tLR: 0.000337\nTraining Epoch: 23 [4096/50000]\tLoss: 0.2031\tLR: 0.000337\nTraining Epoch: 23 [4224/50000]\tLoss: 0.1943\tLR: 0.000337\nTraining Epoch: 23 [4352/50000]\tLoss: 0.2515\tLR: 0.000337\nTraining Epoch: 23 [4480/50000]\tLoss: 0.1322\tLR: 0.000337\nTraining Epoch: 23 [4608/50000]\tLoss: 0.2362\tLR: 0.000337\nTraining Epoch: 23 [4736/50000]\tLoss: 0.2972\tLR: 0.000337\nTraining Epoch: 23 [4864/50000]\tLoss: 0.2100\tLR: 0.000337\nTraining Epoch: 23 [4992/50000]\tLoss: 0.1997\tLR: 0.000337\nTraining Epoch: 23 [5120/50000]\tLoss: 0.1667\tLR: 0.000337\nTraining Epoch: 23 [5248/50000]\tLoss: 0.3408\tLR: 0.000337\nTraining Epoch: 23 [5376/50000]\tLoss: 0.3247\tLR: 0.000337\nTraining Epoch: 23 [5504/50000]\tLoss: 0.2812\tLR: 0.000337\nTraining Epoch: 23 [5632/50000]\tLoss: 0.3036\tLR: 0.000337\nTraining Epoch: 23 [5760/50000]\tLoss: 0.3457\tLR: 0.000337\nTraining Epoch: 23 [5888/50000]\tLoss: 0.1950\tLR: 0.000337\nTraining Epoch: 23 [6016/50000]\tLoss: 0.2843\tLR: 0.000337\nTraining Epoch: 23 [6144/50000]\tLoss: 0.2260\tLR: 0.000337\nTraining Epoch: 23 [6272/50000]\tLoss: 0.2921\tLR: 0.000337\nTraining Epoch: 23 [6400/50000]\tLoss: 0.2102\tLR: 0.000337\nTraining Epoch: 23 [6528/50000]\tLoss: 0.2967\tLR: 0.000337\nTraining Epoch: 23 [6656/50000]\tLoss: 0.2213\tLR: 0.000337\nTraining Epoch: 23 [6784/50000]\tLoss: 0.2606\tLR: 0.000337\nTraining Epoch: 23 [6912/50000]\tLoss: 0.2156\tLR: 0.000337\nTraining Epoch: 23 [7040/50000]\tLoss: 0.2783\tLR: 0.000337\nTraining Epoch: 23 [7168/50000]\tLoss: 0.1958\tLR: 0.000337\nTraining Epoch: 23 [7296/50000]\tLoss: 0.1742\tLR: 0.000337\nTraining Epoch: 23 [7424/50000]\tLoss: 0.2590\tLR: 0.000337\nTraining Epoch: 23 [7552/50000]\tLoss: 0.2703\tLR: 0.000337\nTraining Epoch: 23 [7680/50000]\tLoss: 0.2284\tLR: 0.000337\nTraining Epoch: 23 [7808/50000]\tLoss: 0.2894\tLR: 0.000337\nTraining Epoch: 23 [7936/50000]\tLoss: 0.2490\tLR: 0.000337\nTraining Epoch: 23 [8064/50000]\tLoss: 0.2388\tLR: 0.000337\nTraining Epoch: 23 [8192/50000]\tLoss: 0.3155\tLR: 0.000337\nTraining Epoch: 23 [8320/50000]\tLoss: 0.1315\tLR: 0.000337\nTraining Epoch: 23 [8448/50000]\tLoss: 0.3461\tLR: 0.000337\nTraining Epoch: 23 [8576/50000]\tLoss: 0.2406\tLR: 0.000337\nTraining Epoch: 23 [8704/50000]\tLoss: 0.2638\tLR: 0.000337\nTraining Epoch: 23 [8832/50000]\tLoss: 0.1566\tLR: 0.000337\nTraining Epoch: 23 [8960/50000]\tLoss: 0.2334\tLR: 0.000337\nTraining Epoch: 23 [9088/50000]\tLoss: 0.2403\tLR: 0.000337\nTraining Epoch: 23 [9216/50000]\tLoss: 0.1951\tLR: 0.000337\nTraining Epoch: 23 [9344/50000]\tLoss: 0.2687\tLR: 0.000337\nTraining Epoch: 23 [9472/50000]\tLoss: 0.2791\tLR: 0.000337\nTraining Epoch: 23 [9600/50000]\tLoss: 0.2223\tLR: 0.000337\nTraining Epoch: 23 [9728/50000]\tLoss: 0.2682\tLR: 0.000337\nTraining Epoch: 23 [9856/50000]\tLoss: 0.3267\tLR: 0.000337\nTraining Epoch: 23 [9984/50000]\tLoss: 0.2172\tLR: 0.000337\nTraining Epoch: 23 [10112/50000]\tLoss: 0.2249\tLR: 0.000337\nTraining Epoch: 23 [10240/50000]\tLoss: 0.2685\tLR: 0.000337\nTraining Epoch: 23 [10368/50000]\tLoss: 0.2668\tLR: 0.000337\nTraining Epoch: 23 [10496/50000]\tLoss: 0.3165\tLR: 0.000337\nTraining Epoch: 23 [10624/50000]\tLoss: 0.3418\tLR: 0.000337\nTraining Epoch: 23 [10752/50000]\tLoss: 0.2059\tLR: 0.000337\nTraining Epoch: 23 [10880/50000]\tLoss: 0.2950\tLR: 0.000337\nTraining Epoch: 23 [11008/50000]\tLoss: 0.2932\tLR: 0.000337\nTraining Epoch: 23 [11136/50000]\tLoss: 0.2968\tLR: 0.000337\nTraining Epoch: 23 [11264/50000]\tLoss: 0.2595\tLR: 0.000337\nTraining Epoch: 23 [11392/50000]\tLoss: 0.2792\tLR: 0.000337\nTraining Epoch: 23 [11520/50000]\tLoss: 0.2119\tLR: 0.000337\nTraining Epoch: 23 [11648/50000]\tLoss: 0.3084\tLR: 0.000337\nTraining Epoch: 23 [11776/50000]\tLoss: 0.2467\tLR: 0.000337\nTraining Epoch: 23 [11904/50000]\tLoss: 0.2769\tLR: 0.000337\nTraining Epoch: 23 [12032/50000]\tLoss: 0.1583\tLR: 0.000337\nTraining Epoch: 23 [12160/50000]\tLoss: 0.2565\tLR: 0.000337\nTraining Epoch: 23 [12288/50000]\tLoss: 0.2966\tLR: 0.000337\nTraining Epoch: 23 [12416/50000]\tLoss: 0.2410\tLR: 0.000337\nTraining Epoch: 23 [12544/50000]\tLoss: 0.1762\tLR: 0.000337\nTraining Epoch: 23 [12672/50000]\tLoss: 0.2547\tLR: 0.000337\nTraining Epoch: 23 [12800/50000]\tLoss: 0.2547\tLR: 0.000337\nTraining Epoch: 23 [12928/50000]\tLoss: 0.2951\tLR: 0.000337\nTraining Epoch: 23 [13056/50000]\tLoss: 0.3018\tLR: 0.000337\nTraining Epoch: 23 [13184/50000]\tLoss: 0.3210\tLR: 0.000337\nTraining Epoch: 23 [13312/50000]\tLoss: 0.3706\tLR: 0.000337\nTraining Epoch: 23 [13440/50000]\tLoss: 0.2844\tLR: 0.000337\nTraining Epoch: 23 [13568/50000]\tLoss: 0.2685\tLR: 0.000337\nTraining Epoch: 23 [13696/50000]\tLoss: 0.2856\tLR: 0.000337\nTraining Epoch: 23 [13824/50000]\tLoss: 0.1715\tLR: 0.000337\nTraining Epoch: 23 [13952/50000]\tLoss: 0.2491\tLR: 0.000337\nTraining Epoch: 23 [14080/50000]\tLoss: 0.2292\tLR: 0.000337\nTraining Epoch: 23 [14208/50000]\tLoss: 0.3630\tLR: 0.000337\nTraining Epoch: 23 [14336/50000]\tLoss: 0.2821\tLR: 0.000337\nTraining Epoch: 23 [14464/50000]\tLoss: 0.2485\tLR: 0.000337\nTraining Epoch: 23 [14592/50000]\tLoss: 0.2593\tLR: 0.000337\nTraining Epoch: 23 [14720/50000]\tLoss: 0.3373\tLR: 0.000337\nTraining Epoch: 23 [14848/50000]\tLoss: 0.2884\tLR: 0.000337\nTraining Epoch: 23 [14976/50000]\tLoss: 0.2132\tLR: 0.000337\nTraining Epoch: 23 [15104/50000]\tLoss: 0.3280\tLR: 0.000337\nTraining Epoch: 23 [15232/50000]\tLoss: 0.2489\tLR: 0.000337\nTraining Epoch: 23 [15360/50000]\tLoss: 0.2595\tLR: 0.000337\nTraining Epoch: 23 [15488/50000]\tLoss: 0.2356\tLR: 0.000337\nTraining Epoch: 23 [15616/50000]\tLoss: 0.2424\tLR: 0.000337\nTraining Epoch: 23 [15744/50000]\tLoss: 0.2739\tLR: 0.000337\nTraining Epoch: 23 [15872/50000]\tLoss: 0.3771\tLR: 0.000337\nTraining Epoch: 23 [16000/50000]\tLoss: 0.1812\tLR: 0.000337\nTraining Epoch: 23 [16128/50000]\tLoss: 0.2243\tLR: 0.000337\nTraining Epoch: 23 [16256/50000]\tLoss: 0.2823\tLR: 0.000337\nTraining Epoch: 23 [16384/50000]\tLoss: 0.2213\tLR: 0.000337\nTraining Epoch: 23 [16512/50000]\tLoss: 0.3098\tLR: 0.000337\nTraining Epoch: 23 [16640/50000]\tLoss: 0.2805\tLR: 0.000337\nTraining Epoch: 23 [16768/50000]\tLoss: 0.2782\tLR: 0.000337\nTraining Epoch: 23 [16896/50000]\tLoss: 0.2812\tLR: 0.000337\nTraining Epoch: 23 [17024/50000]\tLoss: 0.2773\tLR: 0.000337\nTraining Epoch: 23 [17152/50000]\tLoss: 0.2862\tLR: 0.000337\nTraining Epoch: 23 [17280/50000]\tLoss: 0.2231\tLR: 0.000337\nTraining Epoch: 23 [17408/50000]\tLoss: 0.2570\tLR: 0.000337\nTraining Epoch: 23 [17536/50000]\tLoss: 0.2384\tLR: 0.000337\nTraining Epoch: 23 [17664/50000]\tLoss: 0.2257\tLR: 0.000337\nTraining Epoch: 23 [17792/50000]\tLoss: 0.2617\tLR: 0.000337\nTraining Epoch: 23 [17920/50000]\tLoss: 0.2328\tLR: 0.000337\nTraining Epoch: 23 [18048/50000]\tLoss: 0.2661\tLR: 0.000337\nTraining Epoch: 23 [18176/50000]\tLoss: 0.2716\tLR: 0.000337\nTraining Epoch: 23 [18304/50000]\tLoss: 0.2703\tLR: 0.000337\nTraining Epoch: 23 [18432/50000]\tLoss: 0.3182\tLR: 0.000337\nTraining Epoch: 23 [18560/50000]\tLoss: 0.2753\tLR: 0.000337\nTraining Epoch: 23 [18688/50000]\tLoss: 0.2308\tLR: 0.000337\nTraining Epoch: 23 [18816/50000]\tLoss: 0.2452\tLR: 0.000337\nTraining Epoch: 23 [18944/50000]\tLoss: 0.1632\tLR: 0.000337\nTraining Epoch: 23 [19072/50000]\tLoss: 0.2539\tLR: 0.000337\nTraining Epoch: 23 [19200/50000]\tLoss: 0.1713\tLR: 0.000337\nTraining Epoch: 23 [19328/50000]\tLoss: 0.4022\tLR: 0.000337\nTraining Epoch: 23 [19456/50000]\tLoss: 0.3315\tLR: 0.000337\nTraining Epoch: 23 [19584/50000]\tLoss: 0.3254\tLR: 0.000337\nTraining Epoch: 23 [19712/50000]\tLoss: 0.1986\tLR: 0.000337\nTraining Epoch: 23 [19840/50000]\tLoss: 0.2871\tLR: 0.000337\nTraining Epoch: 23 [19968/50000]\tLoss: 0.2842\tLR: 0.000337\nTraining Epoch: 23 [20096/50000]\tLoss: 0.2731\tLR: 0.000337\nTraining Epoch: 23 [20224/50000]\tLoss: 0.2834\tLR: 0.000337\nTraining Epoch: 23 [20352/50000]\tLoss: 0.1650\tLR: 0.000337\nTraining Epoch: 23 [20480/50000]\tLoss: 0.2148\tLR: 0.000337\nTraining Epoch: 23 [20608/50000]\tLoss: 0.2050\tLR: 0.000337\nTraining Epoch: 23 [20736/50000]\tLoss: 0.2180\tLR: 0.000337\nTraining Epoch: 23 [20864/50000]\tLoss: 0.3585\tLR: 0.000337\nTraining Epoch: 23 [20992/50000]\tLoss: 0.2357\tLR: 0.000337\nTraining Epoch: 23 [21120/50000]\tLoss: 0.2319\tLR: 0.000337\nTraining Epoch: 23 [21248/50000]\tLoss: 0.2816\tLR: 0.000337\nTraining Epoch: 23 [21376/50000]\tLoss: 0.2854\tLR: 0.000337\nTraining Epoch: 23 [21504/50000]\tLoss: 0.3024\tLR: 0.000337\nTraining Epoch: 23 [21632/50000]\tLoss: 0.3176\tLR: 0.000337\nTraining Epoch: 23 [21760/50000]\tLoss: 0.2922\tLR: 0.000337\nTraining Epoch: 23 [21888/50000]\tLoss: 0.2473\tLR: 0.000337\nTraining Epoch: 23 [22016/50000]\tLoss: 0.3248\tLR: 0.000337\nTraining Epoch: 23 [22144/50000]\tLoss: 0.2566\tLR: 0.000337\nTraining Epoch: 23 [22272/50000]\tLoss: 0.2438\tLR: 0.000337\nTraining Epoch: 23 [22400/50000]\tLoss: 0.2577\tLR: 0.000337\nTraining Epoch: 23 [22528/50000]\tLoss: 0.3660\tLR: 0.000337\nTraining Epoch: 23 [22656/50000]\tLoss: 0.3206\tLR: 0.000337\nTraining Epoch: 23 [22784/50000]\tLoss: 0.4143\tLR: 0.000337\nTraining Epoch: 23 [22912/50000]\tLoss: 0.2061\tLR: 0.000337\nTraining Epoch: 23 [23040/50000]\tLoss: 0.2772\tLR: 0.000337\nTraining Epoch: 23 [23168/50000]\tLoss: 0.1866\tLR: 0.000337\nTraining Epoch: 23 [23296/50000]\tLoss: 0.2733\tLR: 0.000337\nTraining Epoch: 23 [23424/50000]\tLoss: 0.3172\tLR: 0.000337\nTraining Epoch: 23 [23552/50000]\tLoss: 0.3849\tLR: 0.000337\nTraining Epoch: 23 [23680/50000]\tLoss: 0.2147\tLR: 0.000337\nTraining Epoch: 23 [23808/50000]\tLoss: 0.2804\tLR: 0.000337\nTraining Epoch: 23 [23936/50000]\tLoss: 0.2412\tLR: 0.000337\nTraining Epoch: 23 [24064/50000]\tLoss: 0.2111\tLR: 0.000337\nTraining Epoch: 23 [24192/50000]\tLoss: 0.2648\tLR: 0.000337\nTraining Epoch: 23 [24320/50000]\tLoss: 0.2149\tLR: 0.000337\nTraining Epoch: 23 [24448/50000]\tLoss: 0.1927\tLR: 0.000337\nTraining Epoch: 23 [24576/50000]\tLoss: 0.3735\tLR: 0.000337\nTraining Epoch: 23 [24704/50000]\tLoss: 0.3194\tLR: 0.000337\nTraining Epoch: 23 [24832/50000]\tLoss: 0.2660\tLR: 0.000337\nTraining Epoch: 23 [24960/50000]\tLoss: 0.2643\tLR: 0.000337\nTraining Epoch: 23 [25088/50000]\tLoss: 0.2686\tLR: 0.000337\nTraining Epoch: 23 [25216/50000]\tLoss: 0.1631\tLR: 0.000337\nTraining Epoch: 23 [25344/50000]\tLoss: 0.2368\tLR: 0.000337\nTraining Epoch: 23 [25472/50000]\tLoss: 0.2908\tLR: 0.000337\nTraining Epoch: 23 [25600/50000]\tLoss: 0.2919\tLR: 0.000337\nTraining Epoch: 23 [25728/50000]\tLoss: 0.2795\tLR: 0.000337\nTraining Epoch: 23 [25856/50000]\tLoss: 0.2738\tLR: 0.000337\nTraining Epoch: 23 [25984/50000]\tLoss: 0.2461\tLR: 0.000337\nTraining Epoch: 23 [26112/50000]\tLoss: 0.2260\tLR: 0.000337\nTraining Epoch: 23 [26240/50000]\tLoss: 0.2039\tLR: 0.000337\nTraining Epoch: 23 [26368/50000]\tLoss: 0.3120\tLR: 0.000337\nTraining Epoch: 23 [26496/50000]\tLoss: 0.3558\tLR: 0.000337\nTraining Epoch: 23 [26624/50000]\tLoss: 0.3731\tLR: 0.000337\nTraining Epoch: 23 [26752/50000]\tLoss: 0.2546\tLR: 0.000337\nTraining Epoch: 23 [26880/50000]\tLoss: 0.2589\tLR: 0.000337\nTraining Epoch: 23 [27008/50000]\tLoss: 0.2301\tLR: 0.000337\nTraining Epoch: 23 [27136/50000]\tLoss: 0.1851\tLR: 0.000337\nTraining Epoch: 23 [27264/50000]\tLoss: 0.2251\tLR: 0.000337\nTraining Epoch: 23 [27392/50000]\tLoss: 0.2373\tLR: 0.000337\nTraining Epoch: 23 [27520/50000]\tLoss: 0.2413\tLR: 0.000337\nTraining Epoch: 23 [27648/50000]\tLoss: 0.3337\tLR: 0.000337\nTraining Epoch: 23 [27776/50000]\tLoss: 0.3187\tLR: 0.000337\nTraining Epoch: 23 [27904/50000]\tLoss: 0.3460\tLR: 0.000337\nTraining Epoch: 23 [28032/50000]\tLoss: 0.2283\tLR: 0.000337\nTraining Epoch: 23 [28160/50000]\tLoss: 0.2806\tLR: 0.000337\nTraining Epoch: 23 [28288/50000]\tLoss: 0.2467\tLR: 0.000337\nTraining Epoch: 23 [28416/50000]\tLoss: 0.2874\tLR: 0.000337\nTraining Epoch: 23 [28544/50000]\tLoss: 0.2190\tLR: 0.000337\nTraining Epoch: 23 [28672/50000]\tLoss: 0.2363\tLR: 0.000337\nTraining Epoch: 23 [28800/50000]\tLoss: 0.2539\tLR: 0.000337\nTraining Epoch: 23 [28928/50000]\tLoss: 0.1968\tLR: 0.000337\nTraining Epoch: 23 [29056/50000]\tLoss: 0.3463\tLR: 0.000337\nTraining Epoch: 23 [29184/50000]\tLoss: 0.2712\tLR: 0.000337\nTraining Epoch: 23 [29312/50000]\tLoss: 0.1773\tLR: 0.000337\nTraining Epoch: 23 [29440/50000]\tLoss: 0.2750\tLR: 0.000337\nTraining Epoch: 23 [29568/50000]\tLoss: 0.2755\tLR: 0.000337\nTraining Epoch: 23 [29696/50000]\tLoss: 0.3282\tLR: 0.000337\nTraining Epoch: 23 [29824/50000]\tLoss: 0.3239\tLR: 0.000337\nTraining Epoch: 23 [29952/50000]\tLoss: 0.2728\tLR: 0.000337\nTraining Epoch: 23 [30080/50000]\tLoss: 0.2795\tLR: 0.000337\nTraining Epoch: 23 [30208/50000]\tLoss: 0.2405\tLR: 0.000337\nTraining Epoch: 23 [30336/50000]\tLoss: 0.1669\tLR: 0.000337\nTraining Epoch: 23 [30464/50000]\tLoss: 0.2076\tLR: 0.000337\nTraining Epoch: 23 [30592/50000]\tLoss: 0.2298\tLR: 0.000337\nTraining Epoch: 23 [30720/50000]\tLoss: 0.1959\tLR: 0.000337\nTraining Epoch: 23 [30848/50000]\tLoss: 0.2313\tLR: 0.000337\nTraining Epoch: 23 [30976/50000]\tLoss: 0.2720\tLR: 0.000337\nTraining Epoch: 23 [31104/50000]\tLoss: 0.2485\tLR: 0.000337\nTraining Epoch: 23 [31232/50000]\tLoss: 0.2343\tLR: 0.000337\nTraining Epoch: 23 [31360/50000]\tLoss: 0.2811\tLR: 0.000337\nTraining Epoch: 23 [31488/50000]\tLoss: 0.2898\tLR: 0.000337\nTraining Epoch: 23 [31616/50000]\tLoss: 0.2651\tLR: 0.000337\nTraining Epoch: 23 [31744/50000]\tLoss: 0.2501\tLR: 0.000337\nTraining Epoch: 23 [31872/50000]\tLoss: 0.2346\tLR: 0.000337\nTraining Epoch: 23 [32000/50000]\tLoss: 0.2367\tLR: 0.000337\nTraining Epoch: 23 [32128/50000]\tLoss: 0.2839\tLR: 0.000337\nTraining Epoch: 23 [32256/50000]\tLoss: 0.2268\tLR: 0.000337\nTraining Epoch: 23 [32384/50000]\tLoss: 0.2831\tLR: 0.000337\nTraining Epoch: 23 [32512/50000]\tLoss: 0.2502\tLR: 0.000337\nTraining Epoch: 23 [32640/50000]\tLoss: 0.2328\tLR: 0.000337\nTraining Epoch: 23 [32768/50000]\tLoss: 0.2759\tLR: 0.000337\nTraining Epoch: 23 [32896/50000]\tLoss: 0.1750\tLR: 0.000337\nTraining Epoch: 23 [33024/50000]\tLoss: 0.3802\tLR: 0.000337\nTraining Epoch: 23 [33152/50000]\tLoss: 0.3662\tLR: 0.000337\nTraining Epoch: 23 [33280/50000]\tLoss: 0.2355\tLR: 0.000337\nTraining Epoch: 23 [33408/50000]\tLoss: 0.3383\tLR: 0.000337\nTraining Epoch: 23 [33536/50000]\tLoss: 0.2630\tLR: 0.000337\nTraining Epoch: 23 [33664/50000]\tLoss: 0.3490\tLR: 0.000337\nTraining Epoch: 23 [33792/50000]\tLoss: 0.2260\tLR: 0.000337\nTraining Epoch: 23 [33920/50000]\tLoss: 0.3172\tLR: 0.000337\nTraining Epoch: 23 [34048/50000]\tLoss: 0.1808\tLR: 0.000337\nTraining Epoch: 23 [34176/50000]\tLoss: 0.1348\tLR: 0.000337\nTraining Epoch: 23 [34304/50000]\tLoss: 0.2891\tLR: 0.000337\nTraining Epoch: 23 [34432/50000]\tLoss: 0.2174\tLR: 0.000337\nTraining Epoch: 23 [34560/50000]\tLoss: 0.2865\tLR: 0.000337\nTraining Epoch: 23 [34688/50000]\tLoss: 0.2261\tLR: 0.000337\nTraining Epoch: 23 [34816/50000]\tLoss: 0.2058\tLR: 0.000337\nTraining Epoch: 23 [34944/50000]\tLoss: 0.2514\tLR: 0.000337\nTraining Epoch: 23 [35072/50000]\tLoss: 0.2970\tLR: 0.000337\nTraining Epoch: 23 [35200/50000]\tLoss: 0.2704\tLR: 0.000337\nTraining Epoch: 23 [35328/50000]\tLoss: 0.3682\tLR: 0.000337\nTraining Epoch: 23 [35456/50000]\tLoss: 0.3212\tLR: 0.000337\nTraining Epoch: 23 [35584/50000]\tLoss: 0.2448\tLR: 0.000337\nTraining Epoch: 23 [35712/50000]\tLoss: 0.2572\tLR: 0.000337\nTraining Epoch: 23 [35840/50000]\tLoss: 0.2655\tLR: 0.000337\nTraining Epoch: 23 [35968/50000]\tLoss: 0.1997\tLR: 0.000337\nTraining Epoch: 23 [36096/50000]\tLoss: 0.2673\tLR: 0.000337\nTraining Epoch: 23 [36224/50000]\tLoss: 0.2568\tLR: 0.000337\nTraining Epoch: 23 [36352/50000]\tLoss: 0.1659\tLR: 0.000337\nTraining Epoch: 23 [36480/50000]\tLoss: 0.4069\tLR: 0.000337\nTraining Epoch: 23 [36608/50000]\tLoss: 0.2897\tLR: 0.000337\nTraining Epoch: 23 [36736/50000]\tLoss: 0.2010\tLR: 0.000337\nTraining Epoch: 23 [36864/50000]\tLoss: 0.2276\tLR: 0.000337\nTraining Epoch: 23 [36992/50000]\tLoss: 0.2784\tLR: 0.000337\nTraining Epoch: 23 [37120/50000]\tLoss: 0.2070\tLR: 0.000337\nTraining Epoch: 23 [37248/50000]\tLoss: 0.3708\tLR: 0.000337\nTraining Epoch: 23 [37376/50000]\tLoss: 0.2405\tLR: 0.000337\nTraining Epoch: 23 [37504/50000]\tLoss: 0.2253\tLR: 0.000337\nTraining Epoch: 23 [37632/50000]\tLoss: 0.2667\tLR: 0.000337\nTraining Epoch: 23 [37760/50000]\tLoss: 0.3741\tLR: 0.000337\nTraining Epoch: 23 [37888/50000]\tLoss: 0.2420\tLR: 0.000337\nTraining Epoch: 23 [38016/50000]\tLoss: 0.2916\tLR: 0.000337\nTraining Epoch: 23 [38144/50000]\tLoss: 0.3154\tLR: 0.000337\nTraining Epoch: 23 [38272/50000]\tLoss: 0.2398\tLR: 0.000337\nTraining Epoch: 23 [38400/50000]\tLoss: 0.1810\tLR: 0.000337\nTraining Epoch: 23 [38528/50000]\tLoss: 0.2062\tLR: 0.000337\nTraining Epoch: 23 [38656/50000]\tLoss: 0.3285\tLR: 0.000337\nTraining Epoch: 23 [38784/50000]\tLoss: 0.2853\tLR: 0.000337\nTraining Epoch: 23 [38912/50000]\tLoss: 0.2499\tLR: 0.000337\nTraining Epoch: 23 [39040/50000]\tLoss: 0.2717\tLR: 0.000337\nTraining Epoch: 23 [39168/50000]\tLoss: 0.3278\tLR: 0.000337\nTraining Epoch: 23 [39296/50000]\tLoss: 0.1999\tLR: 0.000337\nTraining Epoch: 23 [39424/50000]\tLoss: 0.2421\tLR: 0.000337\nTraining Epoch: 23 [39552/50000]\tLoss: 0.3225\tLR: 0.000337\nTraining Epoch: 23 [39680/50000]\tLoss: 0.3690\tLR: 0.000337\nTraining Epoch: 23 [39808/50000]\tLoss: 0.2483\tLR: 0.000337\nTraining Epoch: 23 [39936/50000]\tLoss: 0.3099\tLR: 0.000337\nTraining Epoch: 23 [40064/50000]\tLoss: 0.3009\tLR: 0.000337\nTraining Epoch: 23 [40192/50000]\tLoss: 0.1746\tLR: 0.000337\nTraining Epoch: 23 [40320/50000]\tLoss: 0.2740\tLR: 0.000337\nTraining Epoch: 23 [40448/50000]\tLoss: 0.3301\tLR: 0.000337\nTraining Epoch: 23 [40576/50000]\tLoss: 0.1831\tLR: 0.000337\nTraining Epoch: 23 [40704/50000]\tLoss: 0.2369\tLR: 0.000337\nTraining Epoch: 23 [40832/50000]\tLoss: 0.3936\tLR: 0.000337\nTraining Epoch: 23 [40960/50000]\tLoss: 0.2812\tLR: 0.000337\nTraining Epoch: 23 [41088/50000]\tLoss: 0.2747\tLR: 0.000337\nTraining Epoch: 23 [41216/50000]\tLoss: 0.2596\tLR: 0.000337\nTraining Epoch: 23 [41344/50000]\tLoss: 0.1713\tLR: 0.000337\nTraining Epoch: 23 [41472/50000]\tLoss: 0.3166\tLR: 0.000337\nTraining Epoch: 23 [41600/50000]\tLoss: 0.2286\tLR: 0.000337\nTraining Epoch: 23 [41728/50000]\tLoss: 0.3208\tLR: 0.000337\nTraining Epoch: 23 [41856/50000]\tLoss: 0.2596\tLR: 0.000337\nTraining Epoch: 23 [41984/50000]\tLoss: 0.2963\tLR: 0.000337\nTraining Epoch: 23 [42112/50000]\tLoss: 0.3416\tLR: 0.000337\nTraining Epoch: 23 [42240/50000]\tLoss: 0.3263\tLR: 0.000337\nTraining Epoch: 23 [42368/50000]\tLoss: 0.3703\tLR: 0.000337\nTraining Epoch: 23 [42496/50000]\tLoss: 0.2512\tLR: 0.000337\nTraining Epoch: 23 [42624/50000]\tLoss: 0.2945\tLR: 0.000337\nTraining Epoch: 23 [42752/50000]\tLoss: 0.3219\tLR: 0.000337\nTraining Epoch: 23 [42880/50000]\tLoss: 0.4240\tLR: 0.000337\nTraining Epoch: 23 [43008/50000]\tLoss: 0.2235\tLR: 0.000337\nTraining Epoch: 23 [43136/50000]\tLoss: 0.3476\tLR: 0.000337\nTraining Epoch: 23 [43264/50000]\tLoss: 0.1964\tLR: 0.000337\nTraining Epoch: 23 [43392/50000]\tLoss: 0.2806\tLR: 0.000337\nTraining Epoch: 23 [43520/50000]\tLoss: 0.2946\tLR: 0.000337\nTraining Epoch: 23 [43648/50000]\tLoss: 0.2242\tLR: 0.000337\nTraining Epoch: 23 [43776/50000]\tLoss: 0.1775\tLR: 0.000337\nTraining Epoch: 23 [43904/50000]\tLoss: 0.2682\tLR: 0.000337\nTraining Epoch: 23 [44032/50000]\tLoss: 0.3434\tLR: 0.000337\nTraining Epoch: 23 [44160/50000]\tLoss: 0.3044\tLR: 0.000337\nTraining Epoch: 23 [44288/50000]\tLoss: 0.3315\tLR: 0.000337\nTraining Epoch: 23 [44416/50000]\tLoss: 0.2769\tLR: 0.000337\nTraining Epoch: 23 [44544/50000]\tLoss: 0.2882\tLR: 0.000337\nTraining Epoch: 23 [44672/50000]\tLoss: 0.3873\tLR: 0.000337\nTraining Epoch: 23 [44800/50000]\tLoss: 0.2980\tLR: 0.000337\nTraining Epoch: 23 [44928/50000]\tLoss: 0.2376\tLR: 0.000337\nTraining Epoch: 23 [45056/50000]\tLoss: 0.1787\tLR: 0.000337\nTraining Epoch: 23 [45184/50000]\tLoss: 0.3226\tLR: 0.000337\nTraining Epoch: 23 [45312/50000]\tLoss: 0.2301\tLR: 0.000337\nTraining Epoch: 23 [45440/50000]\tLoss: 0.1990\tLR: 0.000337\nTraining Epoch: 23 [45568/50000]\tLoss: 0.2448\tLR: 0.000337\nTraining Epoch: 23 [45696/50000]\tLoss: 0.2501\tLR: 0.000337\nTraining Epoch: 23 [45824/50000]\tLoss: 0.1954\tLR: 0.000337\nTraining Epoch: 23 [45952/50000]\tLoss: 0.3273\tLR: 0.000337\nTraining Epoch: 23 [46080/50000]\tLoss: 0.2165\tLR: 0.000337\nTraining Epoch: 23 [46208/50000]\tLoss: 0.1866\tLR: 0.000337\nTraining Epoch: 23 [46336/50000]\tLoss: 0.3345\tLR: 0.000337\nTraining Epoch: 23 [46464/50000]\tLoss: 0.4256\tLR: 0.000337\nTraining Epoch: 23 [46592/50000]\tLoss: 0.3325\tLR: 0.000337\nTraining Epoch: 23 [46720/50000]\tLoss: 0.2248\tLR: 0.000337\nTraining Epoch: 23 [46848/50000]\tLoss: 0.3842\tLR: 0.000337\nTraining Epoch: 23 [46976/50000]\tLoss: 0.2699\tLR: 0.000337\nTraining Epoch: 23 [47104/50000]\tLoss: 0.1824\tLR: 0.000337\nTraining Epoch: 23 [47232/50000]\tLoss: 0.2469\tLR: 0.000337\nTraining Epoch: 23 [47360/50000]\tLoss: 0.3100\tLR: 0.000337\nTraining Epoch: 23 [47488/50000]\tLoss: 0.2789\tLR: 0.000337\nTraining Epoch: 23 [47616/50000]\tLoss: 0.2811\tLR: 0.000337\nTraining Epoch: 23 [47744/50000]\tLoss: 0.2434\tLR: 0.000337\nTraining Epoch: 23 [47872/50000]\tLoss: 0.2494\tLR: 0.000337\nTraining Epoch: 23 [48000/50000]\tLoss: 0.3176\tLR: 0.000337\nTraining Epoch: 23 [48128/50000]\tLoss: 0.2692\tLR: 0.000337\nTraining Epoch: 23 [48256/50000]\tLoss: 0.2612\tLR: 0.000337\nTraining Epoch: 23 [48384/50000]\tLoss: 0.2775\tLR: 0.000337\nTraining Epoch: 23 [48512/50000]\tLoss: 0.3283\tLR: 0.000337\nTraining Epoch: 23 [48640/50000]\tLoss: 0.2723\tLR: 0.000337\nTraining Epoch: 23 [48768/50000]\tLoss: 0.2657\tLR: 0.000337\nTraining Epoch: 23 [48896/50000]\tLoss: 0.2613\tLR: 0.000337\nTraining Epoch: 23 [49024/50000]\tLoss: 0.2696\tLR: 0.000337\nTraining Epoch: 23 [49152/50000]\tLoss: 0.2021\tLR: 0.000337\nTraining Epoch: 23 [49280/50000]\tLoss: 0.1685\tLR: 0.000337\nTraining Epoch: 23 [49408/50000]\tLoss: 0.2272\tLR: 0.000337\nTraining Epoch: 23 [49536/50000]\tLoss: 0.2273\tLR: 0.000337\nTraining Epoch: 23 [49664/50000]\tLoss: 0.1905\tLR: 0.000337\nTraining Epoch: 23 [49792/50000]\tLoss: 0.2946\tLR: 0.000337\nTraining Epoch: 23 [49920/50000]\tLoss: 0.2370\tLR: 0.000337\nTraining Epoch: 23 [50000/50000]\tLoss: 0.2168\tLR: 0.000337\nTest set: Average loss: 0.0025, Accuracy: 0.8929\n\nTraining Epoch: 24 [128/50000]\tLoss: 0.2985\tLR: 0.000337\nTraining Epoch: 24 [256/50000]\tLoss: 0.1992\tLR: 0.000337\nTraining Epoch: 24 [384/50000]\tLoss: 0.3209\tLR: 0.000337\nTraining Epoch: 24 [512/50000]\tLoss: 0.1635\tLR: 0.000337\nTraining Epoch: 24 [640/50000]\tLoss: 0.3383\tLR: 0.000337\nTraining Epoch: 24 [768/50000]\tLoss: 0.1630\tLR: 0.000337\nTraining Epoch: 24 [896/50000]\tLoss: 0.2444\tLR: 0.000337\nTraining Epoch: 24 [1024/50000]\tLoss: 0.2456\tLR: 0.000337\nTraining Epoch: 24 [1152/50000]\tLoss: 0.2148\tLR: 0.000337\nTraining Epoch: 24 [1280/50000]\tLoss: 0.3341\tLR: 0.000337\nTraining Epoch: 24 [1408/50000]\tLoss: 0.3526\tLR: 0.000337\nTraining Epoch: 24 [1536/50000]\tLoss: 0.2970\tLR: 0.000337\nTraining Epoch: 24 [1664/50000]\tLoss: 0.2000\tLR: 0.000337\nTraining Epoch: 24 [1792/50000]\tLoss: 0.2735\tLR: 0.000337\nTraining Epoch: 24 [1920/50000]\tLoss: 0.3303\tLR: 0.000337\nTraining Epoch: 24 [2048/50000]\tLoss: 0.3204\tLR: 0.000337\nTraining Epoch: 24 [2176/50000]\tLoss: 0.3171\tLR: 0.000337\nTraining Epoch: 24 [2304/50000]\tLoss: 0.2741\tLR: 0.000337\nTraining Epoch: 24 [2432/50000]\tLoss: 0.2999\tLR: 0.000337\nTraining Epoch: 24 [2560/50000]\tLoss: 0.3379\tLR: 0.000337\nTraining Epoch: 24 [2688/50000]\tLoss: 0.2807\tLR: 0.000337\nTraining Epoch: 24 [2816/50000]\tLoss: 0.2338\tLR: 0.000337\nTraining Epoch: 24 [2944/50000]\tLoss: 0.3573\tLR: 0.000337\nTraining Epoch: 24 [3072/50000]\tLoss: 0.2655\tLR: 0.000337\nTraining Epoch: 24 [3200/50000]\tLoss: 0.2941\tLR: 0.000337\nTraining Epoch: 24 [3328/50000]\tLoss: 0.2155\tLR: 0.000337\nTraining Epoch: 24 [3456/50000]\tLoss: 0.1642\tLR: 0.000337\nTraining Epoch: 24 [3584/50000]\tLoss: 0.4159\tLR: 0.000337\nTraining Epoch: 24 [3712/50000]\tLoss: 0.2804\tLR: 0.000337\nTraining Epoch: 24 [3840/50000]\tLoss: 0.2434\tLR: 0.000337\nTraining Epoch: 24 [3968/50000]\tLoss: 0.3252\tLR: 0.000337\nTraining Epoch: 24 [4096/50000]\tLoss: 0.2897\tLR: 0.000337\nTraining Epoch: 24 [4224/50000]\tLoss: 0.1555\tLR: 0.000337\nTraining Epoch: 24 [4352/50000]\tLoss: 0.3704\tLR: 0.000337\nTraining Epoch: 24 [4480/50000]\tLoss: 0.2342\tLR: 0.000337\nTraining Epoch: 24 [4608/50000]\tLoss: 0.1970\tLR: 0.000337\nTraining Epoch: 24 [4736/50000]\tLoss: 0.2724\tLR: 0.000337\nTraining Epoch: 24 [4864/50000]\tLoss: 0.1973\tLR: 0.000337\nTraining Epoch: 24 [4992/50000]\tLoss: 0.2546\tLR: 0.000337\nTraining Epoch: 24 [5120/50000]\tLoss: 0.2409\tLR: 0.000337\nTraining Epoch: 24 [5248/50000]\tLoss: 0.3382\tLR: 0.000337\nTraining Epoch: 24 [5376/50000]\tLoss: 0.2397\tLR: 0.000337\nTraining Epoch: 24 [5504/50000]\tLoss: 0.3114\tLR: 0.000337\nTraining Epoch: 24 [5632/50000]\tLoss: 0.2353\tLR: 0.000337\nTraining Epoch: 24 [5760/50000]\tLoss: 0.3275\tLR: 0.000337\nTraining Epoch: 24 [5888/50000]\tLoss: 0.4320\tLR: 0.000337\nTraining Epoch: 24 [6016/50000]\tLoss: 0.2328\tLR: 0.000337\nTraining Epoch: 24 [6144/50000]\tLoss: 0.2137\tLR: 0.000337\nTraining Epoch: 24 [6272/50000]\tLoss: 0.2248\tLR: 0.000337\nTraining Epoch: 24 [6400/50000]\tLoss: 0.2875\tLR: 0.000337\nTraining Epoch: 24 [6528/50000]\tLoss: 0.3520\tLR: 0.000337\nTraining Epoch: 24 [6656/50000]\tLoss: 0.3388\tLR: 0.000337\nTraining Epoch: 24 [6784/50000]\tLoss: 0.3080\tLR: 0.000337\nTraining Epoch: 24 [6912/50000]\tLoss: 0.1621\tLR: 0.000337\nTraining Epoch: 24 [7040/50000]\tLoss: 0.2711\tLR: 0.000337\nTraining Epoch: 24 [7168/50000]\tLoss: 0.2324\tLR: 0.000337\nTraining Epoch: 24 [7296/50000]\tLoss: 0.2512\tLR: 0.000337\nTraining Epoch: 24 [7424/50000]\tLoss: 0.1653\tLR: 0.000337\nTraining Epoch: 24 [7552/50000]\tLoss: 0.2275\tLR: 0.000337\nTraining Epoch: 24 [7680/50000]\tLoss: 0.3542\tLR: 0.000337\nTraining Epoch: 24 [7808/50000]\tLoss: 0.2793\tLR: 0.000337\nTraining Epoch: 24 [7936/50000]\tLoss: 0.3192\tLR: 0.000337\nTraining Epoch: 24 [8064/50000]\tLoss: 0.2415\tLR: 0.000337\nTraining Epoch: 24 [8192/50000]\tLoss: 0.1788\tLR: 0.000337\nTraining Epoch: 24 [8320/50000]\tLoss: 0.2634\tLR: 0.000337\nTraining Epoch: 24 [8448/50000]\tLoss: 0.3039\tLR: 0.000337\nTraining Epoch: 24 [8576/50000]\tLoss: 0.2640\tLR: 0.000337\nTraining Epoch: 24 [8704/50000]\tLoss: 0.3366\tLR: 0.000337\nTraining Epoch: 24 [8832/50000]\tLoss: 0.2379\tLR: 0.000337\nTraining Epoch: 24 [8960/50000]\tLoss: 0.2558\tLR: 0.000337\nTraining Epoch: 24 [9088/50000]\tLoss: 0.2765\tLR: 0.000337\nTraining Epoch: 24 [9216/50000]\tLoss: 0.2043\tLR: 0.000337\nTraining Epoch: 24 [9344/50000]\tLoss: 0.2852\tLR: 0.000337\nTraining Epoch: 24 [9472/50000]\tLoss: 0.2397\tLR: 0.000337\nTraining Epoch: 24 [9600/50000]\tLoss: 0.3068\tLR: 0.000337\nTraining Epoch: 24 [9728/50000]\tLoss: 0.2842\tLR: 0.000337\nTraining Epoch: 24 [9856/50000]\tLoss: 0.1880\tLR: 0.000337\nTraining Epoch: 24 [9984/50000]\tLoss: 0.2263\tLR: 0.000337\nTraining Epoch: 24 [10112/50000]\tLoss: 0.3530\tLR: 0.000337\nTraining Epoch: 24 [10240/50000]\tLoss: 0.2668\tLR: 0.000337\nTraining Epoch: 24 [10368/50000]\tLoss: 0.2053\tLR: 0.000337\nTraining Epoch: 24 [10496/50000]\tLoss: 0.3049\tLR: 0.000337\nTraining Epoch: 24 [10624/50000]\tLoss: 0.2414\tLR: 0.000337\nTraining Epoch: 24 [10752/50000]\tLoss: 0.3308\tLR: 0.000337\nTraining Epoch: 24 [10880/50000]\tLoss: 0.2640\tLR: 0.000337\nTraining Epoch: 24 [11008/50000]\tLoss: 0.2615\tLR: 0.000337\nTraining Epoch: 24 [11136/50000]\tLoss: 0.2478\tLR: 0.000337\nTraining Epoch: 24 [11264/50000]\tLoss: 0.1847\tLR: 0.000337\nTraining Epoch: 24 [11392/50000]\tLoss: 0.3367\tLR: 0.000337\nTraining Epoch: 24 [11520/50000]\tLoss: 0.2604\tLR: 0.000337\nTraining Epoch: 24 [11648/50000]\tLoss: 0.2525\tLR: 0.000337\nTraining Epoch: 24 [11776/50000]\tLoss: 0.3037\tLR: 0.000337\nTraining Epoch: 24 [11904/50000]\tLoss: 0.2869\tLR: 0.000337\nTraining Epoch: 24 [12032/50000]\tLoss: 0.1834\tLR: 0.000337\nTraining Epoch: 24 [12160/50000]\tLoss: 0.2420\tLR: 0.000337\nTraining Epoch: 24 [12288/50000]\tLoss: 0.1994\tLR: 0.000337\nTraining Epoch: 24 [12416/50000]\tLoss: 0.2839\tLR: 0.000337\nTraining Epoch: 24 [12544/50000]\tLoss: 0.2987\tLR: 0.000337\nTraining Epoch: 24 [12672/50000]\tLoss: 0.3218\tLR: 0.000337\nTraining Epoch: 24 [12800/50000]\tLoss: 0.2691\tLR: 0.000337\nTraining Epoch: 24 [12928/50000]\tLoss: 0.1738\tLR: 0.000337\nTraining Epoch: 24 [13056/50000]\tLoss: 0.2331\tLR: 0.000337\nTraining Epoch: 24 [13184/50000]\tLoss: 0.2623\tLR: 0.000337\nTraining Epoch: 24 [13312/50000]\tLoss: 0.2567\tLR: 0.000337\nTraining Epoch: 24 [13440/50000]\tLoss: 0.2201\tLR: 0.000337\nTraining Epoch: 24 [13568/50000]\tLoss: 0.3523\tLR: 0.000337\nTraining Epoch: 24 [13696/50000]\tLoss: 0.3280\tLR: 0.000337\nTraining Epoch: 24 [13824/50000]\tLoss: 0.2711\tLR: 0.000337\nTraining Epoch: 24 [13952/50000]\tLoss: 0.3113\tLR: 0.000337\nTraining Epoch: 24 [14080/50000]\tLoss: 0.1550\tLR: 0.000337\nTraining Epoch: 24 [14208/50000]\tLoss: 0.2281\tLR: 0.000337\nTraining Epoch: 24 [14336/50000]\tLoss: 0.3223\tLR: 0.000337\nTraining Epoch: 24 [14464/50000]\tLoss: 0.2536\tLR: 0.000337\nTraining Epoch: 24 [14592/50000]\tLoss: 0.2053\tLR: 0.000337\nTraining Epoch: 24 [14720/50000]\tLoss: 0.1949\tLR: 0.000337\nTraining Epoch: 24 [14848/50000]\tLoss: 0.2355\tLR: 0.000337\nTraining Epoch: 24 [14976/50000]\tLoss: 0.1365\tLR: 0.000337\nTraining Epoch: 24 [15104/50000]\tLoss: 0.2884\tLR: 0.000337\nTraining Epoch: 24 [15232/50000]\tLoss: 0.3072\tLR: 0.000337\nTraining Epoch: 24 [15360/50000]\tLoss: 0.3122\tLR: 0.000337\nTraining Epoch: 24 [15488/50000]\tLoss: 0.2334\tLR: 0.000337\nTraining Epoch: 24 [15616/50000]\tLoss: 0.2800\tLR: 0.000337\nTraining Epoch: 24 [15744/50000]\tLoss: 0.2311\tLR: 0.000337\nTraining Epoch: 24 [15872/50000]\tLoss: 0.2137\tLR: 0.000337\nTraining Epoch: 24 [16000/50000]\tLoss: 0.1157\tLR: 0.000337\nTraining Epoch: 24 [16128/50000]\tLoss: 0.4272\tLR: 0.000337\nTraining Epoch: 24 [16256/50000]\tLoss: 0.2594\tLR: 0.000337\nTraining Epoch: 24 [16384/50000]\tLoss: 0.2564\tLR: 0.000337\nTraining Epoch: 24 [16512/50000]\tLoss: 0.3539\tLR: 0.000337\nTraining Epoch: 24 [16640/50000]\tLoss: 0.3629\tLR: 0.000337\nTraining Epoch: 24 [16768/50000]\tLoss: 0.3419\tLR: 0.000337\nTraining Epoch: 24 [16896/50000]\tLoss: 0.2636\tLR: 0.000337\nTraining Epoch: 24 [17024/50000]\tLoss: 0.1912\tLR: 0.000337\nTraining Epoch: 24 [17152/50000]\tLoss: 0.2900\tLR: 0.000337\nTraining Epoch: 24 [17280/50000]\tLoss: 0.2665\tLR: 0.000337\nTraining Epoch: 24 [17408/50000]\tLoss: 0.2123\tLR: 0.000337\nTraining Epoch: 24 [17536/50000]\tLoss: 0.1963\tLR: 0.000337\nTraining Epoch: 24 [17664/50000]\tLoss: 0.2998\tLR: 0.000337\nTraining Epoch: 24 [17792/50000]\tLoss: 0.2594\tLR: 0.000337\nTraining Epoch: 24 [17920/50000]\tLoss: 0.2615\tLR: 0.000337\nTraining Epoch: 24 [18048/50000]\tLoss: 0.2567\tLR: 0.000337\nTraining Epoch: 24 [18176/50000]\tLoss: 0.2340\tLR: 0.000337\nTraining Epoch: 24 [18304/50000]\tLoss: 0.2557\tLR: 0.000337\nTraining Epoch: 24 [18432/50000]\tLoss: 0.2715\tLR: 0.000337\nTraining Epoch: 24 [18560/50000]\tLoss: 0.2225\tLR: 0.000337\nTraining Epoch: 24 [18688/50000]\tLoss: 0.2544\tLR: 0.000337\nTraining Epoch: 24 [18816/50000]\tLoss: 0.1854\tLR: 0.000337\nTraining Epoch: 24 [18944/50000]\tLoss: 0.2590\tLR: 0.000337\nTraining Epoch: 24 [19072/50000]\tLoss: 0.2481\tLR: 0.000337\nTraining Epoch: 24 [19200/50000]\tLoss: 0.3322\tLR: 0.000337\nTraining Epoch: 24 [19328/50000]\tLoss: 0.1980\tLR: 0.000337\nTraining Epoch: 24 [19456/50000]\tLoss: 0.2708\tLR: 0.000337\nTraining Epoch: 24 [19584/50000]\tLoss: 0.3414\tLR: 0.000337\nTraining Epoch: 24 [19712/50000]\tLoss: 0.2194\tLR: 0.000337\nTraining Epoch: 24 [19840/50000]\tLoss: 0.2822\tLR: 0.000337\nTraining Epoch: 24 [19968/50000]\tLoss: 0.2384\tLR: 0.000337\nTraining Epoch: 24 [20096/50000]\tLoss: 0.2157\tLR: 0.000337\nTraining Epoch: 24 [20224/50000]\tLoss: 0.2441\tLR: 0.000337\nTraining Epoch: 24 [20352/50000]\tLoss: 0.2760\tLR: 0.000337\nTraining Epoch: 24 [20480/50000]\tLoss: 0.2743\tLR: 0.000337\nTraining Epoch: 24 [20608/50000]\tLoss: 0.2544\tLR: 0.000337\nTraining Epoch: 24 [20736/50000]\tLoss: 0.1979\tLR: 0.000337\nTraining Epoch: 24 [20864/50000]\tLoss: 0.2740\tLR: 0.000337\nTraining Epoch: 24 [20992/50000]\tLoss: 0.2191\tLR: 0.000337\nTraining Epoch: 24 [21120/50000]\tLoss: 0.2553\tLR: 0.000337\nTraining Epoch: 24 [21248/50000]\tLoss: 0.3599\tLR: 0.000337\nTraining Epoch: 24 [21376/50000]\tLoss: 0.2404\tLR: 0.000337\nTraining Epoch: 24 [21504/50000]\tLoss: 0.1912\tLR: 0.000337\nTraining Epoch: 24 [21632/50000]\tLoss: 0.1971\tLR: 0.000337\nTraining Epoch: 24 [21760/50000]\tLoss: 0.2935\tLR: 0.000337\nTraining Epoch: 24 [21888/50000]\tLoss: 0.2458\tLR: 0.000337\nTraining Epoch: 24 [22016/50000]\tLoss: 0.2397\tLR: 0.000337\nTraining Epoch: 24 [22144/50000]\tLoss: 0.3509\tLR: 0.000337\nTraining Epoch: 24 [22272/50000]\tLoss: 0.2743\tLR: 0.000337\nTraining Epoch: 24 [22400/50000]\tLoss: 0.2979\tLR: 0.000337\nTraining Epoch: 24 [22528/50000]\tLoss: 0.2673\tLR: 0.000337\nTraining Epoch: 24 [22656/50000]\tLoss: 0.3007\tLR: 0.000337\nTraining Epoch: 24 [22784/50000]\tLoss: 0.2827\tLR: 0.000337\nTraining Epoch: 24 [22912/50000]\tLoss: 0.4306\tLR: 0.000337\nTraining Epoch: 24 [23040/50000]\tLoss: 0.2108\tLR: 0.000337\nTraining Epoch: 24 [23168/50000]\tLoss: 0.3702\tLR: 0.000337\nTraining Epoch: 24 [23296/50000]\tLoss: 0.2409\tLR: 0.000337\nTraining Epoch: 24 [23424/50000]\tLoss: 0.3671\tLR: 0.000337\nTraining Epoch: 24 [23552/50000]\tLoss: 0.2926\tLR: 0.000337\nTraining Epoch: 24 [23680/50000]\tLoss: 0.3147\tLR: 0.000337\nTraining Epoch: 24 [23808/50000]\tLoss: 0.2034\tLR: 0.000337\nTraining Epoch: 24 [23936/50000]\tLoss: 0.1577\tLR: 0.000337\nTraining Epoch: 24 [24064/50000]\tLoss: 0.3021\tLR: 0.000337\nTraining Epoch: 24 [24192/50000]\tLoss: 0.1982\tLR: 0.000337\nTraining Epoch: 24 [24320/50000]\tLoss: 0.2779\tLR: 0.000337\nTraining Epoch: 24 [24448/50000]\tLoss: 0.3035\tLR: 0.000337\nTraining Epoch: 24 [24576/50000]\tLoss: 0.2636\tLR: 0.000337\nTraining Epoch: 24 [24704/50000]\tLoss: 0.2177\tLR: 0.000337\nTraining Epoch: 24 [24832/50000]\tLoss: 0.2728\tLR: 0.000337\nTraining Epoch: 24 [24960/50000]\tLoss: 0.3219\tLR: 0.000337\nTraining Epoch: 24 [25088/50000]\tLoss: 0.1756\tLR: 0.000337\nTraining Epoch: 24 [25216/50000]\tLoss: 0.3415\tLR: 0.000337\nTraining Epoch: 24 [25344/50000]\tLoss: 0.2903\tLR: 0.000337\nTraining Epoch: 24 [25472/50000]\tLoss: 0.2599\tLR: 0.000337\nTraining Epoch: 24 [25600/50000]\tLoss: 0.2345\tLR: 0.000337\nTraining Epoch: 24 [25728/50000]\tLoss: 0.2210\tLR: 0.000337\nTraining Epoch: 24 [25856/50000]\tLoss: 0.2775\tLR: 0.000337\nTraining Epoch: 24 [25984/50000]\tLoss: 0.2534\tLR: 0.000337\nTraining Epoch: 24 [26112/50000]\tLoss: 0.3137\tLR: 0.000337\nTraining Epoch: 24 [26240/50000]\tLoss: 0.1727\tLR: 0.000337\nTraining Epoch: 24 [26368/50000]\tLoss: 0.1927\tLR: 0.000337\nTraining Epoch: 24 [26496/50000]\tLoss: 0.3270\tLR: 0.000337\nTraining Epoch: 24 [26624/50000]\tLoss: 0.2619\tLR: 0.000337\nTraining Epoch: 24 [26752/50000]\tLoss: 0.2131\tLR: 0.000337\nTraining Epoch: 24 [26880/50000]\tLoss: 0.2424\tLR: 0.000337\nTraining Epoch: 24 [27008/50000]\tLoss: 0.2110\tLR: 0.000337\nTraining Epoch: 24 [27136/50000]\tLoss: 0.3071\tLR: 0.000337\nTraining Epoch: 24 [27264/50000]\tLoss: 0.3599\tLR: 0.000337\nTraining Epoch: 24 [27392/50000]\tLoss: 0.1967\tLR: 0.000337\nTraining Epoch: 24 [27520/50000]\tLoss: 0.2174\tLR: 0.000337\nTraining Epoch: 24 [27648/50000]\tLoss: 0.3958\tLR: 0.000337\nTraining Epoch: 24 [27776/50000]\tLoss: 0.2706\tLR: 0.000337\nTraining Epoch: 24 [27904/50000]\tLoss: 0.2912\tLR: 0.000337\nTraining Epoch: 24 [28032/50000]\tLoss: 0.2652\tLR: 0.000337\nTraining Epoch: 24 [28160/50000]\tLoss: 0.2306\tLR: 0.000337\nTraining Epoch: 24 [28288/50000]\tLoss: 0.3241\tLR: 0.000337\nTraining Epoch: 24 [28416/50000]\tLoss: 0.3039\tLR: 0.000337\nTraining Epoch: 24 [28544/50000]\tLoss: 0.2965\tLR: 0.000337\nTraining Epoch: 24 [28672/50000]\tLoss: 0.2161\tLR: 0.000337\nTraining Epoch: 24 [28800/50000]\tLoss: 0.2918\tLR: 0.000337\nTraining Epoch: 24 [28928/50000]\tLoss: 0.3392\tLR: 0.000337\nTraining Epoch: 24 [29056/50000]\tLoss: 0.2422\tLR: 0.000337\nTraining Epoch: 24 [29184/50000]\tLoss: 0.2814\tLR: 0.000337\nTraining Epoch: 24 [29312/50000]\tLoss: 0.2155\tLR: 0.000337\nTraining Epoch: 24 [29440/50000]\tLoss: 0.1972\tLR: 0.000337\nTraining Epoch: 24 [29568/50000]\tLoss: 0.2423\tLR: 0.000337\nTraining Epoch: 24 [29696/50000]\tLoss: 0.3357\tLR: 0.000337\nTraining Epoch: 24 [29824/50000]\tLoss: 0.2578\tLR: 0.000337\nTraining Epoch: 24 [29952/50000]\tLoss: 0.2609\tLR: 0.000337\nTraining Epoch: 24 [30080/50000]\tLoss: 0.2413\tLR: 0.000337\nTraining Epoch: 24 [30208/50000]\tLoss: 0.2173\tLR: 0.000337\nTraining Epoch: 24 [30336/50000]\tLoss: 0.1578\tLR: 0.000337\nTraining Epoch: 24 [30464/50000]\tLoss: 0.1835\tLR: 0.000337\nTraining Epoch: 24 [30592/50000]\tLoss: 0.2734\tLR: 0.000337\nTraining Epoch: 24 [30720/50000]\tLoss: 0.2590\tLR: 0.000337\nTraining Epoch: 24 [30848/50000]\tLoss: 0.1700\tLR: 0.000337\nTraining Epoch: 24 [30976/50000]\tLoss: 0.2050\tLR: 0.000337\nTraining Epoch: 24 [31104/50000]\tLoss: 0.3183\tLR: 0.000337\nTraining Epoch: 24 [31232/50000]\tLoss: 0.2583\tLR: 0.000337\nTraining Epoch: 24 [31360/50000]\tLoss: 0.2374\tLR: 0.000337\nTraining Epoch: 24 [31488/50000]\tLoss: 0.3559\tLR: 0.000337\nTraining Epoch: 24 [31616/50000]\tLoss: 0.2734\tLR: 0.000337\nTraining Epoch: 24 [31744/50000]\tLoss: 0.2322\tLR: 0.000337\nTraining Epoch: 24 [31872/50000]\tLoss: 0.2503\tLR: 0.000337\nTraining Epoch: 24 [32000/50000]\tLoss: 0.1979\tLR: 0.000337\nTraining Epoch: 24 [32128/50000]\tLoss: 0.2548\tLR: 0.000337\nTraining Epoch: 24 [32256/50000]\tLoss: 0.3214\tLR: 0.000337\nTraining Epoch: 24 [32384/50000]\tLoss: 0.2393\tLR: 0.000337\nTraining Epoch: 24 [32512/50000]\tLoss: 0.3116\tLR: 0.000337\nTraining Epoch: 24 [32640/50000]\tLoss: 0.1993\tLR: 0.000337\nTraining Epoch: 24 [32768/50000]\tLoss: 0.2091\tLR: 0.000337\nTraining Epoch: 24 [32896/50000]\tLoss: 0.3530\tLR: 0.000337\nTraining Epoch: 24 [33024/50000]\tLoss: 0.2045\tLR: 0.000337\nTraining Epoch: 24 [33152/50000]\tLoss: 0.2271\tLR: 0.000337\nTraining Epoch: 24 [33280/50000]\tLoss: 0.2488\tLR: 0.000337\nTraining Epoch: 24 [33408/50000]\tLoss: 0.2917\tLR: 0.000337\nTraining Epoch: 24 [33536/50000]\tLoss: 0.2440\tLR: 0.000337\nTraining Epoch: 24 [33664/50000]\tLoss: 0.1224\tLR: 0.000337\nTraining Epoch: 24 [33792/50000]\tLoss: 0.2614\tLR: 0.000337\nTraining Epoch: 24 [33920/50000]\tLoss: 0.2939\tLR: 0.000337\nTraining Epoch: 24 [34048/50000]\tLoss: 0.2443\tLR: 0.000337\nTraining Epoch: 24 [34176/50000]\tLoss: 0.3109\tLR: 0.000337\nTraining Epoch: 24 [34304/50000]\tLoss: 0.3653\tLR: 0.000337\nTraining Epoch: 24 [34432/50000]\tLoss: 0.2786\tLR: 0.000337\nTraining Epoch: 24 [34560/50000]\tLoss: 0.2900\tLR: 0.000337\nTraining Epoch: 24 [34688/50000]\tLoss: 0.2093\tLR: 0.000337\nTraining Epoch: 24 [34816/50000]\tLoss: 0.3415\tLR: 0.000337\nTraining Epoch: 24 [34944/50000]\tLoss: 0.1762\tLR: 0.000337\nTraining Epoch: 24 [35072/50000]\tLoss: 0.2344\tLR: 0.000337\nTraining Epoch: 24 [35200/50000]\tLoss: 0.2256\tLR: 0.000337\nTraining Epoch: 24 [35328/50000]\tLoss: 0.2402\tLR: 0.000337\nTraining Epoch: 24 [35456/50000]\tLoss: 0.2452\tLR: 0.000337\nTraining Epoch: 24 [35584/50000]\tLoss: 0.3398\tLR: 0.000337\nTraining Epoch: 24 [35712/50000]\tLoss: 0.3067\tLR: 0.000337\nTraining Epoch: 24 [35840/50000]\tLoss: 0.3612\tLR: 0.000337\nTraining Epoch: 24 [35968/50000]\tLoss: 0.3101\tLR: 0.000337\nTraining Epoch: 24 [36096/50000]\tLoss: 0.3500\tLR: 0.000337\nTraining Epoch: 24 [36224/50000]\tLoss: 0.3086\tLR: 0.000337\nTraining Epoch: 24 [36352/50000]\tLoss: 0.3777\tLR: 0.000337\nTraining Epoch: 24 [36480/50000]\tLoss: 0.2783\tLR: 0.000337\nTraining Epoch: 24 [36608/50000]\tLoss: 0.1860\tLR: 0.000337\nTraining Epoch: 24 [36736/50000]\tLoss: 0.1991\tLR: 0.000337\nTraining Epoch: 24 [36864/50000]\tLoss: 0.2620\tLR: 0.000337\nTraining Epoch: 24 [36992/50000]\tLoss: 0.1705\tLR: 0.000337\nTraining Epoch: 24 [37120/50000]\tLoss: 0.2994\tLR: 0.000337\nTraining Epoch: 24 [37248/50000]\tLoss: 0.3333\tLR: 0.000337\nTraining Epoch: 24 [37376/50000]\tLoss: 0.1754\tLR: 0.000337\nTraining Epoch: 24 [37504/50000]\tLoss: 0.2198\tLR: 0.000337\nTraining Epoch: 24 [37632/50000]\tLoss: 0.1940\tLR: 0.000337\nTraining Epoch: 24 [37760/50000]\tLoss: 0.3194\tLR: 0.000337\nTraining Epoch: 24 [37888/50000]\tLoss: 0.2578\tLR: 0.000337\nTraining Epoch: 24 [38016/50000]\tLoss: 0.2667\tLR: 0.000337\nTraining Epoch: 24 [38144/50000]\tLoss: 0.2607\tLR: 0.000337\nTraining Epoch: 24 [38272/50000]\tLoss: 0.2423\tLR: 0.000337\nTraining Epoch: 24 [38400/50000]\tLoss: 0.2440\tLR: 0.000337\nTraining Epoch: 24 [38528/50000]\tLoss: 0.3259\tLR: 0.000337\nTraining Epoch: 24 [38656/50000]\tLoss: 0.2302\tLR: 0.000337\nTraining Epoch: 24 [38784/50000]\tLoss: 0.2432\tLR: 0.000337\nTraining Epoch: 24 [38912/50000]\tLoss: 0.2418\tLR: 0.000337\nTraining Epoch: 24 [39040/50000]\tLoss: 0.2762\tLR: 0.000337\nTraining Epoch: 24 [39168/50000]\tLoss: 0.1843\tLR: 0.000337\nTraining Epoch: 24 [39296/50000]\tLoss: 0.3396\tLR: 0.000337\nTraining Epoch: 24 [39424/50000]\tLoss: 0.4322\tLR: 0.000337\nTraining Epoch: 24 [39552/50000]\tLoss: 0.2436\tLR: 0.000337\nTraining Epoch: 24 [39680/50000]\tLoss: 0.1758\tLR: 0.000337\nTraining Epoch: 24 [39808/50000]\tLoss: 0.2875\tLR: 0.000337\nTraining Epoch: 24 [39936/50000]\tLoss: 0.2538\tLR: 0.000337\nTraining Epoch: 24 [40064/50000]\tLoss: 0.3225\tLR: 0.000337\nTraining Epoch: 24 [40192/50000]\tLoss: 0.2465\tLR: 0.000337\nTraining Epoch: 24 [40320/50000]\tLoss: 0.2561\tLR: 0.000337\nTraining Epoch: 24 [40448/50000]\tLoss: 0.2763\tLR: 0.000337\nTraining Epoch: 24 [40576/50000]\tLoss: 0.2842\tLR: 0.000337\nTraining Epoch: 24 [40704/50000]\tLoss: 0.3273\tLR: 0.000337\nTraining Epoch: 24 [40832/50000]\tLoss: 0.2672\tLR: 0.000337\nTraining Epoch: 24 [40960/50000]\tLoss: 0.3681\tLR: 0.000337\nTraining Epoch: 24 [41088/50000]\tLoss: 0.2882\tLR: 0.000337\nTraining Epoch: 24 [41216/50000]\tLoss: 0.2855\tLR: 0.000337\nTraining Epoch: 24 [41344/50000]\tLoss: 0.2771\tLR: 0.000337\nTraining Epoch: 24 [41472/50000]\tLoss: 0.2770\tLR: 0.000337\nTraining Epoch: 24 [41600/50000]\tLoss: 0.2740\tLR: 0.000337\nTraining Epoch: 24 [41728/50000]\tLoss: 0.2262\tLR: 0.000337\nTraining Epoch: 24 [41856/50000]\tLoss: 0.2274\tLR: 0.000337\nTraining Epoch: 24 [41984/50000]\tLoss: 0.2452\tLR: 0.000337\nTraining Epoch: 24 [42112/50000]\tLoss: 0.2990\tLR: 0.000337\nTraining Epoch: 24 [42240/50000]\tLoss: 0.4152\tLR: 0.000337\nTraining Epoch: 24 [42368/50000]\tLoss: 0.2065\tLR: 0.000337\nTraining Epoch: 24 [42496/50000]\tLoss: 0.2064\tLR: 0.000337\nTraining Epoch: 24 [42624/50000]\tLoss: 0.2540\tLR: 0.000337\nTraining Epoch: 24 [42752/50000]\tLoss: 0.2352\tLR: 0.000337\nTraining Epoch: 24 [42880/50000]\tLoss: 0.3163\tLR: 0.000337\nTraining Epoch: 24 [43008/50000]\tLoss: 0.2841\tLR: 0.000337\nTraining Epoch: 24 [43136/50000]\tLoss: 0.2776\tLR: 0.000337\nTraining Epoch: 24 [43264/50000]\tLoss: 0.3421\tLR: 0.000337\nTraining Epoch: 24 [43392/50000]\tLoss: 0.3130\tLR: 0.000337\nTraining Epoch: 24 [43520/50000]\tLoss: 0.2310\tLR: 0.000337\nTraining Epoch: 24 [43648/50000]\tLoss: 0.2544\tLR: 0.000337\nTraining Epoch: 24 [43776/50000]\tLoss: 0.3005\tLR: 0.000337\nTraining Epoch: 24 [43904/50000]\tLoss: 0.2866\tLR: 0.000337\nTraining Epoch: 24 [44032/50000]\tLoss: 0.3486\tLR: 0.000337\nTraining Epoch: 24 [44160/50000]\tLoss: 0.3072\tLR: 0.000337\nTraining Epoch: 24 [44288/50000]\tLoss: 0.2682\tLR: 0.000337\nTraining Epoch: 24 [44416/50000]\tLoss: 0.2314\tLR: 0.000337\nTraining Epoch: 24 [44544/50000]\tLoss: 0.2857\tLR: 0.000337\nTraining Epoch: 24 [44672/50000]\tLoss: 0.2008\tLR: 0.000337\nTraining Epoch: 24 [44800/50000]\tLoss: 0.2205\tLR: 0.000337\nTraining Epoch: 24 [44928/50000]\tLoss: 0.3238\tLR: 0.000337\nTraining Epoch: 24 [45056/50000]\tLoss: 0.2215\tLR: 0.000337\nTraining Epoch: 24 [45184/50000]\tLoss: 0.1754\tLR: 0.000337\nTraining Epoch: 24 [45312/50000]\tLoss: 0.2689\tLR: 0.000337\nTraining Epoch: 24 [45440/50000]\tLoss: 0.2265\tLR: 0.000337\nTraining Epoch: 24 [45568/50000]\tLoss: 0.2539\tLR: 0.000337\nTraining Epoch: 24 [45696/50000]\tLoss: 0.2926\tLR: 0.000337\nTraining Epoch: 24 [45824/50000]\tLoss: 0.2566\tLR: 0.000337\nTraining Epoch: 24 [45952/50000]\tLoss: 0.2680\tLR: 0.000337\nTraining Epoch: 24 [46080/50000]\tLoss: 0.2248\tLR: 0.000337\nTraining Epoch: 24 [46208/50000]\tLoss: 0.2096\tLR: 0.000337\nTraining Epoch: 24 [46336/50000]\tLoss: 0.2207\tLR: 0.000337\nTraining Epoch: 24 [46464/50000]\tLoss: 0.2866\tLR: 0.000337\nTraining Epoch: 24 [46592/50000]\tLoss: 0.2604\tLR: 0.000337\nTraining Epoch: 24 [46720/50000]\tLoss: 0.2913\tLR: 0.000337\nTraining Epoch: 24 [46848/50000]\tLoss: 0.2452\tLR: 0.000337\nTraining Epoch: 24 [46976/50000]\tLoss: 0.2230\tLR: 0.000337\nTraining Epoch: 24 [47104/50000]\tLoss: 0.3277\tLR: 0.000337\nTraining Epoch: 24 [47232/50000]\tLoss: 0.2754\tLR: 0.000337\nTraining Epoch: 24 [47360/50000]\tLoss: 0.2305\tLR: 0.000337\nTraining Epoch: 24 [47488/50000]\tLoss: 0.2261\tLR: 0.000337\nTraining Epoch: 24 [47616/50000]\tLoss: 0.1445\tLR: 0.000337\nTraining Epoch: 24 [47744/50000]\tLoss: 0.2048\tLR: 0.000337\nTraining Epoch: 24 [47872/50000]\tLoss: 0.2168\tLR: 0.000337\nTraining Epoch: 24 [48000/50000]\tLoss: 0.2889\tLR: 0.000337\nTraining Epoch: 24 [48128/50000]\tLoss: 0.3028\tLR: 0.000337\nTraining Epoch: 24 [48256/50000]\tLoss: 0.2893\tLR: 0.000337\nTraining Epoch: 24 [48384/50000]\tLoss: 0.2755\tLR: 0.000337\nTraining Epoch: 24 [48512/50000]\tLoss: 0.3578\tLR: 0.000337\nTraining Epoch: 24 [48640/50000]\tLoss: 0.3243\tLR: 0.000337\nTraining Epoch: 24 [48768/50000]\tLoss: 0.2420\tLR: 0.000337\nTraining Epoch: 24 [48896/50000]\tLoss: 0.2989\tLR: 0.000337\nTraining Epoch: 24 [49024/50000]\tLoss: 0.2128\tLR: 0.000337\nTraining Epoch: 24 [49152/50000]\tLoss: 0.3031\tLR: 0.000337\nTraining Epoch: 24 [49280/50000]\tLoss: 0.2102\tLR: 0.000337\nTraining Epoch: 24 [49408/50000]\tLoss: 0.2763\tLR: 0.000337\nTraining Epoch: 24 [49536/50000]\tLoss: 0.2635\tLR: 0.000337\nTraining Epoch: 24 [49664/50000]\tLoss: 0.2164\tLR: 0.000337\nTraining Epoch: 24 [49792/50000]\tLoss: 0.2547\tLR: 0.000337\nTraining Epoch: 24 [49920/50000]\tLoss: 0.3292\tLR: 0.000337\nTraining Epoch: 24 [50000/50000]\tLoss: 0.3046\tLR: 0.000337\nTest set: Average loss: 0.0025, Accuracy: 0.8934\n\n\nbest_acc:  tensor(0.8942, device='cuda:0')\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Testing the Model\n","metadata":{}},{"cell_type":"code","source":"weights_file=\"./resnet18.pth\"\ntorch.save(net.state_dict(), weights_file)","metadata":{"execution":{"iopub.status.busy":"2024-03-28T23:43:27.733077Z","iopub.execute_input":"2024-03-28T23:43:27.733417Z","iopub.status.idle":"2024-03-28T23:43:27.822037Z","shell.execute_reply.started":"2024-03-28T23:43:27.733384Z","shell.execute_reply":"2024-03-28T23:43:27.821280Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"if __name__ == '__main__':\n    net = get_network()\n    CIFAR10_test_loader = get_test_dataloader(\n        CIFAR10_TRAIN_MEAN,\n        CIFAR10_TRAIN_STD,\n        #CIFAR10_PATH,\n        num_workers=2,\n        batch_size=128,\n        shuffle=True\n    )\n\n    net.load_state_dict(torch.load(weights_file), True)\n    print(net)\n    net.eval()\n\n    correct_1 = 0.0\n    correct_5 = 0.0\n    total = 0\n\n    for n_iter, (image, label) in enumerate(CIFAR10_test_loader):\n        print(\"iteration: {}\\ttotal {} iterations\".format(n_iter + 1, len(CIFAR10_test_loader)))\n        image = Variable(image).cuda()\n        label = Variable(label).cuda()\n        output = net(image)\n        _, pred = output.topk(5, 1, largest=True, sorted=True)\n\n        label = label.view(label.size(0), -1).expand_as(pred)\n        correct = pred.eq(label).float()\n\n        #compute top 5\n        correct_5 += correct[:, :5].sum()\n\n        #compute top1 \n        correct_1 += correct[:, :1].sum()\n\n\n    print()\n    print(\"Top 1 err: \", 1 - correct_1 / len(CIFAR10_test_loader.dataset))\n    print(\"Top 5 err: \", 1 - correct_5 / len(CIFAR10_test_loader.dataset))\n    print(\"Parameter numbers: {}\".format(sum(p.numel() for p in net.parameters())))","metadata":{"execution":{"iopub.status.busy":"2024-03-28T23:43:27.823151Z","iopub.execute_input":"2024-03-28T23:43:27.823450Z","iopub.status.idle":"2024-03-28T23:43:31.332257Z","shell.execute_reply.started":"2024-03-28T23:43:27.823424Z","shell.execute_reply":"2024-03-28T23:43:31.331214Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Files already downloaded and verified\nResNet(\n  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (layer1): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (shortcut): Sequential()\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (shortcut): Sequential()\n    )\n  )\n  (layer2): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (shortcut): Sequential(\n        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (shortcut): Sequential()\n    )\n  )\n  (layer3): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (shortcut): Sequential(\n        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (shortcut): Sequential()\n    )\n  )\n  (layer4): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (shortcut): Sequential(\n        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (shortcut): Sequential()\n    )\n  )\n  (linear): Linear(in_features=512, out_features=10, bias=True)\n)\niteration: 1\ttotal 79 iterations\niteration: 2\ttotal 79 iterations\niteration: 3\ttotal 79 iterations\niteration: 4\ttotal 79 iterations\niteration: 5\ttotal 79 iterations\niteration: 6\ttotal 79 iterations\niteration: 7\ttotal 79 iterations\niteration: 8\ttotal 79 iterations\niteration: 9\ttotal 79 iterations\niteration: 10\ttotal 79 iterations\niteration: 11\ttotal 79 iterations\niteration: 12\ttotal 79 iterations\niteration: 13\ttotal 79 iterations\niteration: 14\ttotal 79 iterations\niteration: 15\ttotal 79 iterations\niteration: 16\ttotal 79 iterations\niteration: 17\ttotal 79 iterations\niteration: 18\ttotal 79 iterations\niteration: 19\ttotal 79 iterations\niteration: 20\ttotal 79 iterations\niteration: 21\ttotal 79 iterations\niteration: 22\ttotal 79 iterations\niteration: 23\ttotal 79 iterations\niteration: 24\ttotal 79 iterations\niteration: 25\ttotal 79 iterations\niteration: 26\ttotal 79 iterations\niteration: 27\ttotal 79 iterations\niteration: 28\ttotal 79 iterations\niteration: 29\ttotal 79 iterations\niteration: 30\ttotal 79 iterations\niteration: 31\ttotal 79 iterations\niteration: 32\ttotal 79 iterations\niteration: 33\ttotal 79 iterations\niteration: 34\ttotal 79 iterations\niteration: 35\ttotal 79 iterations\niteration: 36\ttotal 79 iterations\niteration: 37\ttotal 79 iterations\niteration: 38\ttotal 79 iterations\niteration: 39\ttotal 79 iterations\niteration: 40\ttotal 79 iterations\niteration: 41\ttotal 79 iterations\niteration: 42\ttotal 79 iterations\niteration: 43\ttotal 79 iterations\niteration: 44\ttotal 79 iterations\niteration: 45\ttotal 79 iterations\niteration: 46\ttotal 79 iterations\niteration: 47\ttotal 79 iterations\niteration: 48\ttotal 79 iterations\niteration: 49\ttotal 79 iterations\niteration: 50\ttotal 79 iterations\niteration: 51\ttotal 79 iterations\niteration: 52\ttotal 79 iterations\niteration: 53\ttotal 79 iterations\niteration: 54\ttotal 79 iterations\niteration: 55\ttotal 79 iterations\niteration: 56\ttotal 79 iterations\niteration: 57\ttotal 79 iterations\niteration: 58\ttotal 79 iterations\niteration: 59\ttotal 79 iterations\niteration: 60\ttotal 79 iterations\niteration: 61\ttotal 79 iterations\niteration: 62\ttotal 79 iterations\niteration: 63\ttotal 79 iterations\niteration: 64\ttotal 79 iterations\niteration: 65\ttotal 79 iterations\niteration: 66\ttotal 79 iterations\niteration: 67\ttotal 79 iterations\niteration: 68\ttotal 79 iterations\niteration: 69\ttotal 79 iterations\niteration: 70\ttotal 79 iterations\niteration: 71\ttotal 79 iterations\niteration: 72\ttotal 79 iterations\niteration: 73\ttotal 79 iterations\niteration: 74\ttotal 79 iterations\niteration: 75\ttotal 79 iterations\niteration: 76\ttotal 79 iterations\niteration: 77\ttotal 79 iterations\niteration: 78\ttotal 79 iterations\niteration: 79\ttotal 79 iterations\n\nTop 1 err:  tensor(0.1066, device='cuda:0')\nTop 5 err:  tensor(0.0034, device='cuda:0')\nParameter numbers: 11173962\n","output_type":"stream"}]}]}